{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ybXGtqNVD2U5",
        "6JEOWtW9T0-m",
        "w4BQ3F6wT_QT",
        "WCP4acTg0dlO"
      ],
      "authorship_tag": "ABX9TyOcf6+N4rrDPD5GvyOu2BhT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX7000/deep-learning-with-python/blob/main/DeepLearning_with_Python_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning with Neaural Networks from the book 'Deep Learning with Python', Part 1, Francois Chollet"
      ],
      "metadata": {
        "id": "UyI5AtRpc4xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1. Classify grayscale images(28x28) of handwritten digits from mnist dataset into 10 categories"
      ],
      "metadata": {
        "id": "MFz5awredGSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a multi-class Classification problem"
      ],
      "metadata": {
        "id": "1WqEJyKNWUte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand what you really have"
      ],
      "metadata": {
        "id": "uGJrI8r7Wayt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9pHWjjhWgm9",
        "outputId": "3d02550a-349b-48f7-e827-c5500e0c9d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "X_train: (60000, 28, 28)\n",
            "y_train: (60000,)\n",
            "X_test: (10000, 28, 28)\n",
            "y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# import the data\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(f'X_train: {train_images.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_images.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pre-process the data: preparing/bringing it to the right form to feed our NN"
      ],
      "metadata": {
        "id": "9NZ9CwrW8DDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorization, value Normalization, handling missing values, feature engineering to name but a few of the steps you need to do during pre-processing of your data!"
      ],
      "metadata": {
        "id": "GbhytbFuXcL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's visualize some examples to see what we have here\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_images[10], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qRRLzG8VNTz1",
        "outputId": "89dfd9ac-f0c9-4f1c-c522-caa06788e02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_images[10], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "t4g_B296PIWs",
        "outputId": "93cb7e61-1ace-4902-b428-f12f23118596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many times in which we need to shuffle the dataset before split it to train and test sets. This is because of data representativeness(more @page100). This is a step during feature engineering like for example feature redundancy you need to do every time you pre-process the data"
      ],
      "metadata": {
        "id": "XSXLl-S2WjLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we have 60000 examples(images) that are 28x28 each (on greyscale) and they are all filled with numbers between 0-255(the higher the number is the more grey the image is)\n",
        "# so, we transform these images in an array of (60000, 28x28) with values between 0 and 1\n",
        "# and we we actually have 60000 examples of 28*28 length each with values between 0 and 1\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "jQQQ71ZFmVLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot representation for train and test labels. As we have 10 classes to predict as output(output is a number between 0-9 representing the digits)\n",
        "# we transform the output values from 0-9 to 0-1 one-hot representation\n",
        "\n",
        "print(f'10th element of train_labels before one-hot: {train_labels[10]}')\n",
        "\n",
        "# one-hot encoding for output labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(f'10th element of train_labels after one-hot: {train_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzI-eHCI4bQV",
        "outputId": "ff4bebe7-6dde-4cf0-bc25-a8457b708722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10th element of train_labels before one-hot: 3\n",
            "10th element of train_labels after one-hot: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the new dimensions now\n",
        "print(f'X_train: {train_images.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_images.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fopOLZFP_Jpk",
        "outputId": "5284bd8b-9dd2-4c99-ec05-511df5b71576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (60000, 784)\n",
            "y_train: (60000, 10)\n",
            "X_test: (10000, 784)\n",
            "y_test: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define and train the model "
      ],
      "metadata": {
        "id": "nG_-YS1n8ej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the aproppriate modules\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# network's architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# compilation step\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128) \n",
        "\n",
        "# deep learning models don't process an entire dataset at once! they break the data into small batches=> computationaly cheaper\n",
        "# so batch_size=128 means: 1st batch=train_images[:128], 2nd batch: train_images[128:256], ...train_images[128*n:128*(n+1)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcybQF6nuqEP",
        "outputId": "9b354be9-e071-4115-e185-c28fcf34ad30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.2597 - accuracy: 0.9249\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.1040 - accuracy: 0.9689\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 0.0681 - accuracy: 0.9791\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.0499 - accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0369 - accuracy: 0.9891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38baf1f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some model's info\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9urxNtynCVS-",
        "outputId": "2240c1a7-bbb0-42a3-be51-d5d1dbe60c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Predict and evaluate the model"
      ],
      "metadata": {
        "id": "qSs0VzpI-y5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "# returns a 10-element for each example with the highest probability in the index which represents a digit\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "print(f'\\n the digit-prediction for the first element of test_labels is: {predictions[10]}\\n')\n",
        "print(f'the actual-digit of the first element of test_labels is: {test_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zC1RxAb7StG",
        "outputId": "f462de09-899d-4a59-be28-1bb3e2b676f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "\n",
            " the digit-prediction for the first element of test_labels is: [9.99998868e-01 5.26618976e-15 6.61115791e-07 1.34554956e-09\n",
            " 1.17183424e-11 6.06490502e-09 1.03153344e-08 1.62709540e-07\n",
            " 7.32354177e-10 1.84800072e-07]\n",
            "\n",
            "the actual-digit of the first element of test_labels is: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f'the loss of the model is: {test_loss}')\n",
        "print(f'the accuracy of the model is: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blmX0emYtWtG",
        "outputId": "fabb6b1d-76ea-4ed0-c46f-13a67a0854b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0725 - accuracy: 0.9786\n",
            "the loss of the model is: 0.07252959907054901\n",
            "the accuracy of the model is: 0.978600025177002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2. Tensors: the inputs of NNs"
      ],
      "metadata": {
        "id": "ybXGtqNVD2U5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks take as inputs Tensors. Tensor is a generalization of matrices to a number of dimensions. \n",
        "Each tensor has 3 attributes: 1) the rank: number of axis(dimensions), 2) the shape: how many dimensions the tensor has along each axis and 3) data type: the type of the data contained in the tensor "
      ],
      "metadata": {
        "id": "z6Nm611fFcf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "l0UiQntBG3lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar(0D-tensor): rank-0 tensor \n",
        "x=np.array(12)\n",
        "print(x)       \n",
        "\n",
        "# ndim gives us the axis(=>dimension) of the tensor\n",
        "print(x.ndim)"
      ],
      "metadata": {
        "id": "bck-bYz3IZug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940fcf1a-2807-422c-fd52-5b908bc59233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector(1D-tensor): rank-1 tensor \n",
        "x1 = np.array([12, 3, 6, 14, 7])\n",
        "print(x1)\n",
        "\n",
        "print(f'the rank of the tensor is: {x1.ndim}')\n",
        "print(f'the shape of the tensor is: {x1.shape}') \n",
        "print(f'the data type of the tensor is: {x1.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNMN4RYAGmOH",
        "outputId": "1637ecb4-ccd5-4988-a5c9-65c3f8137f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12  3  6 14  7]\n",
            "the rank of the tensor is: 1\n",
            "the shape of the tensor is: (5,)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(2D-tensor): rank-2 tensor\n",
        "x2 = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "print(x2)\n",
        "\n",
        "print(f'the rank of the tensor is: {x2.ndim}')\n",
        "print(f'the shape of the tensor is: {x2.shape}') \n",
        "print(f'the data type of the tensor is: {x2.dtype}')"
      ],
      "metadata": {
        "id": "6FZP3K08IZr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0ee6b5-4045-404c-a700-6bfeb0f987c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n",
            "the rank of the tensor is: 2\n",
            "the shape of the tensor is: (3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(3D-tensor): rank-3 tensor\n",
        "x3 = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "print(x3)\n",
        "\n",
        "print(f'the rank of the tensor is: {x3.ndim}')\n",
        "print(f'the shape of the tensor is: {x3.shape}') # the shape of the tensor is the shape of each axis of the tensor\n",
        "print(f'the data type of the tensor is: {x3.dtype}')"
      ],
      "metadata": {
        "id": "jICHuBZJIZpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e779cb9-6356-435d-a6f3-e922f063476b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]]\n",
            "the rank of the tensor is: 3\n",
            "the shape of the tensor is: (3, 3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(4D-tensor): rank-4 tensor, the same happens to all higher rank tensors\n",
        "x4 = np.array([\n",
        "    [\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "    ],\n",
        "    [\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],  \n",
        "    ]\n",
        "   ])\n",
        "print(x4)\n",
        "\n",
        "print(f'the rank of the tensor is: {x4.ndim}')\n",
        "print(f'the shape of the tensor is: {x4.shape}') # the shape of the tensor is the shape of each axis of the tensor\n",
        "print(f'the data type of the tensor is: {x4.dtype}')"
      ],
      "metadata": {
        "id": "gF0mLMIyIZgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff53359a-d4b2-45fb-8cc8-839004f90fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]]\n",
            "\n",
            "\n",
            " [[[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]]]\n",
            "the rank of the tensor is: 4\n",
            "the shape of the tensor is: (2, 3, 3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 types of operations between tensors: 1) element-wise operations, 2) dot product and 3) reshaping"
      ],
      "metadata": {
        "id": "vocbHZAHcKwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# broadcasting: the smaller tensor will be broadcasted to match the shape of the larger tensor when applying two tensor element-wise operations\n",
        "z1 = np.maximum(x4, x3)\n",
        "z2 = np.minimum(x4, x2)\n",
        "z3 = np.maximum(x3, x2)\n",
        "z4 = np.maximum(x4, x1)"
      ],
      "metadata": {
        "id": "4vOP0LmAZlsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 3. Classifying movie reviews, based on text content, into positive or negative"
      ],
      "metadata": {
        "id": "6JEOWtW9T0-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a Binary Classification problem"
      ],
      "metadata": {
        "id": "CX_jHucQWDBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand it"
      ],
      "metadata": {
        "id": "d7Muxn2qEwXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data\n",
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # num_words=10000 means that we only keep the top 10000 most frequently occuring words in the training data\n",
        " \n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bN_XeAFT4Yj",
        "outputId": "8917997b-7f2c-443c-add6-1a30e8c08a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "X_train: (25000,)\n",
            "y_train: (25000,)\n",
            "X_test: (25000,)\n",
            "y_test: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV88-WY2ksTq",
        "outputId": "66a38f5b-f3e2-4b80-d599-57b61bf6dc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [1, 785, 189, 438, 47, 110, 142, 7, 6, 7475, 120, 4, 236, 378, 7, 153, 19, 87, 108, 141, 17, 1004, 5, 2, 883, 2, 23, 8, 4, 136, 2, 2, 4, 7475, 43, 1076, 21, 1407, 419, 5, 5202, 120, 91, 682, 189, 2818, 5, 9, 1348, 31, 7, 4, 118, 785, 189, 108, 126, 93, 2, 16, 540, 324, 23, 6, 364, 352, 21, 14, 9, 93, 56, 18, 11, 230, 53, 771, 74, 31, 34, 4, 2834, 7, 4, 22, 5, 14, 11, 471, 9, 2, 34, 4, 321, 487, 5, 116, 15, 6584, 4, 22, 9, 6, 2286, 4, 114, 2679, 23, 107, 293, 1008, 1172, 5, 328, 1236, 4, 1375, 109, 9, 6, 132, 773, 2, 1412, 8, 1172, 18, 7865, 29, 9, 276, 11, 6, 2768, 19, 289, 409, 4, 5341, 2140, 2, 648, 1430, 2, 8914, 5, 27, 3000, 1432, 7130, 103, 6, 346, 137, 11, 4, 2768, 295, 36, 7740, 725, 6, 3208, 273, 11, 4, 1513, 15, 1367, 35, 154, 2, 103, 2, 173, 7, 12, 36, 515, 3547, 94, 2547, 1722, 5, 3547, 36, 203, 30, 502, 8, 361, 12, 8, 989, 143, 4, 1172, 3404, 10, 10, 328, 1236, 9, 6, 55, 221, 2989, 5, 146, 165, 179, 770, 15, 50, 713, 53, 108, 448, 23, 12, 17, 225, 38, 76, 4397, 18, 183, 8, 81, 19, 12, 45, 1257, 8, 135, 15, 2, 166, 4, 118, 7, 45, 2, 17, 466, 45, 2, 4, 22, 115, 165, 764, 6075, 5, 1030, 8, 2973, 73, 469, 167, 2127, 2, 1568, 6, 87, 841, 18, 4, 22, 4, 192, 15, 91, 7, 12, 304, 273, 1004, 4, 1375, 1172, 2768, 2, 15, 4, 22, 764, 55, 5773, 5, 14, 4233, 7444, 4, 1375, 326, 7, 4, 4760, 1786, 8, 361, 1236, 8, 989, 46, 7, 4, 2768, 45, 55, 776, 8, 79, 496, 98, 45, 400, 301, 15, 4, 1859, 9, 4, 155, 15, 66, 2, 84, 5, 14, 22, 1534, 15, 17, 4, 167, 2, 15, 75, 70, 115, 66, 30, 252, 7, 618, 51, 9, 2161, 4, 3130, 5, 14, 1525, 8, 6584, 15, 2, 165, 127, 1921, 8, 30, 179, 2532, 4, 22, 9, 906, 18, 6, 176, 7, 1007, 1005, 4, 1375, 114, 4, 105, 26, 32, 55, 221, 11, 68, 205, 96, 5, 4, 192, 15, 4, 274, 410, 220, 304, 23, 94, 205, 109, 9, 55, 73, 224, 259, 3786, 15, 4, 22, 528, 1645, 34, 4, 130, 528, 30, 685, 345, 17, 4, 277, 199, 166, 281, 5, 1030, 8, 30, 179, 4442, 444, 2, 9, 6, 371, 87, 189, 22, 5, 31, 7, 4, 118, 7, 4, 2068, 545, 1178, 829]\n",
            "length of 11th example of train_data: 450\n",
            "the label of 11th example of train_labels: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process the data: preparing/bringing it to the right form to feed our NN"
      ],
      "metadata": {
        "id": "bD-h0iUdnddW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our train/test data here is comprised of examples(rows) of text reviews that are represented by a list of 450 integers(integers are the indexes of the word in the 10000 corpus we took from imbd database).\n",
        "We can't feed a NN with lists of integers. we need to turn them into Tensors. 2 ways to do that: a) word embedding and b) one-hot encoding to turn integer lists to vectors of 0s and 1s"
      ],
      "metadata": {
        "id": "JeD6aTZ5tH5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the integer sequences via multi-hot encoding for train and test data: each example now is a 10000 sequence\n",
        "# if a word is on corpus of 10000, then 1 is representing the index of that word in the corpus. if a word is not in the corpus, we put 0 \n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "# vectorize the labels   \n",
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "0jY72gmRlwXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train after preprocessing: {x_train.shape}')\n",
        "print(f'y_train after preprocessing: {y_train.shape}')\n",
        "print(f'X_test after preprocessing: {x_test.shape}')\n",
        "print(f'y_test after preprocessing: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y-HyQnCu4hY",
        "outputId": "76d4ac88-ca0e-438a-e847-5cc963718c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train after preprocessing: (25000, 10000)\n",
            "y_train after preprocessing: (25000,)\n",
            "X_test after preprocessing: (25000, 10000)\n",
            "y_test after preprocessing: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'length of 11th example of train_data after preprocessing: {x_train[10].shape}')\n",
        "print(f'11th example of train_data after preprocessing:\\n {x_train[10]}')\n",
        "print(f'the label of 11th example of train_labels after preprocessing: {y_train[10]}')\n",
        "\n",
        "print(f'\\n11th example of x_test after preprocessing:\\n {x_test[10]}')\n",
        "print(f'the label of 11th example of test_labels after preprocessing: {y_test[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbfLpf4KuML7",
        "outputId": "bb324532-9ae2-456d-d470-9014de5f364f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of 11th example of train_data after preprocessing: (10000,)\n",
            "11th example of train_data after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of train_labels after preprocessing: 1.0\n",
            "\n",
            "11th example of x_test after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of test_labels after preprocessing: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define, compile and train the Neaural Network"
      ],
      "metadata": {
        "id": "Z-pcxBOZ63xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every model is not the best initially and always needs improvements through hyperparameter tuning process for example. So, always create a validation set to test the model and when find the best hyperparameters, train the final model on test set. We can also try several models and compare them in the validation set in order to choose the best one, and when this is done, we evaluate the chosen model on the test set. 3 ways to create a validation set: 1) simple hold-out validation, 2) K-fold validation and 3) iterated K-fold validation with shuffling(more @page98)"
      ],
      "metadata": {
        "id": "YTXEU_w3V5TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# training the model\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=512)\n",
        "\n",
        "# (also in order to monitor during the training the accuracy of the model on data it has never seen before, let's create a validation set) \n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]\n",
        "\n",
        "# training the model by monitoring how the model performs on unseen data\n",
        "print('\\n\\ntraining with validation ...\\n')\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=9,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd-pKZHpvFf-",
        "outputId": "54f66e78-6d79-4bbb-9f26-c8d937d0e7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/5\n",
            "49/49 [==============================] - 3s 33ms/step - loss: 0.4345 - accuracy: 0.8219\n",
            "Epoch 2/5\n",
            "49/49 [==============================] - 4s 75ms/step - loss: 0.2493 - accuracy: 0.9106\n",
            "Epoch 3/5\n",
            "49/49 [==============================] - 4s 81ms/step - loss: 0.1966 - accuracy: 0.9278\n",
            "Epoch 4/5\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.1633 - accuracy: 0.9412\n",
            "Epoch 5/5\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.1413 - accuracy: 0.9491\n",
            "\n",
            "\n",
            "training with validation ...\n",
            "\n",
            "Epoch 1/9\n",
            "47/47 [==============================] - 2s 49ms/step - loss: 0.1245 - accuracy: 0.9568 - val_loss: 0.1150 - val_accuracy: 0.9590\n",
            "Epoch 2/9\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 0.1093 - accuracy: 0.9627 - val_loss: 0.1364 - val_accuracy: 0.9480\n",
            "Epoch 3/9\n",
            "47/47 [==============================] - 3s 66ms/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 0.1638 - val_accuracy: 0.9370\n",
            "Epoch 4/9\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 0.0843 - accuracy: 0.9726 - val_loss: 0.1890 - val_accuracy: 0.9260\n",
            "Epoch 5/9\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 0.0763 - accuracy: 0.9743 - val_loss: 0.1984 - val_accuracy: 0.9220\n",
            "Epoch 6/9\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.2232 - val_accuracy: 0.9220\n",
            "Epoch 7/9\n",
            "47/47 [==============================] - 2s 39ms/step - loss: 0.0581 - accuracy: 0.9821 - val_loss: 0.2595 - val_accuracy: 0.9040\n",
            "Epoch 8/9\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.2826 - val_accuracy: 0.9070\n",
            "Epoch 9/9\n",
            "47/47 [==============================] - 2s 52ms/step - loss: 0.0458 - accuracy: 0.9859 - val_loss: 0.3195 - val_accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some model's info\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gxO7x_-5E5C",
        "outputId": "d4094152-274f-4c13-abe7-e723ecf8443f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 16)                160016    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,305\n",
            "Trainable params: 160,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.fit returns a History object, which is a dictionary cantaining data about everything happened during training. Dictionary's elements are all metrics which were being monitored during training"
      ],
      "metadata": {
        "id": "E8LwfR9x8FZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in our case history includes data for loss, accuracy, val_loss and val_accuracy\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aYW1O6s6-H3",
        "outputId": "a46f7d9f-87a4-454b-af27-a61ff276777e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss and accuracy of the model "
      ],
      "metadata": {
        "id": "tevw8HEB9lEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Asy-Bh-f6-CD",
        "outputId": "cafa3286-d4ad-445a-dfd3-338cee06a60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we can see, this is an example of overfitting(high variance): our model can't generalize on new, unseen data"
      ],
      "metadata": {
        "id": "kh2NCTdn-UmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "psbvFM0q-DR7",
        "outputId": "19d3aaca-5de6-4d66-c218-741756e1e8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model and improve it"
      ],
      "metadata": {
        "id": "XGSzBaH-SQm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "after the 3rd epoch, our model is getting worse in performance, so it needs several improvement steps. Hyperparameter Tuning is a process that helps us make our model better. We can try to add more hidden layers or more units to them, try different loss function where is applicable, try different activation function, try also different numbers of epochs, batch_size, and generally tune all the hyperparameters of the model(we call parameters of the model its weights and bs)"
      ],
      "metadata": {
        "id": "LD0yHPLBMU-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our case here, we just limit our model to 4 epochs(early stop point), as after that it is getting worse. The new model is just the old model trained for 4 epochs! This is what we call manually early stopping"
      ],
      "metadata": {
        "id": "eLXhb6yqNJxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the below cell, only and only if the above model is your final model! Don't forget it, because now, during this proces, it is not needed to do it, as we first need to choose the right model and then evaluate on the test set"
      ],
      "metadata": {
        "id": "MzIwyuj0wfiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model on the test set\n",
        "#results = model.evaluate(x_test, y_test)\n",
        "#results"
      ],
      "metadata": {
        "id": "WUUUP5t5RhlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain the model from scratch "
      ],
      "metadata": {
        "id": "5GwFlT7w_CFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the new model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# training the model\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=4,\n",
        "                    batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYw_n5Rn-kP1",
        "outputId": "8d1eb81f-37b9-4928-827d-f40c368e021f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/4\n",
            "49/49 [==============================] - 6s 112ms/step - loss: 0.4454 - accuracy: 0.8234\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.2549 - accuracy: 0.9112\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.1992 - accuracy: 0.9290\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 3s 53ms/step - loss: 0.1674 - accuracy: 0.9409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the new model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98X7FGVpEjrb",
        "outputId": "5dd80888-e6f1-42e8-c8b5-6519b8b241ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 16)                160016    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,305\n",
            "Trainable params: 160,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss and accuracy of the new model"
      ],
      "metadata": {
        "id": "85sP2vZYD4NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, label=\"Training loss\")\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pKxQYYMND6Fw",
        "outputId": "712dcf6d-90d4-4d72-fead-8998c438d742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the loss has decreased and the accuracy is improved(94% instead of 90% we had earlier). So, this new model performs better than the previous one, so we can now evaluate it on the test set"
      ],
      "metadata": {
        "id": "ZZar-BDuxT_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "plt.plot(epochs, acc, label=\"Training accuracy\")\n",
        "plt.title(\"Training accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CNdfTF0mD86U",
        "outputId": "798dc644-a099-48dc-dba5-09fe348c6037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model and predict"
      ],
      "metadata": {
        "id": "n21hSzVXPVDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "results = model.evaluate(x_test, y_test)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ1wzg-8OrCi",
        "outputId": "38a8c851-c30a-4958-84e8-7b7e4e1ba119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 3ms/step - loss: 0.3205 - accuracy: 0.8726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32046642899513245, 0.8725600242614746]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions and explore/understand the results"
      ],
      "metadata": {
        "id": "wU6M0HQfTj-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoKs6JHtPNyN",
        "outputId": "89446a3b-32be-4cfd-cbca-0eed183920f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFY_BRdiTWL3",
        "outputId": "04331a6f-c60d-4021-9d58-ba7980bb641b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13699357],\n",
              "       [0.9998619 ],\n",
              "       [0.5870197 ],\n",
              "       ...,\n",
              "       [0.08932838],\n",
              "       [0.04493114],\n",
              "       [0.43320382]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[10] # which is a close to 1=>a positive review, as we initially have seen it!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YJmKyP3PpUn",
        "outputId": "336165f8-93fe-458c-fb74-bcf134924335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8281189], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, to prevent your model from Overfitting: 1) get more training data, 2) reduce the capacity of the network, 3) add weight regularization and 4) add dropout layers. To prevent your model from Underfitting in NNs just try a bigger network!(@page 104)"
      ],
      "metadata": {
        "id": "iJ3ODB5PZDXD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kpco8jxTP2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 4. Classifying newswires, based on text content, into 46 topics"
      ],
      "metadata": {
        "id": "w4BQ3F6wT_QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a multi-class Classification problem"
      ],
      "metadata": {
        "id": "NGu5orJGVuXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand it"
      ],
      "metadata": {
        "id": "NXvdvz47W-oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) # num_words=10000 means that we only keep the top 10000 most frequently occuring words in the training data\n",
        " \n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwGWmZKwUJVR",
        "outputId": "33ed561e-d9be-4edb-db35-f39655a6a2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n",
            "X_train: (8982,)\n",
            "y_train: (8982,)\n",
            "X_test: (2246,)\n",
            "y_test: (2246,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_labels[10]}')\n",
        "print(f'the label of 11th example of test_labels: {test_labels[10]}\\n')\n",
        "print(f'the first 11 elements of train_labels: {train_labels[:11]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvlbhm3jVaWm",
        "outputId": "d35ad21a-fe37-4710-fbc1-ffc27085b0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n",
            "length of 11th example of train_data: 31\n",
            "the label of 11th example of train_labels: 3\n",
            "the label of 11th example of test_labels: 5\n",
            "\n",
            "the first 11 elements of train_labels: [ 3  4  3  4  4  4  4  3  3 16  3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with the imdb's reviews, each example here is also a list of integers(word indices)"
      ],
      "metadata": {
        "id": "dxborw1AXqe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data for the NN"
      ],
      "metadata": {
        "id": "Xn1nQd_UZW0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the integer sequences via multi-hot encoding for train_data and test_data: each example now is a 10000 sequence of 0s and 1s\n",
        "# if a word is on corpus of 10000, we have 1 and if a word is not in the corpus, we have 0\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "xIjj87rnZDyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 ways to handle the labels/targets in such cases: 1) one-hot(categorical) encoding in which we use loss=categorical_crossentropy(and dtype is float) and 2) labels as integers in which we use sparse_categorical_crossentropy(dtype here is int, more @page 83)"
      ],
      "metadata": {
        "id": "a_goUT_TzsvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding for the train and test labels\n",
        "# (a 46 dimensional list with 0s and 1s)\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "07IJJhOSzqwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train after preprocessing: {x_train.shape}')\n",
        "print(f'y_train after preprocessing: {one_hot_train_labels.shape}')\n",
        "print(f'X_test after preprocessing: {x_test.shape}')\n",
        "print(f'y_test after preprocessing: {one_hot_test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGK6txb7lVt4",
        "outputId": "3898e1c5-8e32-4d07-921d-8ae5a810920b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train after preprocessing: (8982, 10000)\n",
            "y_train after preprocessing: (8982, 46)\n",
            "X_test after preprocessing: (2246, 10000)\n",
            "y_test after preprocessing: (2246, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'length of 11th example of train_data after preprocessing: {x_train[10].shape}')\n",
        "print(f'11th example of train_data after preprocessing:\\n {x_train[10]}')\n",
        "print(f'the label of 11th example of train_labels after preprocessing: {one_hot_train_labels[10]}')\n",
        "\n",
        "print(f'\\n11th example of x_test after preprocessing:\\n {x_test[10]}')\n",
        "print(f'the label of 11th example of test_labels after preprocessing: {one_hot_test_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiCwu4Rple95",
        "outputId": "f70f3517-c42c-4fa2-c7a6-1846a0f9433d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of 11th example of train_data after preprocessing: (10000,)\n",
            "11th example of train_data after preprocessing:\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            "the label of 11th example of train_labels after preprocessing: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "11th example of x_test after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of test_labels after preprocessing: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and train the model"
      ],
      "metadata": {
        "id": "E47YY_Fpc7ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's architecture\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# model's compiling\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# create a validation set \n",
        "# every model is not the best initially and always needs improvements via hyperparameter tuning. So, always create a validation set to test the model and when find the best tuning, train the final model on test set\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]\n",
        "\n",
        "# start training\n",
        "print('training ...\\n')\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCmDLGouZDvW",
        "outputId": "997a86f3-5982-47a9-e7f3-6adb134de876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 2.5618 - accuracy: 0.5204 - val_loss: 1.7102 - val_accuracy: 0.6500\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 1.3944 - accuracy: 0.7065 - val_loss: 1.2984 - val_accuracy: 0.7330\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 1.0426 - accuracy: 0.7772 - val_loss: 1.1017 - val_accuracy: 0.7660\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.8185 - accuracy: 0.8246 - val_loss: 1.0311 - val_accuracy: 0.7790\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.6555 - accuracy: 0.8612 - val_loss: 0.9386 - val_accuracy: 0.8070\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.5300 - accuracy: 0.8906 - val_loss: 0.9115 - val_accuracy: 0.8110\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.4226 - accuracy: 0.9137 - val_loss: 0.8860 - val_accuracy: 0.8140\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.3456 - accuracy: 0.9258 - val_loss: 0.8667 - val_accuracy: 0.8200\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 0.2832 - accuracy: 0.9369 - val_loss: 0.8644 - val_accuracy: 0.8250\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.2455 - accuracy: 0.9432 - val_loss: 0.8706 - val_accuracy: 0.8180\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2043 - accuracy: 0.9488 - val_loss: 0.9056 - val_accuracy: 0.8130\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 2s 91ms/step - loss: 0.1817 - accuracy: 0.9508 - val_loss: 0.8945 - val_accuracy: 0.8150\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1676 - accuracy: 0.9541 - val_loss: 0.9394 - val_accuracy: 0.8160\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.1532 - accuracy: 0.9551 - val_loss: 0.9869 - val_accuracy: 0.8080\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1367 - accuracy: 0.9569 - val_loss: 0.9546 - val_accuracy: 0.8170\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.1307 - accuracy: 0.9553 - val_loss: 1.0463 - val_accuracy: 0.8040\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.1266 - accuracy: 0.9563 - val_loss: 0.9947 - val_accuracy: 0.8110\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.1170 - accuracy: 0.9574 - val_loss: 1.0606 - val_accuracy: 0.8050\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1157 - accuracy: 0.9567 - val_loss: 1.1120 - val_accuracy: 0.7960\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1128 - accuracy: 0.9574 - val_loss: 1.0810 - val_accuracy: 0.8010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Eb6MLAftY6R",
        "outputId": "1cf31dd9-d368-46f8-d4c2-214a83a3f39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the training .vs validation loss and accuracy and Evaluating the model"
      ],
      "metadata": {
        "id": "EBXNskY0pe3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see what we have in history\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUqkqi08qi_W",
        "outputId": "774374a8-9666-48c3-dfd1-52a953be9111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LUR5KbFiZDsN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e62bd94c-c04f-4477-96da-3259d39d9edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YOIHJwh1ZDpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8416d800-c144-49db-b428-2d2460fe684d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the model starts to overfit after 8 epochs. So, we train a new model with 9 epochs"
      ],
      "metadata": {
        "id": "-PMkZzb1qv9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below cell, only and only if the above model is your final chosen model "
      ],
      "metadata": {
        "id": "opaXCwa6x2aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "#results = model.evaluate(x_test, one_hot_test_labels)\n",
        "#results"
      ],
      "metadata": {
        "id": "eiqmudSxZDmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain from scratch a new model, Evaluate it and Predict"
      ],
      "metadata": {
        "id": "P56CPMperQ1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the previous model, we train it again with just 9 epochs only"
      ],
      "metadata": {
        "id": "X31OTDQtr3q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# model's compiling\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# start training\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    one_hot_train_labels,\n",
        "                    epochs=8,\n",
        "                    batch_size=512)"
      ],
      "metadata": {
        "id": "IfqH8531ZDjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab250de5-0aba-468c-8fc7-24b7ac8c094e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/8\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 2.5396 - accuracy: 0.5689\n",
            "Epoch 2/8\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 1.3540 - accuracy: 0.7193\n",
            "Epoch 3/8\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.9933 - accuracy: 0.7929\n",
            "Epoch 4/8\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.7783 - accuracy: 0.8412\n",
            "Epoch 5/8\n",
            "18/18 [==============================] - 2s 111ms/step - loss: 0.6112 - accuracy: 0.8744\n",
            "Epoch 6/8\n",
            "18/18 [==============================] - 3s 168ms/step - loss: 0.4853 - accuracy: 0.8977\n",
            "Epoch 7/8\n",
            "18/18 [==============================] - 2s 109ms/step - loss: 0.3916 - accuracy: 0.9183\n",
            "Epoch 8/8\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.3201 - accuracy: 0.9311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the new model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1XHwTVxtVmU",
        "outputId": "12f1444d-cd31-4456-b72f-3629323c5f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 models have almost the same accuracy, but the new one has significatly decreased loss"
      ],
      "metadata": {
        "id": "rMODNe5FycHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this new model on test set\n",
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilDxbizUsYJq",
        "outputId": "f4ae810a-f4b2-41f8-b1f1-eab14857a5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 6ms/step - loss: 1.0037 - accuracy: 0.7818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0036550760269165, 0.7818343639373779]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions. understand what the results are\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "ZldgN5ksZDgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c211790-551b-4809-fa91-48a71f315db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "r4998LAWZDdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ec6b7e-713e-432e-ad77-ba16002f5135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9495428e-05, 1.3296199e-05, 3.6895951e-06, ..., 7.1986651e-06,\n",
              "        3.4198890e-06, 1.6939182e-05],\n",
              "       [2.0897888e-04, 1.0091536e-03, 1.3802850e-03, ..., 6.1391504e-04,\n",
              "        9.8795954e-06, 1.0300666e-04],\n",
              "       [1.4757402e-03, 4.4161284e-01, 7.5308233e-03, ..., 6.0695685e-03,\n",
              "        1.1402445e-03, 3.0210447e-03],\n",
              "       ...,\n",
              "       [2.8125995e-05, 6.9062538e-05, 1.5078267e-05, ..., 3.7804410e-05,\n",
              "        1.2923571e-05, 3.0063711e-05],\n",
              "       [1.0545923e-03, 1.3320736e-02, 9.8353392e-04, ..., 4.3499615e-04,\n",
              "        1.8568625e-04, 4.8552672e-04],\n",
              "       [6.3449894e-05, 1.7428231e-01, 7.9245577e-03, ..., 6.0169160e-04,\n",
              "        2.6538069e-04, 4.8529194e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every prediction is comprised of 46 probs vector\n",
        "predictions[10].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv1ewRT6wjCP",
        "outputId": "c911c9a5-3d9e-4b1c-af76-8f01ef47dee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a prediction vector\n",
        "predictions[10] "
      ],
      "metadata": {
        "id": "mYKkApDlZDap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d1f9a4-710d-479f-95f2-9a4b2e21949f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.14632270e-04, 5.79779267e-01, 1.23179648e-02, 3.65803973e-03,\n",
              "       1.08881518e-01, 1.74482577e-02, 1.90305000e-03, 5.02081169e-03,\n",
              "       6.33821124e-04, 4.84910852e-04, 5.07359728e-02, 2.35104235e-03,\n",
              "       2.97833176e-05, 5.52383857e-03, 1.22885313e-02, 6.25073910e-03,\n",
              "       9.42342216e-04, 7.45899917e-04, 5.18579967e-04, 7.41407881e-03,\n",
              "       1.53952686e-03, 1.29163812e-03, 6.36699190e-03, 1.34543004e-03,\n",
              "       1.05633438e-01, 6.18205639e-03, 9.84719809e-05, 1.86446891e-03,\n",
              "       6.32492127e-03, 3.67840845e-03, 4.70015686e-04, 1.22045297e-02,\n",
              "       6.67589158e-03, 8.74775811e-04, 5.81820635e-03, 3.02119297e-04,\n",
              "       1.08573084e-04, 9.23173153e-04, 1.71241991e-03, 1.34056760e-03,\n",
              "       4.24162997e-03, 1.85495731e-03, 7.90634099e-03, 1.23321160e-03,\n",
              "       7.86852324e-04, 1.67829404e-03], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index of the highest probability. check it above\n",
        "np.argmax(predictions[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO7otZzLwiT1",
        "outputId": "0adcd811-b3ea-4d07-c699-26020efffeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficients of each vector of 46 elements must have sum=1 \n",
        "np.sum(predictions[10])"
      ],
      "metadata": {
        "id": "6UV7DX5lZDXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b05bac-ad94-461c-8abc-090a44938566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99999994"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and check manually if the prediction is correct \n",
        "one_hot_test_labels[10]"
      ],
      "metadata": {
        "id": "uR29IupWZDU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61708e3-c123-4175-da68-69d46ae20e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4muV4R33ZI8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 5. Predicting house prices"
      ],
      "metadata": {
        "id": "WCP4acTg0dlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a linear regression problem"
      ],
      "metadata": {
        "id": "gNX4DGhV0uS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "ete78P9067Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_targets.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_targets.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ8RyWph0jPZ",
        "outputId": "40bddd7e-7079-45b8-cb49-e74bcac007b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n",
            "X_train: (404, 13)\n",
            "y_train: (404,)\n",
            "X_test: (102, 13)\n",
            "y_test: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_targets[10]}')\n",
        "print(f'the label of 11th example of test_labels: {test_targets[10]}\\n')\n",
        "print(f'the first 11 elements of train_labels: {train_targets[:11]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ-AYtSP0_Sr",
        "outputId": "2f039a3a-b4b5-499f-d211-9b31bdd12a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [  9.59571   0.       18.1       0.        0.693     6.404   100.\n",
            "   1.639    24.      666.       20.2     376.11     20.31   ]\n",
            "length of 11th example of train_data: 13\n",
            "the label of 11th example of train_labels: 12.1\n",
            "the label of 11th example of test_labels: 18.6\n",
            "\n",
            "the first 11 elements of train_labels: [15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data"
      ],
      "metadata": {
        "id": "UlrGVwn07n2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization of the train and test data\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "metadata": {
        "id": "YrWIytyT0_P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build, Train and Evaluate the model using K-fold cross-validation"
      ],
      "metadata": {
        "id": "okjds-Ld9Fy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building function of the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# when little data available for training, we use a small network!\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "pHqgsX150_NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a best model, we need a validation set in order to use it as an intermediate dataset to improve it, as we always do. However, having so few examples in the train_data, a small validation set does not help, so we split the train_data into k partitions, build, train(on k-1 partitions) and evaluate(on k partition) k models. The final model is the average of k models(more @page87)"
      ],
      "metadata": {
        "id": "RlKCmUnF95Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]  \n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=16)#, verbose=0\n",
        "    mae_history = history.history[\"val_mae\"]\n",
        "    all_mae_histories.append(mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHVWITi30_J_",
        "outputId": "af0d9ec3-c81e-4278-c185-447a2a10b07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing fold #0\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 10ms/step - loss: 483.8998 - mae: 20.2704 - val_loss: 385.4236 - val_mae: 17.5238\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 335.3716 - mae: 16.3148 - val_loss: 228.2413 - val_mae: 12.8005\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 188.4021 - mae: 11.5057 - val_loss: 104.6122 - val_mae: 7.8777\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 92.9368 - mae: 7.5467 - val_loss: 52.7219 - val_mae: 5.1641\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 54.1869 - mae: 5.5454 - val_loss: 38.8553 - val_mae: 4.1879\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 39.3521 - mae: 4.5998 - val_loss: 31.8821 - val_mae: 3.6745\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 30.9591 - mae: 4.1006 - val_loss: 27.5196 - val_mae: 3.3772\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 26.3351 - mae: 3.7282 - val_loss: 25.3538 - val_mae: 3.2553\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 23.4291 - mae: 3.4967 - val_loss: 23.1411 - val_mae: 3.0879\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 21.8081 - mae: 3.2727 - val_loss: 21.5954 - val_mae: 2.9882\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 19.8950 - mae: 3.1515 - val_loss: 19.7458 - val_mae: 2.9869\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 18.3090 - mae: 3.0334 - val_loss: 18.6236 - val_mae: 2.9208\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 17.2560 - mae: 2.8887 - val_loss: 17.6176 - val_mae: 2.9811\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 15.9095 - mae: 2.8273 - val_loss: 16.7965 - val_mae: 2.7139\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 15.4319 - mae: 2.7494 - val_loss: 16.3670 - val_mae: 2.6962\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 15.0141 - mae: 2.6838 - val_loss: 15.0175 - val_mae: 2.7221\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 14.2930 - mae: 2.6434 - val_loss: 14.0132 - val_mae: 2.5916\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.9983 - mae: 2.6193 - val_loss: 14.3336 - val_mae: 2.5869\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.6201 - mae: 2.6069 - val_loss: 13.3989 - val_mae: 2.5139\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.2805 - mae: 2.5665 - val_loss: 12.9254 - val_mae: 2.4997\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 12.8345 - mae: 2.5067 - val_loss: 12.8486 - val_mae: 2.4704\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 12.3205 - mae: 2.4590 - val_loss: 12.2776 - val_mae: 2.5162\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 12.0062 - mae: 2.4253 - val_loss: 11.6550 - val_mae: 2.3496\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 11.6959 - mae: 2.3884 - val_loss: 11.6426 - val_mae: 2.4887\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 11.5259 - mae: 2.3780 - val_loss: 11.1528 - val_mae: 2.4261\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 11.4806 - mae: 2.3631 - val_loss: 10.6684 - val_mae: 2.3236\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.0288 - mae: 2.3056 - val_loss: 10.3024 - val_mae: 2.3441\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.8945 - mae: 2.2856 - val_loss: 10.0186 - val_mae: 2.2811\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 10.7174 - mae: 2.3104 - val_loss: 10.2909 - val_mae: 2.3420\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.7073 - mae: 2.3003 - val_loss: 9.6666 - val_mae: 2.2452\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.4520 - mae: 2.2537 - val_loss: 9.4776 - val_mae: 2.1779\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.3145 - mae: 2.2512 - val_loss: 9.2045 - val_mae: 2.1650\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 10.1051 - mae: 2.2348 - val_loss: 9.0862 - val_mae: 2.1374\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.2742 - mae: 2.2693 - val_loss: 9.5213 - val_mae: 2.1619\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.7090 - mae: 2.1993 - val_loss: 9.3712 - val_mae: 2.1778\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.9402 - mae: 2.2100 - val_loss: 9.3037 - val_mae: 2.2413\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 9.5045 - mae: 2.1567 - val_loss: 8.9749 - val_mae: 2.1389\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.7091 - mae: 2.1792 - val_loss: 8.6907 - val_mae: 2.1208\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 9.5647 - mae: 2.1587 - val_loss: 8.5874 - val_mae: 2.0616\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 9.2442 - mae: 2.0963 - val_loss: 9.3532 - val_mae: 2.1573\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.0978 - mae: 2.0785 - val_loss: 8.4718 - val_mae: 2.0583\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.0416 - mae: 2.1064 - val_loss: 8.2964 - val_mae: 2.0432\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.1735 - mae: 2.0856 - val_loss: 8.7455 - val_mae: 2.1586\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.9440 - mae: 2.0914 - val_loss: 8.0657 - val_mae: 1.9925\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.8993 - mae: 2.0479 - val_loss: 8.1838 - val_mae: 2.1152\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.8062 - mae: 2.0996 - val_loss: 8.2021 - val_mae: 1.9882\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.9461 - mae: 2.0794 - val_loss: 7.9812 - val_mae: 1.9999\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.6524 - mae: 2.0108 - val_loss: 8.1252 - val_mae: 2.0839\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.7190 - mae: 2.0374 - val_loss: 7.9453 - val_mae: 2.0722\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 1s 48ms/step - loss: 8.6450 - mae: 2.0435 - val_loss: 8.0989 - val_mae: 2.0865\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.2877 - mae: 1.9927 - val_loss: 7.8560 - val_mae: 1.9911\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.3904 - mae: 2.0040 - val_loss: 7.6221 - val_mae: 1.9394\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.4584 - mae: 2.0078 - val_loss: 8.1510 - val_mae: 2.0351\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.2829 - mae: 1.9897 - val_loss: 7.6352 - val_mae: 1.9925\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.3697 - mae: 1.9929 - val_loss: 7.6409 - val_mae: 2.0214\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.1341 - mae: 1.9700 - val_loss: 7.8697 - val_mae: 2.0801\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.9381 - mae: 1.9639 - val_loss: 7.8403 - val_mae: 2.0034\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.0101 - mae: 1.9594 - val_loss: 7.4610 - val_mae: 2.0121\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.0163 - mae: 2.0000 - val_loss: 7.7252 - val_mae: 1.9433\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.0161 - mae: 1.9758 - val_loss: 7.5965 - val_mae: 2.0458\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.7981 - mae: 1.9440 - val_loss: 7.8326 - val_mae: 2.0585\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.8889 - mae: 1.9429 - val_loss: 7.8383 - val_mae: 2.1182\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.6883 - mae: 1.9153 - val_loss: 7.3405 - val_mae: 1.9471\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.5846 - mae: 1.9097 - val_loss: 8.0057 - val_mae: 2.1559\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.8298 - mae: 1.9331 - val_loss: 7.6026 - val_mae: 2.0670\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.6206 - mae: 1.8795 - val_loss: 7.4082 - val_mae: 2.0413\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.5500 - mae: 1.9174 - val_loss: 7.2007 - val_mae: 1.9652\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 7.2793 - mae: 1.8845 - val_loss: 7.7914 - val_mae: 2.0533\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.5439 - mae: 1.8953 - val_loss: 7.3553 - val_mae: 2.0481\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.4887 - mae: 1.9030 - val_loss: 7.3589 - val_mae: 2.0532\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.1413 - mae: 1.8259 - val_loss: 7.5790 - val_mae: 2.1056\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.2779 - mae: 1.8887 - val_loss: 7.1689 - val_mae: 1.9931\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0816 - mae: 1.8408 - val_loss: 7.3637 - val_mae: 2.0967\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.1754 - mae: 1.8631 - val_loss: 7.3121 - val_mae: 2.0171\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.2493 - mae: 1.8495 - val_loss: 7.3710 - val_mae: 2.1295\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.9192 - mae: 1.8177 - val_loss: 7.6752 - val_mae: 1.9787\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0055 - mae: 1.8273 - val_loss: 7.0619 - val_mae: 2.0165\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.1006 - mae: 1.8516 - val_loss: 7.2029 - val_mae: 1.9672\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.7486 - mae: 1.8559 - val_loss: 7.2626 - val_mae: 1.9526\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.9164 - mae: 1.8067 - val_loss: 7.3426 - val_mae: 2.0131\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.8929 - mae: 1.8311 - val_loss: 7.1969 - val_mae: 1.9171\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5176 - mae: 1.7816 - val_loss: 8.8346 - val_mae: 2.3463\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.7792 - mae: 1.8005 - val_loss: 6.9351 - val_mae: 1.9993\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.6659 - mae: 1.8003 - val_loss: 6.9410 - val_mae: 1.9720\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5492 - mae: 1.7549 - val_loss: 7.2740 - val_mae: 2.1082\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.7415 - mae: 1.7491 - val_loss: 6.9815 - val_mae: 1.9989\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.3927 - mae: 1.7552 - val_loss: 8.7991 - val_mae: 2.3669\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.6023 - mae: 1.7810 - val_loss: 6.9308 - val_mae: 1.9916\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.3157 - mae: 1.7632 - val_loss: 6.9670 - val_mae: 1.9405\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2200 - mae: 1.7665 - val_loss: 7.0500 - val_mae: 1.9029\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.5396 - mae: 1.7190 - val_loss: 7.4242 - val_mae: 1.9457\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.3550 - mae: 1.7371 - val_loss: 6.8176 - val_mae: 2.0122\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.3178 - mae: 1.7189 - val_loss: 7.0588 - val_mae: 1.9601\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.2668 - mae: 1.7310 - val_loss: 7.4534 - val_mae: 2.1859\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1523 - mae: 1.7381 - val_loss: 6.6799 - val_mae: 1.9317\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.4614 - mae: 1.7594 - val_loss: 6.7782 - val_mae: 1.9807\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.1098 - mae: 1.7243 - val_loss: 6.8781 - val_mae: 1.9153\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.2417 - mae: 1.7299 - val_loss: 7.4550 - val_mae: 2.1755\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.3396 - mae: 1.7345 - val_loss: 6.7925 - val_mae: 1.9716\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.0508 - mae: 1.7165 - val_loss: 7.0116 - val_mae: 2.0823\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.1798 - mae: 1.7161 - val_loss: 7.6284 - val_mae: 2.0861\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.1137 - mae: 1.6852 - val_loss: 6.8581 - val_mae: 1.9579\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8714 - mae: 1.6636 - val_loss: 6.8543 - val_mae: 2.0566\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8721 - mae: 1.6719 - val_loss: 6.7673 - val_mae: 1.9818\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.9305 - mae: 1.6955 - val_loss: 6.7694 - val_mae: 2.0428\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.8361 - mae: 1.6975 - val_loss: 7.1751 - val_mae: 2.1671\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8734 - mae: 1.6634 - val_loss: 6.7840 - val_mae: 1.8923\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8298 - mae: 1.7029 - val_loss: 6.7333 - val_mae: 1.9443\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7724 - mae: 1.6820 - val_loss: 6.9961 - val_mae: 2.0799\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.9198 - mae: 1.6689 - val_loss: 6.8186 - val_mae: 2.0186\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6520 - mae: 1.6458 - val_loss: 6.5039 - val_mae: 1.9708\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7821 - mae: 1.6489 - val_loss: 6.7752 - val_mae: 2.0458\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5033 - mae: 1.6340 - val_loss: 6.8007 - val_mae: 1.8699\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.6874 - mae: 1.6465 - val_loss: 6.5504 - val_mae: 1.9622\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3942 - mae: 1.5816 - val_loss: 7.1886 - val_mae: 2.0035\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5391 - mae: 1.6452 - val_loss: 6.7463 - val_mae: 1.9198\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6507 - mae: 1.6248 - val_loss: 6.6030 - val_mae: 1.9473\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3448 - mae: 1.5951 - val_loss: 7.3509 - val_mae: 2.0262\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.4320 - mae: 1.6433 - val_loss: 6.6109 - val_mae: 1.8594\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3573 - mae: 1.6084 - val_loss: 6.5207 - val_mae: 1.8824\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.4581 - mae: 1.6397 - val_loss: 6.3618 - val_mae: 1.9089\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.2850 - mae: 1.5518 - val_loss: 6.3747 - val_mae: 1.9349\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.2012 - mae: 1.5624 - val_loss: 6.5385 - val_mae: 2.0415\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3469 - mae: 1.5928 - val_loss: 7.4943 - val_mae: 2.1564\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1885 - mae: 1.5985 - val_loss: 7.3081 - val_mae: 2.0642\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1763 - mae: 1.5898 - val_loss: 6.6411 - val_mae: 2.0018\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1394 - mae: 1.5762 - val_loss: 7.0714 - val_mae: 2.0765\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.3163 - mae: 1.6418 - val_loss: 7.0941 - val_mae: 2.0792\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1131 - mae: 1.5412 - val_loss: 6.6964 - val_mae: 1.8709\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.1143 - mae: 1.5745 - val_loss: 8.4174 - val_mae: 2.2553\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.1196 - mae: 1.5791 - val_loss: 6.4762 - val_mae: 1.9652\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0161 - mae: 1.5617 - val_loss: 6.3404 - val_mae: 1.9343\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.9621 - mae: 1.5607 - val_loss: 6.8575 - val_mae: 1.9681\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.0527 - mae: 1.5829 - val_loss: 6.7008 - val_mae: 1.8892\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0464 - mae: 1.5546 - val_loss: 6.8526 - val_mae: 2.1079\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9008 - mae: 1.5485 - val_loss: 6.9986 - val_mae: 2.0037\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.8781 - mae: 1.5344 - val_loss: 6.8100 - val_mae: 2.0299\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.9253 - mae: 1.5370 - val_loss: 6.3241 - val_mae: 1.8859\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7023 - mae: 1.5279 - val_loss: 7.2205 - val_mae: 2.0310\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.8792 - mae: 1.5828 - val_loss: 6.6083 - val_mae: 1.9774\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.6992 - mae: 1.5364 - val_loss: 6.7538 - val_mae: 2.0353\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.7550 - mae: 1.5299 - val_loss: 6.5756 - val_mae: 1.8573\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7286 - mae: 1.4905 - val_loss: 6.5739 - val_mae: 1.9995\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5806 - mae: 1.5440 - val_loss: 6.7357 - val_mae: 1.8711\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7477 - mae: 1.5267 - val_loss: 6.8074 - val_mae: 1.9467\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7765 - mae: 1.5529 - val_loss: 6.3826 - val_mae: 1.8838\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.5809 - mae: 1.4877 - val_loss: 6.6423 - val_mae: 2.0200\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5607 - mae: 1.5092 - val_loss: 6.6021 - val_mae: 2.0193\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4686 - mae: 1.4918 - val_loss: 6.5234 - val_mae: 1.9119\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4896 - mae: 1.5028 - val_loss: 6.5624 - val_mae: 2.0003\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4739 - mae: 1.4545 - val_loss: 6.5084 - val_mae: 1.9667\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5228 - mae: 1.4745 - val_loss: 6.7986 - val_mae: 1.9547\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.3760 - mae: 1.4477 - val_loss: 6.8120 - val_mae: 2.0214\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4807 - mae: 1.4982 - val_loss: 7.4014 - val_mae: 2.1727\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4896 - mae: 1.5019 - val_loss: 6.3657 - val_mae: 1.9058\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.3748 - mae: 1.4761 - val_loss: 6.4297 - val_mae: 1.8711\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.4596 - mae: 1.4930 - val_loss: 6.6419 - val_mae: 1.9871\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.3129 - mae: 1.4426 - val_loss: 7.0592 - val_mae: 2.0934\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4670 - mae: 1.4786 - val_loss: 6.6095 - val_mae: 1.9762\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1365 - mae: 1.4134 - val_loss: 6.8778 - val_mae: 1.9796\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.3666 - mae: 1.4840 - val_loss: 6.7670 - val_mae: 1.8680\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3445 - mae: 1.4666 - val_loss: 6.6368 - val_mae: 1.8795\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.2212 - mae: 1.4152 - val_loss: 6.4549 - val_mae: 1.8850\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2162 - mae: 1.4345 - val_loss: 6.8142 - val_mae: 2.0052\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.2720 - mae: 1.4632 - val_loss: 6.6274 - val_mae: 1.9741\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9767 - mae: 1.3989 - val_loss: 6.9738 - val_mae: 1.9661\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1516 - mae: 1.4429 - val_loss: 6.9670 - val_mae: 1.9685\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9257 - mae: 1.3763 - val_loss: 7.3735 - val_mae: 2.0487\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.1086 - mae: 1.4580 - val_loss: 6.4145 - val_mae: 1.9041\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0100 - mae: 1.4158 - val_loss: 6.6614 - val_mae: 1.9814\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9838 - mae: 1.3979 - val_loss: 6.2596 - val_mae: 1.8535\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0263 - mae: 1.4558 - val_loss: 6.6922 - val_mae: 2.0083\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.9335 - mae: 1.4055 - val_loss: 6.6613 - val_mae: 2.0074\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.1188 - mae: 1.4245 - val_loss: 6.2955 - val_mae: 1.8960\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.8593 - mae: 1.3747 - val_loss: 6.8591 - val_mae: 2.0343\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9373 - mae: 1.3856 - val_loss: 6.4462 - val_mae: 1.9266\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.7789 - mae: 1.3754 - val_loss: 6.4005 - val_mae: 1.8470\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7095 - mae: 1.3566 - val_loss: 6.8172 - val_mae: 1.8658\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8764 - mae: 1.3718 - val_loss: 6.4908 - val_mae: 1.9968\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.8318 - mae: 1.3534 - val_loss: 6.3875 - val_mae: 1.8881\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7374 - mae: 1.3827 - val_loss: 7.8549 - val_mae: 2.2254\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8628 - mae: 1.4111 - val_loss: 6.3753 - val_mae: 1.8805\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.7212 - mae: 1.3741 - val_loss: 6.4905 - val_mae: 1.9523\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6380 - mae: 1.3457 - val_loss: 7.3411 - val_mae: 2.1268\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.5914 - mae: 1.3742 - val_loss: 6.5222 - val_mae: 1.8658\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9065 - mae: 1.3860 - val_loss: 6.5079 - val_mae: 1.9747\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5549 - mae: 1.3139 - val_loss: 8.3088 - val_mae: 2.3190\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 3.8126 - mae: 1.3848 - val_loss: 6.6845 - val_mae: 1.8964\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6641 - mae: 1.3608 - val_loss: 6.6880 - val_mae: 1.9775\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7276 - mae: 1.3768 - val_loss: 6.4083 - val_mae: 1.9050\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.5053 - mae: 1.3178 - val_loss: 6.6520 - val_mae: 1.8680\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5751 - mae: 1.3418 - val_loss: 7.4994 - val_mae: 2.1197\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.5508 - mae: 1.3495 - val_loss: 6.6091 - val_mae: 1.9324\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.4368 - mae: 1.3133 - val_loss: 6.8897 - val_mae: 1.9272\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4674 - mae: 1.3617 - val_loss: 7.0279 - val_mae: 1.9883\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5019 - mae: 1.3448 - val_loss: 6.6441 - val_mae: 1.8769\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.5813 - mae: 1.3514 - val_loss: 6.7487 - val_mae: 1.9779\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6576 - mae: 1.3334 - val_loss: 6.4006 - val_mae: 1.9045\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3768 - mae: 1.2806 - val_loss: 6.2866 - val_mae: 1.8543\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3770 - mae: 1.2930 - val_loss: 7.3133 - val_mae: 2.1219\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4687 - mae: 1.3177 - val_loss: 6.6277 - val_mae: 1.9656\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.4580 - mae: 1.2884 - val_loss: 7.3380 - val_mae: 2.1173\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5012 - mae: 1.3504 - val_loss: 6.7421 - val_mae: 2.0136\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3426 - mae: 1.2694 - val_loss: 6.6380 - val_mae: 1.9655\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.3113 - mae: 1.3026 - val_loss: 6.7694 - val_mae: 1.9758\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3344 - mae: 1.3122 - val_loss: 6.3590 - val_mae: 1.8544\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3417 - mae: 1.2988 - val_loss: 6.8009 - val_mae: 1.9958\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2472 - mae: 1.2802 - val_loss: 6.8671 - val_mae: 1.9807\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.3118 - mae: 1.2880 - val_loss: 7.4219 - val_mae: 2.1394\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2200 - mae: 1.2783 - val_loss: 7.0893 - val_mae: 2.1304\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4891 - mae: 1.2988 - val_loss: 6.4482 - val_mae: 1.8930\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2793 - mae: 1.3001 - val_loss: 7.4981 - val_mae: 2.1164\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.1631 - mae: 1.2499 - val_loss: 6.6476 - val_mae: 1.9528\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1662 - mae: 1.2386 - val_loss: 6.7677 - val_mae: 2.0064\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1949 - mae: 1.2882 - val_loss: 6.8937 - val_mae: 1.9575\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0686 - mae: 1.2341 - val_loss: 7.5504 - val_mae: 2.1159\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2329 - mae: 1.2931 - val_loss: 7.2666 - val_mae: 2.0551\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.0670 - mae: 1.2476 - val_loss: 7.8301 - val_mae: 2.2533\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3263 - mae: 1.2986 - val_loss: 7.5046 - val_mae: 2.1173\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.3836 - mae: 1.3034 - val_loss: 6.5167 - val_mae: 1.9130\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9510 - mae: 1.2121 - val_loss: 6.7079 - val_mae: 1.8616\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0543 - mae: 1.2568 - val_loss: 6.8181 - val_mae: 1.9201\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1086 - mae: 1.2338 - val_loss: 6.7282 - val_mae: 2.0298\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0475 - mae: 1.2447 - val_loss: 7.6554 - val_mae: 2.2355\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.0529 - mae: 1.2378 - val_loss: 6.6929 - val_mae: 1.9518\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0214 - mae: 1.2392 - val_loss: 8.5749 - val_mae: 2.3426\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.0026 - mae: 1.2176 - val_loss: 6.6993 - val_mae: 1.9647\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1316 - mae: 1.2788 - val_loss: 6.5861 - val_mae: 1.8495\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.9168 - mae: 1.2335 - val_loss: 7.5252 - val_mae: 2.1402\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.0848 - mae: 1.2634 - val_loss: 7.3630 - val_mae: 2.1288\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.0776 - mae: 1.2540 - val_loss: 6.5354 - val_mae: 1.8613\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.8862 - mae: 1.2158 - val_loss: 7.5027 - val_mae: 2.1644\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.9010 - mae: 1.2492 - val_loss: 6.6406 - val_mae: 1.9230\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.9560 - mae: 1.2296 - val_loss: 7.0654 - val_mae: 2.0027\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.9784 - mae: 1.2281 - val_loss: 6.7867 - val_mae: 1.9061\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7487 - mae: 1.1968 - val_loss: 6.3813 - val_mae: 1.8468\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9384 - mae: 1.2344 - val_loss: 6.7955 - val_mae: 1.9557\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8367 - mae: 1.2192 - val_loss: 6.7076 - val_mae: 1.9646\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.8362 - mae: 1.2281 - val_loss: 7.0769 - val_mae: 2.0338\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8794 - mae: 1.2041 - val_loss: 7.3286 - val_mae: 2.1197\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8057 - mae: 1.1835 - val_loss: 8.1412 - val_mae: 2.2791\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8668 - mae: 1.2339 - val_loss: 7.6740 - val_mae: 2.1721\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8100 - mae: 1.2247 - val_loss: 6.7030 - val_mae: 1.9175\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8064 - mae: 1.2118 - val_loss: 6.5490 - val_mae: 1.8328\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7323 - mae: 1.2013 - val_loss: 6.5036 - val_mae: 1.8614\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7362 - mae: 1.2009 - val_loss: 6.4341 - val_mae: 1.8851\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8278 - mae: 1.1959 - val_loss: 7.3160 - val_mae: 2.1224\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6899 - mae: 1.1835 - val_loss: 6.6527 - val_mae: 1.9185\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7680 - mae: 1.1955 - val_loss: 6.9242 - val_mae: 1.9765\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7681 - mae: 1.2057 - val_loss: 7.1720 - val_mae: 1.9486\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.7569 - mae: 1.1893 - val_loss: 7.9458 - val_mae: 2.1690\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.7268 - mae: 1.1884 - val_loss: 6.9024 - val_mae: 1.9040\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.5600 - mae: 1.1622 - val_loss: 6.9539 - val_mae: 1.9604\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6961 - mae: 1.1746 - val_loss: 7.0731 - val_mae: 2.0491\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6286 - mae: 1.1513 - val_loss: 6.9674 - val_mae: 1.9194\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.6443 - mae: 1.1683 - val_loss: 7.4367 - val_mae: 2.1034\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6461 - mae: 1.2002 - val_loss: 7.7151 - val_mae: 2.2165\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5280 - mae: 1.1257 - val_loss: 6.3738 - val_mae: 1.8541\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.5900 - mae: 1.1541 - val_loss: 7.1477 - val_mae: 2.0483\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5046 - mae: 1.1446 - val_loss: 6.5983 - val_mae: 1.8772\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8031 - mae: 1.2130 - val_loss: 7.3766 - val_mae: 2.0269\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6045 - mae: 1.1613 - val_loss: 7.7287 - val_mae: 2.1964\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.4992 - mae: 1.1645 - val_loss: 6.9204 - val_mae: 1.9795\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6129 - mae: 1.1879 - val_loss: 6.9364 - val_mae: 1.9803\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4381 - mae: 1.1125 - val_loss: 6.9529 - val_mae: 1.9157\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6166 - mae: 1.2011 - val_loss: 6.6695 - val_mae: 1.8851\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4191 - mae: 1.1375 - val_loss: 6.9256 - val_mae: 1.9713\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4977 - mae: 1.1193 - val_loss: 6.8505 - val_mae: 1.9274\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6449 - mae: 1.1781 - val_loss: 7.5469 - val_mae: 2.0220\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.3871 - mae: 1.1254 - val_loss: 7.2189 - val_mae: 2.0207\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.5009 - mae: 1.1538 - val_loss: 7.5182 - val_mae: 2.1017\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4147 - mae: 1.1165 - val_loss: 7.1759 - val_mae: 2.0254\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4931 - mae: 1.1360 - val_loss: 6.9804 - val_mae: 1.9591\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4050 - mae: 1.1077 - val_loss: 6.9866 - val_mae: 2.0230\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4976 - mae: 1.1513 - val_loss: 7.3576 - val_mae: 2.0417\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4862 - mae: 1.1402 - val_loss: 6.6873 - val_mae: 1.8993\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3088 - mae: 1.0806 - val_loss: 7.9141 - val_mae: 2.1953\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5493 - mae: 1.1436 - val_loss: 6.7032 - val_mae: 1.8847\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3372 - mae: 1.0794 - val_loss: 6.7886 - val_mae: 1.8932\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3945 - mae: 1.1160 - val_loss: 6.7664 - val_mae: 1.9236\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.5178 - mae: 1.1855 - val_loss: 7.4612 - val_mae: 2.0748\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3543 - mae: 1.1052 - val_loss: 7.0951 - val_mae: 1.9669\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2106 - mae: 1.0691 - val_loss: 6.9340 - val_mae: 1.8953\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2170 - mae: 1.0676 - val_loss: 6.8913 - val_mae: 1.9087\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3914 - mae: 1.1021 - val_loss: 7.0249 - val_mae: 1.9804\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1369 - mae: 1.0645 - val_loss: 7.4680 - val_mae: 2.0814\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3770 - mae: 1.1039 - val_loss: 7.0861 - val_mae: 1.9504\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1115 - mae: 1.0765 - val_loss: 6.7890 - val_mae: 1.8971\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2276 - mae: 1.1230 - val_loss: 6.9337 - val_mae: 1.9917\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2226 - mae: 1.0771 - val_loss: 6.7264 - val_mae: 1.8658\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3192 - mae: 1.1002 - val_loss: 6.8536 - val_mae: 1.9174\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1594 - mae: 1.0260 - val_loss: 6.8011 - val_mae: 1.9225\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3211 - mae: 1.1103 - val_loss: 7.7281 - val_mae: 2.1239\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.3081 - mae: 1.1137 - val_loss: 6.8780 - val_mae: 1.9540\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1011 - mae: 1.0416 - val_loss: 7.0395 - val_mae: 2.0515\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3073 - mae: 1.1151 - val_loss: 6.8612 - val_mae: 1.9471\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3732 - mae: 1.1076 - val_loss: 6.8365 - val_mae: 1.9391\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1962 - mae: 1.0594 - val_loss: 7.0872 - val_mae: 1.9395\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1956 - mae: 1.0795 - val_loss: 6.9210 - val_mae: 1.9150\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0642 - mae: 1.0293 - val_loss: 7.3276 - val_mae: 1.9460\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0533 - mae: 1.0541 - val_loss: 9.3089 - val_mae: 2.4077\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2533 - mae: 1.0897 - val_loss: 7.1132 - val_mae: 1.9521\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1586 - mae: 1.0601 - val_loss: 6.7879 - val_mae: 1.8932\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2466 - mae: 1.0826 - val_loss: 6.8353 - val_mae: 1.9180\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.1573 - mae: 1.0500 - val_loss: 7.2746 - val_mae: 1.9676\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0229 - mae: 1.0566 - val_loss: 7.3417 - val_mae: 1.9981\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.0506 - mae: 1.0140 - val_loss: 7.9058 - val_mae: 2.1385\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1878 - mae: 1.0714 - val_loss: 7.1699 - val_mae: 1.9561\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0427 - mae: 1.0428 - val_loss: 7.0025 - val_mae: 1.9653\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8415 - mae: 1.0078 - val_loss: 7.2198 - val_mae: 1.9384\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0062 - mae: 1.0210 - val_loss: 8.8727 - val_mae: 2.3065\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0248 - mae: 1.0635 - val_loss: 6.9180 - val_mae: 1.9239\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0590 - mae: 1.0453 - val_loss: 7.0178 - val_mae: 1.9178\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0141 - mae: 1.0363 - val_loss: 6.8809 - val_mae: 1.9250\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8576 - mae: 0.9884 - val_loss: 7.1613 - val_mae: 1.9600\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0207 - mae: 1.0415 - val_loss: 7.1586 - val_mae: 1.9782\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9938 - mae: 1.0217 - val_loss: 7.0131 - val_mae: 1.9603\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9611 - mae: 1.0204 - val_loss: 7.7874 - val_mae: 2.1228\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0810 - mae: 1.0292 - val_loss: 7.1597 - val_mae: 1.9397\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0173 - mae: 1.0332 - val_loss: 7.1979 - val_mae: 1.9525\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9174 - mae: 0.9921 - val_loss: 8.2584 - val_mae: 2.2022\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8261 - mae: 0.9925 - val_loss: 6.8628 - val_mae: 1.9007\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8611 - mae: 1.0169 - val_loss: 7.1608 - val_mae: 1.9130\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0781 - mae: 1.0629 - val_loss: 7.1432 - val_mae: 1.9207\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8070 - mae: 0.9953 - val_loss: 7.4543 - val_mae: 2.0214\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9615 - mae: 1.0274 - val_loss: 7.2601 - val_mae: 1.9476\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7467 - mae: 0.9724 - val_loss: 7.5712 - val_mae: 1.9873\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8622 - mae: 1.0000 - val_loss: 7.6289 - val_mae: 1.9802\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8489 - mae: 0.9936 - val_loss: 7.9957 - val_mae: 2.0965\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8546 - mae: 1.0203 - val_loss: 7.5415 - val_mae: 1.9901\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8588 - mae: 0.9956 - val_loss: 7.9335 - val_mae: 2.0877\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8948 - mae: 1.0178 - val_loss: 7.3189 - val_mae: 2.0231\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8257 - mae: 0.9839 - val_loss: 7.3525 - val_mae: 1.9509\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8362 - mae: 0.9971 - val_loss: 7.2457 - val_mae: 1.9451\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7885 - mae: 0.9714 - val_loss: 7.3570 - val_mae: 1.9990\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7862 - mae: 0.9872 - val_loss: 7.8536 - val_mae: 2.1407\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7626 - mae: 0.9602 - val_loss: 7.1438 - val_mae: 1.9299\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8386 - mae: 0.9950 - val_loss: 8.3093 - val_mae: 2.1761\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8271 - mae: 0.9959 - val_loss: 7.7917 - val_mae: 2.0705\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5768 - mae: 0.9291 - val_loss: 7.7327 - val_mae: 2.0782\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9080 - mae: 1.0302 - val_loss: 7.2196 - val_mae: 1.9487\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7095 - mae: 0.9561 - val_loss: 7.6231 - val_mae: 2.0497\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6686 - mae: 0.9527 - val_loss: 7.3483 - val_mae: 1.9779\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8087 - mae: 0.9861 - val_loss: 7.7665 - val_mae: 2.0656\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6613 - mae: 0.9855 - val_loss: 7.5363 - val_mae: 2.0069\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6781 - mae: 0.9294 - val_loss: 7.4112 - val_mae: 2.0187\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7138 - mae: 0.9537 - val_loss: 7.3141 - val_mae: 1.9507\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8599 - mae: 1.0000 - val_loss: 7.4577 - val_mae: 1.9929\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6870 - mae: 0.9485 - val_loss: 7.3188 - val_mae: 1.9600\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 1.6540 - mae: 0.9457 - val_loss: 7.4885 - val_mae: 2.0016\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7276 - mae: 0.9587 - val_loss: 8.0152 - val_mae: 2.1052\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6606 - mae: 0.9544 - val_loss: 7.4320 - val_mae: 2.0094\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6368 - mae: 0.9392 - val_loss: 7.1737 - val_mae: 1.9299\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6984 - mae: 0.9547 - val_loss: 7.5335 - val_mae: 2.0555\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6946 - mae: 0.9577 - val_loss: 7.2989 - val_mae: 1.9588\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5672 - mae: 0.9089 - val_loss: 7.2992 - val_mae: 1.9563\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6136 - mae: 0.9317 - val_loss: 7.6170 - val_mae: 2.0368\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6191 - mae: 0.9142 - val_loss: 7.2774 - val_mae: 1.9780\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6585 - mae: 0.9624 - val_loss: 7.4666 - val_mae: 1.9948\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5774 - mae: 0.9391 - val_loss: 7.6066 - val_mae: 2.0130\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5006 - mae: 0.9124 - val_loss: 7.1955 - val_mae: 1.9999\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5963 - mae: 0.9204 - val_loss: 7.6999 - val_mae: 2.0594\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6783 - mae: 0.9499 - val_loss: 7.4023 - val_mae: 1.9469\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6233 - mae: 0.9156 - val_loss: 7.2574 - val_mae: 1.9868\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5673 - mae: 0.9048 - val_loss: 7.5421 - val_mae: 2.0393\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7225 - mae: 0.9505 - val_loss: 7.5304 - val_mae: 2.0147\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5465 - mae: 0.8955 - val_loss: 7.7756 - val_mae: 2.1161\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4366 - mae: 0.8655 - val_loss: 7.8246 - val_mae: 2.0975\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5571 - mae: 0.8944 - val_loss: 7.2647 - val_mae: 1.9849\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4998 - mae: 0.9122 - val_loss: 7.4428 - val_mae: 2.0082\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4270 - mae: 0.8762 - val_loss: 7.6389 - val_mae: 2.0702\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6153 - mae: 0.9304 - val_loss: 7.3482 - val_mae: 1.9609\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5879 - mae: 0.8874 - val_loss: 7.1967 - val_mae: 1.9688\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3993 - mae: 0.8762 - val_loss: 7.4931 - val_mae: 2.0185\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3958 - mae: 0.8578 - val_loss: 8.2854 - val_mae: 2.1555\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3812 - mae: 0.8549 - val_loss: 8.1479 - val_mae: 2.1348\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5405 - mae: 0.8817 - val_loss: 7.6756 - val_mae: 2.0003\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.3963 - mae: 0.8587 - val_loss: 7.9816 - val_mae: 2.0885\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5174 - mae: 0.9079 - val_loss: 7.9506 - val_mae: 2.0959\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3898 - mae: 0.8454 - val_loss: 8.2487 - val_mae: 2.1634\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5696 - mae: 0.9161 - val_loss: 7.4972 - val_mae: 1.9918\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3923 - mae: 0.8593 - val_loss: 7.5261 - val_mae: 2.0165\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3804 - mae: 0.8749 - val_loss: 7.5789 - val_mae: 1.9822\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4281 - mae: 0.8813 - val_loss: 7.4346 - val_mae: 2.0177\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4225 - mae: 0.8675 - val_loss: 7.7739 - val_mae: 2.0771\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4231 - mae: 0.8977 - val_loss: 7.0870 - val_mae: 1.9410\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3484 - mae: 0.8590 - val_loss: 7.3108 - val_mae: 1.9686\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3813 - mae: 0.8533 - val_loss: 7.5507 - val_mae: 2.0205\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4656 - mae: 0.9013 - val_loss: 7.3204 - val_mae: 2.0027\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3237 - mae: 0.8551 - val_loss: 7.4444 - val_mae: 2.0157\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3518 - mae: 0.8460 - val_loss: 7.6087 - val_mae: 1.9880\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4001 - mae: 0.8670 - val_loss: 7.8951 - val_mae: 2.1078\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3597 - mae: 0.8588 - val_loss: 7.7805 - val_mae: 2.0278\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3853 - mae: 0.8674 - val_loss: 7.6743 - val_mae: 2.1007\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3444 - mae: 0.8322 - val_loss: 9.3707 - val_mae: 2.3285\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3912 - mae: 0.8361 - val_loss: 7.8020 - val_mae: 2.0457\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3043 - mae: 0.8347 - val_loss: 7.9145 - val_mae: 2.1247\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3499 - mae: 0.8512 - val_loss: 7.5278 - val_mae: 1.9961\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4301 - mae: 0.8556 - val_loss: 7.2819 - val_mae: 1.9596\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3239 - mae: 0.8351 - val_loss: 8.6568 - val_mae: 2.2054\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3600 - mae: 0.8607 - val_loss: 7.8213 - val_mae: 2.0119\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1770 - mae: 0.7861 - val_loss: 7.9426 - val_mae: 2.0949\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3601 - mae: 0.8525 - val_loss: 7.6073 - val_mae: 2.0039\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2916 - mae: 0.8272 - val_loss: 7.8936 - val_mae: 2.0633\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2576 - mae: 0.8555 - val_loss: 9.0499 - val_mae: 2.2163\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2030 - mae: 0.8139 - val_loss: 7.5381 - val_mae: 1.9862\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1922 - mae: 0.8085 - val_loss: 7.5148 - val_mae: 1.9813\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3261 - mae: 0.8719 - val_loss: 7.9100 - val_mae: 2.0944\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1632 - mae: 0.7964 - val_loss: 7.6955 - val_mae: 2.0787\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2803 - mae: 0.8252 - val_loss: 7.8281 - val_mae: 2.0272\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2985 - mae: 0.8165 - val_loss: 8.4334 - val_mae: 2.1806\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1940 - mae: 0.7892 - val_loss: 7.7454 - val_mae: 2.0728\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3177 - mae: 0.8606 - val_loss: 8.2027 - val_mae: 2.1633\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2697 - mae: 0.8406 - val_loss: 7.5702 - val_mae: 2.0209\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1831 - mae: 0.7905 - val_loss: 7.8350 - val_mae: 2.0394\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3130 - mae: 0.8502 - val_loss: 7.8857 - val_mae: 2.0268\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1624 - mae: 0.7642 - val_loss: 7.6542 - val_mae: 2.0155\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1548 - mae: 0.7920 - val_loss: 8.1420 - val_mae: 2.1195\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1153 - mae: 0.7674 - val_loss: 7.8383 - val_mae: 2.0862\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4292 - mae: 0.8847 - val_loss: 7.7380 - val_mae: 2.0399\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1631 - mae: 0.7983 - val_loss: 7.8971 - val_mae: 2.0911\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1527 - mae: 0.7939 - val_loss: 7.7322 - val_mae: 2.0291\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1884 - mae: 0.7838 - val_loss: 7.6416 - val_mae: 2.0252\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1133 - mae: 0.7960 - val_loss: 7.7335 - val_mae: 2.0420\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2267 - mae: 0.8193 - val_loss: 7.8479 - val_mae: 2.0305\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1949 - mae: 0.7947 - val_loss: 8.2154 - val_mae: 2.1353\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1422 - mae: 0.7695 - val_loss: 8.3502 - val_mae: 2.1279\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1765 - mae: 0.8010 - val_loss: 7.4720 - val_mae: 1.9966\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1558 - mae: 0.7969 - val_loss: 8.2900 - val_mae: 2.1651\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1339 - mae: 0.7770 - val_loss: 9.0118 - val_mae: 2.2220\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2509 - mae: 0.8368 - val_loss: 7.6169 - val_mae: 2.0194\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1914 - mae: 0.7819 - val_loss: 7.7122 - val_mae: 2.0327\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0387 - mae: 0.7595 - val_loss: 7.9819 - val_mae: 2.0567\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1505 - mae: 0.7718 - val_loss: 7.9401 - val_mae: 2.0425\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0490 - mae: 0.7484 - val_loss: 8.1961 - val_mae: 2.1496\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1964 - mae: 0.7886 - val_loss: 8.4405 - val_mae: 2.1649\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1143 - mae: 0.7961 - val_loss: 7.7504 - val_mae: 2.0478\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1688 - mae: 0.8202 - val_loss: 7.5727 - val_mae: 2.0097\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0621 - mae: 0.7650 - val_loss: 8.1515 - val_mae: 2.0716\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0373 - mae: 0.7526 - val_loss: 7.9795 - val_mae: 2.0397\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0836 - mae: 0.7644 - val_loss: 7.9028 - val_mae: 2.0814\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0667 - mae: 0.7486 - val_loss: 7.9361 - val_mae: 2.0239\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0943 - mae: 0.7781 - val_loss: 8.2725 - val_mae: 2.1066\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0748 - mae: 0.7520 - val_loss: 8.0708 - val_mae: 2.0475\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1540 - mae: 0.7928 - val_loss: 7.6638 - val_mae: 2.0411\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1358 - mae: 0.7779 - val_loss: 8.1554 - val_mae: 2.1434\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0682 - mae: 0.7574 - val_loss: 7.8807 - val_mae: 2.0393\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0578 - mae: 0.7549 - val_loss: 7.8515 - val_mae: 2.0313\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1340 - mae: 0.7828 - val_loss: 7.4459 - val_mae: 2.0211\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0170 - mae: 0.7439 - val_loss: 7.8073 - val_mae: 2.0316\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0833 - mae: 0.7777 - val_loss: 8.1360 - val_mae: 2.1362\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9910 - mae: 0.7449 - val_loss: 7.6502 - val_mae: 2.0280\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0073 - mae: 0.7612 - val_loss: 8.3857 - val_mae: 2.1535\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0763 - mae: 0.7950 - val_loss: 8.6326 - val_mae: 2.1579\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0358 - mae: 0.7643 - val_loss: 7.7331 - val_mae: 2.0778\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0643 - mae: 0.7355 - val_loss: 7.8484 - val_mae: 2.0537\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9412 - mae: 0.7130 - val_loss: 8.3136 - val_mae: 2.1489\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0318 - mae: 0.7644 - val_loss: 8.4543 - val_mae: 2.1165\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0107 - mae: 0.7306 - val_loss: 8.1520 - val_mae: 2.0908\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0522 - mae: 0.7494 - val_loss: 8.4865 - val_mae: 2.0864\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9931 - mae: 0.7367 - val_loss: 8.2231 - val_mae: 2.1093\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0424 - mae: 0.7645 - val_loss: 8.1789 - val_mae: 2.0541\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0112 - mae: 0.7297 - val_loss: 8.3060 - val_mae: 2.1448\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1814 - mae: 0.7807 - val_loss: 7.8479 - val_mae: 2.0675\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8857 - mae: 0.6928 - val_loss: 7.7825 - val_mae: 2.0435\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8926 - mae: 0.7068 - val_loss: 8.0381 - val_mae: 2.0300\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0447 - mae: 0.7487 - val_loss: 8.5992 - val_mae: 2.2049\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0051 - mae: 0.7560 - val_loss: 8.0687 - val_mae: 2.0561\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9819 - mae: 0.7088 - val_loss: 10.2217 - val_mae: 2.4274\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9959 - mae: 0.7289 - val_loss: 8.3248 - val_mae: 2.1324\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0052 - mae: 0.7434 - val_loss: 8.4631 - val_mae: 2.0889\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9750 - mae: 0.7291 - val_loss: 8.1864 - val_mae: 2.0869\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0378 - mae: 0.7291 - val_loss: 8.1441 - val_mae: 2.1119\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8771 - mae: 0.6985 - val_loss: 7.9670 - val_mae: 2.0616\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0498 - mae: 0.7578 - val_loss: 8.6616 - val_mae: 2.1551\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8463 - mae: 0.6966 - val_loss: 8.4407 - val_mae: 2.1109\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0591 - mae: 0.7744 - val_loss: 7.6718 - val_mae: 2.0458\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8826 - mae: 0.7013 - val_loss: 7.8235 - val_mae: 2.0105\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9226 - mae: 0.6883 - val_loss: 8.0422 - val_mae: 2.0766\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9370 - mae: 0.7234 - val_loss: 7.8620 - val_mae: 2.0386\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8575 - mae: 0.6832 - val_loss: 8.2488 - val_mae: 2.0978\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9785 - mae: 0.7344 - val_loss: 8.7282 - val_mae: 2.1653\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9367 - mae: 0.7285 - val_loss: 8.4750 - val_mae: 2.1030\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9920 - mae: 0.7366 - val_loss: 8.3609 - val_mae: 2.1067\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9613 - mae: 0.7007 - val_loss: 8.2617 - val_mae: 2.1005\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0109 - mae: 0.7338 - val_loss: 8.6510 - val_mae: 2.1506\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9265 - mae: 0.7166 - val_loss: 8.0616 - val_mae: 2.0484\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 0.8430 - mae: 0.6763 - val_loss: 8.9122 - val_mae: 2.1929\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9541 - mae: 0.7408 - val_loss: 8.3336 - val_mae: 2.0757\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9630 - mae: 0.7127 - val_loss: 7.9505 - val_mae: 2.0539\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9290 - mae: 0.7052 - val_loss: 8.2673 - val_mae: 2.0938\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8206 - mae: 0.6898 - val_loss: 8.6143 - val_mae: 2.1882\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9232 - mae: 0.6985 - val_loss: 8.1417 - val_mae: 2.0920\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9213 - mae: 0.6727 - val_loss: 8.1220 - val_mae: 2.0622\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8438 - mae: 0.6521 - val_loss: 8.3056 - val_mae: 2.0810\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9478 - mae: 0.6853 - val_loss: 8.5915 - val_mae: 2.1445\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9507 - mae: 0.7232 - val_loss: 8.2845 - val_mae: 2.1680\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7512 - mae: 0.6386 - val_loss: 8.6928 - val_mae: 2.1574\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9503 - mae: 0.7170 - val_loss: 8.1794 - val_mae: 2.1355\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7842 - mae: 0.6437 - val_loss: 8.8880 - val_mae: 2.1563\n",
            "Processing fold #1\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 532.6863 - mae: 21.1058 - val_loss: 436.2392 - val_mae: 19.2341\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 406.0208 - mae: 18.1006 - val_loss: 301.4521 - val_mae: 15.6931\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 257.0452 - mae: 13.9886 - val_loss: 159.9773 - val_mae: 11.0625\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 130.2894 - mae: 9.2669 - val_loss: 68.8267 - val_mae: 6.6955\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 63.3406 - mae: 6.0068 - val_loss: 36.5613 - val_mae: 4.7473\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 41.5720 - mae: 4.6717 - val_loss: 27.3738 - val_mae: 4.1309\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 32.4401 - mae: 4.0464 - val_loss: 23.5562 - val_mae: 3.8189\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 27.2603 - mae: 3.6923 - val_loss: 22.4679 - val_mae: 3.7176\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 24.2452 - mae: 3.5132 - val_loss: 20.0333 - val_mae: 3.4518\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 21.9941 - mae: 3.2592 - val_loss: 19.2173 - val_mae: 3.3971\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 19.9776 - mae: 3.0899 - val_loss: 18.5923 - val_mae: 3.3426\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 18.6302 - mae: 3.0375 - val_loss: 17.1165 - val_mae: 3.1498\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 17.2337 - mae: 2.8616 - val_loss: 17.4783 - val_mae: 3.1709\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 16.2246 - mae: 2.7858 - val_loss: 17.2579 - val_mae: 3.2022\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 15.6562 - mae: 2.7515 - val_loss: 15.9945 - val_mae: 3.1141\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 14.6542 - mae: 2.6592 - val_loss: 14.7067 - val_mae: 2.9302\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.7476 - mae: 2.5313 - val_loss: 14.4969 - val_mae: 2.9338\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.3675 - mae: 2.4679 - val_loss: 14.0099 - val_mae: 2.9086\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.7731 - mae: 2.4428 - val_loss: 14.0206 - val_mae: 2.9157\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 12.2796 - mae: 2.4223 - val_loss: 13.4074 - val_mae: 2.7705\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 12.1138 - mae: 2.3987 - val_loss: 13.2070 - val_mae: 2.8086\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.4644 - mae: 2.3142 - val_loss: 12.5230 - val_mae: 2.7360\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.3898 - mae: 2.3515 - val_loss: 12.3201 - val_mae: 2.6508\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.1181 - mae: 2.2974 - val_loss: 12.2524 - val_mae: 2.7199\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.7189 - mae: 2.2826 - val_loss: 12.2881 - val_mae: 2.7066\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 10.6793 - mae: 2.2274 - val_loss: 12.9741 - val_mae: 2.8203\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.3947 - mae: 2.1977 - val_loss: 11.8598 - val_mae: 2.6560\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.3304 - mae: 2.2275 - val_loss: 11.6463 - val_mae: 2.6410\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.8777 - mae: 2.1864 - val_loss: 12.2776 - val_mae: 2.7482\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.1478 - mae: 2.2098 - val_loss: 12.4261 - val_mae: 2.7690\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.8167 - mae: 2.1743 - val_loss: 11.1428 - val_mae: 2.5879\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.7101 - mae: 2.1622 - val_loss: 11.6472 - val_mae: 2.6477\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.8111 - mae: 2.1457 - val_loss: 12.4544 - val_mae: 2.7899\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.5679 - mae: 2.1256 - val_loss: 12.2775 - val_mae: 2.7579\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.3396 - mae: 2.1257 - val_loss: 11.2583 - val_mae: 2.6091\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.5657 - mae: 2.1503 - val_loss: 11.8457 - val_mae: 2.6986\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.3519 - mae: 2.1349 - val_loss: 11.3556 - val_mae: 2.6268\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.0938 - mae: 2.0673 - val_loss: 11.6253 - val_mae: 2.6682\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.8974 - mae: 2.0585 - val_loss: 12.7864 - val_mae: 2.8431\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.1261 - mae: 2.0990 - val_loss: 11.4944 - val_mae: 2.6468\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.9229 - mae: 2.1089 - val_loss: 11.0351 - val_mae: 2.5878\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.9761 - mae: 2.0572 - val_loss: 11.5398 - val_mae: 2.6528\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 8.7654 - mae: 2.0456 - val_loss: 11.4983 - val_mae: 2.6565\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.6157 - mae: 2.0585 - val_loss: 11.5128 - val_mae: 2.6529\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 8.5478 - mae: 2.0393 - val_loss: 10.5619 - val_mae: 2.5039\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.4531 - mae: 1.9946 - val_loss: 11.4273 - val_mae: 2.6407\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.2337 - mae: 2.0025 - val_loss: 10.8880 - val_mae: 2.5091\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.4249 - mae: 1.9958 - val_loss: 11.1146 - val_mae: 2.5896\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.3253 - mae: 1.9969 - val_loss: 11.5563 - val_mae: 2.6691\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.4353 - mae: 2.0266 - val_loss: 11.1186 - val_mae: 2.5917\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0482 - mae: 1.9703 - val_loss: 10.8197 - val_mae: 2.5468\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.1412 - mae: 1.9890 - val_loss: 10.6372 - val_mae: 2.5246\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.0051 - mae: 1.9379 - val_loss: 11.9441 - val_mae: 2.7337\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.0082 - mae: 1.9469 - val_loss: 10.8526 - val_mae: 2.5686\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.7596 - mae: 1.9311 - val_loss: 10.2875 - val_mae: 2.4893\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.7994 - mae: 1.8982 - val_loss: 11.1702 - val_mae: 2.6238\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.8569 - mae: 1.9326 - val_loss: 12.1343 - val_mae: 2.7735\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.5220 - mae: 1.9434 - val_loss: 11.4604 - val_mae: 2.6555\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 1s 48ms/step - loss: 7.8199 - mae: 1.9102 - val_loss: 10.2847 - val_mae: 2.4812\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.4080 - mae: 1.9140 - val_loss: 11.1606 - val_mae: 2.6202\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 7.6099 - mae: 1.8585 - val_loss: 10.6313 - val_mae: 2.5343\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.4197 - mae: 1.8861 - val_loss: 10.3601 - val_mae: 2.5075\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.4706 - mae: 1.9064 - val_loss: 10.3961 - val_mae: 2.5103\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3202 - mae: 1.8852 - val_loss: 10.6570 - val_mae: 2.5126\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.2462 - mae: 1.8437 - val_loss: 12.2440 - val_mae: 2.7484\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 7.1800 - mae: 1.8613 - val_loss: 10.0721 - val_mae: 2.4512\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3397 - mae: 1.8538 - val_loss: 10.6115 - val_mae: 2.5336\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0489 - mae: 1.8155 - val_loss: 11.5413 - val_mae: 2.6741\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0645 - mae: 1.8832 - val_loss: 10.8139 - val_mae: 2.5549\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0672 - mae: 1.8526 - val_loss: 10.9153 - val_mae: 2.5798\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.8597 - mae: 1.8325 - val_loss: 10.6866 - val_mae: 2.5217\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.0265 - mae: 1.8560 - val_loss: 10.7022 - val_mae: 2.5532\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.7308 - mae: 1.7938 - val_loss: 10.9534 - val_mae: 2.6072\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.8044 - mae: 1.8288 - val_loss: 10.3938 - val_mae: 2.5094\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5321 - mae: 1.7785 - val_loss: 10.3706 - val_mae: 2.5130\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.6779 - mae: 1.7916 - val_loss: 11.0874 - val_mae: 2.6230\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.7665 - mae: 1.8263 - val_loss: 10.3526 - val_mae: 2.5169\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5374 - mae: 1.7355 - val_loss: 10.9557 - val_mae: 2.5956\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.2896 - mae: 1.7473 - val_loss: 11.0873 - val_mae: 2.6085\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5556 - mae: 1.7763 - val_loss: 10.2235 - val_mae: 2.4647\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3934 - mae: 1.7541 - val_loss: 10.8771 - val_mae: 2.5757\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.3508 - mae: 1.7565 - val_loss: 9.8295 - val_mae: 2.3932\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.3899 - mae: 1.7474 - val_loss: 10.9057 - val_mae: 2.5769\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.2530 - mae: 1.7115 - val_loss: 10.1903 - val_mae: 2.4680\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.1454 - mae: 1.7109 - val_loss: 10.0740 - val_mae: 2.4500\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0745 - mae: 1.7166 - val_loss: 9.8781 - val_mae: 2.3951\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 6.0228 - mae: 1.7548 - val_loss: 10.9685 - val_mae: 2.5962\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0529 - mae: 1.7241 - val_loss: 10.4398 - val_mae: 2.5004\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8395 - mae: 1.6662 - val_loss: 10.0083 - val_mae: 2.4262\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9862 - mae: 1.7085 - val_loss: 11.1233 - val_mae: 2.5957\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.9013 - mae: 1.6781 - val_loss: 11.5013 - val_mae: 2.6424\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8198 - mae: 1.6736 - val_loss: 11.0124 - val_mae: 2.5733\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6442 - mae: 1.6478 - val_loss: 12.8888 - val_mae: 2.8310\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6422 - mae: 1.7030 - val_loss: 10.1220 - val_mae: 2.4231\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8712 - mae: 1.6731 - val_loss: 11.4645 - val_mae: 2.6524\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5338 - mae: 1.6525 - val_loss: 9.9704 - val_mae: 2.4065\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6136 - mae: 1.6493 - val_loss: 10.4942 - val_mae: 2.5126\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5624 - mae: 1.6253 - val_loss: 10.2146 - val_mae: 2.4668\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5851 - mae: 1.6130 - val_loss: 10.4864 - val_mae: 2.4934\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5999 - mae: 1.6446 - val_loss: 11.5001 - val_mae: 2.6220\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.4312 - mae: 1.6175 - val_loss: 10.8063 - val_mae: 2.5370\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3891 - mae: 1.5985 - val_loss: 12.0453 - val_mae: 2.7024\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1288 - mae: 1.5738 - val_loss: 11.9106 - val_mae: 2.6851\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3852 - mae: 1.6398 - val_loss: 10.1776 - val_mae: 2.4381\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3205 - mae: 1.6092 - val_loss: 10.2285 - val_mae: 2.4529\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1822 - mae: 1.6255 - val_loss: 10.0713 - val_mae: 2.4035\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.2130 - mae: 1.5779 - val_loss: 10.0180 - val_mae: 2.3914\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1022 - mae: 1.6021 - val_loss: 10.0207 - val_mae: 2.4033\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0957 - mae: 1.5840 - val_loss: 10.7162 - val_mae: 2.5216\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9876 - mae: 1.5680 - val_loss: 11.6609 - val_mae: 2.6385\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8932 - mae: 1.5733 - val_loss: 10.8332 - val_mae: 2.5270\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0227 - mae: 1.5714 - val_loss: 9.8404 - val_mae: 2.3747\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.9580 - mae: 1.5421 - val_loss: 13.4828 - val_mae: 2.9270\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9050 - mae: 1.5869 - val_loss: 10.6434 - val_mae: 2.5222\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9208 - mae: 1.5585 - val_loss: 9.8846 - val_mae: 2.3844\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.6988 - mae: 1.5337 - val_loss: 10.2143 - val_mae: 2.4466\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7967 - mae: 1.5256 - val_loss: 10.9019 - val_mae: 2.5020\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5902 - mae: 1.5065 - val_loss: 11.8422 - val_mae: 2.6534\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6186 - mae: 1.5117 - val_loss: 10.8928 - val_mae: 2.5117\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.6236 - mae: 1.5475 - val_loss: 9.9376 - val_mae: 2.3875\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7113 - mae: 1.5336 - val_loss: 11.2201 - val_mae: 2.5872\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5282 - mae: 1.5015 - val_loss: 13.7148 - val_mae: 2.8771\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.6560 - mae: 1.5391 - val_loss: 13.4217 - val_mae: 2.8703\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5625 - mae: 1.5353 - val_loss: 11.1323 - val_mae: 2.6254\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5063 - mae: 1.4965 - val_loss: 11.4214 - val_mae: 2.6572\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4575 - mae: 1.5019 - val_loss: 10.4018 - val_mae: 2.4450\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5586 - mae: 1.5325 - val_loss: 10.5319 - val_mae: 2.4683\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1608 - mae: 1.4439 - val_loss: 10.4850 - val_mae: 2.4862\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4316 - mae: 1.4845 - val_loss: 12.4351 - val_mae: 2.7487\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2870 - mae: 1.4746 - val_loss: 10.4707 - val_mae: 2.4552\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4244 - mae: 1.5166 - val_loss: 12.2534 - val_mae: 2.7471\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2940 - mae: 1.4881 - val_loss: 10.2863 - val_mae: 2.4535\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1000 - mae: 1.4446 - val_loss: 11.1888 - val_mae: 2.5545\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3129 - mae: 1.4837 - val_loss: 11.2361 - val_mae: 2.6111\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0149 - mae: 1.4197 - val_loss: 11.1360 - val_mae: 2.5871\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0720 - mae: 1.4270 - val_loss: 11.6451 - val_mae: 2.6291\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0663 - mae: 1.4428 - val_loss: 11.4674 - val_mae: 2.6537\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0255 - mae: 1.4226 - val_loss: 10.8892 - val_mae: 2.4501\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8615 - mae: 1.4117 - val_loss: 12.2332 - val_mae: 2.6255\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8899 - mae: 1.4325 - val_loss: 13.4826 - val_mae: 2.8037\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9691 - mae: 1.4513 - val_loss: 10.2425 - val_mae: 2.4215\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1137 - mae: 1.4531 - val_loss: 11.9341 - val_mae: 2.6659\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7830 - mae: 1.3637 - val_loss: 11.5937 - val_mae: 2.6021\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9441 - mae: 1.4194 - val_loss: 10.9674 - val_mae: 2.5160\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8909 - mae: 1.4078 - val_loss: 11.0938 - val_mae: 2.4845\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8063 - mae: 1.4094 - val_loss: 10.8703 - val_mae: 2.5175\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7862 - mae: 1.4024 - val_loss: 10.7053 - val_mae: 2.4146\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7487 - mae: 1.3830 - val_loss: 11.9852 - val_mae: 2.6182\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6363 - mae: 1.3643 - val_loss: 12.4709 - val_mae: 2.6687\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5746 - mae: 1.3517 - val_loss: 10.8312 - val_mae: 2.4774\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6847 - mae: 1.3801 - val_loss: 10.5923 - val_mae: 2.3929\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6051 - mae: 1.3417 - val_loss: 13.2387 - val_mae: 2.7936\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5102 - mae: 1.3724 - val_loss: 11.2763 - val_mae: 2.4888\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5617 - mae: 1.3761 - val_loss: 11.5487 - val_mae: 2.5303\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5812 - mae: 1.3671 - val_loss: 11.0209 - val_mae: 2.4212\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5687 - mae: 1.3374 - val_loss: 10.9309 - val_mae: 2.4669\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5642 - mae: 1.3779 - val_loss: 12.7719 - val_mae: 2.7250\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4844 - mae: 1.3508 - val_loss: 10.9239 - val_mae: 2.5066\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5269 - mae: 1.3250 - val_loss: 12.1883 - val_mae: 2.7007\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5104 - mae: 1.3630 - val_loss: 12.1635 - val_mae: 2.5717\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5319 - mae: 1.3733 - val_loss: 11.2751 - val_mae: 2.4712\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3318 - mae: 1.3270 - val_loss: 11.3961 - val_mae: 2.4940\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2684 - mae: 1.2784 - val_loss: 14.1411 - val_mae: 2.9206\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3656 - mae: 1.3364 - val_loss: 13.8454 - val_mae: 2.8483\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3513 - mae: 1.3203 - val_loss: 12.2296 - val_mae: 2.6662\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4467 - mae: 1.3290 - val_loss: 12.0628 - val_mae: 2.5759\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3946 - mae: 1.3226 - val_loss: 13.1596 - val_mae: 2.6867\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3806 - mae: 1.3154 - val_loss: 12.3726 - val_mae: 2.5967\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2870 - mae: 1.3176 - val_loss: 13.8116 - val_mae: 2.7701\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2434 - mae: 1.3164 - val_loss: 10.8934 - val_mae: 2.4533\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1308 - mae: 1.3093 - val_loss: 13.3525 - val_mae: 2.7895\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2164 - mae: 1.2622 - val_loss: 11.0949 - val_mae: 2.3814\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1573 - mae: 1.2803 - val_loss: 11.3195 - val_mae: 2.5278\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2131 - mae: 1.2718 - val_loss: 10.9171 - val_mae: 2.4204\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1594 - mae: 1.2897 - val_loss: 12.3732 - val_mae: 2.5839\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0986 - mae: 1.2636 - val_loss: 12.3661 - val_mae: 2.5417\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9824 - mae: 1.2579 - val_loss: 13.4738 - val_mae: 2.7192\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1460 - mae: 1.2922 - val_loss: 11.2255 - val_mae: 2.4690\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1733 - mae: 1.2661 - val_loss: 12.6048 - val_mae: 2.5888\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1435 - mae: 1.2565 - val_loss: 13.1534 - val_mae: 2.6576\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9117 - mae: 1.2450 - val_loss: 12.3419 - val_mae: 2.5426\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9282 - mae: 1.2407 - val_loss: 11.7075 - val_mae: 2.4750\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0388 - mae: 1.2471 - val_loss: 11.6514 - val_mae: 2.4867\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8335 - mae: 1.2185 - val_loss: 12.0203 - val_mae: 2.5605\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0239 - mae: 1.2556 - val_loss: 11.3904 - val_mae: 2.4226\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8378 - mae: 1.2353 - val_loss: 12.4183 - val_mae: 2.6295\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0144 - mae: 1.2592 - val_loss: 11.7517 - val_mae: 2.4494\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6931 - mae: 1.1454 - val_loss: 11.8276 - val_mae: 2.4184\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.8253 - mae: 1.2290 - val_loss: 13.4527 - val_mae: 2.6981\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8338 - mae: 1.2263 - val_loss: 13.0569 - val_mae: 2.7200\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7351 - mae: 1.1860 - val_loss: 14.0189 - val_mae: 2.8100\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8927 - mae: 1.2134 - val_loss: 12.7792 - val_mae: 2.5554\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7821 - mae: 1.1779 - val_loss: 11.8670 - val_mae: 2.4486\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9093 - mae: 1.2139 - val_loss: 12.9159 - val_mae: 2.5504\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6294 - mae: 1.1525 - val_loss: 13.2844 - val_mae: 2.7006\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8159 - mae: 1.2096 - val_loss: 12.5633 - val_mae: 2.5380\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 2.8064 - mae: 1.2222 - val_loss: 13.4845 - val_mae: 2.5362\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6089 - mae: 1.1698 - val_loss: 16.0163 - val_mae: 2.9980\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8296 - mae: 1.2118 - val_loss: 13.2931 - val_mae: 2.6906\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8277 - mae: 1.2011 - val_loss: 12.0743 - val_mae: 2.4568\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.5179 - mae: 1.1459 - val_loss: 12.7921 - val_mae: 2.4808\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6218 - mae: 1.1699 - val_loss: 16.1862 - val_mae: 3.0227\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7633 - mae: 1.1794 - val_loss: 13.7274 - val_mae: 2.6530\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5873 - mae: 1.1431 - val_loss: 11.8703 - val_mae: 2.4738\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5997 - mae: 1.1768 - val_loss: 13.2965 - val_mae: 2.6415\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5764 - mae: 1.1513 - val_loss: 13.2877 - val_mae: 2.6535\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6026 - mae: 1.1553 - val_loss: 11.7629 - val_mae: 2.4624\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5497 - mae: 1.1694 - val_loss: 12.4029 - val_mae: 2.4526\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4729 - mae: 1.1188 - val_loss: 14.6071 - val_mae: 2.6848\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4942 - mae: 1.1231 - val_loss: 16.1017 - val_mae: 2.9838\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5169 - mae: 1.1367 - val_loss: 12.9170 - val_mae: 2.5842\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.2779 - mae: 1.1124 - val_loss: 14.1960 - val_mae: 2.6276\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5833 - mae: 1.1586 - val_loss: 13.9393 - val_mae: 2.6507\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 2.4982 - mae: 1.1426 - val_loss: 13.3841 - val_mae: 2.5023\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4921 - mae: 1.1556 - val_loss: 13.6223 - val_mae: 2.6364\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5206 - mae: 1.1154 - val_loss: 14.5985 - val_mae: 2.7762\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3113 - mae: 1.0639 - val_loss: 13.9593 - val_mae: 2.6442\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3545 - mae: 1.0980 - val_loss: 14.2156 - val_mae: 2.7317\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3620 - mae: 1.0991 - val_loss: 12.9168 - val_mae: 2.5128\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3130 - mae: 1.1091 - val_loss: 15.6086 - val_mae: 2.8245\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4724 - mae: 1.1099 - val_loss: 12.8807 - val_mae: 2.4633\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3399 - mae: 1.1002 - val_loss: 12.3159 - val_mae: 2.4176\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2949 - mae: 1.1054 - val_loss: 12.6357 - val_mae: 2.4843\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2964 - mae: 1.1036 - val_loss: 16.5863 - val_mae: 2.9334\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3489 - mae: 1.0839 - val_loss: 13.7898 - val_mae: 2.6680\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4555 - mae: 1.1406 - val_loss: 14.2476 - val_mae: 2.6108\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1725 - mae: 1.0572 - val_loss: 14.3259 - val_mae: 2.7576\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2730 - mae: 1.0859 - val_loss: 12.8414 - val_mae: 2.4528\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2934 - mae: 1.0721 - val_loss: 14.7557 - val_mae: 2.7056\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 2.1081 - mae: 1.0660 - val_loss: 13.8467 - val_mae: 2.5417\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2875 - mae: 1.0934 - val_loss: 13.1052 - val_mae: 2.4951\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2581 - mae: 1.0749 - val_loss: 14.4888 - val_mae: 2.6781\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2280 - mae: 1.0786 - val_loss: 13.0711 - val_mae: 2.4532\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2228 - mae: 1.0535 - val_loss: 12.6033 - val_mae: 2.5188\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1084 - mae: 1.0388 - val_loss: 14.4081 - val_mae: 2.7661\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1941 - mae: 1.0865 - val_loss: 14.4305 - val_mae: 2.5882\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3080 - mae: 1.0815 - val_loss: 14.0804 - val_mae: 2.6284\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0978 - mae: 1.0184 - val_loss: 13.3403 - val_mae: 2.5297\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0073 - mae: 1.0196 - val_loss: 12.1106 - val_mae: 2.3976\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1585 - mae: 1.0567 - val_loss: 15.0364 - val_mae: 2.7275\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9936 - mae: 1.0015 - val_loss: 13.0121 - val_mae: 2.5360\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1017 - mae: 1.0838 - val_loss: 12.9907 - val_mae: 2.5447\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 2.0666 - mae: 1.0302 - val_loss: 15.6208 - val_mae: 2.8524\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0342 - mae: 1.0339 - val_loss: 14.3955 - val_mae: 2.6306\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0407 - mae: 1.0658 - val_loss: 11.8467 - val_mae: 2.3221\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9928 - mae: 1.0229 - val_loss: 12.9839 - val_mae: 2.5529\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0262 - mae: 1.0102 - val_loss: 14.4412 - val_mae: 2.6378\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0058 - mae: 1.0272 - val_loss: 12.9552 - val_mae: 2.4909\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 2.0485 - mae: 1.0218 - val_loss: 13.1420 - val_mae: 2.5211\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9297 - mae: 0.9906 - val_loss: 15.5938 - val_mae: 2.7343\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9856 - mae: 1.0216 - val_loss: 13.6345 - val_mae: 2.5574\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7531 - mae: 0.9508 - val_loss: 12.9113 - val_mae: 2.5134\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9562 - mae: 1.0217 - val_loss: 12.9652 - val_mae: 2.4956\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9127 - mae: 0.9981 - val_loss: 14.1868 - val_mae: 2.5834\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0026 - mae: 1.0276 - val_loss: 13.5557 - val_mae: 2.5375\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8059 - mae: 0.9688 - val_loss: 13.9347 - val_mae: 2.5461\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9622 - mae: 1.0310 - val_loss: 13.0496 - val_mae: 2.5296\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0135 - mae: 1.0357 - val_loss: 15.0529 - val_mae: 2.6971\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8536 - mae: 0.9865 - val_loss: 12.9314 - val_mae: 2.5502\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8463 - mae: 1.0012 - val_loss: 15.7945 - val_mae: 2.7412\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8463 - mae: 0.9609 - val_loss: 14.7137 - val_mae: 2.5814\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7350 - mae: 0.9740 - val_loss: 13.2116 - val_mae: 2.5395\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8200 - mae: 0.9709 - val_loss: 13.6347 - val_mae: 2.4715\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7540 - mae: 0.9564 - val_loss: 15.3107 - val_mae: 2.6505\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8790 - mae: 0.9981 - val_loss: 12.6554 - val_mae: 2.4093\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8411 - mae: 0.9708 - val_loss: 12.9456 - val_mae: 2.4761\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7741 - mae: 0.9480 - val_loss: 13.8110 - val_mae: 2.6188\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7299 - mae: 0.9725 - val_loss: 14.3432 - val_mae: 2.6543\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8630 - mae: 0.9815 - val_loss: 12.7890 - val_mae: 2.4786\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7346 - mae: 0.9342 - val_loss: 12.8835 - val_mae: 2.4037\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6608 - mae: 0.9264 - val_loss: 15.2734 - val_mae: 2.6975\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6927 - mae: 0.9552 - val_loss: 13.2426 - val_mae: 2.4144\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7235 - mae: 0.9473 - val_loss: 13.8334 - val_mae: 2.4666\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6730 - mae: 0.9408 - val_loss: 15.7934 - val_mae: 2.7887\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7018 - mae: 0.9416 - val_loss: 13.5640 - val_mae: 2.5335\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7155 - mae: 0.9308 - val_loss: 15.2642 - val_mae: 2.5943\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6126 - mae: 0.9311 - val_loss: 15.0851 - val_mae: 2.8032\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8088 - mae: 0.9682 - val_loss: 18.1043 - val_mae: 2.9362\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6291 - mae: 0.9535 - val_loss: 13.4083 - val_mae: 2.4959\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7023 - mae: 0.9568 - val_loss: 14.9127 - val_mae: 2.6547\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5967 - mae: 0.8772 - val_loss: 13.7444 - val_mae: 2.4310\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6615 - mae: 0.9393 - val_loss: 14.1555 - val_mae: 2.5573\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7130 - mae: 0.9507 - val_loss: 16.2609 - val_mae: 2.8441\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6551 - mae: 0.9486 - val_loss: 14.7440 - val_mae: 2.6065\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6521 - mae: 0.9340 - val_loss: 12.8491 - val_mae: 2.4876\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6629 - mae: 0.9042 - val_loss: 14.6683 - val_mae: 2.6830\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6378 - mae: 0.9581 - val_loss: 13.6886 - val_mae: 2.4371\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5617 - mae: 0.9243 - val_loss: 13.9617 - val_mae: 2.5187\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5531 - mae: 0.9006 - val_loss: 12.4781 - val_mae: 2.3655\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5957 - mae: 0.9351 - val_loss: 14.3088 - val_mae: 2.6104\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4789 - mae: 0.8642 - val_loss: 14.9248 - val_mae: 2.5527\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6222 - mae: 0.9340 - val_loss: 12.6621 - val_mae: 2.4417\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3242 - mae: 0.8420 - val_loss: 16.0318 - val_mae: 2.8068\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5267 - mae: 0.9186 - val_loss: 13.6688 - val_mae: 2.4474\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5812 - mae: 0.8999 - val_loss: 17.0232 - val_mae: 2.8401\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4644 - mae: 0.8898 - val_loss: 12.4152 - val_mae: 2.4241\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5436 - mae: 0.9073 - val_loss: 15.1340 - val_mae: 2.7415\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4305 - mae: 0.8655 - val_loss: 13.8136 - val_mae: 2.5439\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4710 - mae: 0.8859 - val_loss: 14.9305 - val_mae: 2.5409\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5437 - mae: 0.9118 - val_loss: 13.6538 - val_mae: 2.5450\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4631 - mae: 0.8800 - val_loss: 15.4022 - val_mae: 2.6800\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5225 - mae: 0.8855 - val_loss: 16.1505 - val_mae: 2.6578\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.4596 - mae: 0.8859 - val_loss: 12.6674 - val_mae: 2.3707\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4443 - mae: 0.9059 - val_loss: 13.3803 - val_mae: 2.3853\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3169 - mae: 0.8463 - val_loss: 14.0580 - val_mae: 2.5327\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3631 - mae: 0.8462 - val_loss: 15.4854 - val_mae: 2.6162\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4555 - mae: 0.8951 - val_loss: 14.3180 - val_mae: 2.5610\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3342 - mae: 0.8228 - val_loss: 17.0863 - val_mae: 2.8506\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3792 - mae: 0.8330 - val_loss: 14.6509 - val_mae: 2.5964\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4487 - mae: 0.8961 - val_loss: 14.5227 - val_mae: 2.6429\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2835 - mae: 0.8306 - val_loss: 15.4605 - val_mae: 2.6801\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3471 - mae: 0.8418 - val_loss: 17.5665 - val_mae: 2.8713\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3891 - mae: 0.8652 - val_loss: 17.1171 - val_mae: 2.8069\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2263 - mae: 0.8135 - val_loss: 13.2976 - val_mae: 2.4336\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2865 - mae: 0.8066 - val_loss: 13.5878 - val_mae: 2.4582\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4430 - mae: 0.8750 - val_loss: 15.7276 - val_mae: 2.6504\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3482 - mae: 0.8508 - val_loss: 15.9920 - val_mae: 2.7328\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2950 - mae: 0.8276 - val_loss: 15.0193 - val_mae: 2.6802\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2688 - mae: 0.8443 - val_loss: 15.8070 - val_mae: 2.7464\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3472 - mae: 0.8493 - val_loss: 13.5914 - val_mae: 2.4795\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3111 - mae: 0.8621 - val_loss: 15.8187 - val_mae: 2.6089\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2417 - mae: 0.8387 - val_loss: 16.4842 - val_mae: 2.7558\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2243 - mae: 0.7903 - val_loss: 14.1052 - val_mae: 2.4483\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3911 - mae: 0.8701 - val_loss: 16.9231 - val_mae: 2.7524\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3004 - mae: 0.8429 - val_loss: 14.6291 - val_mae: 2.5992\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2653 - mae: 0.8062 - val_loss: 14.6449 - val_mae: 2.6070\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2977 - mae: 0.8040 - val_loss: 14.5494 - val_mae: 2.6495\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1412 - mae: 0.7996 - val_loss: 14.7840 - val_mae: 2.5979\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1987 - mae: 0.7956 - val_loss: 14.5258 - val_mae: 2.5371\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3105 - mae: 0.8320 - val_loss: 14.6789 - val_mae: 2.5769\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2434 - mae: 0.8248 - val_loss: 15.4597 - val_mae: 2.7294\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1992 - mae: 0.8117 - val_loss: 15.2292 - val_mae: 2.5735\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2813 - mae: 0.8335 - val_loss: 17.0235 - val_mae: 2.8598\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2836 - mae: 0.8392 - val_loss: 15.9334 - val_mae: 2.6531\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2988 - mae: 0.8360 - val_loss: 14.5573 - val_mae: 2.5867\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.2037 - mae: 0.7745 - val_loss: 17.1380 - val_mae: 2.8273\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2217 - mae: 0.8206 - val_loss: 12.5440 - val_mae: 2.3851\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2206 - mae: 0.8084 - val_loss: 17.5346 - val_mae: 2.8929\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2226 - mae: 0.8180 - val_loss: 14.2827 - val_mae: 2.4980\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1139 - mae: 0.7663 - val_loss: 15.0980 - val_mae: 2.5925\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1654 - mae: 0.7774 - val_loss: 15.8939 - val_mae: 2.6718\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1855 - mae: 0.8127 - val_loss: 13.5254 - val_mae: 2.4042\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0882 - mae: 0.7702 - val_loss: 16.9047 - val_mae: 2.8073\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4087 - mae: 0.8608 - val_loss: 14.4667 - val_mae: 2.5455\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0903 - mae: 0.7520 - val_loss: 13.7202 - val_mae: 2.4221\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2113 - mae: 0.8352 - val_loss: 15.1290 - val_mae: 2.5881\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0660 - mae: 0.7543 - val_loss: 15.5701 - val_mae: 2.6233\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2158 - mae: 0.7885 - val_loss: 13.7231 - val_mae: 2.4392\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2199 - mae: 0.8266 - val_loss: 16.2215 - val_mae: 2.7236\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1639 - mae: 0.8215 - val_loss: 13.2101 - val_mae: 2.4001\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0226 - mae: 0.7136 - val_loss: 15.1675 - val_mae: 2.5703\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2069 - mae: 0.7837 - val_loss: 13.8793 - val_mae: 2.4496\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9557 - mae: 0.7139 - val_loss: 14.9132 - val_mae: 2.6182\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2021 - mae: 0.8030 - val_loss: 16.6768 - val_mae: 2.7026\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1160 - mae: 0.7911 - val_loss: 16.7617 - val_mae: 2.7768\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1710 - mae: 0.7943 - val_loss: 14.4308 - val_mae: 2.5653\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1608 - mae: 0.7848 - val_loss: 17.2640 - val_mae: 2.7461\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.1216 - mae: 0.7649 - val_loss: 13.4085 - val_mae: 2.4478\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0280 - mae: 0.7589 - val_loss: 14.6995 - val_mae: 2.5107\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0664 - mae: 0.7681 - val_loss: 16.7110 - val_mae: 2.8247\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0835 - mae: 0.7531 - val_loss: 15.4024 - val_mae: 2.5377\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1697 - mae: 0.7696 - val_loss: 16.3219 - val_mae: 2.6749\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0681 - mae: 0.7386 - val_loss: 15.0396 - val_mae: 2.5329\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1255 - mae: 0.7917 - val_loss: 15.0002 - val_mae: 2.6564\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0213 - mae: 0.7220 - val_loss: 15.5518 - val_mae: 2.7070\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9496 - mae: 0.7206 - val_loss: 13.4809 - val_mae: 2.4127\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1042 - mae: 0.7828 - val_loss: 16.1196 - val_mae: 2.7382\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0633 - mae: 0.7583 - val_loss: 16.5825 - val_mae: 2.8374\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9456 - mae: 0.7302 - val_loss: 16.2409 - val_mae: 2.6800\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0677 - mae: 0.7607 - val_loss: 16.0099 - val_mae: 2.6259\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0822 - mae: 0.7211 - val_loss: 14.2621 - val_mae: 2.5103\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1095 - mae: 0.7264 - val_loss: 14.7934 - val_mae: 2.5322\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0816 - mae: 0.7438 - val_loss: 14.7135 - val_mae: 2.6300\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0064 - mae: 0.7212 - val_loss: 14.4000 - val_mae: 2.4809\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9678 - mae: 0.7221 - val_loss: 16.4233 - val_mae: 2.7653\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0351 - mae: 0.7436 - val_loss: 15.4204 - val_mae: 2.5372\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0313 - mae: 0.7381 - val_loss: 14.1506 - val_mae: 2.4283\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9936 - mae: 0.7250 - val_loss: 14.6844 - val_mae: 2.5259\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9983 - mae: 0.7267 - val_loss: 14.1929 - val_mae: 2.5618\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0029 - mae: 0.7098 - val_loss: 16.2112 - val_mae: 2.6746\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9911 - mae: 0.7321 - val_loss: 14.7462 - val_mae: 2.5527\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9076 - mae: 0.7054 - val_loss: 14.3340 - val_mae: 2.5396\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9984 - mae: 0.7428 - val_loss: 16.4407 - val_mae: 2.6995\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0953 - mae: 0.7555 - val_loss: 13.4977 - val_mae: 2.5616\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0078 - mae: 0.7242 - val_loss: 15.3810 - val_mae: 2.6409\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9190 - mae: 0.6991 - val_loss: 17.7261 - val_mae: 2.8198\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9741 - mae: 0.7298 - val_loss: 14.7337 - val_mae: 2.5647\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9016 - mae: 0.7020 - val_loss: 14.6993 - val_mae: 2.5041\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8732 - mae: 0.7011 - val_loss: 12.1903 - val_mae: 2.4195\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0687 - mae: 0.7626 - val_loss: 15.1300 - val_mae: 2.5902\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9405 - mae: 0.7130 - val_loss: 16.8628 - val_mae: 2.7228\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9233 - mae: 0.6933 - val_loss: 18.4024 - val_mae: 2.9237\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0770 - mae: 0.7568 - val_loss: 13.6435 - val_mae: 2.4804\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0000 - mae: 0.7493 - val_loss: 16.0902 - val_mae: 2.6066\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0112 - mae: 0.7289 - val_loss: 15.2292 - val_mae: 2.6045\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9440 - mae: 0.7042 - val_loss: 14.9298 - val_mae: 2.6018\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8978 - mae: 0.7179 - val_loss: 13.7189 - val_mae: 2.5050\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.9790 - mae: 0.6926 - val_loss: 16.9240 - val_mae: 2.8182\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9604 - mae: 0.6979 - val_loss: 16.4346 - val_mae: 2.6881\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8977 - mae: 0.6997 - val_loss: 14.7607 - val_mae: 2.5511\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8428 - mae: 0.6772 - val_loss: 15.7639 - val_mae: 2.6489\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9433 - mae: 0.7198 - val_loss: 16.0315 - val_mae: 2.6401\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9604 - mae: 0.6898 - val_loss: 17.0744 - val_mae: 2.7495\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9877 - mae: 0.7486 - val_loss: 16.3132 - val_mae: 2.7329\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8460 - mae: 0.6553 - val_loss: 16.2108 - val_mae: 2.6081\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8917 - mae: 0.6696 - val_loss: 16.0574 - val_mae: 2.6063\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9036 - mae: 0.6942 - val_loss: 15.6553 - val_mae: 2.6418\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8306 - mae: 0.6563 - val_loss: 14.8640 - val_mae: 2.4745\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8388 - mae: 0.6654 - val_loss: 16.7677 - val_mae: 2.6517\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8852 - mae: 0.6698 - val_loss: 14.0163 - val_mae: 2.4945\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9499 - mae: 0.7022 - val_loss: 16.0422 - val_mae: 2.6329\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7720 - mae: 0.6346 - val_loss: 16.0516 - val_mae: 2.6528\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.8841 - mae: 0.6816 - val_loss: 18.0558 - val_mae: 2.9271\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9577 - mae: 0.7297 - val_loss: 17.3346 - val_mae: 2.7170\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8846 - mae: 0.6711 - val_loss: 14.7210 - val_mae: 2.5672\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 1.0838 - mae: 0.7467 - val_loss: 15.6775 - val_mae: 2.5497\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8493 - mae: 0.6575 - val_loss: 14.8558 - val_mae: 2.5595\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8314 - mae: 0.6679 - val_loss: 15.3471 - val_mae: 2.5888\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9258 - mae: 0.7054 - val_loss: 15.4219 - val_mae: 2.5972\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7804 - mae: 0.6203 - val_loss: 15.9835 - val_mae: 2.5834\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7868 - mae: 0.6543 - val_loss: 15.9346 - val_mae: 2.7019\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8666 - mae: 0.6937 - val_loss: 19.0656 - val_mae: 2.9287\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8504 - mae: 0.6940 - val_loss: 14.2389 - val_mae: 2.4657\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8327 - mae: 0.6439 - val_loss: 14.9180 - val_mae: 2.4796\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8283 - mae: 0.6683 - val_loss: 15.3280 - val_mae: 2.6410\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8902 - mae: 0.6759 - val_loss: 16.5268 - val_mae: 2.6923\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7678 - mae: 0.6398 - val_loss: 13.5521 - val_mae: 2.4440\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8368 - mae: 0.6643 - val_loss: 15.9970 - val_mae: 2.6710\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8319 - mae: 0.6769 - val_loss: 13.7038 - val_mae: 2.4182\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7996 - mae: 0.6836 - val_loss: 16.3594 - val_mae: 2.7055\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7730 - mae: 0.6577 - val_loss: 15.9595 - val_mae: 2.5077\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9497 - mae: 0.6960 - val_loss: 16.1078 - val_mae: 2.6586\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8380 - mae: 0.6511 - val_loss: 14.8531 - val_mae: 2.6167\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7929 - mae: 0.6354 - val_loss: 18.5485 - val_mae: 2.9291\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7024 - mae: 0.6048 - val_loss: 14.0494 - val_mae: 2.4871\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.9330 - mae: 0.7064 - val_loss: 14.8444 - val_mae: 2.5184\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7346 - mae: 0.6153 - val_loss: 18.5638 - val_mae: 2.8406\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8309 - mae: 0.6753 - val_loss: 14.6974 - val_mae: 2.4930\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.8948 - mae: 0.7143 - val_loss: 14.2587 - val_mae: 2.4497\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7682 - mae: 0.6275 - val_loss: 17.5639 - val_mae: 2.8288\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7324 - mae: 0.6355 - val_loss: 15.7831 - val_mae: 2.6107\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7861 - mae: 0.6397 - val_loss: 17.3841 - val_mae: 2.6751\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7874 - mae: 0.6564 - val_loss: 14.5415 - val_mae: 2.4961\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8089 - mae: 0.6639 - val_loss: 17.3379 - val_mae: 2.7890\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7939 - mae: 0.6306 - val_loss: 15.4491 - val_mae: 2.5384\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7213 - mae: 0.6177 - val_loss: 13.7948 - val_mae: 2.4169\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9030 - mae: 0.7010 - val_loss: 16.0068 - val_mae: 2.6295\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7203 - mae: 0.6028 - val_loss: 14.2932 - val_mae: 2.4766\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8004 - mae: 0.6429 - val_loss: 16.5987 - val_mae: 2.7799\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7132 - mae: 0.5951 - val_loss: 17.4723 - val_mae: 2.7254\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9530 - mae: 0.7292 - val_loss: 16.9520 - val_mae: 2.6402\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6692 - mae: 0.5998 - val_loss: 14.4344 - val_mae: 2.5907\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9006 - mae: 0.6929 - val_loss: 15.9014 - val_mae: 2.5753\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7287 - mae: 0.6409 - val_loss: 13.9952 - val_mae: 2.4567\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6662 - mae: 0.6139 - val_loss: 17.4994 - val_mae: 2.6387\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7350 - mae: 0.6262 - val_loss: 14.7438 - val_mae: 2.4986\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9109 - mae: 0.6905 - val_loss: 15.4415 - val_mae: 2.5656\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7839 - mae: 0.6641 - val_loss: 14.1670 - val_mae: 2.4304\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7489 - mae: 0.6281 - val_loss: 18.8545 - val_mae: 2.8823\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7214 - mae: 0.6333 - val_loss: 16.0179 - val_mae: 2.6051\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8378 - mae: 0.6697 - val_loss: 14.6726 - val_mae: 2.5149\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6214 - mae: 0.5729 - val_loss: 14.1745 - val_mae: 2.4799\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7200 - mae: 0.6237 - val_loss: 14.9901 - val_mae: 2.4985\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.7120 - mae: 0.6110 - val_loss: 16.6072 - val_mae: 2.7251\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8342 - mae: 0.6763 - val_loss: 13.8333 - val_mae: 2.4757\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8479 - mae: 0.6877 - val_loss: 15.3962 - val_mae: 2.5791\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5900 - mae: 0.5588 - val_loss: 13.9245 - val_mae: 2.4140\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9073 - mae: 0.7063 - val_loss: 16.8046 - val_mae: 2.7006\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5816 - mae: 0.5644 - val_loss: 16.9492 - val_mae: 2.7067\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7442 - mae: 0.6619 - val_loss: 15.9716 - val_mae: 2.7938\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7697 - mae: 0.6366 - val_loss: 15.1004 - val_mae: 2.5086\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8367 - mae: 0.6553 - val_loss: 13.3546 - val_mae: 2.4298\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 0.6115 - mae: 0.5763 - val_loss: 16.6961 - val_mae: 2.7428\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6939 - mae: 0.6173 - val_loss: 13.7966 - val_mae: 2.5190\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8079 - mae: 0.6742 - val_loss: 15.1199 - val_mae: 2.6266\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6494 - mae: 0.5687 - val_loss: 16.3611 - val_mae: 2.6615\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7328 - mae: 0.6395 - val_loss: 15.9892 - val_mae: 2.6547\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6944 - mae: 0.6227 - val_loss: 13.7698 - val_mae: 2.4494\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6908 - mae: 0.6214 - val_loss: 15.4947 - val_mae: 2.5036\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7337 - mae: 0.6251 - val_loss: 14.5705 - val_mae: 2.4547\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7376 - mae: 0.6294 - val_loss: 15.8163 - val_mae: 2.6793\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6246 - mae: 0.5796 - val_loss: 15.2010 - val_mae: 2.5384\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.7205 - mae: 0.6238 - val_loss: 17.9224 - val_mae: 2.7225\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7960 - mae: 0.6381 - val_loss: 14.3515 - val_mae: 2.5501\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6311 - mae: 0.5867 - val_loss: 15.6370 - val_mae: 2.5563\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6949 - mae: 0.6020 - val_loss: 14.9244 - val_mae: 2.5426\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7722 - mae: 0.6265 - val_loss: 17.0007 - val_mae: 2.7524\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7160 - mae: 0.6113 - val_loss: 14.5716 - val_mae: 2.5006\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7401 - mae: 0.6338 - val_loss: 13.2421 - val_mae: 2.4382\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6319 - mae: 0.5872 - val_loss: 14.5042 - val_mae: 2.4797\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7557 - mae: 0.6389 - val_loss: 16.0714 - val_mae: 2.7988\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6898 - mae: 0.6273 - val_loss: 15.1242 - val_mae: 2.4999\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5877 - mae: 0.5658 - val_loss: 15.8939 - val_mae: 2.6869\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6657 - mae: 0.6210 - val_loss: 15.8532 - val_mae: 2.5965\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6969 - mae: 0.5994 - val_loss: 15.2608 - val_mae: 2.5804\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6182 - mae: 0.5662 - val_loss: 14.9422 - val_mae: 2.4646\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7390 - mae: 0.6461 - val_loss: 16.9998 - val_mae: 2.7082\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8020 - mae: 0.6411 - val_loss: 15.6372 - val_mae: 2.6056\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6259 - mae: 0.5712 - val_loss: 14.8495 - val_mae: 2.5728\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6823 - mae: 0.5815 - val_loss: 16.3783 - val_mae: 2.5947\n",
            "Processing fold #2\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 543.9337 - mae: 21.4083 - val_loss: 416.2020 - val_mae: 18.8823\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 420.4948 - mae: 18.5358 - val_loss: 304.1194 - val_mae: 15.8549\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 285.7067 - mae: 14.7577 - val_loss: 189.8615 - val_mae: 12.0074\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 158.9005 - mae: 10.2517 - val_loss: 99.5645 - val_mae: 8.0784\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 84.3390 - mae: 6.8391 - val_loss: 59.2326 - val_mae: 5.9130\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 51.7884 - mae: 5.2525 - val_loss: 40.6001 - val_mae: 4.6122\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 36.7310 - mae: 4.4090 - val_loss: 33.5141 - val_mae: 3.9593\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 29.0078 - mae: 3.9233 - val_loss: 29.4998 - val_mae: 3.6987\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 24.9234 - mae: 3.5947 - val_loss: 26.8879 - val_mae: 3.5186\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 22.8353 - mae: 3.4550 - val_loss: 24.7533 - val_mae: 3.3695\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 20.6995 - mae: 3.2659 - val_loss: 23.7031 - val_mae: 3.3505\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 19.0882 - mae: 3.1374 - val_loss: 22.2152 - val_mae: 3.2495\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 17.8685 - mae: 3.0426 - val_loss: 20.6219 - val_mae: 3.0493\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 16.6849 - mae: 2.9251 - val_loss: 19.9150 - val_mae: 3.0223\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 15.4576 - mae: 2.8608 - val_loss: 18.8248 - val_mae: 2.9209\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 14.6962 - mae: 2.7594 - val_loss: 18.4121 - val_mae: 2.8657\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.8716 - mae: 2.6965 - val_loss: 18.1104 - val_mae: 2.9125\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 13.5015 - mae: 2.6790 - val_loss: 17.6669 - val_mae: 2.8389\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.6064 - mae: 2.5810 - val_loss: 17.5565 - val_mae: 2.8359\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.1410 - mae: 2.5265 - val_loss: 16.8908 - val_mae: 2.8462\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.8461 - mae: 2.5289 - val_loss: 16.6451 - val_mae: 2.7629\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.1599 - mae: 2.4757 - val_loss: 16.4786 - val_mae: 2.6781\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.1180 - mae: 2.4324 - val_loss: 16.2854 - val_mae: 2.7577\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.9523 - mae: 2.4189 - val_loss: 15.9448 - val_mae: 2.7188\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.3693 - mae: 2.3593 - val_loss: 15.9933 - val_mae: 2.7166\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.1071 - mae: 2.3070 - val_loss: 15.9783 - val_mae: 2.6878\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.0625 - mae: 2.3644 - val_loss: 15.4090 - val_mae: 2.6922\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.7063 - mae: 2.2781 - val_loss: 15.6558 - val_mae: 2.6065\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.4031 - mae: 2.2379 - val_loss: 15.3649 - val_mae: 2.7092\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.4865 - mae: 2.2411 - val_loss: 15.2058 - val_mae: 2.7043\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.0378 - mae: 2.2190 - val_loss: 15.0513 - val_mae: 2.6649\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.1039 - mae: 2.2112 - val_loss: 15.0587 - val_mae: 2.6188\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 8.9575 - mae: 2.1800 - val_loss: 14.9368 - val_mae: 2.6516\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.6428 - mae: 2.1797 - val_loss: 15.3977 - val_mae: 2.6612\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.4190 - mae: 2.1170 - val_loss: 14.9191 - val_mae: 2.6051\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.4370 - mae: 2.1081 - val_loss: 14.4952 - val_mae: 2.6468\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.1563 - mae: 2.1087 - val_loss: 14.8618 - val_mae: 2.5797\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.1824 - mae: 2.1025 - val_loss: 15.6486 - val_mae: 2.7029\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.2412 - mae: 2.0948 - val_loss: 14.6470 - val_mae: 2.6004\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 8.0038 - mae: 2.0423 - val_loss: 14.7899 - val_mae: 2.6364\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.7748 - mae: 2.0108 - val_loss: 14.7150 - val_mae: 2.6892\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.8678 - mae: 2.0466 - val_loss: 14.3017 - val_mae: 2.6220\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.7056 - mae: 2.0264 - val_loss: 14.4704 - val_mae: 2.5853\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.5488 - mae: 1.9962 - val_loss: 14.4351 - val_mae: 2.5782\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.3855 - mae: 1.9899 - val_loss: 14.7318 - val_mae: 2.7279\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.4944 - mae: 1.9933 - val_loss: 14.1569 - val_mae: 2.6199\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.2485 - mae: 1.9956 - val_loss: 14.2641 - val_mae: 2.6049\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 7.2355 - mae: 1.9599 - val_loss: 14.4476 - val_mae: 2.5640\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.2404 - mae: 1.9731 - val_loss: 14.1451 - val_mae: 2.6046\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 7.1336 - mae: 1.9496 - val_loss: 14.1540 - val_mae: 2.5594\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9708 - mae: 1.9490 - val_loss: 14.1485 - val_mae: 2.5505\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9075 - mae: 1.9495 - val_loss: 13.9177 - val_mae: 2.5929\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.8273 - mae: 1.9266 - val_loss: 14.1644 - val_mae: 2.5510\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.8786 - mae: 1.9130 - val_loss: 14.1662 - val_mae: 2.5450\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.7922 - mae: 1.9089 - val_loss: 13.9178 - val_mae: 2.5455\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.5471 - mae: 1.8853 - val_loss: 13.7885 - val_mae: 2.5812\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.5625 - mae: 1.8738 - val_loss: 13.7949 - val_mae: 2.5034\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5259 - mae: 1.8677 - val_loss: 14.1200 - val_mae: 2.5460\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.3981 - mae: 1.8398 - val_loss: 13.9877 - val_mae: 2.5111\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.3586 - mae: 1.8348 - val_loss: 14.5121 - val_mae: 2.5432\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.4632 - mae: 1.8404 - val_loss: 14.0744 - val_mae: 2.5332\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.2350 - mae: 1.8069 - val_loss: 14.0568 - val_mae: 2.5552\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 6.0004 - mae: 1.7886 - val_loss: 14.1629 - val_mae: 2.5367\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2208 - mae: 1.7868 - val_loss: 13.7982 - val_mae: 2.5330\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.2385 - mae: 1.8147 - val_loss: 13.9175 - val_mae: 2.5309\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0615 - mae: 1.8155 - val_loss: 13.9167 - val_mae: 2.4737\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1175 - mae: 1.8004 - val_loss: 13.6521 - val_mae: 2.4897\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.9400 - mae: 1.7820 - val_loss: 14.1252 - val_mae: 2.5473\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0148 - mae: 1.7966 - val_loss: 13.6055 - val_mae: 2.5065\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8969 - mae: 1.7802 - val_loss: 13.9510 - val_mae: 2.5296\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8087 - mae: 1.7812 - val_loss: 13.6281 - val_mae: 2.5193\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.8008 - mae: 1.7757 - val_loss: 14.2330 - val_mae: 2.5435\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7426 - mae: 1.7684 - val_loss: 13.7124 - val_mae: 2.4882\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6653 - mae: 1.7568 - val_loss: 13.7299 - val_mae: 2.4604\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8021 - mae: 1.7599 - val_loss: 13.8297 - val_mae: 2.4995\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7011 - mae: 1.7806 - val_loss: 13.8622 - val_mae: 2.4678\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4861 - mae: 1.7053 - val_loss: 13.6295 - val_mae: 2.4955\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5268 - mae: 1.7058 - val_loss: 13.7857 - val_mae: 2.5798\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5333 - mae: 1.7198 - val_loss: 13.4746 - val_mae: 2.5092\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4714 - mae: 1.7026 - val_loss: 13.9060 - val_mae: 2.4796\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4244 - mae: 1.7038 - val_loss: 13.7984 - val_mae: 2.4950\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 5.4219 - mae: 1.7182 - val_loss: 13.7266 - val_mae: 2.5097\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 5.2736 - mae: 1.6942 - val_loss: 13.4847 - val_mae: 2.4856\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 5.2356 - mae: 1.6817 - val_loss: 14.0395 - val_mae: 2.5326\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3406 - mae: 1.7068 - val_loss: 13.9886 - val_mae: 2.4898\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 5.1245 - mae: 1.6944 - val_loss: 13.7463 - val_mae: 2.4393\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.2931 - mae: 1.6986 - val_loss: 13.4736 - val_mae: 2.5015\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.1360 - mae: 1.6540 - val_loss: 13.8546 - val_mae: 2.4911\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.1028 - mae: 1.7032 - val_loss: 13.3013 - val_mae: 2.4508\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 4.8893 - mae: 1.6500 - val_loss: 13.5013 - val_mae: 2.5576\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 4.9708 - mae: 1.6329 - val_loss: 13.5029 - val_mae: 2.4682\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 5.0226 - mae: 1.6230 - val_loss: 13.2734 - val_mae: 2.4477\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 4.9972 - mae: 1.6296 - val_loss: 13.1013 - val_mae: 2.4642\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.9489 - mae: 1.6455 - val_loss: 13.4574 - val_mae: 2.4679\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8485 - mae: 1.5956 - val_loss: 13.3423 - val_mae: 2.4761\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.9502 - mae: 1.6457 - val_loss: 13.3879 - val_mae: 2.4431\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7640 - mae: 1.5860 - val_loss: 13.3472 - val_mae: 2.5095\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7325 - mae: 1.6284 - val_loss: 13.3091 - val_mae: 2.4884\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8335 - mae: 1.6374 - val_loss: 13.8167 - val_mae: 2.5253\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8957 - mae: 1.6451 - val_loss: 13.3636 - val_mae: 2.4382\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6492 - mae: 1.5553 - val_loss: 13.4302 - val_mae: 2.4798\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5134 - mae: 1.5697 - val_loss: 13.3908 - val_mae: 2.4406\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6018 - mae: 1.5770 - val_loss: 13.8148 - val_mae: 2.5651\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4587 - mae: 1.5628 - val_loss: 13.6870 - val_mae: 2.4277\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5259 - mae: 1.5754 - val_loss: 13.3988 - val_mae: 2.4712\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7221 - mae: 1.5591 - val_loss: 13.1366 - val_mae: 2.4552\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3782 - mae: 1.5288 - val_loss: 13.3965 - val_mae: 2.4634\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6061 - mae: 1.6060 - val_loss: 13.2248 - val_mae: 2.4368\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4722 - mae: 1.5049 - val_loss: 13.1817 - val_mae: 2.4421\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3452 - mae: 1.5336 - val_loss: 13.1211 - val_mae: 2.4220\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 4.2268 - mae: 1.5188 - val_loss: 13.2248 - val_mae: 2.4427\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3419 - mae: 1.5336 - val_loss: 13.3443 - val_mae: 2.4880\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2558 - mae: 1.4977 - val_loss: 13.1913 - val_mae: 2.4504\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2053 - mae: 1.5229 - val_loss: 13.5415 - val_mae: 2.4954\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3084 - mae: 1.5252 - val_loss: 13.1834 - val_mae: 2.4516\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2246 - mae: 1.5040 - val_loss: 13.2571 - val_mae: 2.4568\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0659 - mae: 1.4826 - val_loss: 13.3222 - val_mae: 2.4639\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0290 - mae: 1.4497 - val_loss: 13.1795 - val_mae: 2.4757\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0564 - mae: 1.4756 - val_loss: 13.0964 - val_mae: 2.4534\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9232 - mae: 1.4709 - val_loss: 13.0760 - val_mae: 2.4116\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9861 - mae: 1.4730 - val_loss: 13.4159 - val_mae: 2.4407\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1520 - mae: 1.5036 - val_loss: 12.7803 - val_mae: 2.3997\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0079 - mae: 1.4872 - val_loss: 12.9292 - val_mae: 2.4620\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9715 - mae: 1.4724 - val_loss: 12.7445 - val_mae: 2.4299\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.9619 - mae: 1.4619 - val_loss: 12.8166 - val_mae: 2.4485\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9226 - mae: 1.4625 - val_loss: 12.8866 - val_mae: 2.4084\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8727 - mae: 1.4547 - val_loss: 12.7880 - val_mae: 2.4211\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8515 - mae: 1.4458 - val_loss: 13.0897 - val_mae: 2.5232\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8128 - mae: 1.4387 - val_loss: 12.7893 - val_mae: 2.4477\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9084 - mae: 1.4615 - val_loss: 12.8920 - val_mae: 2.3949\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7572 - mae: 1.4314 - val_loss: 12.8927 - val_mae: 2.4652\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7873 - mae: 1.4603 - val_loss: 12.9745 - val_mae: 2.4364\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6809 - mae: 1.4096 - val_loss: 12.9252 - val_mae: 2.4476\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.7757 - mae: 1.4135 - val_loss: 12.6960 - val_mae: 2.4173\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6154 - mae: 1.4285 - val_loss: 12.7223 - val_mae: 2.4086\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.4802 - mae: 1.3946 - val_loss: 12.9305 - val_mae: 2.4744\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6860 - mae: 1.4392 - val_loss: 13.3752 - val_mae: 2.4179\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5835 - mae: 1.3981 - val_loss: 12.9154 - val_mae: 2.4316\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6746 - mae: 1.4098 - val_loss: 12.5860 - val_mae: 2.4202\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6153 - mae: 1.4353 - val_loss: 12.5411 - val_mae: 2.4435\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4583 - mae: 1.3758 - val_loss: 12.8050 - val_mae: 2.4238\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3507 - mae: 1.3644 - val_loss: 12.5995 - val_mae: 2.4454\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4573 - mae: 1.3699 - val_loss: 12.8137 - val_mae: 2.4532\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2626 - mae: 1.3244 - val_loss: 12.8853 - val_mae: 2.4363\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4132 - mae: 1.3779 - val_loss: 12.6030 - val_mae: 2.4332\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3499 - mae: 1.3584 - val_loss: 13.1631 - val_mae: 2.4622\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 3.2990 - mae: 1.3376 - val_loss: 12.7301 - val_mae: 2.4547\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4185 - mae: 1.3581 - val_loss: 12.5121 - val_mae: 2.4389\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2154 - mae: 1.3484 - val_loss: 12.7548 - val_mae: 2.4395\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3269 - mae: 1.3456 - val_loss: 12.5386 - val_mae: 2.4063\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.2012 - mae: 1.3364 - val_loss: 12.3962 - val_mae: 2.3857\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1096 - mae: 1.2915 - val_loss: 12.5310 - val_mae: 2.3998\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2027 - mae: 1.3418 - val_loss: 12.3739 - val_mae: 2.3871\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0869 - mae: 1.2810 - val_loss: 12.7931 - val_mae: 2.5398\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.2282 - mae: 1.3188 - val_loss: 12.4974 - val_mae: 2.4390\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9880 - mae: 1.3086 - val_loss: 12.2443 - val_mae: 2.4062\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0807 - mae: 1.3329 - val_loss: 12.3785 - val_mae: 2.4109\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0538 - mae: 1.2934 - val_loss: 12.6051 - val_mae: 2.4601\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9592 - mae: 1.2831 - val_loss: 12.2515 - val_mae: 2.4236\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1207 - mae: 1.3168 - val_loss: 12.3804 - val_mae: 2.4243\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 2.9622 - mae: 1.2567 - val_loss: 12.4208 - val_mae: 2.4542\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0477 - mae: 1.2781 - val_loss: 12.5332 - val_mae: 2.4716\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9995 - mae: 1.2727 - val_loss: 12.2787 - val_mae: 2.4396\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9354 - mae: 1.2638 - val_loss: 12.0777 - val_mae: 2.4134\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0131 - mae: 1.2758 - val_loss: 12.2774 - val_mae: 2.4410\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8229 - mae: 1.2613 - val_loss: 12.1864 - val_mae: 2.4079\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0738 - mae: 1.2754 - val_loss: 12.1504 - val_mae: 2.4027\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9433 - mae: 1.2916 - val_loss: 12.1261 - val_mae: 2.4028\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7957 - mae: 1.2504 - val_loss: 12.3840 - val_mae: 2.4621\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8659 - mae: 1.2530 - val_loss: 12.1657 - val_mae: 2.4008\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8494 - mae: 1.2503 - val_loss: 12.6722 - val_mae: 2.4494\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7098 - mae: 1.2212 - val_loss: 12.1194 - val_mae: 2.3922\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6909 - mae: 1.2275 - val_loss: 12.6533 - val_mae: 2.4317\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8634 - mae: 1.2408 - val_loss: 12.1969 - val_mae: 2.3965\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6426 - mae: 1.2217 - val_loss: 12.8911 - val_mae: 2.5483\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8539 - mae: 1.2728 - val_loss: 12.1474 - val_mae: 2.4002\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6493 - mae: 1.1938 - val_loss: 12.1684 - val_mae: 2.4190\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6487 - mae: 1.2319 - val_loss: 12.0012 - val_mae: 2.4263\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5799 - mae: 1.1954 - val_loss: 12.1053 - val_mae: 2.4409\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6282 - mae: 1.1970 - val_loss: 12.6313 - val_mae: 2.4548\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6623 - mae: 1.2078 - val_loss: 12.3833 - val_mae: 2.4738\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6388 - mae: 1.2025 - val_loss: 11.8303 - val_mae: 2.4088\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5370 - mae: 1.1815 - val_loss: 12.3445 - val_mae: 2.4559\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4988 - mae: 1.1941 - val_loss: 12.3467 - val_mae: 2.4358\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 2.5910 - mae: 1.2032 - val_loss: 12.1630 - val_mae: 2.4366\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4466 - mae: 1.1687 - val_loss: 11.8134 - val_mae: 2.3950\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5624 - mae: 1.1937 - val_loss: 11.9549 - val_mae: 2.4030\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5399 - mae: 1.1696 - val_loss: 11.9585 - val_mae: 2.4383\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4755 - mae: 1.1730 - val_loss: 11.9325 - val_mae: 2.4177\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 2.3618 - mae: 1.1627 - val_loss: 11.9850 - val_mae: 2.4016\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4144 - mae: 1.1727 - val_loss: 12.0699 - val_mae: 2.4480\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4412 - mae: 1.1852 - val_loss: 11.9757 - val_mae: 2.3878\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3577 - mae: 1.1530 - val_loss: 11.6641 - val_mae: 2.4133\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2666 - mae: 1.1291 - val_loss: 11.5561 - val_mae: 2.3965\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3576 - mae: 1.1421 - val_loss: 12.1293 - val_mae: 2.4417\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4153 - mae: 1.1872 - val_loss: 11.9375 - val_mae: 2.4474\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2258 - mae: 1.1163 - val_loss: 12.0305 - val_mae: 2.4290\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4719 - mae: 1.1887 - val_loss: 12.1795 - val_mae: 2.4591\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2516 - mae: 1.1367 - val_loss: 12.3042 - val_mae: 2.4917\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4265 - mae: 1.1767 - val_loss: 11.9460 - val_mae: 2.4571\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1922 - mae: 1.0851 - val_loss: 11.8532 - val_mae: 2.4333\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2693 - mae: 1.1312 - val_loss: 11.8080 - val_mae: 2.4502\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3555 - mae: 1.1509 - val_loss: 11.6583 - val_mae: 2.4249\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3050 - mae: 1.1405 - val_loss: 11.6711 - val_mae: 2.4330\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2304 - mae: 1.1289 - val_loss: 11.7083 - val_mae: 2.4248\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.1767 - mae: 1.1067 - val_loss: 11.8489 - val_mae: 2.4260\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1467 - mae: 1.1082 - val_loss: 12.4163 - val_mae: 2.4839\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1760 - mae: 1.1262 - val_loss: 12.3876 - val_mae: 2.4670\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2769 - mae: 1.1340 - val_loss: 11.9251 - val_mae: 2.4312\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1664 - mae: 1.1106 - val_loss: 11.7755 - val_mae: 2.4136\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0047 - mae: 1.0859 - val_loss: 12.2735 - val_mae: 2.4254\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1563 - mae: 1.1068 - val_loss: 11.6344 - val_mae: 2.4394\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0468 - mae: 1.0988 - val_loss: 11.7738 - val_mae: 2.4240\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1237 - mae: 1.0862 - val_loss: 11.2815 - val_mae: 2.4028\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1575 - mae: 1.1000 - val_loss: 11.5716 - val_mae: 2.4382\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2007 - mae: 1.1232 - val_loss: 11.9883 - val_mae: 2.4829\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9783 - mae: 1.0623 - val_loss: 11.9421 - val_mae: 2.4423\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0034 - mae: 1.0626 - val_loss: 12.3839 - val_mae: 2.5018\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9923 - mae: 1.0604 - val_loss: 11.5367 - val_mae: 2.4503\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9942 - mae: 1.0930 - val_loss: 12.2553 - val_mae: 2.4758\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9851 - mae: 1.0617 - val_loss: 12.0150 - val_mae: 2.4929\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9558 - mae: 1.0517 - val_loss: 11.9807 - val_mae: 2.4513\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1469 - mae: 1.1039 - val_loss: 11.4050 - val_mae: 2.4109\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9719 - mae: 1.0585 - val_loss: 11.5868 - val_mae: 2.4143\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9520 - mae: 1.0388 - val_loss: 12.0593 - val_mae: 2.4563\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8923 - mae: 1.0521 - val_loss: 12.1045 - val_mae: 2.4644\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9117 - mae: 1.0218 - val_loss: 11.5506 - val_mae: 2.4289\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8248 - mae: 1.0131 - val_loss: 11.7589 - val_mae: 2.4278\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9016 - mae: 1.0215 - val_loss: 11.6248 - val_mae: 2.4207\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9660 - mae: 1.0377 - val_loss: 11.8376 - val_mae: 2.4440\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8332 - mae: 1.0038 - val_loss: 12.0257 - val_mae: 2.4749\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8479 - mae: 1.0322 - val_loss: 11.8668 - val_mae: 2.4284\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8828 - mae: 1.0312 - val_loss: 11.6681 - val_mae: 2.4017\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8543 - mae: 1.0362 - val_loss: 11.8409 - val_mae: 2.4410\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8243 - mae: 0.9932 - val_loss: 11.6314 - val_mae: 2.4349\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8541 - mae: 1.0315 - val_loss: 11.7155 - val_mae: 2.4299\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8040 - mae: 1.0010 - val_loss: 11.6440 - val_mae: 2.4208\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7344 - mae: 0.9840 - val_loss: 11.7663 - val_mae: 2.4932\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7051 - mae: 0.9805 - val_loss: 11.4035 - val_mae: 2.4234\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7551 - mae: 1.0038 - val_loss: 11.5458 - val_mae: 2.4466\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7655 - mae: 0.9987 - val_loss: 11.6764 - val_mae: 2.4393\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7366 - mae: 0.9712 - val_loss: 11.2006 - val_mae: 2.4156\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6685 - mae: 0.9754 - val_loss: 11.8935 - val_mae: 2.4267\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.6798 - mae: 1.0070 - val_loss: 11.8947 - val_mae: 2.4740\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7264 - mae: 0.9734 - val_loss: 11.8660 - val_mae: 2.4592\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6759 - mae: 0.9602 - val_loss: 12.2546 - val_mae: 2.5371\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6838 - mae: 0.9705 - val_loss: 11.7020 - val_mae: 2.4726\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6944 - mae: 0.9785 - val_loss: 11.4294 - val_mae: 2.4616\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6445 - mae: 0.9450 - val_loss: 12.1675 - val_mae: 2.4969\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7048 - mae: 0.9654 - val_loss: 11.4507 - val_mae: 2.4049\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5676 - mae: 0.9583 - val_loss: 11.8072 - val_mae: 2.4893\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5940 - mae: 0.9422 - val_loss: 11.6193 - val_mae: 2.4543\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5870 - mae: 0.9338 - val_loss: 11.5419 - val_mae: 2.4452\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5968 - mae: 0.9513 - val_loss: 12.2706 - val_mae: 2.5287\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6119 - mae: 0.9383 - val_loss: 11.4587 - val_mae: 2.4254\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6101 - mae: 0.9643 - val_loss: 12.1189 - val_mae: 2.4890\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4915 - mae: 0.9091 - val_loss: 11.4459 - val_mae: 2.4712\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5453 - mae: 0.9371 - val_loss: 11.9110 - val_mae: 2.4859\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6098 - mae: 0.9541 - val_loss: 11.7793 - val_mae: 2.4433\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5227 - mae: 0.9297 - val_loss: 11.4668 - val_mae: 2.4186\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6308 - mae: 0.9843 - val_loss: 11.5811 - val_mae: 2.4281\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4042 - mae: 0.9011 - val_loss: 11.5103 - val_mae: 2.4657\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5862 - mae: 0.9488 - val_loss: 11.8372 - val_mae: 2.4372\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.4716 - mae: 0.9064 - val_loss: 11.5342 - val_mae: 2.4477\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5270 - mae: 0.9114 - val_loss: 12.0779 - val_mae: 2.5084\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5134 - mae: 0.9187 - val_loss: 11.3918 - val_mae: 2.4285\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5129 - mae: 0.9235 - val_loss: 11.6361 - val_mae: 2.4557\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5508 - mae: 0.9371 - val_loss: 11.3905 - val_mae: 2.4122\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4629 - mae: 0.9193 - val_loss: 12.0867 - val_mae: 2.4930\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5621 - mae: 0.9105 - val_loss: 12.0701 - val_mae: 2.4814\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3694 - mae: 0.8782 - val_loss: 12.1950 - val_mae: 2.4909\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 1.5258 - mae: 0.9526 - val_loss: 12.0034 - val_mae: 2.4946\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3023 - mae: 0.8727 - val_loss: 11.4569 - val_mae: 2.4505\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5483 - mae: 0.9322 - val_loss: 12.1997 - val_mae: 2.4739\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3969 - mae: 0.8686 - val_loss: 11.6126 - val_mae: 2.4251\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4295 - mae: 0.9051 - val_loss: 12.2022 - val_mae: 2.5018\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3666 - mae: 0.8572 - val_loss: 11.6807 - val_mae: 2.4709\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4324 - mae: 0.9119 - val_loss: 11.6588 - val_mae: 2.4671\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4097 - mae: 0.8829 - val_loss: 11.9197 - val_mae: 2.5061\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3535 - mae: 0.8824 - val_loss: 11.5250 - val_mae: 2.4610\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.4626 - mae: 0.9226 - val_loss: 11.7843 - val_mae: 2.4822\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2637 - mae: 0.8454 - val_loss: 12.0091 - val_mae: 2.4805\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3706 - mae: 0.8720 - val_loss: 11.3786 - val_mae: 2.4479\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3389 - mae: 0.8451 - val_loss: 11.8419 - val_mae: 2.4764\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2150 - mae: 0.8170 - val_loss: 12.2693 - val_mae: 2.5413\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3873 - mae: 0.9114 - val_loss: 12.2469 - val_mae: 2.5229\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4481 - mae: 0.8869 - val_loss: 11.9115 - val_mae: 2.4741\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2864 - mae: 0.8645 - val_loss: 12.6686 - val_mae: 2.5350\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2174 - mae: 0.8157 - val_loss: 11.6129 - val_mae: 2.4655\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1680 - mae: 0.8389 - val_loss: 11.8736 - val_mae: 2.4759\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2968 - mae: 0.8521 - val_loss: 12.1905 - val_mae: 2.5136\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1.2261 - mae: 0.8365 - val_loss: 12.3185 - val_mae: 2.5224\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2644 - mae: 0.8267 - val_loss: 11.4131 - val_mae: 2.4652\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2590 - mae: 0.8585 - val_loss: 12.1143 - val_mae: 2.5090\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2628 - mae: 0.8532 - val_loss: 12.5494 - val_mae: 2.5547\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2883 - mae: 0.8290 - val_loss: 11.9229 - val_mae: 2.4755\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2004 - mae: 0.8102 - val_loss: 11.4300 - val_mae: 2.4647\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2915 - mae: 0.8278 - val_loss: 11.8972 - val_mae: 2.5103\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 1.2815 - mae: 0.8299 - val_loss: 12.2031 - val_mae: 2.4969\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1826 - mae: 0.8016 - val_loss: 13.2502 - val_mae: 2.6303\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1724 - mae: 0.8183 - val_loss: 12.4718 - val_mae: 2.5534\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.2805 - mae: 0.8678 - val_loss: 11.6042 - val_mae: 2.4572\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2169 - mae: 0.8455 - val_loss: 12.2602 - val_mae: 2.5328\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2226 - mae: 0.8306 - val_loss: 11.3973 - val_mae: 2.4393\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1827 - mae: 0.8257 - val_loss: 11.4369 - val_mae: 2.4426\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2216 - mae: 0.8283 - val_loss: 12.2319 - val_mae: 2.5040\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0883 - mae: 0.7823 - val_loss: 12.7381 - val_mae: 2.5596\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1722 - mae: 0.8045 - val_loss: 11.8968 - val_mae: 2.4822\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2349 - mae: 0.8153 - val_loss: 11.9975 - val_mae: 2.4928\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1077 - mae: 0.8198 - val_loss: 12.0148 - val_mae: 2.4884\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1925 - mae: 0.8149 - val_loss: 11.6775 - val_mae: 2.4596\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1194 - mae: 0.7859 - val_loss: 12.2131 - val_mae: 2.5126\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.0369 - mae: 0.7785 - val_loss: 12.9665 - val_mae: 2.5395\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2211 - mae: 0.8338 - val_loss: 12.1049 - val_mae: 2.4851\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.1219 - mae: 0.7817 - val_loss: 12.2458 - val_mae: 2.4978\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1336 - mae: 0.8012 - val_loss: 12.0507 - val_mae: 2.4689\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1198 - mae: 0.7841 - val_loss: 12.1528 - val_mae: 2.5460\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1329 - mae: 0.8034 - val_loss: 12.4438 - val_mae: 2.5235\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2262 - mae: 0.8206 - val_loss: 11.7957 - val_mae: 2.4753\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0857 - mae: 0.7696 - val_loss: 12.0392 - val_mae: 2.5273\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0777 - mae: 0.7765 - val_loss: 12.7092 - val_mae: 2.5804\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0404 - mae: 0.7582 - val_loss: 12.4380 - val_mae: 2.5004\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1458 - mae: 0.8037 - val_loss: 12.1363 - val_mae: 2.4952\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 1.0977 - mae: 0.7901 - val_loss: 12.1213 - val_mae: 2.4927\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0245 - mae: 0.7520 - val_loss: 12.1089 - val_mae: 2.5025\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0062 - mae: 0.7559 - val_loss: 11.7381 - val_mae: 2.4939\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.0993 - mae: 0.7854 - val_loss: 12.4344 - val_mae: 2.5211\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0168 - mae: 0.7428 - val_loss: 12.0838 - val_mae: 2.5058\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1289 - mae: 0.7786 - val_loss: 12.0285 - val_mae: 2.5005\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0165 - mae: 0.7653 - val_loss: 11.7883 - val_mae: 2.5031\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 1.1146 - mae: 0.7701 - val_loss: 12.0625 - val_mae: 2.4933\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0732 - mae: 0.7822 - val_loss: 11.9389 - val_mae: 2.4958\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0215 - mae: 0.7691 - val_loss: 12.1048 - val_mae: 2.4791\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1322 - mae: 0.7854 - val_loss: 11.9262 - val_mae: 2.5144\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0137 - mae: 0.7506 - val_loss: 12.5574 - val_mae: 2.5296\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9616 - mae: 0.7191 - val_loss: 12.1125 - val_mae: 2.5039\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0398 - mae: 0.7542 - val_loss: 12.0580 - val_mae: 2.4967\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9608 - mae: 0.7367 - val_loss: 12.3322 - val_mae: 2.5051\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9712 - mae: 0.7339 - val_loss: 12.1000 - val_mae: 2.5098\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0275 - mae: 0.7598 - val_loss: 12.7447 - val_mae: 2.5994\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1002 - mae: 0.7831 - val_loss: 11.9051 - val_mae: 2.4868\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9227 - mae: 0.7332 - val_loss: 12.0829 - val_mae: 2.4559\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1043 - mae: 0.7910 - val_loss: 12.0863 - val_mae: 2.5135\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9682 - mae: 0.7246 - val_loss: 12.3875 - val_mae: 2.5524\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9519 - mae: 0.7378 - val_loss: 11.9351 - val_mae: 2.4971\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0216 - mae: 0.7551 - val_loss: 12.2780 - val_mae: 2.5086\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1189 - mae: 0.7866 - val_loss: 12.2669 - val_mae: 2.4874\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.8959 - mae: 0.6951 - val_loss: 11.8418 - val_mae: 2.4859\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0249 - mae: 0.7524 - val_loss: 12.5779 - val_mae: 2.5225\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0151 - mae: 0.7498 - val_loss: 12.1326 - val_mae: 2.4857\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9872 - mae: 0.7319 - val_loss: 12.1977 - val_mae: 2.4896\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9336 - mae: 0.7276 - val_loss: 12.2177 - val_mae: 2.5243\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0021 - mae: 0.7473 - val_loss: 11.9813 - val_mae: 2.5205\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9523 - mae: 0.7123 - val_loss: 12.1626 - val_mae: 2.5144\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9808 - mae: 0.7401 - val_loss: 12.2467 - val_mae: 2.5136\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0500 - mae: 0.7633 - val_loss: 12.0497 - val_mae: 2.4862\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9078 - mae: 0.7083 - val_loss: 11.5257 - val_mae: 2.4890\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9407 - mae: 0.7347 - val_loss: 11.9350 - val_mae: 2.4892\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8711 - mae: 0.6947 - val_loss: 12.2524 - val_mae: 2.5103\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.0599 - mae: 0.7581 - val_loss: 12.6791 - val_mae: 2.5479\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8247 - mae: 0.6735 - val_loss: 12.7399 - val_mae: 2.5972\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8866 - mae: 0.6931 - val_loss: 12.7583 - val_mae: 2.5904\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9234 - mae: 0.7276 - val_loss: 11.8944 - val_mae: 2.4958\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9089 - mae: 0.7035 - val_loss: 12.0969 - val_mae: 2.4975\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8981 - mae: 0.7091 - val_loss: 12.4231 - val_mae: 2.5227\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9941 - mae: 0.7286 - val_loss: 11.6996 - val_mae: 2.4860\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9565 - mae: 0.7330 - val_loss: 11.9757 - val_mae: 2.5390\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8766 - mae: 0.6913 - val_loss: 12.3112 - val_mae: 2.5307\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8217 - mae: 0.6834 - val_loss: 12.2508 - val_mae: 2.5229\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7986 - mae: 0.6803 - val_loss: 12.2455 - val_mae: 2.5015\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8567 - mae: 0.6878 - val_loss: 12.4579 - val_mae: 2.5403\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8568 - mae: 0.6916 - val_loss: 12.5121 - val_mae: 2.5599\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8615 - mae: 0.6876 - val_loss: 11.9419 - val_mae: 2.5478\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9378 - mae: 0.7334 - val_loss: 11.9620 - val_mae: 2.5376\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8216 - mae: 0.6849 - val_loss: 12.9667 - val_mae: 2.5991\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7794 - mae: 0.6715 - val_loss: 12.1266 - val_mae: 2.5192\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7919 - mae: 0.6642 - val_loss: 12.6861 - val_mae: 2.5607\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8652 - mae: 0.6968 - val_loss: 12.4192 - val_mae: 2.5548\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7582 - mae: 0.6527 - val_loss: 12.2344 - val_mae: 2.5469\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8746 - mae: 0.6897 - val_loss: 12.3326 - val_mae: 2.5214\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8369 - mae: 0.6938 - val_loss: 12.5388 - val_mae: 2.5698\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8055 - mae: 0.6731 - val_loss: 11.9585 - val_mae: 2.5349\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8059 - mae: 0.6758 - val_loss: 12.7314 - val_mae: 2.5467\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8209 - mae: 0.6731 - val_loss: 11.8991 - val_mae: 2.5585\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8416 - mae: 0.6797 - val_loss: 11.9850 - val_mae: 2.5022\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8552 - mae: 0.6756 - val_loss: 11.9887 - val_mae: 2.5153\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7874 - mae: 0.6536 - val_loss: 12.4307 - val_mae: 2.5205\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8731 - mae: 0.6863 - val_loss: 12.0857 - val_mae: 2.5338\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8257 - mae: 0.6759 - val_loss: 12.6595 - val_mae: 2.5347\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7438 - mae: 0.6547 - val_loss: 12.2598 - val_mae: 2.5284\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7187 - mae: 0.6528 - val_loss: 12.8304 - val_mae: 2.5458\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.8745 - mae: 0.6745 - val_loss: 12.0391 - val_mae: 2.5224\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7787 - mae: 0.6463 - val_loss: 12.0827 - val_mae: 2.5144\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8296 - mae: 0.6825 - val_loss: 12.8093 - val_mae: 2.5678\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7412 - mae: 0.6428 - val_loss: 13.6014 - val_mae: 2.7254\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7349 - mae: 0.6448 - val_loss: 12.8137 - val_mae: 2.5617\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8120 - mae: 0.6755 - val_loss: 13.2968 - val_mae: 2.5872\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7673 - mae: 0.6654 - val_loss: 12.2360 - val_mae: 2.5478\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7885 - mae: 0.6545 - val_loss: 12.3472 - val_mae: 2.5574\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8279 - mae: 0.6777 - val_loss: 12.4120 - val_mae: 2.5442\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6635 - mae: 0.5861 - val_loss: 11.8872 - val_mae: 2.5237\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8474 - mae: 0.6880 - val_loss: 11.9219 - val_mae: 2.5399\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7781 - mae: 0.6606 - val_loss: 12.4442 - val_mae: 2.5592\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7231 - mae: 0.6392 - val_loss: 12.4190 - val_mae: 2.5381\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6856 - mae: 0.6206 - val_loss: 12.2584 - val_mae: 2.5573\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7756 - mae: 0.6331 - val_loss: 13.1366 - val_mae: 2.6027\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8009 - mae: 0.6736 - val_loss: 12.3712 - val_mae: 2.5375\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6759 - mae: 0.6105 - val_loss: 12.4003 - val_mae: 2.5319\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7848 - mae: 0.6820 - val_loss: 12.6363 - val_mae: 2.5304\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7282 - mae: 0.6379 - val_loss: 11.9905 - val_mae: 2.5290\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7624 - mae: 0.6508 - val_loss: 12.1705 - val_mae: 2.4989\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7176 - mae: 0.6271 - val_loss: 12.4263 - val_mae: 2.5718\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8004 - mae: 0.6621 - val_loss: 12.1233 - val_mae: 2.5241\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7758 - mae: 0.6652 - val_loss: 12.9159 - val_mae: 2.6153\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.7340 - mae: 0.6347 - val_loss: 12.8364 - val_mae: 2.5771\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6787 - mae: 0.6140 - val_loss: 12.1754 - val_mae: 2.5363\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7033 - mae: 0.6160 - val_loss: 12.7420 - val_mae: 2.5614\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7060 - mae: 0.6475 - val_loss: 13.4312 - val_mae: 2.6037\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6766 - mae: 0.6176 - val_loss: 13.0922 - val_mae: 2.5765\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7193 - mae: 0.6226 - val_loss: 12.4850 - val_mae: 2.5455\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6405 - mae: 0.5929 - val_loss: 12.7413 - val_mae: 2.5964\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7209 - mae: 0.6441 - val_loss: 12.7426 - val_mae: 2.5733\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7761 - mae: 0.6360 - val_loss: 12.5154 - val_mae: 2.5585\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7424 - mae: 0.6307 - val_loss: 12.3570 - val_mae: 2.5453\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6418 - mae: 0.5967 - val_loss: 13.6452 - val_mae: 2.7139\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7122 - mae: 0.6256 - val_loss: 12.6363 - val_mae: 2.5617\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7424 - mae: 0.6157 - val_loss: 12.5353 - val_mae: 2.5731\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7008 - mae: 0.6281 - val_loss: 12.7806 - val_mae: 2.6141\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5948 - mae: 0.5836 - val_loss: 13.9693 - val_mae: 2.7025\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7439 - mae: 0.6374 - val_loss: 12.8668 - val_mae: 2.6210\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6199 - mae: 0.5839 - val_loss: 12.7773 - val_mae: 2.5845\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7354 - mae: 0.6233 - val_loss: 12.7376 - val_mae: 2.6087\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6866 - mae: 0.6197 - val_loss: 12.3822 - val_mae: 2.5321\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6151 - mae: 0.5822 - val_loss: 11.9735 - val_mae: 2.5324\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7429 - mae: 0.6370 - val_loss: 13.0939 - val_mae: 2.5807\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6038 - mae: 0.5947 - val_loss: 12.3798 - val_mae: 2.5319\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8318 - mae: 0.6611 - val_loss: 12.7876 - val_mae: 2.6053\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6208 - mae: 0.5778 - val_loss: 11.9896 - val_mae: 2.5305\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.5941 - mae: 0.5780 - val_loss: 13.2526 - val_mae: 2.6158\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6733 - mae: 0.6043 - val_loss: 12.7283 - val_mae: 2.5719\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6292 - mae: 0.5830 - val_loss: 13.0552 - val_mae: 2.5871\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5589 - mae: 0.5616 - val_loss: 12.7180 - val_mae: 2.6151\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7268 - mae: 0.6381 - val_loss: 12.5310 - val_mae: 2.5935\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6056 - mae: 0.5642 - val_loss: 12.7110 - val_mae: 2.6007\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7570 - mae: 0.6339 - val_loss: 12.6306 - val_mae: 2.5657\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.6616 - mae: 0.6000 - val_loss: 12.1637 - val_mae: 2.5314\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5868 - mae: 0.5634 - val_loss: 11.9869 - val_mae: 2.5179\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6382 - mae: 0.5890 - val_loss: 13.0534 - val_mae: 2.6069\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6869 - mae: 0.6001 - val_loss: 13.1161 - val_mae: 2.6571\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5841 - mae: 0.5797 - val_loss: 13.4694 - val_mae: 2.6294\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6576 - mae: 0.6176 - val_loss: 12.5622 - val_mae: 2.5673\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6354 - mae: 0.5862 - val_loss: 12.6954 - val_mae: 2.5711\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5811 - mae: 0.5745 - val_loss: 12.2786 - val_mae: 2.5528\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6869 - mae: 0.6167 - val_loss: 12.4767 - val_mae: 2.5817\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5991 - mae: 0.5802 - val_loss: 12.7286 - val_mae: 2.6006\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6159 - mae: 0.5915 - val_loss: 12.7908 - val_mae: 2.5765\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5877 - mae: 0.5496 - val_loss: 12.6880 - val_mae: 2.6033\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5985 - mae: 0.5701 - val_loss: 12.5661 - val_mae: 2.5733\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6658 - mae: 0.6138 - val_loss: 12.5671 - val_mae: 2.5794\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6724 - mae: 0.5936 - val_loss: 12.3146 - val_mae: 2.5661\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5441 - mae: 0.5450 - val_loss: 12.4598 - val_mae: 2.5788\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7102 - mae: 0.6035 - val_loss: 12.4684 - val_mae: 2.5810\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6946 - mae: 0.6218 - val_loss: 13.0353 - val_mae: 2.6048\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5162 - mae: 0.5454 - val_loss: 12.2325 - val_mae: 2.5683\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5927 - mae: 0.5766 - val_loss: 13.1198 - val_mae: 2.6312\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6551 - mae: 0.5930 - val_loss: 14.0611 - val_mae: 2.7259\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6667 - mae: 0.6000 - val_loss: 13.4054 - val_mae: 2.6615\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5529 - mae: 0.5470 - val_loss: 12.3063 - val_mae: 2.5393\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5712 - mae: 0.5677 - val_loss: 13.4225 - val_mae: 2.6059\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5670 - mae: 0.5758 - val_loss: 12.2129 - val_mae: 2.5342\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.5980 - mae: 0.5557 - val_loss: 12.9766 - val_mae: 2.6224\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.4743 - mae: 0.5186 - val_loss: 12.3547 - val_mae: 2.5876\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6900 - mae: 0.6323 - val_loss: 13.0556 - val_mae: 2.5980\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5563 - mae: 0.5547 - val_loss: 12.2107 - val_mae: 2.5536\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5549 - mae: 0.5422 - val_loss: 12.8328 - val_mae: 2.6013\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5389 - mae: 0.5345 - val_loss: 13.5286 - val_mae: 2.6682\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6223 - mae: 0.5795 - val_loss: 12.6477 - val_mae: 2.5746\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5989 - mae: 0.5595 - val_loss: 13.0751 - val_mae: 2.6176\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5312 - mae: 0.5452 - val_loss: 13.5525 - val_mae: 2.6696\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6694 - mae: 0.6079 - val_loss: 12.3374 - val_mae: 2.5536\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4853 - mae: 0.5350 - val_loss: 12.5255 - val_mae: 2.5871\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5600 - mae: 0.5641 - val_loss: 12.5476 - val_mae: 2.5639\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5795 - mae: 0.5564 - val_loss: 12.4612 - val_mae: 2.6085\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5050 - mae: 0.5294 - val_loss: 12.6720 - val_mae: 2.6037\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5036 - mae: 0.5505 - val_loss: 12.3938 - val_mae: 2.6004\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5764 - mae: 0.5669 - val_loss: 12.2936 - val_mae: 2.5803\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5279 - mae: 0.5505 - val_loss: 12.3563 - val_mae: 2.5699\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5220 - mae: 0.5473 - val_loss: 12.8590 - val_mae: 2.6104\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5609 - mae: 0.5519 - val_loss: 13.0103 - val_mae: 2.6025\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5436 - mae: 0.5519 - val_loss: 13.2721 - val_mae: 2.6232\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4858 - mae: 0.5195 - val_loss: 12.5271 - val_mae: 2.5881\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5223 - mae: 0.5446 - val_loss: 11.9738 - val_mae: 2.5428\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4560 - mae: 0.4957 - val_loss: 13.0579 - val_mae: 2.6251\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5039 - mae: 0.5385 - val_loss: 13.1621 - val_mae: 2.6236\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6223 - mae: 0.5689 - val_loss: 12.8364 - val_mae: 2.6063\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.5274 - mae: 0.5296 - val_loss: 12.9792 - val_mae: 2.6130\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6272 - mae: 0.5826 - val_loss: 12.3709 - val_mae: 2.5491\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5514 - mae: 0.5332 - val_loss: 13.2120 - val_mae: 2.6439\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4716 - mae: 0.5089 - val_loss: 13.0532 - val_mae: 2.6479\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5507 - mae: 0.5545 - val_loss: 12.8599 - val_mae: 2.6377\n",
            "Processing fold #3\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 501.6005 - mae: 20.6106 - val_loss: 566.9244 - val_mae: 21.6815\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 384.2441 - mae: 17.5863 - val_loss: 423.7494 - val_mae: 18.2393\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 254.6224 - mae: 13.7269 - val_loss: 268.1717 - val_mae: 13.8461\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 140.2345 - mae: 9.6452 - val_loss: 150.1642 - val_mae: 9.3524\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 69.2883 - mae: 6.3016 - val_loss: 86.8385 - val_mae: 6.6812\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 40.4865 - mae: 4.6145 - val_loss: 60.2267 - val_mae: 5.3968\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 30.5644 - mae: 3.8543 - val_loss: 45.7954 - val_mae: 4.6401\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 25.1999 - mae: 3.4695 - val_loss: 39.5571 - val_mae: 4.2393\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 22.2984 - mae: 3.2159 - val_loss: 32.4876 - val_mae: 3.9157\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 20.0495 - mae: 3.0548 - val_loss: 28.8704 - val_mae: 3.7577\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 18.4716 - mae: 2.9328 - val_loss: 26.0379 - val_mae: 3.5802\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 17.2635 - mae: 2.8858 - val_loss: 24.8098 - val_mae: 3.4556\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 15.9217 - mae: 2.7561 - val_loss: 22.2043 - val_mae: 3.2493\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 14.9471 - mae: 2.6531 - val_loss: 20.8214 - val_mae: 3.1284\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 14.4038 - mae: 2.6154 - val_loss: 19.6929 - val_mae: 3.0598\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 13.4526 - mae: 2.5258 - val_loss: 18.9354 - val_mae: 3.0444\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 12.9855 - mae: 2.5268 - val_loss: 18.3838 - val_mae: 2.9395\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.5270 - mae: 2.4304 - val_loss: 17.2778 - val_mae: 2.8873\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 12.0741 - mae: 2.3854 - val_loss: 16.2649 - val_mae: 2.7877\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.4829 - mae: 2.3487 - val_loss: 16.1008 - val_mae: 2.7934\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.1492 - mae: 2.3337 - val_loss: 15.3869 - val_mae: 2.7867\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.8147 - mae: 2.2872 - val_loss: 15.5700 - val_mae: 2.8192\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.6323 - mae: 2.3121 - val_loss: 15.2668 - val_mae: 2.7210\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 10.4388 - mae: 2.2630 - val_loss: 14.9348 - val_mae: 2.7061\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.0198 - mae: 2.2046 - val_loss: 14.8270 - val_mae: 2.7099\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.9550 - mae: 2.1679 - val_loss: 13.9605 - val_mae: 2.6476\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.7205 - mae: 2.1840 - val_loss: 13.9467 - val_mae: 2.6209\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.5950 - mae: 2.1688 - val_loss: 13.7398 - val_mae: 2.6080\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.3174 - mae: 2.0987 - val_loss: 13.2434 - val_mae: 2.5439\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.2503 - mae: 2.1280 - val_loss: 13.8576 - val_mae: 2.6778\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.0441 - mae: 2.0859 - val_loss: 13.0874 - val_mae: 2.5661\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.9651 - mae: 2.1173 - val_loss: 13.2719 - val_mae: 2.5745\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.9062 - mae: 2.1055 - val_loss: 13.2919 - val_mae: 2.5705\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.7729 - mae: 2.0276 - val_loss: 12.7719 - val_mae: 2.4825\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.7679 - mae: 2.0741 - val_loss: 13.0468 - val_mae: 2.5507\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.2752 - mae: 2.0158 - val_loss: 13.2728 - val_mae: 2.5760\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.5107 - mae: 2.0227 - val_loss: 12.7767 - val_mae: 2.4857\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.2386 - mae: 1.9797 - val_loss: 13.5377 - val_mae: 2.6850\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 8.2595 - mae: 1.9861 - val_loss: 13.0000 - val_mae: 2.5149\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.0675 - mae: 2.0075 - val_loss: 12.7974 - val_mae: 2.5228\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.0786 - mae: 1.9526 - val_loss: 12.4733 - val_mae: 2.4671\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.1068 - mae: 2.0030 - val_loss: 12.7200 - val_mae: 2.5466\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.9438 - mae: 1.9317 - val_loss: 12.8602 - val_mae: 2.5013\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.7832 - mae: 1.9446 - val_loss: 12.6660 - val_mae: 2.5092\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.6540 - mae: 1.8903 - val_loss: 12.4708 - val_mae: 2.4553\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.7910 - mae: 1.9403 - val_loss: 12.3503 - val_mae: 2.4564\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.5481 - mae: 1.8685 - val_loss: 12.2700 - val_mae: 2.4355\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 7.5128 - mae: 1.8723 - val_loss: 12.4537 - val_mae: 2.4696\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.5294 - mae: 1.8698 - val_loss: 12.4128 - val_mae: 2.4706\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 7.3774 - mae: 1.8985 - val_loss: 12.6265 - val_mae: 2.4983\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.1353 - mae: 1.8278 - val_loss: 12.4694 - val_mae: 2.4550\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 7.0434 - mae: 1.8766 - val_loss: 12.6587 - val_mae: 2.5592\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.0406 - mae: 1.7484 - val_loss: 12.2680 - val_mae: 2.4281\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.1462 - mae: 1.8508 - val_loss: 12.4815 - val_mae: 2.4980\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.2971 - mae: 1.8475 - val_loss: 12.2684 - val_mae: 2.4804\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9698 - mae: 1.7956 - val_loss: 12.2806 - val_mae: 2.4726\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.1175 - mae: 1.8234 - val_loss: 12.4081 - val_mae: 2.5060\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.7883 - mae: 1.7738 - val_loss: 12.1358 - val_mae: 2.4731\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.7034 - mae: 1.7694 - val_loss: 12.4396 - val_mae: 2.4835\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.8320 - mae: 1.8058 - val_loss: 12.3668 - val_mae: 2.4942\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.6633 - mae: 1.7730 - val_loss: 12.6455 - val_mae: 2.5192\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.5925 - mae: 1.7735 - val_loss: 12.8168 - val_mae: 2.5537\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5197 - mae: 1.7541 - val_loss: 12.2384 - val_mae: 2.4749\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 6.6753 - mae: 1.7649 - val_loss: 12.2127 - val_mae: 2.4742\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.3478 - mae: 1.7289 - val_loss: 12.5852 - val_mae: 2.5390\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.4313 - mae: 1.7453 - val_loss: 12.3879 - val_mae: 2.4888\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.2674 - mae: 1.6857 - val_loss: 12.4615 - val_mae: 2.4601\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3305 - mae: 1.7601 - val_loss: 12.3393 - val_mae: 2.4947\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.1763 - mae: 1.7215 - val_loss: 12.2964 - val_mae: 2.4795\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.1738 - mae: 1.7012 - val_loss: 12.0017 - val_mae: 2.4582\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9968 - mae: 1.6827 - val_loss: 12.2898 - val_mae: 2.4925\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0272 - mae: 1.6888 - val_loss: 12.3368 - val_mae: 2.5049\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8964 - mae: 1.6573 - val_loss: 12.2921 - val_mae: 2.4414\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7038 - mae: 1.6354 - val_loss: 12.4527 - val_mae: 2.5284\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9567 - mae: 1.6496 - val_loss: 12.4830 - val_mae: 2.5179\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8761 - mae: 1.6461 - val_loss: 12.5478 - val_mae: 2.5123\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7457 - mae: 1.6680 - val_loss: 12.0628 - val_mae: 2.4344\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7277 - mae: 1.6229 - val_loss: 12.4115 - val_mae: 2.4791\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.6915 - mae: 1.6456 - val_loss: 12.2902 - val_mae: 2.4446\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6231 - mae: 1.6543 - val_loss: 12.5257 - val_mae: 2.5190\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4707 - mae: 1.5924 - val_loss: 12.6167 - val_mae: 2.5422\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6174 - mae: 1.6446 - val_loss: 12.2823 - val_mae: 2.4829\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5283 - mae: 1.5983 - val_loss: 12.3902 - val_mae: 2.4882\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5544 - mae: 1.6176 - val_loss: 12.2998 - val_mae: 2.4831\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.3845 - mae: 1.5558 - val_loss: 12.4025 - val_mae: 2.5322\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4871 - mae: 1.5818 - val_loss: 12.4224 - val_mae: 2.4952\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.2535 - mae: 1.5539 - val_loss: 12.4674 - val_mae: 2.4865\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4141 - mae: 1.5674 - val_loss: 12.1456 - val_mae: 2.4758\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.3669 - mae: 1.5650 - val_loss: 12.6015 - val_mae: 2.5183\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1226 - mae: 1.5435 - val_loss: 12.1281 - val_mae: 2.4840\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 5.2178 - mae: 1.5565 - val_loss: 12.0098 - val_mae: 2.4548\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.3244 - mae: 1.5650 - val_loss: 11.9007 - val_mae: 2.4562\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1795 - mae: 1.5535 - val_loss: 12.3203 - val_mae: 2.4755\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0565 - mae: 1.5571 - val_loss: 12.2327 - val_mae: 2.4795\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0084 - mae: 1.5194 - val_loss: 11.9562 - val_mae: 2.4580\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0917 - mae: 1.5389 - val_loss: 12.0976 - val_mae: 2.4390\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0490 - mae: 1.5045 - val_loss: 12.3312 - val_mae: 2.4408\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.9405 - mae: 1.5287 - val_loss: 12.5765 - val_mae: 2.5558\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.9182 - mae: 1.5098 - val_loss: 12.3161 - val_mae: 2.4576\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0120 - mae: 1.5160 - val_loss: 12.3949 - val_mae: 2.5453\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8173 - mae: 1.5038 - val_loss: 12.3051 - val_mae: 2.4715\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.8444 - mae: 1.4872 - val_loss: 12.1783 - val_mae: 2.4678\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8275 - mae: 1.4647 - val_loss: 12.0829 - val_mae: 2.4427\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8261 - mae: 1.4971 - val_loss: 12.7226 - val_mae: 2.5651\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8246 - mae: 1.5543 - val_loss: 12.4294 - val_mae: 2.4740\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7311 - mae: 1.4628 - val_loss: 12.5660 - val_mae: 2.4704\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6931 - mae: 1.4761 - val_loss: 12.3866 - val_mae: 2.5406\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7255 - mae: 1.4789 - val_loss: 12.9443 - val_mae: 2.5171\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5757 - mae: 1.4623 - val_loss: 12.0634 - val_mae: 2.4783\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6252 - mae: 1.4726 - val_loss: 12.2167 - val_mae: 2.4568\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5782 - mae: 1.4517 - val_loss: 12.2782 - val_mae: 2.4470\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5810 - mae: 1.4432 - val_loss: 12.4246 - val_mae: 2.4750\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5563 - mae: 1.4497 - val_loss: 13.3072 - val_mae: 2.5688\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4815 - mae: 1.4070 - val_loss: 12.3368 - val_mae: 2.4722\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4529 - mae: 1.4376 - val_loss: 12.8592 - val_mae: 2.5267\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4619 - mae: 1.4575 - val_loss: 13.1159 - val_mae: 2.5647\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5855 - mae: 1.4648 - val_loss: 12.2124 - val_mae: 2.4552\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3102 - mae: 1.4111 - val_loss: 12.3711 - val_mae: 2.5081\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4392 - mae: 1.4417 - val_loss: 12.4898 - val_mae: 2.4766\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4347 - mae: 1.4557 - val_loss: 12.8480 - val_mae: 2.5485\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4431 - mae: 1.4331 - val_loss: 12.3095 - val_mae: 2.4855\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2667 - mae: 1.3874 - val_loss: 12.6492 - val_mae: 2.4816\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2698 - mae: 1.4209 - val_loss: 12.7795 - val_mae: 2.5129\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3508 - mae: 1.4241 - val_loss: 12.6786 - val_mae: 2.5394\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2113 - mae: 1.4028 - val_loss: 12.4946 - val_mae: 2.5113\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2761 - mae: 1.4063 - val_loss: 12.7361 - val_mae: 2.5106\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2319 - mae: 1.4008 - val_loss: 12.3378 - val_mae: 2.4546\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1882 - mae: 1.3509 - val_loss: 13.1085 - val_mae: 2.5486\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1565 - mae: 1.4036 - val_loss: 12.4939 - val_mae: 2.4944\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2177 - mae: 1.3563 - val_loss: 12.5741 - val_mae: 2.4522\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9913 - mae: 1.3483 - val_loss: 13.7939 - val_mae: 2.6378\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1599 - mae: 1.3762 - val_loss: 12.2983 - val_mae: 2.4557\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0601 - mae: 1.3529 - val_loss: 13.4565 - val_mae: 2.6209\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0087 - mae: 1.3614 - val_loss: 12.3115 - val_mae: 2.4556\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0008 - mae: 1.3545 - val_loss: 12.8313 - val_mae: 2.4929\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9088 - mae: 1.3421 - val_loss: 13.0194 - val_mae: 2.5412\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0072 - mae: 1.3573 - val_loss: 13.1571 - val_mae: 2.5264\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9291 - mae: 1.3261 - val_loss: 12.2935 - val_mae: 2.4834\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 3.9781 - mae: 1.3610 - val_loss: 12.2571 - val_mae: 2.4591\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9581 - mae: 1.3642 - val_loss: 12.9647 - val_mae: 2.5340\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.9201 - mae: 1.3565 - val_loss: 13.2064 - val_mae: 2.5038\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0332 - mae: 1.3631 - val_loss: 12.9956 - val_mae: 2.5153\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9364 - mae: 1.3442 - val_loss: 12.6828 - val_mae: 2.4735\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8531 - mae: 1.3571 - val_loss: 13.4223 - val_mae: 2.5751\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1111 - mae: 1.3607 - val_loss: 12.3601 - val_mae: 2.4343\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8239 - mae: 1.3275 - val_loss: 12.6359 - val_mae: 2.4810\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7426 - mae: 1.3083 - val_loss: 12.6109 - val_mae: 2.4877\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7325 - mae: 1.3443 - val_loss: 12.7651 - val_mae: 2.5061\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8720 - mae: 1.3124 - val_loss: 12.4751 - val_mae: 2.4580\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 3.9748 - mae: 1.3258 - val_loss: 12.1171 - val_mae: 2.4229\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6301 - mae: 1.2904 - val_loss: 12.4633 - val_mae: 2.4529\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7220 - mae: 1.3088 - val_loss: 12.7444 - val_mae: 2.4857\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8218 - mae: 1.3469 - val_loss: 12.4856 - val_mae: 2.4599\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7447 - mae: 1.2953 - val_loss: 12.4214 - val_mae: 2.4790\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7268 - mae: 1.3274 - val_loss: 12.4164 - val_mae: 2.4682\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6700 - mae: 1.2898 - val_loss: 12.9606 - val_mae: 2.5770\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6597 - mae: 1.2975 - val_loss: 13.0510 - val_mae: 2.5294\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5784 - mae: 1.3091 - val_loss: 12.1695 - val_mae: 2.4428\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5804 - mae: 1.2689 - val_loss: 12.7903 - val_mae: 2.4674\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6340 - mae: 1.2908 - val_loss: 12.4010 - val_mae: 2.4970\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4164 - mae: 1.2340 - val_loss: 12.3951 - val_mae: 2.4748\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5325 - mae: 1.2769 - val_loss: 12.7020 - val_mae: 2.4609\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6782 - mae: 1.2862 - val_loss: 12.4779 - val_mae: 2.4637\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2925 - mae: 1.2279 - val_loss: 12.8082 - val_mae: 2.5069\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4533 - mae: 1.2207 - val_loss: 12.5246 - val_mae: 2.4659\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5921 - mae: 1.2542 - val_loss: 12.9748 - val_mae: 2.4925\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3372 - mae: 1.2190 - val_loss: 13.0636 - val_mae: 2.5631\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4362 - mae: 1.2812 - val_loss: 12.8415 - val_mae: 2.4681\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4891 - mae: 1.2604 - val_loss: 12.5155 - val_mae: 2.4855\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4323 - mae: 1.2437 - val_loss: 12.6831 - val_mae: 2.4921\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2723 - mae: 1.1990 - val_loss: 12.6023 - val_mae: 2.4674\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 3.4258 - mae: 1.2574 - val_loss: 12.7637 - val_mae: 2.4884\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4667 - mae: 1.2420 - val_loss: 13.4493 - val_mae: 2.6081\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3092 - mae: 1.2132 - val_loss: 12.8053 - val_mae: 2.5773\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3563 - mae: 1.2604 - val_loss: 12.3278 - val_mae: 2.4532\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2308 - mae: 1.1907 - val_loss: 13.0137 - val_mae: 2.5545\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3621 - mae: 1.2427 - val_loss: 12.9385 - val_mae: 2.5572\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2691 - mae: 1.2288 - val_loss: 12.3013 - val_mae: 2.4329\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2256 - mae: 1.2524 - val_loss: 12.4166 - val_mae: 2.4709\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2165 - mae: 1.2111 - val_loss: 13.3496 - val_mae: 2.6478\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2348 - mae: 1.2015 - val_loss: 12.6150 - val_mae: 2.5011\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3449 - mae: 1.2566 - val_loss: 12.5093 - val_mae: 2.4912\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1075 - mae: 1.1907 - val_loss: 13.2155 - val_mae: 2.6140\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3317 - mae: 1.2192 - val_loss: 12.3811 - val_mae: 2.4535\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1803 - mae: 1.2031 - val_loss: 12.4090 - val_mae: 2.4433\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0655 - mae: 1.1792 - val_loss: 13.2446 - val_mae: 2.5634\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0405 - mae: 1.1886 - val_loss: 14.1006 - val_mae: 2.7248\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2821 - mae: 1.2295 - val_loss: 12.1248 - val_mae: 2.4568\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1610 - mae: 1.2002 - val_loss: 12.7918 - val_mae: 2.4762\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1520 - mae: 1.2088 - val_loss: 12.6733 - val_mae: 2.5050\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9242 - mae: 1.1662 - val_loss: 12.7704 - val_mae: 2.4653\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9105 - mae: 1.1854 - val_loss: 13.9940 - val_mae: 2.6900\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 2.9951 - mae: 1.1714 - val_loss: 13.2304 - val_mae: 2.6082\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9914 - mae: 1.2079 - val_loss: 12.3303 - val_mae: 2.4731\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 3.0896 - mae: 1.1760 - val_loss: 12.7110 - val_mae: 2.5002\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0475 - mae: 1.1436 - val_loss: 12.9184 - val_mae: 2.5631\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1209 - mae: 1.2184 - val_loss: 12.5462 - val_mae: 2.4682\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0881 - mae: 1.1939 - val_loss: 12.3592 - val_mae: 2.4409\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0469 - mae: 1.1993 - val_loss: 12.4168 - val_mae: 2.4841\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8715 - mae: 1.1664 - val_loss: 12.6676 - val_mae: 2.5307\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9741 - mae: 1.1774 - val_loss: 12.7561 - val_mae: 2.4971\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8889 - mae: 1.1867 - val_loss: 12.2907 - val_mae: 2.4327\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9802 - mae: 1.1691 - val_loss: 12.4796 - val_mae: 2.4496\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9887 - mae: 1.1703 - val_loss: 12.6300 - val_mae: 2.4783\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8119 - mae: 1.1176 - val_loss: 13.2391 - val_mae: 2.5424\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0595 - mae: 1.1785 - val_loss: 12.8722 - val_mae: 2.5665\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 2.9388 - mae: 1.1702 - val_loss: 13.0944 - val_mae: 2.5706\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8403 - mae: 1.1390 - val_loss: 12.3467 - val_mae: 2.4173\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8860 - mae: 1.1703 - val_loss: 12.3015 - val_mae: 2.4601\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8009 - mae: 1.1446 - val_loss: 12.5605 - val_mae: 2.4575\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8160 - mae: 1.1365 - val_loss: 12.6290 - val_mae: 2.4987\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7941 - mae: 1.1266 - val_loss: 12.3886 - val_mae: 2.4588\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 2.7500 - mae: 1.1302 - val_loss: 13.4441 - val_mae: 2.6100\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0392 - mae: 1.1509 - val_loss: 12.6915 - val_mae: 2.4532\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7907 - mae: 1.1033 - val_loss: 12.6010 - val_mae: 2.4943\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8768 - mae: 1.1647 - val_loss: 12.5367 - val_mae: 2.4690\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6967 - mae: 1.1068 - val_loss: 13.1349 - val_mae: 2.5856\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9037 - mae: 1.1588 - val_loss: 12.3011 - val_mae: 2.4440\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7503 - mae: 1.1375 - val_loss: 12.3331 - val_mae: 2.4626\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7945 - mae: 1.1095 - val_loss: 12.8699 - val_mae: 2.5078\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7385 - mae: 1.1376 - val_loss: 13.1248 - val_mae: 2.5878\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7178 - mae: 1.0994 - val_loss: 12.6751 - val_mae: 2.4886\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7492 - mae: 1.1002 - val_loss: 12.2885 - val_mae: 2.4164\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6539 - mae: 1.0982 - val_loss: 12.5972 - val_mae: 2.5076\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7459 - mae: 1.1011 - val_loss: 12.6211 - val_mae: 2.4716\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6969 - mae: 1.1039 - val_loss: 12.4075 - val_mae: 2.4634\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7483 - mae: 1.1141 - val_loss: 12.5914 - val_mae: 2.5105\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6900 - mae: 1.1166 - val_loss: 13.1742 - val_mae: 2.4992\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7647 - mae: 1.1241 - val_loss: 12.8338 - val_mae: 2.4867\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5904 - mae: 1.0965 - val_loss: 12.8698 - val_mae: 2.5312\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6248 - mae: 1.0691 - val_loss: 12.3794 - val_mae: 2.4663\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7097 - mae: 1.1342 - val_loss: 12.5584 - val_mae: 2.5184\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6627 - mae: 1.0922 - val_loss: 12.8133 - val_mae: 2.4898\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6199 - mae: 1.0801 - val_loss: 12.8593 - val_mae: 2.5426\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.5552 - mae: 1.0728 - val_loss: 12.6402 - val_mae: 2.4495\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6113 - mae: 1.0954 - val_loss: 12.2958 - val_mae: 2.4606\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8031 - mae: 1.1214 - val_loss: 13.0728 - val_mae: 2.5024\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6011 - mae: 1.0978 - val_loss: 12.6813 - val_mae: 2.5250\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5513 - mae: 1.0580 - val_loss: 13.1923 - val_mae: 2.5069\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6178 - mae: 1.0634 - val_loss: 12.7988 - val_mae: 2.5146\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5723 - mae: 1.0845 - val_loss: 12.4117 - val_mae: 2.5120\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5797 - mae: 1.0813 - val_loss: 12.5203 - val_mae: 2.5042\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6987 - mae: 1.1085 - val_loss: 12.7710 - val_mae: 2.5155\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5626 - mae: 1.1095 - val_loss: 12.3826 - val_mae: 2.4513\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5151 - mae: 1.0524 - val_loss: 13.2346 - val_mae: 2.5182\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4754 - mae: 1.0709 - val_loss: 12.5922 - val_mae: 2.4358\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4651 - mae: 1.0458 - val_loss: 13.2720 - val_mae: 2.5307\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4324 - mae: 1.0675 - val_loss: 12.6710 - val_mae: 2.4571\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4302 - mae: 1.0494 - val_loss: 12.8912 - val_mae: 2.5197\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4448 - mae: 1.0541 - val_loss: 12.7993 - val_mae: 2.5374\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4325 - mae: 1.0710 - val_loss: 12.7839 - val_mae: 2.5008\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4652 - mae: 1.0344 - val_loss: 14.1334 - val_mae: 2.7014\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4198 - mae: 1.0564 - val_loss: 12.3771 - val_mae: 2.4697\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3971 - mae: 1.0765 - val_loss: 12.4232 - val_mae: 2.5158\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4419 - mae: 1.0673 - val_loss: 13.3029 - val_mae: 2.5252\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4578 - mae: 1.0557 - val_loss: 12.6521 - val_mae: 2.5269\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3996 - mae: 1.0398 - val_loss: 12.7802 - val_mae: 2.4940\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3071 - mae: 1.0391 - val_loss: 13.1642 - val_mae: 2.4982\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.5073 - mae: 1.0682 - val_loss: 12.6100 - val_mae: 2.4436\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5016 - mae: 1.0522 - val_loss: 12.2000 - val_mae: 2.4189\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3555 - mae: 1.0290 - val_loss: 12.8671 - val_mae: 2.4427\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3973 - mae: 1.0401 - val_loss: 12.4420 - val_mae: 2.4423\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3325 - mae: 1.0337 - val_loss: 12.2739 - val_mae: 2.4479\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3851 - mae: 1.0298 - val_loss: 12.1440 - val_mae: 2.4423\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2434 - mae: 1.0162 - val_loss: 13.0938 - val_mae: 2.5730\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2191 - mae: 1.0227 - val_loss: 12.9534 - val_mae: 2.6200\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2026 - mae: 1.0120 - val_loss: 12.6817 - val_mae: 2.4902\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4194 - mae: 1.0613 - val_loss: 12.5063 - val_mae: 2.5194\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3031 - mae: 1.0044 - val_loss: 12.7597 - val_mae: 2.4976\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1835 - mae: 0.9995 - val_loss: 14.5665 - val_mae: 2.6723\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 1s 6ms/step - loss: 2.2992 - mae: 1.0047 - val_loss: 12.8945 - val_mae: 2.5423\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4787 - mae: 1.0598 - val_loss: 12.6215 - val_mae: 2.4788\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2183 - mae: 0.9694 - val_loss: 12.3484 - val_mae: 2.4651\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1584 - mae: 0.9872 - val_loss: 12.4888 - val_mae: 2.4945\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 2.2389 - mae: 1.0339 - val_loss: 12.4947 - val_mae: 2.4698\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2783 - mae: 1.0077 - val_loss: 12.5080 - val_mae: 2.5086\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3441 - mae: 1.0323 - val_loss: 12.6265 - val_mae: 2.4935\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2304 - mae: 1.0210 - val_loss: 12.7815 - val_mae: 2.5064\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1956 - mae: 1.0301 - val_loss: 14.1003 - val_mae: 2.7748\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3112 - mae: 1.0327 - val_loss: 12.7678 - val_mae: 2.5046\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1213 - mae: 0.9783 - val_loss: 12.6155 - val_mae: 2.5414\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2442 - mae: 1.0283 - val_loss: 13.9479 - val_mae: 2.7709\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2587 - mae: 0.9875 - val_loss: 12.7164 - val_mae: 2.5211\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3036 - mae: 1.0204 - val_loss: 12.4304 - val_mae: 2.4993\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1335 - mae: 0.9817 - val_loss: 12.2382 - val_mae: 2.4265\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1826 - mae: 0.9853 - val_loss: 13.0448 - val_mae: 2.5456\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2281 - mae: 1.0295 - val_loss: 13.0295 - val_mae: 2.6145\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3013 - mae: 0.9787 - val_loss: 12.4023 - val_mae: 2.4337\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2860 - mae: 1.0370 - val_loss: 13.0109 - val_mae: 2.5459\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1559 - mae: 0.9986 - val_loss: 12.5034 - val_mae: 2.4850\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.1386 - mae: 0.9950 - val_loss: 13.0919 - val_mae: 2.5131\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2473 - mae: 1.0231 - val_loss: 12.6628 - val_mae: 2.5089\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1417 - mae: 0.9727 - val_loss: 12.8764 - val_mae: 2.5878\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0572 - mae: 1.0030 - val_loss: 12.6691 - val_mae: 2.5148\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2458 - mae: 1.0625 - val_loss: 13.1702 - val_mae: 2.5200\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0962 - mae: 0.9599 - val_loss: 13.0828 - val_mae: 2.4849\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2000 - mae: 0.9863 - val_loss: 12.6119 - val_mae: 2.4760\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1390 - mae: 0.9599 - val_loss: 12.9305 - val_mae: 2.5004\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0371 - mae: 0.9651 - val_loss: 12.6763 - val_mae: 2.5160\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0603 - mae: 0.9934 - val_loss: 12.6236 - val_mae: 2.4770\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1650 - mae: 0.9865 - val_loss: 12.7860 - val_mae: 2.5006\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1909 - mae: 0.9899 - val_loss: 13.0730 - val_mae: 2.6155\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1963 - mae: 1.0252 - val_loss: 12.5148 - val_mae: 2.4943\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0765 - mae: 0.9335 - val_loss: 12.7143 - val_mae: 2.5224\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2487 - mae: 1.0304 - val_loss: 12.6200 - val_mae: 2.4800\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0446 - mae: 0.9512 - val_loss: 13.4646 - val_mae: 2.5484\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1230 - mae: 0.9615 - val_loss: 12.3502 - val_mae: 2.5110\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0480 - mae: 0.9600 - val_loss: 12.7485 - val_mae: 2.4969\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1.9599 - mae: 0.9347 - val_loss: 12.5634 - val_mae: 2.5025\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0563 - mae: 0.9745 - val_loss: 12.4491 - val_mae: 2.4717\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0289 - mae: 0.9308 - val_loss: 12.7863 - val_mae: 2.5512\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.0959 - mae: 0.9626 - val_loss: 12.8763 - val_mae: 2.5608\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0842 - mae: 0.9470 - val_loss: 13.1864 - val_mae: 2.5953\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9542 - mae: 0.9340 - val_loss: 13.2439 - val_mae: 2.5851\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0318 - mae: 0.9543 - val_loss: 12.9136 - val_mae: 2.5855\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.0717 - mae: 0.9884 - val_loss: 12.6027 - val_mae: 2.5333\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9942 - mae: 0.9540 - val_loss: 13.0267 - val_mae: 2.5139\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0132 - mae: 0.9584 - val_loss: 13.4117 - val_mae: 2.5213\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0885 - mae: 0.9773 - val_loss: 12.8836 - val_mae: 2.5213\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9299 - mae: 0.9319 - val_loss: 12.9705 - val_mae: 2.5586\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9408 - mae: 0.9520 - val_loss: 12.7382 - val_mae: 2.5039\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0724 - mae: 0.9522 - val_loss: 12.8486 - val_mae: 2.6035\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8892 - mae: 0.9273 - val_loss: 12.8787 - val_mae: 2.5495\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9274 - mae: 0.9521 - val_loss: 12.5389 - val_mae: 2.5157\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9921 - mae: 0.9456 - val_loss: 12.6802 - val_mae: 2.5001\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1.8904 - mae: 0.9317 - val_loss: 13.3296 - val_mae: 2.6024\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0309 - mae: 0.9789 - val_loss: 12.3887 - val_mae: 2.5302\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9250 - mae: 0.9615 - val_loss: 13.7363 - val_mae: 2.6650\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9416 - mae: 0.9398 - val_loss: 12.8896 - val_mae: 2.5359\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9081 - mae: 0.9390 - val_loss: 12.6974 - val_mae: 2.5661\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7210 - mae: 0.9002 - val_loss: 12.7490 - val_mae: 2.5068\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9137 - mae: 0.9213 - val_loss: 13.1298 - val_mae: 2.5580\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9826 - mae: 0.9314 - val_loss: 13.4261 - val_mae: 2.5802\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9218 - mae: 0.9328 - val_loss: 13.1057 - val_mae: 2.5863\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9055 - mae: 0.9610 - val_loss: 13.1944 - val_mae: 2.5706\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7902 - mae: 0.9055 - val_loss: 13.4251 - val_mae: 2.5739\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9723 - mae: 0.9740 - val_loss: 13.9496 - val_mae: 2.7334\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6931 - mae: 0.8775 - val_loss: 12.7338 - val_mae: 2.5161\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9269 - mae: 0.9515 - val_loss: 13.1171 - val_mae: 2.6216\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9559 - mae: 0.9584 - val_loss: 12.9362 - val_mae: 2.5611\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8192 - mae: 0.9206 - val_loss: 12.8238 - val_mae: 2.5433\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8108 - mae: 0.8875 - val_loss: 12.5331 - val_mae: 2.4978\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9864 - mae: 0.9641 - val_loss: 12.7653 - val_mae: 2.5171\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7483 - mae: 0.8817 - val_loss: 12.7583 - val_mae: 2.5388\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8007 - mae: 0.9133 - val_loss: 14.0032 - val_mae: 2.6247\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.8215 - mae: 0.9042 - val_loss: 13.1284 - val_mae: 2.5330\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8199 - mae: 0.8987 - val_loss: 13.4036 - val_mae: 2.6001\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7458 - mae: 0.8937 - val_loss: 12.7547 - val_mae: 2.5235\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7831 - mae: 0.9220 - val_loss: 13.1277 - val_mae: 2.5616\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8211 - mae: 0.8936 - val_loss: 12.9048 - val_mae: 2.5623\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7914 - mae: 0.8714 - val_loss: 12.8751 - val_mae: 2.5434\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8144 - mae: 0.8979 - val_loss: 13.1676 - val_mae: 2.5884\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6904 - mae: 0.9068 - val_loss: 12.9934 - val_mae: 2.5824\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7423 - mae: 0.8865 - val_loss: 12.9476 - val_mae: 2.5682\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6418 - mae: 0.9003 - val_loss: 13.8182 - val_mae: 2.6988\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9097 - mae: 0.9212 - val_loss: 12.6453 - val_mae: 2.5217\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.6420 - mae: 0.8462 - val_loss: 13.8216 - val_mae: 2.6261\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.7378 - mae: 0.9044 - val_loss: 13.1557 - val_mae: 2.5705\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6794 - mae: 0.8668 - val_loss: 12.9923 - val_mae: 2.5489\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6652 - mae: 0.8762 - val_loss: 13.1600 - val_mae: 2.5877\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7626 - mae: 0.8684 - val_loss: 13.5220 - val_mae: 2.6144\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.7403 - mae: 0.8860 - val_loss: 13.4368 - val_mae: 2.5993\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7086 - mae: 0.8737 - val_loss: 12.7394 - val_mae: 2.5193\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7683 - mae: 0.8996 - val_loss: 13.0460 - val_mae: 2.5394\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9124 - mae: 0.9602 - val_loss: 13.0914 - val_mae: 2.5974\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6391 - mae: 0.8577 - val_loss: 13.1149 - val_mae: 2.5758\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7119 - mae: 0.8810 - val_loss: 13.0003 - val_mae: 2.5625\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6263 - mae: 0.8768 - val_loss: 12.9434 - val_mae: 2.5700\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6730 - mae: 0.8786 - val_loss: 12.8431 - val_mae: 2.5582\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7361 - mae: 0.8792 - val_loss: 14.0946 - val_mae: 2.7270\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6832 - mae: 0.8782 - val_loss: 12.9057 - val_mae: 2.5766\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6406 - mae: 0.8817 - val_loss: 13.3946 - val_mae: 2.6358\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6865 - mae: 0.8842 - val_loss: 12.5497 - val_mae: 2.5262\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6819 - mae: 0.8921 - val_loss: 13.0993 - val_mae: 2.5793\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6362 - mae: 0.8561 - val_loss: 13.3235 - val_mae: 2.6166\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5333 - mae: 0.8093 - val_loss: 12.6211 - val_mae: 2.5317\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4809 - mae: 0.8562 - val_loss: 12.6816 - val_mae: 2.5471\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6775 - mae: 0.9006 - val_loss: 12.8156 - val_mae: 2.5914\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.4762 - mae: 0.8435 - val_loss: 13.0127 - val_mae: 2.5972\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5953 - mae: 0.8735 - val_loss: 12.4677 - val_mae: 2.5116\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6541 - mae: 0.8927 - val_loss: 12.7459 - val_mae: 2.5030\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4407 - mae: 0.8567 - val_loss: 13.8210 - val_mae: 2.6734\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6552 - mae: 0.8578 - val_loss: 12.9304 - val_mae: 2.5565\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5801 - mae: 0.8765 - val_loss: 13.0297 - val_mae: 2.5997\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5176 - mae: 0.8540 - val_loss: 13.1701 - val_mae: 2.5573\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6178 - mae: 0.8452 - val_loss: 12.9311 - val_mae: 2.5821\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5074 - mae: 0.8330 - val_loss: 13.0871 - val_mae: 2.5951\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6507 - mae: 0.8601 - val_loss: 12.8639 - val_mae: 2.5503\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5248 - mae: 0.8472 - val_loss: 12.7042 - val_mae: 2.5297\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5944 - mae: 0.8672 - val_loss: 13.5234 - val_mae: 2.6332\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4764 - mae: 0.8215 - val_loss: 13.0768 - val_mae: 2.5609\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 1.6708 - mae: 0.8726 - val_loss: 13.0167 - val_mae: 2.5657\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5200 - mae: 0.8483 - val_loss: 13.2385 - val_mae: 2.6413\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6099 - mae: 0.8648 - val_loss: 13.8205 - val_mae: 2.6074\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4438 - mae: 0.8018 - val_loss: 13.2779 - val_mae: 2.5734\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6712 - mae: 0.8557 - val_loss: 12.7604 - val_mae: 2.5454\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4914 - mae: 0.8279 - val_loss: 13.5432 - val_mae: 2.6173\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6109 - mae: 0.8672 - val_loss: 13.1620 - val_mae: 2.5853\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5054 - mae: 0.8514 - val_loss: 13.0389 - val_mae: 2.5659\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4803 - mae: 0.8217 - val_loss: 12.7003 - val_mae: 2.5258\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4484 - mae: 0.7955 - val_loss: 13.1122 - val_mae: 2.6312\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5541 - mae: 0.8427 - val_loss: 13.4957 - val_mae: 2.6419\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.4806 - mae: 0.8314 - val_loss: 13.3391 - val_mae: 2.5647\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5910 - mae: 0.8656 - val_loss: 12.9333 - val_mae: 2.5531\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3271 - mae: 0.7722 - val_loss: 13.6867 - val_mae: 2.6649\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3315 - mae: 0.7799 - val_loss: 13.2758 - val_mae: 2.5967\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5273 - mae: 0.8217 - val_loss: 13.6723 - val_mae: 2.6311\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4864 - mae: 0.8362 - val_loss: 13.0536 - val_mae: 2.5812\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4957 - mae: 0.8131 - val_loss: 14.2848 - val_mae: 2.6461\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4233 - mae: 0.8140 - val_loss: 13.5386 - val_mae: 2.6637\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4035 - mae: 0.7747 - val_loss: 13.4188 - val_mae: 2.6075\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4659 - mae: 0.8413 - val_loss: 13.7720 - val_mae: 2.6450\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4136 - mae: 0.7723 - val_loss: 13.5729 - val_mae: 2.6009\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5548 - mae: 0.8535 - val_loss: 13.6919 - val_mae: 2.6135\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2431 - mae: 0.7792 - val_loss: 13.8737 - val_mae: 2.6332\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5082 - mae: 0.8266 - val_loss: 13.1450 - val_mae: 2.5866\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.3888 - mae: 0.7811 - val_loss: 12.8948 - val_mae: 2.5731\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4188 - mae: 0.8086 - val_loss: 13.3225 - val_mae: 2.6664\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.6235 - mae: 0.8766 - val_loss: 13.0873 - val_mae: 2.5898\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3290 - mae: 0.8014 - val_loss: 13.0617 - val_mae: 2.5349\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4960 - mae: 0.8463 - val_loss: 14.3220 - val_mae: 2.6894\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3841 - mae: 0.8192 - val_loss: 13.0138 - val_mae: 2.6144\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4052 - mae: 0.7951 - val_loss: 13.9136 - val_mae: 2.6704\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3515 - mae: 0.7782 - val_loss: 13.2559 - val_mae: 2.5862\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3706 - mae: 0.7825 - val_loss: 14.0567 - val_mae: 2.6566\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3687 - mae: 0.7944 - val_loss: 13.9582 - val_mae: 2.6208\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4458 - mae: 0.8199 - val_loss: 13.1970 - val_mae: 2.5259\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2658 - mae: 0.7858 - val_loss: 13.5177 - val_mae: 2.6318\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3635 - mae: 0.7904 - val_loss: 13.4485 - val_mae: 2.5955\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3638 - mae: 0.7734 - val_loss: 13.2590 - val_mae: 2.6157\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3546 - mae: 0.8101 - val_loss: 13.7104 - val_mae: 2.6450\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2990 - mae: 0.7849 - val_loss: 13.7536 - val_mae: 2.6388\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3868 - mae: 0.8027 - val_loss: 13.0170 - val_mae: 2.5981\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4263 - mae: 0.8002 - val_loss: 13.1674 - val_mae: 2.5412\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4445 - mae: 0.8546 - val_loss: 12.9611 - val_mae: 2.5354\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3783 - mae: 0.7955 - val_loss: 14.6906 - val_mae: 2.6586\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2912 - mae: 0.7783 - val_loss: 13.7072 - val_mae: 2.5929\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4303 - mae: 0.8046 - val_loss: 13.1412 - val_mae: 2.5540\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3504 - mae: 0.7976 - val_loss: 13.4462 - val_mae: 2.6118\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2544 - mae: 0.7354 - val_loss: 13.5451 - val_mae: 2.6204\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3534 - mae: 0.7991 - val_loss: 13.9480 - val_mae: 2.7162\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3846 - mae: 0.7999 - val_loss: 13.9872 - val_mae: 2.6024\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3260 - mae: 0.7772 - val_loss: 13.1099 - val_mae: 2.5613\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2213 - mae: 0.7542 - val_loss: 13.3375 - val_mae: 2.5891\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2832 - mae: 0.7844 - val_loss: 14.3613 - val_mae: 2.6745\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3731 - mae: 0.8365 - val_loss: 13.2599 - val_mae: 2.5926\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3025 - mae: 0.7541 - val_loss: 13.9873 - val_mae: 2.6562\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1279 - mae: 0.7064 - val_loss: 13.9890 - val_mae: 2.6456\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3616 - mae: 0.8485 - val_loss: 13.5212 - val_mae: 2.6417\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2379 - mae: 0.7586 - val_loss: 13.5581 - val_mae: 2.5883\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3023 - mae: 0.8170 - val_loss: 13.1562 - val_mae: 2.5879\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1678 - mae: 0.7302 - val_loss: 13.0399 - val_mae: 2.6130\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2499 - mae: 0.7538 - val_loss: 13.4534 - val_mae: 2.6272\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2370 - mae: 0.7741 - val_loss: 14.3896 - val_mae: 2.6491\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3063 - mae: 0.7814 - val_loss: 13.3505 - val_mae: 2.5994\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2464 - mae: 0.7597 - val_loss: 13.4763 - val_mae: 2.6615\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2011 - mae: 0.7519 - val_loss: 14.1600 - val_mae: 2.6857\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2856 - mae: 0.7930 - val_loss: 12.8924 - val_mae: 2.5696\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1266 - mae: 0.7453 - val_loss: 14.9726 - val_mae: 2.7301\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3617 - mae: 0.8161 - val_loss: 13.0827 - val_mae: 2.5885\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2454 - mae: 0.7637 - val_loss: 13.8255 - val_mae: 2.6100\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1370 - mae: 0.7074 - val_loss: 13.9265 - val_mae: 2.6468\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2570 - mae: 0.7708 - val_loss: 12.9327 - val_mae: 2.5406\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2560 - mae: 0.7500 - val_loss: 13.2155 - val_mae: 2.5834\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3225 - mae: 0.7889 - val_loss: 13.5708 - val_mae: 2.5767\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2731 - mae: 0.7619 - val_loss: 13.7061 - val_mae: 2.5977\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1243 - mae: 0.7302 - val_loss: 13.4797 - val_mae: 2.6013\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2372 - mae: 0.7730 - val_loss: 12.9977 - val_mae: 2.6054\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2514 - mae: 0.7885 - val_loss: 13.2734 - val_mae: 2.6294\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2604 - mae: 0.7820 - val_loss: 13.5291 - val_mae: 2.6873\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3248 - mae: 0.7843 - val_loss: 13.1319 - val_mae: 2.5892\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2730 - mae: 0.7816 - val_loss: 13.5407 - val_mae: 2.6819\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1239 - mae: 0.6977 - val_loss: 12.6783 - val_mae: 2.5660\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2060 - mae: 0.7418 - val_loss: 12.9808 - val_mae: 2.6485\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1357 - mae: 0.7258 - val_loss: 13.2464 - val_mae: 2.6100\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2666 - mae: 0.7988 - val_loss: 13.5209 - val_mae: 2.6495\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1261 - mae: 0.7169 - val_loss: 13.9728 - val_mae: 2.6483\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2277 - mae: 0.7573 - val_loss: 14.0116 - val_mae: 2.6971\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1946 - mae: 0.7460 - val_loss: 14.9151 - val_mae: 2.7774\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2175 - mae: 0.7610 - val_loss: 13.7658 - val_mae: 2.6837\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1344 - mae: 0.7296 - val_loss: 13.1733 - val_mae: 2.6026\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1668 - mae: 0.7345 - val_loss: 13.2057 - val_mae: 2.6067\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1948 - mae: 0.7446 - val_loss: 12.8455 - val_mae: 2.5577\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1100 - mae: 0.6993 - val_loss: 13.7337 - val_mae: 2.6845\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1762 - mae: 0.7356 - val_loss: 13.4370 - val_mae: 2.6742\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1475 - mae: 0.7344 - val_loss: 13.8954 - val_mae: 2.7123\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3000 - mae: 0.7743 - val_loss: 13.9215 - val_mae: 2.6548\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0365 - mae: 0.7009 - val_loss: 13.7913 - val_mae: 2.6788\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1704 - mae: 0.7646 - val_loss: 14.1547 - val_mae: 2.7617\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1611 - mae: 0.7436 - val_loss: 13.8273 - val_mae: 2.6766\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1214 - mae: 0.7155 - val_loss: 14.5250 - val_mae: 2.6977\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1279 - mae: 0.7379 - val_loss: 14.4057 - val_mae: 2.7397\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1462 - mae: 0.7478 - val_loss: 13.7158 - val_mae: 2.6339\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.1398 - mae: 0.7730 - val_loss: 13.5968 - val_mae: 2.6537\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1042 - mae: 0.7376 - val_loss: 14.1442 - val_mae: 2.6755\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2827 - mae: 0.7936 - val_loss: 13.0692 - val_mae: 2.5743\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0342 - mae: 0.6789 - val_loss: 13.6247 - val_mae: 2.6741\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1511 - mae: 0.7437 - val_loss: 13.2211 - val_mae: 2.6517\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2010 - mae: 0.7792 - val_loss: 13.8234 - val_mae: 2.6634\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0003 - mae: 0.7091 - val_loss: 14.0065 - val_mae: 2.6481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxjP0zY6MP0h",
        "outputId": "1f7ad5a4-04ae-4917-e1d4-6f51f4e1e572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "metadata": {
        "id": "D0Vzwvxw0_HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(average_mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vkSuFUDIJNn",
        "outputId": "8c2ded72-0f02-432a-9ace-d093d691af50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_mae_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FisnsYzSBFB5",
        "outputId": "23db0be4-4509-477d-d69b-4a3aa8f61881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19.330423831939697,\n",
              " 15.646936893463135,\n",
              " 11.198412299156189,\n",
              " 7.322607398033142,\n",
              " 5.382370114326477,\n",
              " 4.453585743904114,\n",
              " 3.94888699054718,\n",
              " 3.7277280688285828,\n",
              " 3.4934995770454407,\n",
              " 3.378144919872284,\n",
              " 3.3150357604026794,\n",
              " 3.1939221024513245,\n",
              " 3.1126657724380493,\n",
              " 3.016705095767975,\n",
              " 2.947726309299469,\n",
              " 2.8905916810035706,\n",
              " 2.844377279281616,\n",
              " 2.8054211139678955,\n",
              " 2.7632837891578674,\n",
              " 2.727452576160431,\n",
              " 2.7071542739868164,\n",
              " 2.6873815655708313,\n",
              " 2.6197709441184998,\n",
              " 2.6583800315856934,\n",
              " 2.6398157477378845,\n",
              " 2.619827687740326,\n",
              " 2.57830274105072,\n",
              " 2.5341355204582214,\n",
              " 2.585829734802246,\n",
              " 2.5990625619888306,\n",
              " 2.4992095232009888,\n",
              " 2.5015295147895813,\n",
              " 2.5373610258102417,\n",
              " 2.5158721208572388,\n",
              " 2.4856655597686768,\n",
              " 2.5406631231307983,\n",
              " 2.457769274711609,\n",
              " 2.5442235469818115,\n",
              " 2.504962742328644,\n",
              " 2.4908522367477417,\n",
              " 2.4506319761276245,\n",
              " 2.466180205345154,\n",
              " 2.475414752960205,\n",
              " 2.4331957399845123,\n",
              " 2.4505631923675537,\n",
              " 2.4262986183166504,\n",
              " 2.3873375952243805,\n",
              " 2.4267899990081787,\n",
              " 2.45412278175354,\n",
              " 2.4339702129364014,\n",
              " 2.3858660459518433,\n",
              " 2.4040266573429108,\n",
              " 2.436962842941284,\n",
              " 2.4010326266288757,\n",
              " 2.3841355443000793,\n",
              " 2.439426064491272,\n",
              " 2.4465507864952087,\n",
              " 2.421686887741089,\n",
              " 2.354786902666092,\n",
              " 2.425835430622101,\n",
              " 2.411318838596344,\n",
              " 2.4336398243904114,\n",
              " 2.3672436475753784,\n",
              " 2.4189494848251343,\n",
              " 2.4713560938835144,\n",
              " 2.363738715648651,\n",
              " 2.362136274576187,\n",
              " 2.4423627853393555,\n",
              " 2.39723938703537,\n",
              " 2.4052083492279053,\n",
              " 2.409793198108673,\n",
              " 2.3987033367156982,\n",
              " 2.4083950519561768,\n",
              " 2.3788341283798218,\n",
              " 2.4149818420410156,\n",
              " 2.3954664170742035,\n",
              " 2.3658000826835632,\n",
              " 2.405402898788452,\n",
              " 2.3787214159965515,\n",
              " 2.3691059947013855,\n",
              " 2.3824871480464935,\n",
              " 2.4330422282218933,\n",
              " 2.3875047862529755,\n",
              " 2.363914430141449,\n",
              " 2.3950340151786804,\n",
              " 2.3321004807949066,\n",
              " 2.4877794981002808,\n",
              " 2.3647336065769196,\n",
              " 2.333946079015732,\n",
              " 2.3850340843200684,\n",
              " 2.3777878284454346,\n",
              " 2.372352957725525,\n",
              " 2.4327171444892883,\n",
              " 2.389083743095398,\n",
              " 2.3795511424541473,\n",
              " 2.317320317029953,\n",
              " 2.3445269763469696,\n",
              " 2.421636700630188,\n",
              " 2.361963540315628,\n",
              " 2.42197322845459,\n",
              " 2.3935964107513428,\n",
              " 2.392203688621521,\n",
              " 2.4373809695243835,\n",
              " 2.3531790673732758,\n",
              " 2.360226094722748,\n",
              " 2.374067008495331,\n",
              " 2.321929007768631,\n",
              " 2.3253640830516815,\n",
              " 2.3804842829704285,\n",
              " 2.383968949317932,\n",
              " 2.3468866050243378,\n",
              " 2.345881938934326,\n",
              " 2.4540431201457977,\n",
              " 2.362996220588684,\n",
              " 2.3415451645851135,\n",
              " 2.346986413002014,\n",
              " 2.3421105444431305,\n",
              " 2.4158442616462708,\n",
              " 2.325277179479599,\n",
              " 2.307488113641739,\n",
              " 2.355566293001175,\n",
              " 2.423310339450836,\n",
              " 2.4716890454292297,\n",
              " 2.437782108783722,\n",
              " 2.420304238796234,\n",
              " 2.341428279876709,\n",
              " 2.355129301548004,\n",
              " 2.409302592277527,\n",
              " 2.390426367521286,\n",
              " 2.389387011528015,\n",
              " 2.453845113515854,\n",
              " 2.319965362548828,\n",
              " 2.3977842926979065,\n",
              " 2.343300700187683,\n",
              " 2.399130880832672,\n",
              " 2.4121070504188538,\n",
              " 2.406953811645508,\n",
              " 2.3127670288085938,\n",
              " 2.383943796157837,\n",
              " 2.439653903245926,\n",
              " 2.3460853695869446,\n",
              " 2.3709577918052673,\n",
              " 2.3820977210998535,\n",
              " 2.3496566116809845,\n",
              " 2.324694573879242,\n",
              " 2.336109548807144,\n",
              " 2.344285249710083,\n",
              " 2.395631790161133,\n",
              " 2.3695259392261505,\n",
              " 2.3267416954040527,\n",
              " 2.2995636761188507,\n",
              " 2.408447653055191,\n",
              " 2.339343845844269,\n",
              " 2.430442690849304,\n",
              " 2.3085553646087646,\n",
              " 2.33028244972229,\n",
              " 2.4131197929382324,\n",
              " 2.375719964504242,\n",
              " 2.3919949531555176,\n",
              " 2.368155002593994,\n",
              " 2.317054510116577,\n",
              " 2.3265092074871063,\n",
              " 2.427245110273361,\n",
              " 2.443457305431366,\n",
              " 2.3868227303028107,\n",
              " 2.3606036901474,\n",
              " 2.405258387327194,\n",
              " 2.3790919184684753,\n",
              " 2.4054538309574127,\n",
              " 2.3318850696086884,\n",
              " 2.389935940504074,\n",
              " 2.3175830841064453,\n",
              " 2.3937447667121887,\n",
              " 2.3225467801094055,\n",
              " 2.404924213886261,\n",
              " 2.355762332677841,\n",
              " 2.385598123073578,\n",
              " 2.298495590686798,\n",
              " 2.3743506968021393,\n",
              " 2.4120901226997375,\n",
              " 2.4357205033302307,\n",
              " 2.3138792514801025,\n",
              " 2.3772428035736084,\n",
              " 2.394148051738739,\n",
              " 2.2920676469802856,\n",
              " 2.39065945148468,\n",
              " 2.474056124687195,\n",
              " 2.30245777964592,\n",
              " 2.392354905605316,\n",
              " 2.3828973472118378,\n",
              " 2.3978203535079956,\n",
              " 2.438250958919525,\n",
              " 2.35064235329628,\n",
              " 2.336783915758133,\n",
              " 2.4076996743679047,\n",
              " 2.3563473224639893,\n",
              " 2.3528169989585876,\n",
              " 2.4506059288978577,\n",
              " 2.3801687955856323,\n",
              " 2.3916640281677246,\n",
              " 2.3442258834838867,\n",
              " 2.505718231201172,\n",
              " 2.3852850198745728,\n",
              " 2.3376534283161163,\n",
              " 2.3961504101753235,\n",
              " 2.3751013576984406,\n",
              " 2.3781738579273224,\n",
              " 2.329396963119507,\n",
              " 2.428858757019043,\n",
              " 2.4963186979293823,\n",
              " 2.3503419756889343,\n",
              " 2.410532236099243,\n",
              " 2.4093756079673767,\n",
              " 2.341188907623291,\n",
              " 2.381595879793167,\n",
              " 2.4610142707824707,\n",
              " 2.4317973852157593,\n",
              " 2.4827001690864563,\n",
              " 2.3857725858688354,\n",
              " 2.4302639067173004,\n",
              " 2.351384252309799,\n",
              " 2.3193978667259216,\n",
              " 2.33533376455307,\n",
              " 2.522703170776367,\n",
              " 2.3869165778160095,\n",
              " 2.4702927470207214,\n",
              " 2.4154127538204193,\n",
              " 2.3073232173919678,\n",
              " 2.438305139541626,\n",
              " 2.4114264845848083,\n",
              " 2.3244201242923737,\n",
              " 2.447322130203247,\n",
              " 2.3169403076171875,\n",
              " 2.3762654662132263,\n",
              " 2.3891680240631104,\n",
              " 2.331395387649536,\n",
              " 2.376835733652115,\n",
              " 2.378111958503723,\n",
              " 2.340433418750763,\n",
              " 2.4521167278289795,\n",
              " 2.441605567932129,\n",
              " 2.409149467945099,\n",
              " 2.4280019998550415,\n",
              " 2.347178339958191,\n",
              " 2.29022279381752,\n",
              " 2.352737456560135,\n",
              " 2.4408884048461914,\n",
              " 2.3320279717445374,\n",
              " 2.3785755038261414,\n",
              " 2.4063127040863037,\n",
              " 2.4291035532951355,\n",
              " 2.3932890594005585,\n",
              " 2.342706561088562,\n",
              " 2.41922789812088,\n",
              " 2.351875811815262,\n",
              " 2.4163541197776794,\n",
              " 2.427827000617981,\n",
              " 2.3838062286376953,\n",
              " 2.3713507652282715,\n",
              " 2.3639514446258545,\n",
              " 2.3697495460510254,\n",
              " 2.410972535610199,\n",
              " 2.3340242505073547,\n",
              " 2.3801738619804382,\n",
              " 2.3516111969947815,\n",
              " 2.3524285554885864,\n",
              " 2.3839869499206543,\n",
              " 2.3783324360847473,\n",
              " 2.3727962970733643,\n",
              " 2.394534170627594,\n",
              " 2.458110988140106,\n",
              " 2.353286623954773,\n",
              " 2.335336744785309,\n",
              " 2.4450247287750244,\n",
              " 2.3675219416618347,\n",
              " 2.376007169485092,\n",
              " 2.4907573461532593,\n",
              " 2.448587715625763,\n",
              " 2.4174784123897552,\n",
              " 2.385958284139633,\n",
              " 2.3823622465133667,\n",
              " 2.4438691437244415,\n",
              " 2.4270788729190826,\n",
              " 2.3727279901504517,\n",
              " 2.3589243292808533,\n",
              " 2.4582308530807495,\n",
              " 2.3690184950828552,\n",
              " 2.346143275499344,\n",
              " 2.3421412110328674,\n",
              " 2.359289050102234,\n",
              " 2.3742006719112396,\n",
              " 2.3488859832286835,\n",
              " 2.495937407016754,\n",
              " 2.3563055098056793,\n",
              " 2.4915568232536316,\n",
              " 2.3329142034053802,\n",
              " 2.405335634946823,\n",
              " 2.3735224902629852,\n",
              " 2.3671846091747284,\n",
              " 2.399574488401413,\n",
              " 2.5354296565055847,\n",
              " 2.4206463992595673,\n",
              " 2.3227544128894806,\n",
              " 2.3162535429000854,\n",
              " 2.3557229042053223,\n",
              " 2.416660964488983,\n",
              " 2.4425142407417297,\n",
              " 2.446440190076828,\n",
              " 2.3892463743686676,\n",
              " 2.385343015193939,\n",
              " 2.499349892139435,\n",
              " 2.4671199321746826,\n",
              " 2.464886784553528,\n",
              " 2.3571870028972626,\n",
              " 2.3753631114959717,\n",
              " 2.4076862931251526,\n",
              " 2.4382407665252686,\n",
              " 2.461952328681946,\n",
              " 2.4206640124320984,\n",
              " 2.3794980943202972,\n",
              " 2.473820984363556,\n",
              " 2.440085381269455,\n",
              " 2.3514840602874756,\n",
              " 2.4203604459762573,\n",
              " 2.40581476688385,\n",
              " 2.4127418994903564,\n",
              " 2.422035962343216,\n",
              " 2.4372172355651855,\n",
              " 2.4174967408180237,\n",
              " 2.4090734720230103,\n",
              " 2.45429265499115,\n",
              " 2.4126121401786804,\n",
              " 2.467517673969269,\n",
              " 2.4247089326381683,\n",
              " 2.421448290348053,\n",
              " 2.5114649534225464,\n",
              " 2.386267304420471,\n",
              " 2.52254718542099,\n",
              " 2.424999237060547,\n",
              " 2.457816243171692,\n",
              " 2.4126206040382385,\n",
              " 2.35193794965744,\n",
              " 2.4539455473423004,\n",
              " 2.4255565404891968,\n",
              " 2.387680172920227,\n",
              " 2.412095844745636,\n",
              " 2.4153478741645813,\n",
              " 2.3603857159614563,\n",
              " 2.4419162273406982,\n",
              " 2.362437069416046,\n",
              " 2.4271249175071716,\n",
              " 2.3929107785224915,\n",
              " 2.412770450115204,\n",
              " 2.4601811170578003,\n",
              " 2.487018495798111,\n",
              " 2.382373660802841,\n",
              " 2.4745283126831055,\n",
              " 2.3713904321193695,\n",
              " 2.3911728262901306,\n",
              " 2.493314564228058,\n",
              " 2.437301069498062,\n",
              " 2.48099684715271,\n",
              " 2.3737005293369293,\n",
              " 2.4200273752212524,\n",
              " 2.466596007347107,\n",
              " 2.3723050951957703,\n",
              " 2.488968074321747,\n",
              " 2.50888192653656,\n",
              " 2.4364859759807587,\n",
              " 2.465661346912384,\n",
              " 2.424363374710083,\n",
              " 2.4221883416175842,\n",
              " 2.4181904196739197,\n",
              " 2.404099464416504,\n",
              " 2.534129500389099,\n",
              " 2.430728018283844,\n",
              " 2.3841174840927124,\n",
              " 2.4401625990867615,\n",
              " 2.450450897216797,\n",
              " 2.4677420258522034,\n",
              " 2.4043164551258087,\n",
              " 2.4411112666130066,\n",
              " 2.4462229311466217,\n",
              " 2.4343689680099487,\n",
              " 2.4443867802619934,\n",
              " 2.464550733566284,\n",
              " 2.4122237861156464,\n",
              " 2.4021669030189514,\n",
              " 2.3716410994529724,\n",
              " 2.4418907165527344,\n",
              " 2.4543478190898895,\n",
              " 2.529873847961426,\n",
              " 2.4159777760505676,\n",
              " 2.4706186056137085,\n",
              " 2.557932674884796,\n",
              " 2.438669979572296,\n",
              " 2.4585334062576294,\n",
              " 2.4868434071540833,\n",
              " 2.4427325427532196,\n",
              " 2.4566304087638855,\n",
              " 2.453928828239441,\n",
              " 2.479196071624756,\n",
              " 2.469318687915802,\n",
              " 2.4718628525733948,\n",
              " 2.511655628681183,\n",
              " 2.4479694962501526,\n",
              " 2.4479162395000458,\n",
              " 2.4205092787742615,\n",
              " 2.4767112731933594,\n",
              " 2.4286094903945923,\n",
              " 2.479997217655182,\n",
              " 2.485593259334564,\n",
              " 2.5538532733917236,\n",
              " 2.4916659593582153,\n",
              " 2.4542306065559387,\n",
              " 2.4248353838920593,\n",
              " 2.427355110645294,\n",
              " 2.4946184754371643,\n",
              " 2.4624147415161133,\n",
              " 2.425914466381073,\n",
              " 2.519680619239807,\n",
              " 2.536395311355591,\n",
              " 2.429945468902588,\n",
              " 2.4132919311523438,\n",
              " 2.5104944705963135,\n",
              " 2.502515971660614,\n",
              " 2.417747735977173,\n",
              " 2.4783821403980255,\n",
              " 2.4703257083892822,\n",
              " 2.5410627722740173,\n",
              " 2.4391424655914307,\n",
              " 2.4846854209899902,\n",
              " 2.4509055614471436,\n",
              " 2.511287033557892,\n",
              " 2.4381787180900574,\n",
              " 2.468460977077484,\n",
              " 2.5216275453567505,\n",
              " 2.3968228101730347,\n",
              " 2.43724662065506,\n",
              " 2.515185058116913,\n",
              " 2.4988306760787964,\n",
              " 2.4791215658187866,\n",
              " 2.439371407032013,\n",
              " 2.506575644016266,\n",
              " 2.4549007415771484,\n",
              " 2.421078383922577,\n",
              " 2.460708498954773,\n",
              " 2.4401187896728516,\n",
              " 2.5249571800231934,\n",
              " 2.493677496910095,\n",
              " 2.482886493206024,\n",
              " 2.4506924152374268,\n",
              " 2.4771982431411743,\n",
              " 2.4613365530967712,\n",
              " 2.4791187047958374,\n",
              " 2.447590172290802,\n",
              " 2.500899016857147,\n",
              " 2.422450542449951,\n",
              " 2.570649564266205,\n",
              " 2.461524486541748,\n",
              " 2.453244686126709,\n",
              " 2.440441846847534,\n",
              " 2.447163939476013,\n",
              " 2.4860768914222717,\n",
              " 2.4317463040351868,\n",
              " 2.483168363571167,\n",
              " 2.4704224467277527,\n",
              " 2.475349187850952,\n",
              " 2.592374086380005,\n",
              " 2.5369316935539246,\n",
              " 2.452272951602936,\n",
              " 2.4465668201446533,\n",
              " 2.504659414291382,\n",
              " 2.4456623792648315,\n",
              " 2.498252809047699,\n",
              " 2.522535562515259,\n",
              " 2.480859875679016,\n",
              " 2.443674147129059,\n",
              " 2.5067896246910095,\n",
              " 2.432673990726471,\n",
              " 2.4917027950286865,\n",
              " 2.4685786366462708,\n",
              " 2.4979376792907715,\n",
              " 2.4862561225891113,\n",
              " 2.482829749584198,\n",
              " 2.4964796900749207,\n",
              " 2.50639009475708,\n",
              " 2.4956692457199097,\n",
              " 2.4695075154304504,\n",
              " 2.4583354592323303,\n",
              " 2.544614017009735,\n",
              " 2.4926602244377136,\n",
              " 2.509487807750702,\n",
              " 2.483984053134918,\n",
              " 2.485789716243744,\n",
              " 2.4490870237350464,\n",
              " 2.5248382687568665,\n",
              " 2.5146541595458984,\n",
              " 2.504908323287964,\n",
              " 2.509202241897583]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the mae of the model is not good(~2.5), so we need to improve it"
      ],
      "metadata": {
        "id": "yUSojn1HzdMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bZ_CjphBHXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3a6bbd55-1ab0-4b17-c6ef-c40f78a650be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see better the above plot, let's exclude some first points(20)\n",
        "truncated_mae_history = average_mae_history[20:]\n",
        "plt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "En_MfXGHI2Ho",
        "outputId": "73c15803-286c-4a55-e564-9bd68c419ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After 200 epochs, the model is getting worse. So, let's build a new one with let's say 130 epochs!"
      ],
      "metadata": {
        "id": "rurQ7ZqsKSuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final model"
      ],
      "metadata": {
        "id": "MwvzSN4WLdT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build and train the final model by limiting the number of epochs to 130\n",
        "model = build_model()\n",
        "\n",
        "history = model.fit(train_data, train_targets,\n",
        "          epochs=130, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2xMaQWOK_RM",
        "outputId": "66882f69-782a-4983-880d-0afd68136ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/130\n",
            "26/26 [==============================] - 1s 7ms/step - loss: 523.2817 - mae: 20.9437\n",
            "Epoch 2/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 364.2340 - mae: 16.9871\n",
            "Epoch 3/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 192.0521 - mae: 11.5118\n",
            "Epoch 4/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 80.0411 - mae: 6.7020\n",
            "Epoch 5/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 45.1536 - mae: 4.8838\n",
            "Epoch 6/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 32.1826 - mae: 4.0408\n",
            "Epoch 7/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 26.1202 - mae: 3.5798\n",
            "Epoch 8/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 22.3751 - mae: 3.3326\n",
            "Epoch 9/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 19.9084 - mae: 3.1449\n",
            "Epoch 10/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 17.6304 - mae: 2.9404\n",
            "Epoch 11/130\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 15.7993 - mae: 2.8030\n",
            "Epoch 12/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 14.5925 - mae: 2.6588\n",
            "Epoch 13/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 13.3968 - mae: 2.5864\n",
            "Epoch 14/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 12.7843 - mae: 2.5140\n",
            "Epoch 15/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 12.0122 - mae: 2.4657\n",
            "Epoch 16/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 11.7679 - mae: 2.4533\n",
            "Epoch 17/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 11.0198 - mae: 2.3985\n",
            "Epoch 18/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 11.1445 - mae: 2.3576\n",
            "Epoch 19/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.6294 - mae: 2.3506\n",
            "Epoch 20/130\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 10.5983 - mae: 2.3112\n",
            "Epoch 21/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.2195 - mae: 2.3015\n",
            "Epoch 22/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.0720 - mae: 2.2716\n",
            "Epoch 23/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.9809 - mae: 2.2630\n",
            "Epoch 24/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.6397 - mae: 2.2355\n",
            "Epoch 25/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.4152 - mae: 2.1910\n",
            "Epoch 26/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.3858 - mae: 2.1936\n",
            "Epoch 27/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.1527 - mae: 2.1739\n",
            "Epoch 28/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.9840 - mae: 2.1558\n",
            "Epoch 29/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.8824 - mae: 2.1769\n",
            "Epoch 30/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.9321 - mae: 2.1346\n",
            "Epoch 31/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.7560 - mae: 2.1317\n",
            "Epoch 32/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.4299 - mae: 2.0921\n",
            "Epoch 33/130\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8.3006 - mae: 2.0591\n",
            "Epoch 34/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.3946 - mae: 2.0676\n",
            "Epoch 35/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.3363 - mae: 2.0561\n",
            "Epoch 36/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.1389 - mae: 2.0329\n",
            "Epoch 37/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.0060 - mae: 2.0302\n",
            "Epoch 38/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.9456 - mae: 2.0239\n",
            "Epoch 39/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.8308 - mae: 2.0019\n",
            "Epoch 40/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.7657 - mae: 2.0112\n",
            "Epoch 41/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.7920 - mae: 1.9997\n",
            "Epoch 42/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.6005 - mae: 1.9666\n",
            "Epoch 43/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.5263 - mae: 1.9675\n",
            "Epoch 44/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.3498 - mae: 1.9488\n",
            "Epoch 45/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.2229 - mae: 1.9281\n",
            "Epoch 46/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.4379 - mae: 1.9344\n",
            "Epoch 47/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.9545 - mae: 1.9026\n",
            "Epoch 48/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.0102 - mae: 1.8988\n",
            "Epoch 49/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.0325 - mae: 1.8804\n",
            "Epoch 50/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.8637 - mae: 1.8611\n",
            "Epoch 51/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.9438 - mae: 1.8689\n",
            "Epoch 52/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.7499 - mae: 1.8690\n",
            "Epoch 53/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.6082 - mae: 1.8893\n",
            "Epoch 54/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.8093 - mae: 1.8417\n",
            "Epoch 55/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.6322 - mae: 1.8129\n",
            "Epoch 56/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.5892 - mae: 1.8182\n",
            "Epoch 57/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.5564 - mae: 1.8104\n",
            "Epoch 58/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.3641 - mae: 1.8290\n",
            "Epoch 59/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.4939 - mae: 1.7896\n",
            "Epoch 60/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.3795 - mae: 1.7900\n",
            "Epoch 61/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.2870 - mae: 1.7665\n",
            "Epoch 62/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0829 - mae: 1.7622\n",
            "Epoch 63/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.1572 - mae: 1.7646\n",
            "Epoch 64/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0854 - mae: 1.7764\n",
            "Epoch 65/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.2293 - mae: 1.7954\n",
            "Epoch 66/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0212 - mae: 1.7287\n",
            "Epoch 67/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.9803 - mae: 1.7321\n",
            "Epoch 68/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.8275 - mae: 1.7120\n",
            "Epoch 69/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.9401 - mae: 1.7543\n",
            "Epoch 70/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0083 - mae: 1.7211\n",
            "Epoch 71/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.6915 - mae: 1.7007\n",
            "Epoch 72/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.7133 - mae: 1.6943\n",
            "Epoch 73/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.7357 - mae: 1.7371\n",
            "Epoch 74/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.5752 - mae: 1.6924\n",
            "Epoch 75/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.6432 - mae: 1.7230\n",
            "Epoch 76/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.6213 - mae: 1.6732\n",
            "Epoch 77/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4487 - mae: 1.6673\n",
            "Epoch 78/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4079 - mae: 1.6499\n",
            "Epoch 79/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4570 - mae: 1.6925\n",
            "Epoch 80/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.2772 - mae: 1.6569\n",
            "Epoch 81/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.5657 - mae: 1.6744\n",
            "Epoch 82/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1779 - mae: 1.6452\n",
            "Epoch 83/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4714 - mae: 1.6643\n",
            "Epoch 84/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.2646 - mae: 1.6467\n",
            "Epoch 85/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.2033 - mae: 1.6139\n",
            "Epoch 86/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1899 - mae: 1.6201\n",
            "Epoch 87/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1121 - mae: 1.6024\n",
            "Epoch 88/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1517 - mae: 1.6161\n",
            "Epoch 89/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.8799 - mae: 1.5745\n",
            "Epoch 90/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1256 - mae: 1.5910\n",
            "Epoch 91/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.9999 - mae: 1.6064\n",
            "Epoch 92/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.9228 - mae: 1.5655\n",
            "Epoch 93/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.8490 - mae: 1.5656\n",
            "Epoch 94/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.9271 - mae: 1.5758\n",
            "Epoch 95/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6929 - mae: 1.5587\n",
            "Epoch 96/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7785 - mae: 1.5373\n",
            "Epoch 97/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7786 - mae: 1.5507\n",
            "Epoch 98/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7907 - mae: 1.5519\n",
            "Epoch 99/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6245 - mae: 1.5442\n",
            "Epoch 100/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.5542 - mae: 1.5327\n",
            "Epoch 101/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6764 - mae: 1.5568\n",
            "Epoch 102/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4594 - mae: 1.5058\n",
            "Epoch 103/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7358 - mae: 1.5557\n",
            "Epoch 104/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4875 - mae: 1.5375\n",
            "Epoch 105/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.2953 - mae: 1.5230\n",
            "Epoch 106/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4046 - mae: 1.5012\n",
            "Epoch 107/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.3570 - mae: 1.5017\n",
            "Epoch 108/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4829 - mae: 1.4978\n",
            "Epoch 109/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4737 - mae: 1.5168\n",
            "Epoch 110/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.2651 - mae: 1.4796\n",
            "Epoch 111/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.3795 - mae: 1.5118\n",
            "Epoch 112/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.1468 - mae: 1.4715\n",
            "Epoch 113/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.3437 - mae: 1.4737\n",
            "Epoch 114/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4157 - mae: 1.4838\n",
            "Epoch 115/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.1389 - mae: 1.4694\n",
            "Epoch 116/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.2318 - mae: 1.4832\n",
            "Epoch 117/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.1201 - mae: 1.5038\n",
            "Epoch 118/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9932 - mae: 1.4364\n",
            "Epoch 119/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0487 - mae: 1.4304\n",
            "Epoch 120/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0124 - mae: 1.4502\n",
            "Epoch 121/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.1808 - mae: 1.4558\n",
            "Epoch 122/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0766 - mae: 1.4565\n",
            "Epoch 123/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9730 - mae: 1.4294\n",
            "Epoch 124/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9908 - mae: 1.4257\n",
            "Epoch 125/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9555 - mae: 1.4425\n",
            "Epoch 126/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.8906 - mae: 1.4388\n",
            "Epoch 127/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9920 - mae: 1.4228\n",
            "Epoch 128/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.7956 - mae: 1.3788\n",
            "Epoch 129/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.7039 - mae: 1.3864\n",
            "Epoch 130/130\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 3.8035 - mae: 1.3929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the final model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-OgOExKMA6_",
        "outputId": "00708a62-f394-4c32-fdd9-8a5491de47bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this final model on the test set\n",
        "results = model.evaluate(test_data, test_targets)  # returns test_mse_score, test_mae_score\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNOFEm5Miox",
        "outputId": "3f71f30a-8f5e-45ac-a69a-fe20d9933c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 14.2040 - mae: 2.5260\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.203964233398438, 2.526021957397461]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mse and mae here are decreased from the previous ones"
      ],
      "metadata": {
        "id": "ce7ZTUCXP1gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions. understand the outputs\n",
        "predictions = model.predict(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfmGEsS9M2q7",
        "outputId": "2eb0eff1-f8bb-4a96-cc07-f00832852b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV2ROPSCQOOX",
        "outputId": "18cf0123-9e68-4b95-c246-acaaf261302b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every prediction is a scalar\n",
        "predictions[10].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqZm6sAM2nZ",
        "outputId": "fa8aa646-7b7e-45a9-acf7-8639802a2a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a prediction \n",
        "predictions[10] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMn_Xxq3NQt-",
        "outputId": "77e434e7-375b-4b28-e4d5-8e943d6c7105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23.222536], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and check it manually with its initial test_target \n",
        "test_targets[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdRW6RJYNVc5",
        "outputId": "18f75c19-27ff-439e-e635-1d6ad45e6ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.6"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction[10] and test_target[10] are different, however their distance is small. That's what we are trying to do in all ml and dl problems: to minimize this distance!"
      ],
      "metadata": {
        "id": "KwnSuVa1QdtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, the universal workflow in machine learning(especially when working with NNs):"
      ],
      "metadata": {
        "id": "Chq4Do1_Zyxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the problem and collect the data\n",
        "2. Choose the metrics\n",
        "3. Prepare your data and split to train/val/test sets\n",
        "4. Build, train and evaluate the first model\n",
        "5. Improve the model via addressing overfitting and hyperparameter tuning"
      ],
      "metadata": {
        "id": "cAOOoylVadDf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ff_1urlNNi5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}