{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MFz5awredGSV",
        "ybXGtqNVD2U5",
        "6JEOWtW9T0-m",
        "w4BQ3F6wT_QT"
      ],
      "authorship_tag": "ABX9TyMHamoAFPyIlSifFn+kuu5L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX7000/deep-learning-with-python/blob/main/DeepLearning_with_Python_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning examples from the book 'Deep Learning with Python', Part 1, Francois Chollet"
      ],
      "metadata": {
        "id": "UyI5AtRpc4xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1. Classify grayscale images(28x28) of handwritten digits from mnist dataset into 10 categories"
      ],
      "metadata": {
        "id": "MFz5awredGSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a multi-class Classification problem"
      ],
      "metadata": {
        "id": "1WqEJyKNWUte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand what you really have"
      ],
      "metadata": {
        "id": "uGJrI8r7Wayt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9pHWjjhWgm9",
        "outputId": "ddca993e-3283-461a-ba30-25db16b84470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (60000, 28, 28)\n",
            "y_train: (60000,)\n",
            "X_test: (10000, 28, 28)\n",
            "y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# import the data\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(f'X_train: {train_images.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_images.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pre-process the data: preparing/bringing it to the right form to feed our NN"
      ],
      "metadata": {
        "id": "9NZ9CwrW8DDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorization, value Normalization, handling missing values, feature engineering to name but a few of the steps you need to do during pre-processing of your data!"
      ],
      "metadata": {
        "id": "GbhytbFuXcL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's visualize some examples to see what we have here\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_images[10], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qRRLzG8VNTz1",
        "outputId": "a2375daf-fb97-40c5-e38f-247b5c8b0822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_images[10], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "t4g_B296PIWs",
        "outputId": "c498e2f9-d5ca-4017-f5c3-be11c2c6cf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many times in which we need to shuffle the dataset before split it to train and test sets. This is because of data representativeness(more @page100). This is a step during feature engineering like for example feature redundancy you need to do every time you pre-process the data"
      ],
      "metadata": {
        "id": "XSXLl-S2WjLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we have 60000 examples(images) that are 28x28 each (on greyscale) and they are all filled with numbers between 0-255(the higher the number is the more grey the image is)\n",
        "# so, we transform these images in an array of (60000, 28x28) with values between 0 and 1\n",
        "# and we we actually have 60000 examples of 28*28 length each with values between 0 and 1\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "jQQQ71ZFmVLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot representation for train and test labels. As we have 10 classes to predict as output(output is a number between 0-9 representing the digits)\n",
        "# we transform the output values from 0-9 to 0-1 one-hot representation\n",
        "\n",
        "print(f'10th element of train_labels before one-hot: {train_labels[10]}')\n",
        "\n",
        "# one-hot encoding for output labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(f'10th element of train_labels after one-hot: {train_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzI-eHCI4bQV",
        "outputId": "6bff8601-f59a-4607-8112-175cc460d82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10th element of train_labels before one-hot: 3\n",
            "10th element of train_labels after one-hot: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the new dimensions now\n",
        "print(f'X_train: {train_images.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_images.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fopOLZFP_Jpk",
        "outputId": "19405dcc-62dc-467f-a484-a34a83559677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (60000, 784)\n",
            "y_train: (60000, 10)\n",
            "X_test: (10000, 784)\n",
            "y_test: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define and train the model "
      ],
      "metadata": {
        "id": "nG_-YS1n8ej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# network's architecture\n",
        "# import the aproppriate modules\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# compilation step\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128) \n",
        "\n",
        "# deep learning models don't process an entire dataset at once! they break the data into small batches=> computationaly cheaper\n",
        "# so batch_size=128 means: 1st batch=train_images[:128], 2nd batch: train_images[128:256], ...train_images[128*n:128*(n+1)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcybQF6nuqEP",
        "outputId": "fd3761be-e3ea-4056-c7a6-cd97db37610a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 11s 18ms/step - loss: 0.2541 - accuracy: 0.9261\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.1026 - accuracy: 0.9698\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0684 - accuracy: 0.9793\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0500 - accuracy: 0.9843\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0375 - accuracy: 0.9886\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4824892110>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some model's info\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9urxNtynCVS-",
        "outputId": "6c78c68d-3ce9-45a7-b433-dc8a00472c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Predict and evaluate the model"
      ],
      "metadata": {
        "id": "qSs0VzpI-y5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "# returns a 10-element for each example with the highest probability in the index which represents a digit\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "print(f'\\n the digit-prediction for the first element of test_labels is: {predictions[10]}\\n')\n",
        "print(f'the actual-digit of the first element of test_labels is: {test_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zC1RxAb7StG",
        "outputId": "9994485f-5ee7-436d-a0d0-63c8b4c5151a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n",
            "\n",
            " the digit-prediction for the first element of test_labels is: [9.9998659e-01 1.5300014e-14 1.3191635e-05 1.3249479e-09 9.6179194e-15\n",
            " 2.9272570e-08 1.2704849e-08 8.0467458e-08 2.5869007e-11 9.7939807e-09]\n",
            "\n",
            "the actual-digit of the first element of test_labels is: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2. Tensors: the inputs of NNs"
      ],
      "metadata": {
        "id": "ybXGtqNVD2U5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks take as inputs Tensors. Tensor is a generalization of matrices to a number of dimensions. \n",
        "Each tensor has 3 attributes: 1) the rank: number of axis(dimensions), 2) the shape: how many dimensions the tensor has along each axis and 3) data type: the type of the data contained in the tensor "
      ],
      "metadata": {
        "id": "z6Nm611fFcf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "l0UiQntBG3lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar(0D-tensor): rank-0 tensor \n",
        "x=np.array(12)\n",
        "print(x)       \n",
        "\n",
        "# ndim gives us the axis(=>dimension) of the tensor\n",
        "print(x.ndim)"
      ],
      "metadata": {
        "id": "bck-bYz3IZug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29047ed-e6da-4685-bfce-007bf7b001a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector(1D-tensor): rank-1 tensor \n",
        "x1 = np.array([12, 3, 6, 14, 7])\n",
        "print(x1)\n",
        "\n",
        "print(f'the rank of the tensor is: {x1.ndim}')\n",
        "print(f'the shape of the tensor is: {x1.shape}') \n",
        "print(f'the data type of the tensor is: {x1.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNMN4RYAGmOH",
        "outputId": "b202cba1-907a-445e-9515-fbbd9cad8ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12  3  6 14  7]\n",
            "the rank of the tensor is: 1\n",
            "the shape of the tensor is: (5,)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(2D-tensor): rank-2 tensor\n",
        "x2 = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "print(x2)\n",
        "\n",
        "print(f'the rank of the tensor is: {x2.ndim}')\n",
        "print(f'the shape of the tensor is: {x2.shape}') \n",
        "print(f'the data type of the tensor is: {x2.dtype}')"
      ],
      "metadata": {
        "id": "6FZP3K08IZr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c088b271-f949-4256-b534-8e4578f032b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n",
            "the rank of the tensor is: 2\n",
            "the shape of the tensor is: (3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(3D-tensor): rank-3 tensor\n",
        "x3 = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "print(x3)\n",
        "\n",
        "print(f'the rank of the tensor is: {x3.ndim}')\n",
        "print(f'the shape of the tensor is: {x3.shape}') # the shape of the tensor is the shape of each axis of the tensor\n",
        "print(f'the data type of the tensor is: {x3.dtype}')"
      ],
      "metadata": {
        "id": "jICHuBZJIZpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc94404a-7fd1-464a-c084-f141d21f5dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]]\n",
            "the rank of the tensor is: 3\n",
            "the shape of the tensor is: (3, 3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(4D-tensor): rank-4 tensor, the same happens to all higher rank tensors\n",
        "x4 = np.array([\n",
        "    [\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "    ],\n",
        "    [\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],  \n",
        "    ]\n",
        "   ])\n",
        "print(x4)\n",
        "\n",
        "print(f'the rank of the tensor is: {x4.ndim}')\n",
        "print(f'the shape of the tensor is: {x4.shape}') # the shape of the tensor is the shape of each axis of the tensor\n",
        "print(f'the data type of the tensor is: {x4.dtype}')"
      ],
      "metadata": {
        "id": "gF0mLMIyIZgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee330229-8b42-414a-a38d-bed43f0faf42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]]\n",
            "\n",
            "\n",
            " [[[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]]]\n",
            "the rank of the tensor is: 4\n",
            "the shape of the tensor is: (2, 3, 3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 types of operations between tensors: 1) element-wise operations, 2) dot product and 3) reshaping"
      ],
      "metadata": {
        "id": "vocbHZAHcKwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# broadcasting: the smaller tensor will be broadcasted to match the shape of the larger tensor when applying two tensor element-wise operations\n",
        "z1 = np.maximum(x4, x3)\n",
        "z2 = np.minimum(x4, x2)\n",
        "z3 = np.maximum(x3, x2)\n",
        "z4 = np.maximum(x4, x1)"
      ],
      "metadata": {
        "id": "4vOP0LmAZlsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# "
      ],
      "metadata": {
        "id": "sqhDEWgBbm85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3. Classifying movie reviews, based on text content, into positive or negative"
      ],
      "metadata": {
        "id": "6JEOWtW9T0-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a Binary Classification problem"
      ],
      "metadata": {
        "id": "CX_jHucQWDBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand it"
      ],
      "metadata": {
        "id": "d7Muxn2qEwXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data\n",
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # num_words=10000 means that we only keep the top 10000 most frequently occuring words in the training data\n",
        " \n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bN_XeAFT4Yj",
        "outputId": "880bc3e0-9393-44db-b8d5-a605556829c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (25000,)\n",
            "y_train: (25000,)\n",
            "X_test: (25000,)\n",
            "y_test: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV88-WY2ksTq",
        "outputId": "bbe79a04-9e0f-420c-bd7d-8d6b5bfcbd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [1, 785, 189, 438, 47, 110, 142, 7, 6, 7475, 120, 4, 236, 378, 7, 153, 19, 87, 108, 141, 17, 1004, 5, 2, 883, 2, 23, 8, 4, 136, 2, 2, 4, 7475, 43, 1076, 21, 1407, 419, 5, 5202, 120, 91, 682, 189, 2818, 5, 9, 1348, 31, 7, 4, 118, 785, 189, 108, 126, 93, 2, 16, 540, 324, 23, 6, 364, 352, 21, 14, 9, 93, 56, 18, 11, 230, 53, 771, 74, 31, 34, 4, 2834, 7, 4, 22, 5, 14, 11, 471, 9, 2, 34, 4, 321, 487, 5, 116, 15, 6584, 4, 22, 9, 6, 2286, 4, 114, 2679, 23, 107, 293, 1008, 1172, 5, 328, 1236, 4, 1375, 109, 9, 6, 132, 773, 2, 1412, 8, 1172, 18, 7865, 29, 9, 276, 11, 6, 2768, 19, 289, 409, 4, 5341, 2140, 2, 648, 1430, 2, 8914, 5, 27, 3000, 1432, 7130, 103, 6, 346, 137, 11, 4, 2768, 295, 36, 7740, 725, 6, 3208, 273, 11, 4, 1513, 15, 1367, 35, 154, 2, 103, 2, 173, 7, 12, 36, 515, 3547, 94, 2547, 1722, 5, 3547, 36, 203, 30, 502, 8, 361, 12, 8, 989, 143, 4, 1172, 3404, 10, 10, 328, 1236, 9, 6, 55, 221, 2989, 5, 146, 165, 179, 770, 15, 50, 713, 53, 108, 448, 23, 12, 17, 225, 38, 76, 4397, 18, 183, 8, 81, 19, 12, 45, 1257, 8, 135, 15, 2, 166, 4, 118, 7, 45, 2, 17, 466, 45, 2, 4, 22, 115, 165, 764, 6075, 5, 1030, 8, 2973, 73, 469, 167, 2127, 2, 1568, 6, 87, 841, 18, 4, 22, 4, 192, 15, 91, 7, 12, 304, 273, 1004, 4, 1375, 1172, 2768, 2, 15, 4, 22, 764, 55, 5773, 5, 14, 4233, 7444, 4, 1375, 326, 7, 4, 4760, 1786, 8, 361, 1236, 8, 989, 46, 7, 4, 2768, 45, 55, 776, 8, 79, 496, 98, 45, 400, 301, 15, 4, 1859, 9, 4, 155, 15, 66, 2, 84, 5, 14, 22, 1534, 15, 17, 4, 167, 2, 15, 75, 70, 115, 66, 30, 252, 7, 618, 51, 9, 2161, 4, 3130, 5, 14, 1525, 8, 6584, 15, 2, 165, 127, 1921, 8, 30, 179, 2532, 4, 22, 9, 906, 18, 6, 176, 7, 1007, 1005, 4, 1375, 114, 4, 105, 26, 32, 55, 221, 11, 68, 205, 96, 5, 4, 192, 15, 4, 274, 410, 220, 304, 23, 94, 205, 109, 9, 55, 73, 224, 259, 3786, 15, 4, 22, 528, 1645, 34, 4, 130, 528, 30, 685, 345, 17, 4, 277, 199, 166, 281, 5, 1030, 8, 30, 179, 4442, 444, 2, 9, 6, 371, 87, 189, 22, 5, 31, 7, 4, 118, 7, 4, 2068, 545, 1178, 829]\n",
            "length of 11th example of train_data: 450\n",
            "the label of 11th example of train_labels: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process the data: preparing/bringing it to the right form to feed our NN"
      ],
      "metadata": {
        "id": "bD-h0iUdnddW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our train/test data here is comprised of examples(rows) of text reviews that are represented by a list of 450 integers(integers are the indexes of the word in the 10000 corpus we took from imbd database).\n",
        "We can't feed a NN with lists of integers. we need to turn them into Tensors. 2 ways to do that: a) word embedding and b) one-hot encoding to turn integer lists to vectors of 0s and 1s"
      ],
      "metadata": {
        "id": "JeD6aTZ5tH5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the integer sequences via multi-hot encoding for train and test data: each example now is a 10000 sequence\n",
        "# if a word is on corpus of 10000, then 1 is representing the index of that word in the corpus. if a word is not in the corpus, we put 0 \n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "# vectorize the labels   \n",
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "0jY72gmRlwXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train after preprocessing: {x_train.shape}')\n",
        "print(f'y_train after preprocessing: {y_train.shape}')\n",
        "print(f'X_test after preprocessing: {x_test.shape}')\n",
        "print(f'y_test after preprocessing: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y-HyQnCu4hY",
        "outputId": "183dbab1-abaa-4977-92f7-545d84477339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train after preprocessing: (25000, 10000)\n",
            "y_train after preprocessing: (25000,)\n",
            "X_test after preprocessing: (25000, 10000)\n",
            "y_test after preprocessing: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'length of 11th example of train_data after preprocessing: {x_train[10].shape}')\n",
        "print(f'11th example of train_data after preprocessing:\\n {x_train[10]}')\n",
        "print(f'the label of 11th example of train_labels after preprocessing: {y_train[10]}')\n",
        "\n",
        "print(f'\\n11th example of x_test after preprocessing:\\n {x_test[10]}')\n",
        "print(f'the label of 11th example of test_labels after preprocessing: {y_test[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbfLpf4KuML7",
        "outputId": "3238ad05-42a6-4602-d074-0a0658fdb8cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of 11th example of train_data after preprocessing: (10000,)\n",
            "11th example of train_data after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of train_labels after preprocessing: 1.0\n",
            "\n",
            "11th example of x_test after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of test_labels after preprocessing: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define, compile and train the NN model"
      ],
      "metadata": {
        "id": "Z-pcxBOZ63xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every model is not the best initially and always needs improvements via hyperparameter tuning process. So, always create a validation set to test the model and when find the best hyperparameters, train the final model on test set. 3 ways to create a validation set: 1) simple hold-out validation, 2) K-fold validation and 3) iterated K-fold validation with shuffling(more @page98)"
      ],
      "metadata": {
        "id": "YTXEU_w3V5TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# training the model\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=512)\n",
        "\n",
        "# (also in order to monitor during the training the accuracy of the model on data it has never seen before, let's create a validation set) \n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]\n",
        "\n",
        "# training the model by monitoring how the model performs on unseen data\n",
        "print('\\n\\ntraining with validation ...\\n')\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=9,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd-pKZHpvFf-",
        "outputId": "6b9d23e9-15d8-4b33-a44d-bde9ec3fe866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/5\n",
            "49/49 [==============================] - 6s 96ms/step - loss: 0.4353 - accuracy: 0.8302\n",
            "Epoch 2/5\n",
            "49/49 [==============================] - 2s 35ms/step - loss: 0.2562 - accuracy: 0.9090\n",
            "Epoch 3/5\n",
            "49/49 [==============================] - 2s 35ms/step - loss: 0.1974 - accuracy: 0.9307\n",
            "Epoch 4/5\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 0.1649 - accuracy: 0.9415\n",
            "Epoch 5/5\n",
            "49/49 [==============================] - 2s 35ms/step - loss: 0.1416 - accuracy: 0.9502\n",
            "\n",
            "\n",
            "training with validation ...\n",
            "\n",
            "Epoch 1/9\n",
            "47/47 [==============================] - 2s 42ms/step - loss: 0.1234 - accuracy: 0.9576 - val_loss: 0.1134 - val_accuracy: 0.9580\n",
            "Epoch 2/9\n",
            "47/47 [==============================] - 2s 38ms/step - loss: 0.1046 - accuracy: 0.9651 - val_loss: 0.1314 - val_accuracy: 0.9530\n",
            "Epoch 3/9\n",
            "47/47 [==============================] - 2s 52ms/step - loss: 0.0906 - accuracy: 0.9698 - val_loss: 0.1500 - val_accuracy: 0.9400\n",
            "Epoch 4/9\n",
            "47/47 [==============================] - 3s 62ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 0.1845 - val_accuracy: 0.9320\n",
            "Epoch 5/9\n",
            "47/47 [==============================] - 2s 39ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.1956 - val_accuracy: 0.9270\n",
            "Epoch 6/9\n",
            "47/47 [==============================] - 2s 40ms/step - loss: 0.0553 - accuracy: 0.9845 - val_loss: 0.2442 - val_accuracy: 0.9100\n",
            "Epoch 7/9\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.2411 - val_accuracy: 0.9140\n",
            "Epoch 8/9\n",
            "47/47 [==============================] - 3s 56ms/step - loss: 0.0374 - accuracy: 0.9899 - val_loss: 0.2725 - val_accuracy: 0.9110\n",
            "Epoch 9/9\n",
            "47/47 [==============================] - 2s 39ms/step - loss: 0.0328 - accuracy: 0.9919 - val_loss: 0.3446 - val_accuracy: 0.8970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some model's info\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gxO7x_-5E5C",
        "outputId": "7b79214c-8b5d-43cc-915e-c6d74bfd1499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                160016    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,305\n",
            "Trainable params: 160,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.fit returns a History object, which is a dictionary cantaining data about everything happened during training. Dictionary's elements are all metrics which were being monitored during training"
      ],
      "metadata": {
        "id": "E8LwfR9x8FZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in our case history includes data for loss, accuracy, val_loss and val_accuracy\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aYW1O6s6-H3",
        "outputId": "c7257571-709d-4525-cbf4-6b08e0ff12e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss and accuracy of the model "
      ],
      "metadata": {
        "id": "tevw8HEB9lEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Asy-Bh-f6-CD",
        "outputId": "457b8c9c-9b88-4bb9-e534-f1cd76bb704e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we can see, this is an example of overfitting(high variance): our model can't generalize on new, unseen data"
      ],
      "metadata": {
        "id": "kh2NCTdn-UmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "psbvFM0q-DR7",
        "outputId": "d4ad2a90-bc15-4b2b-f5a5-b5ea316a015b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model and improve it"
      ],
      "metadata": {
        "id": "XGSzBaH-SQm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "after the 3rd epoch, our model is getting worse in performance, so it needs several improvement steps. Hyperparameter Tuning is a process that helps us make our model better. We can try to add more hidden layers or more units to them, try different loss function where is applicable, try different activation function, try also different numbers of epochs, batch_size, and generally tune all the hyperparameters of the model(we call parameters of the model its weights and bs)"
      ],
      "metadata": {
        "id": "LD0yHPLBMU-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our case here, we just limit our model to 4 epochs, as after that it is getting worse. The new model is just the old model trained for 4 epochs!"
      ],
      "metadata": {
        "id": "eLXhb6yqNJxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "results = model.evaluate(x_test, y_test)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUUUP5t5RhlM",
        "outputId": "5888a857-d66f-41b7-f76c-d160339fc67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6667 - accuracy: 0.8456\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6667125225067139, 0.8455600142478943]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain the model from scratch "
      ],
      "metadata": {
        "id": "5GwFlT7w_CFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the new model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# training the model\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=4,\n",
        "                    batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYw_n5Rn-kP1",
        "outputId": "fb89f875-1d32-4866-d544-e55006b5ff73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/4\n",
            "49/49 [==============================] - 6s 107ms/step - loss: 0.4401 - accuracy: 0.8229\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 0.2562 - accuracy: 0.9089\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 0.1959 - accuracy: 0.9307\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.1648 - accuracy: 0.9418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the new model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98X7FGVpEjrb",
        "outputId": "e57a13ba-144f-4d35-f53c-b4740beffaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                160016    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,305\n",
            "Trainable params: 160,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss and accuracy of the new model"
      ],
      "metadata": {
        "id": "85sP2vZYD4NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, label=\"Training loss\")\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pKxQYYMND6Fw",
        "outputId": "ca52ac22-a435-4c6d-90ff-b28a0a6f53c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "plt.plot(epochs, acc, label=\"Training accuracy\")\n",
        "plt.title(\"Training accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CNdfTF0mD86U",
        "outputId": "28c63a3b-41e4-4bb3-d4be-01b5698aa0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model and predict"
      ],
      "metadata": {
        "id": "n21hSzVXPVDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "results = model.evaluate(x_test, y_test)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ1wzg-8OrCi",
        "outputId": "a356c773-70a2-47b0-fb85-97cc23ac8928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3034 - accuracy: 0.8811\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30336320400238037, 0.8811200261116028]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the loss has decreased and the accuracy is improved. So, this new model performs better than the old one"
      ],
      "metadata": {
        "id": "F1LnXtFlSjxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions and explore/understand the results"
      ],
      "metadata": {
        "id": "wU6M0HQfTj-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoKs6JHtPNyN",
        "outputId": "53fafc7d-39cc-4a58-b01b-6112405dffcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFY_BRdiTWL3",
        "outputId": "132d6492-fb11-4bbb-b11d-90830b50f21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16233885],\n",
              "       [0.9996952 ],\n",
              "       [0.5383056 ],\n",
              "       ...,\n",
              "       [0.11845585],\n",
              "       [0.05670902],\n",
              "       [0.567876  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[10] # which is a close to 1=>a positive review, as we initially have seen it!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YJmKyP3PpUn",
        "outputId": "f4c08561-df8d-4f24-d521-8f733047484b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.93629014], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, to prevent your model from Overfitting: 1) get more training data, 2) reduce the capacity of the network, 3) add weight regularization and 4) add dropout layers. To prevent your model from Underfitting in NNs just try a bigger network!(from page 104)"
      ],
      "metadata": {
        "id": "iJ3ODB5PZDXD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kpco8jxTP2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 4. Classifying newswires, based on text content, into 46 topics"
      ],
      "metadata": {
        "id": "w4BQ3F6wT_QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a multi-class Classification problem"
      ],
      "metadata": {
        "id": "NGu5orJGVuXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand it"
      ],
      "metadata": {
        "id": "NXvdvz47W-oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) # num_words=10000 means that we only keep the top 10000 most frequently occuring words in the training data\n",
        " \n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwGWmZKwUJVR",
        "outputId": "9a396a63-c700-4dac-982e-a172ab5d8326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (8982,)\n",
            "y_train: (8982,)\n",
            "X_test: (2246,)\n",
            "y_test: (2246,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_labels[10]}')\n",
        "print(f'the label of 11th example of test_labels: {test_labels[10]}\\n')\n",
        "print(f'the first 11 elements of train_labels: {train_labels[:11]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvlbhm3jVaWm",
        "outputId": "9aacc2c7-f0fc-4c8a-faab-449fbfbdcd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n",
            "length of 11th example of train_data: 31\n",
            "the label of 11th example of train_labels: 3\n",
            "the label of 11th example of test_labels: 5\n",
            "\n",
            "the first 11 elements of train_labels: [ 3  4  3  4  4  4  4  3  3 16  3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with the imdb's reviews, each example here is also a list of integers(word indices)"
      ],
      "metadata": {
        "id": "dxborw1AXqe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data for the NN"
      ],
      "metadata": {
        "id": "Xn1nQd_UZW0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the integer sequences via multi-hot encoding for train_data and test_data: each example now is a 10000 sequence of 0s and 1s\n",
        "# if a word is on corpus of 10000, we have 1 and if a word is not in the corpus, we have 0\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "xIjj87rnZDyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 ways to handle the labels/targets in such cases: 1) one-hot(categorical) encoding in which we use loss=categorical_crossentropy(and dtype is float) and 2) labels as integers in which we use sparse_categorical_crossentropy(dtype here is int, more @page 83)"
      ],
      "metadata": {
        "id": "a_goUT_TzsvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding for the train and test labels\n",
        "# (a 46 dimensional list with 0s and 1s)\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "07IJJhOSzqwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train after preprocessing: {x_train.shape}')\n",
        "print(f'y_train after preprocessing: {one_hot_train_labels.shape}')\n",
        "print(f'X_test after preprocessing: {x_test.shape}')\n",
        "print(f'y_test after preprocessing: {one_hot_test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGK6txb7lVt4",
        "outputId": "a7aa2db7-86c7-437d-9bf7-543f792af54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train after preprocessing: (8982, 10000)\n",
            "y_train after preprocessing: (8982, 46)\n",
            "X_test after preprocessing: (2246, 10000)\n",
            "y_test after preprocessing: (2246, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'length of 11th example of train_data after preprocessing: {x_train[10].shape}')\n",
        "print(f'11th example of train_data after preprocessing:\\n {x_train[10]}')\n",
        "print(f'the label of 11th example of train_labels after preprocessing: {one_hot_train_labels[10]}')\n",
        "\n",
        "print(f'\\n11th example of x_test after preprocessing:\\n {x_test[10]}')\n",
        "print(f'the label of 11th example of test_labels after preprocessing: {one_hot_test_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiCwu4Rple95",
        "outputId": "3102991d-b80a-4520-8a35-62f015523c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of 11th example of train_data after preprocessing: (10000,)\n",
            "11th example of train_data after preprocessing:\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            "the label of 11th example of train_labels after preprocessing: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "11th example of x_test after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of test_labels after preprocessing: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and train the model"
      ],
      "metadata": {
        "id": "E47YY_Fpc7ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's architecture\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# model's compiling\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# create a validation set \n",
        "# every model is not the best initially and always needs improvements via hyperparameter tuning. So, always create a validation set to test the model and when find the best tuning, train the final model on test set\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]\n",
        "\n",
        "# start training\n",
        "print('training ...\\n')\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCmDLGouZDvW",
        "outputId": "c094f618-c3aa-4d4c-baf5-da5a573b2a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 4s 215ms/step - loss: 2.6660 - accuracy: 0.5316 - val_loss: 1.7728 - val_accuracy: 0.6590\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 1.4426 - accuracy: 0.7076 - val_loss: 1.3066 - val_accuracy: 0.7190\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 1.0516 - accuracy: 0.7732 - val_loss: 1.1531 - val_accuracy: 0.7330\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.8257 - accuracy: 0.8231 - val_loss: 1.0236 - val_accuracy: 0.7820\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 62ms/step - loss: 0.6555 - accuracy: 0.8636 - val_loss: 0.9531 - val_accuracy: 0.8060\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.5231 - accuracy: 0.8920 - val_loss: 0.9036 - val_accuracy: 0.8160\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 62ms/step - loss: 0.4186 - accuracy: 0.9123 - val_loss: 0.8899 - val_accuracy: 0.8120\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.3401 - accuracy: 0.9285 - val_loss: 0.9330 - val_accuracy: 0.7990\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.2790 - accuracy: 0.9416 - val_loss: 0.8766 - val_accuracy: 0.8160\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 0.2388 - accuracy: 0.9451 - val_loss: 0.8821 - val_accuracy: 0.8280\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2040 - accuracy: 0.9499 - val_loss: 0.9254 - val_accuracy: 0.8160\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.1799 - accuracy: 0.9530 - val_loss: 0.9672 - val_accuracy: 0.8100\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 67ms/step - loss: 0.1593 - accuracy: 0.9546 - val_loss: 0.9271 - val_accuracy: 0.8290\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 66ms/step - loss: 0.1469 - accuracy: 0.9551 - val_loss: 0.9553 - val_accuracy: 0.8130\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 4s 266ms/step - loss: 0.1381 - accuracy: 0.9568 - val_loss: 0.9636 - val_accuracy: 0.8150\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.1314 - accuracy: 0.9579 - val_loss: 1.0133 - val_accuracy: 0.8170\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 3s 181ms/step - loss: 0.1225 - accuracy: 0.9572 - val_loss: 1.0587 - val_accuracy: 0.8050\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 3s 193ms/step - loss: 0.1198 - accuracy: 0.9578 - val_loss: 0.9941 - val_accuracy: 0.8190\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1157 - accuracy: 0.9577 - val_loss: 1.0998 - val_accuracy: 0.8000\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 96ms/step - loss: 0.1141 - accuracy: 0.9579 - val_loss: 1.0880 - val_accuracy: 0.8110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Eb6MLAftY6R",
        "outputId": "c7ef1378-b0c5-4198-a545-713a64a6f79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the training .vs validation loss and accuracy and Evaluating the model"
      ],
      "metadata": {
        "id": "EBXNskY0pe3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see what we have in history\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUqkqi08qi_W",
        "outputId": "75035b3b-5283-4e1c-c08d-40c6bb0e85d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LUR5KbFiZDsN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a0541920-af11-4111-8181-7711d8ebf0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YOIHJwh1ZDpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "06b38457-98e4-43f5-efdc-a0904e2f3fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the model starts to overfit after 8 epochs. So, we train a new model with 9 epochs"
      ],
      "metadata": {
        "id": "-PMkZzb1qv9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ],
      "metadata": {
        "id": "eiqmudSxZDmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ada081-bd04-48fa-97a5-5e074af5ee63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 0s 4ms/step - loss: 1.2568 - accuracy: 0.7841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.256787896156311, 0.784060537815094]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain from scratch a new model, Evaluate it and Predict"
      ],
      "metadata": {
        "id": "P56CPMperQ1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the previous model, we train it again with just 9 epochs only"
      ],
      "metadata": {
        "id": "X31OTDQtr3q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# model's compiling\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# start training\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    one_hot_train_labels,\n",
        "                    epochs=8,\n",
        "                    batch_size=512)"
      ],
      "metadata": {
        "id": "IfqH8531ZDjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b08d45c-696d-4cdb-bb1f-8fceaea891ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/8\n",
            "18/18 [==============================] - 2s 59ms/step - loss: 2.4377 - accuracy: 0.5331\n",
            "Epoch 2/8\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 1.3336 - accuracy: 0.7110\n",
            "Epoch 3/8\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 0.9873 - accuracy: 0.7828\n",
            "Epoch 4/8\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 0.7657 - accuracy: 0.8332\n",
            "Epoch 5/8\n",
            "18/18 [==============================] - 3s 197ms/step - loss: 0.6045 - accuracy: 0.8704\n",
            "Epoch 6/8\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 0.4796 - accuracy: 0.8980\n",
            "Epoch 7/8\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.3800 - accuracy: 0.9172\n",
            "Epoch 8/8\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.3118 - accuracy: 0.9281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the new model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1XHwTVxtVmU",
        "outputId": "d8e525d3-44be-4a4b-b99a-7546cabefe14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this new model\n",
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilDxbizUsYJq",
        "outputId": "c8a41a6d-2e39-4bd6-b152-d837199b487e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 30ms/step - loss: 0.9289 - accuracy: 0.7965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9289433360099792, 0.7965271472930908]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 models have almost the same accuracy, but the new one has significatly decreased loss"
      ],
      "metadata": {
        "id": "Pfdqp9W5syDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions. understand what the results are\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "ZldgN5ksZDgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fa73ec-6c5a-40ca-9ba6-7f686998460b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "r4998LAWZDdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# every prediction is comprised of 46 probs vector\n",
        "predictions[10].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv1ewRT6wjCP",
        "outputId": "86066b9e-8d1f-4034-a43d-00e93c9dfb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a prediction vector\n",
        "predictions[10] "
      ],
      "metadata": {
        "id": "mYKkApDlZDap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b891a75f-4c4e-42f5-ec17-c082bd5807b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.26412062e-03, 9.12307620e-01, 1.73646421e-03, 9.05314519e-04,\n",
              "       6.92098122e-03, 2.52958965e-02, 7.58594892e-04, 2.24091971e-04,\n",
              "       9.78066510e-06, 1.11424585e-03, 1.27960229e-02, 2.81922083e-04,\n",
              "       1.17566095e-04, 4.54508699e-04, 1.56262179e-03, 3.30960378e-04,\n",
              "       1.27479216e-04, 2.39883098e-04, 1.92524050e-04, 1.22233725e-03,\n",
              "       9.03669163e-04, 5.76941762e-04, 3.34238540e-03, 2.13922863e-03,\n",
              "       1.41469510e-02, 8.83744331e-04, 2.45795032e-04, 4.23668273e-04,\n",
              "       1.90938672e-03, 4.20893746e-04, 7.63645367e-05, 1.40431244e-03,\n",
              "       1.90489693e-03, 2.87322706e-04, 1.39482963e-05, 2.67029591e-05,\n",
              "       3.75945201e-05, 4.14669994e-05, 1.92056978e-04, 6.12927906e-05,\n",
              "       8.17486609e-04, 6.29354094e-04, 4.63092001e-04, 3.25627880e-05,\n",
              "       9.60659963e-05, 5.97688231e-05], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index of the highest probability. check it above\n",
        "np.argmax(predictions[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO7otZzLwiT1",
        "outputId": "be0cc94f-c124-4548-c68c-a23e30cdea6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficients of each vector of 46 elements must have sum=1 \n",
        "np.sum(predictions[10])"
      ],
      "metadata": {
        "id": "6UV7DX5lZDXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a555473b-6b99-4f6a-cbbd-b37090fdfd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and check manually if the prediction is correct \n",
        "one_hot_test_labels[10]"
      ],
      "metadata": {
        "id": "uR29IupWZDU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffd989d-0ee5-4523-9edb-588f4bff096a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4muV4R33ZI8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 5. Predicting house prices"
      ],
      "metadata": {
        "id": "WCP4acTg0dlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a linear regression problem"
      ],
      "metadata": {
        "id": "gNX4DGhV0uS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "ete78P9067Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_targets.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_targets.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ8RyWph0jPZ",
        "outputId": "4ec80bc2-e9b0-4052-b21b-d48256350e20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (404, 13)\n",
            "y_train: (404,)\n",
            "X_test: (102, 13)\n",
            "y_test: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_targets[10]}')\n",
        "print(f'the label of 11th example of test_labels: {test_targets[10]}\\n')\n",
        "print(f'the first 11 elements of train_labels: {train_targets[:11]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ-AYtSP0_Sr",
        "outputId": "6f7bb348-27ee-4317-c793-594677d70cf8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [  9.59571   0.       18.1       0.        0.693     6.404   100.\n",
            "   1.639    24.      666.       20.2     376.11     20.31   ]\n",
            "length of 11th example of train_data: 13\n",
            "the label of 11th example of train_labels: 12.1\n",
            "the label of 11th example of test_labels: 18.6\n",
            "\n",
            "the first 11 elements of train_labels: [15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data"
      ],
      "metadata": {
        "id": "UlrGVwn07n2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization of the train and test data\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "metadata": {
        "id": "YrWIytyT0_P0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build, Train and Evaluate the model using K-fold cross-validation"
      ],
      "metadata": {
        "id": "okjds-Ld9Fy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building function of the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# when little data available for training, we use a small network!\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "pHqgsX150_NF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a best model, we need a validation set in order to use it as an intermediate dataset to improve it, as we always do. However, having so few examples in the train_data, a small validation set does not help, so we split the train_data into k partitions, build, train(on k-1 partitions) and evaluate(on k partition) k models. The final model is the average of k models(more @page87)"
      ],
      "metadata": {
        "id": "RlKCmUnF95Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]  \n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=16)#, verbose=0\n",
        "    mae_history = history.history[\"val_mae\"]\n",
        "    all_mae_histories.append(mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHVWITi30_J_",
        "outputId": "42f0aead-bbee-4d99-9a7c-9faf48c4e503"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing fold #0\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 2s 11ms/step - loss: 497.0964 - mae: 20.4045 - val_loss: 405.9922 - val_mae: 17.7957\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 354.2267 - mae: 16.8139 - val_loss: 253.8676 - val_mae: 13.5586\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 207.3270 - mae: 12.3005 - val_loss: 121.8844 - val_mae: 8.7699\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 101.1403 - mae: 7.9170 - val_loss: 56.5331 - val_mae: 5.3890\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 53.4007 - mae: 5.5904 - val_loss: 38.3350 - val_mae: 4.0848\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 37.6708 - mae: 4.6078 - val_loss: 32.3809 - val_mae: 3.6018\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 31.0968 - mae: 4.0677 - val_loss: 29.6878 - val_mae: 3.4491\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 26.9461 - mae: 3.7311 - val_loss: 26.6918 - val_mae: 3.3557\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 24.5479 - mae: 3.5816 - val_loss: 24.0934 - val_mae: 3.1892\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 22.3770 - mae: 3.3970 - val_loss: 22.2667 - val_mae: 3.0656\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 20.3460 - mae: 3.2180 - val_loss: 20.7765 - val_mae: 3.1082\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 18.6859 - mae: 3.0815 - val_loss: 19.3161 - val_mae: 3.0132\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 17.6779 - mae: 2.9952 - val_loss: 18.0470 - val_mae: 2.9028\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 16.6748 - mae: 2.8336 - val_loss: 16.6011 - val_mae: 2.6724\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 15.6764 - mae: 2.7538 - val_loss: 15.7609 - val_mae: 2.6935\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 15.1291 - mae: 2.6897 - val_loss: 14.9405 - val_mae: 2.5995\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 14.3596 - mae: 2.6171 - val_loss: 14.3082 - val_mae: 2.6099\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 14.0704 - mae: 2.5757 - val_loss: 13.3826 - val_mae: 2.5212\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 13.4876 - mae: 2.5560 - val_loss: 12.9151 - val_mae: 2.4608\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 13.0994 - mae: 2.4402 - val_loss: 12.8077 - val_mae: 2.5735\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.7536 - mae: 2.4869 - val_loss: 12.2572 - val_mae: 2.3885\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.6685 - mae: 2.4227 - val_loss: 11.7491 - val_mae: 2.3611\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.9838 - mae: 2.3602 - val_loss: 11.7170 - val_mae: 2.3600\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.6614 - mae: 2.3538 - val_loss: 10.9438 - val_mae: 2.2511\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.6689 - mae: 2.3574 - val_loss: 10.6257 - val_mae: 2.2991\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.1432 - mae: 2.3477 - val_loss: 10.4268 - val_mae: 2.2282\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.1149 - mae: 2.3334 - val_loss: 10.2289 - val_mae: 2.2189\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 10.7179 - mae: 2.2932 - val_loss: 11.3661 - val_mae: 2.4774\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 11.2576 - mae: 2.3582 - val_loss: 10.1299 - val_mae: 2.2709\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.7364 - mae: 2.2714 - val_loss: 9.7936 - val_mae: 2.1820\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.4932 - mae: 2.2531 - val_loss: 9.5001 - val_mae: 2.1269\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.0938 - mae: 2.2219 - val_loss: 10.3915 - val_mae: 2.1990\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.2128 - mae: 2.1897 - val_loss: 9.4259 - val_mae: 2.1172\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.1088 - mae: 2.1859 - val_loss: 9.4869 - val_mae: 2.2031\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.0872 - mae: 2.1843 - val_loss: 9.2305 - val_mae: 2.1119\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.8893 - mae: 2.1593 - val_loss: 9.0960 - val_mae: 2.0794\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.7521 - mae: 2.1680 - val_loss: 9.2334 - val_mae: 2.1196\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.5049 - mae: 2.1134 - val_loss: 8.9425 - val_mae: 2.1083\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.4052 - mae: 2.1155 - val_loss: 9.6000 - val_mae: 2.1761\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.4347 - mae: 2.1185 - val_loss: 9.0569 - val_mae: 2.1699\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.3977 - mae: 2.1377 - val_loss: 8.6455 - val_mae: 2.0340\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.0509 - mae: 2.1326 - val_loss: 8.8590 - val_mae: 2.0427\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.2268 - mae: 2.1179 - val_loss: 8.7458 - val_mae: 2.1157\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.0099 - mae: 2.1011 - val_loss: 8.9342 - val_mae: 2.0407\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.7299 - mae: 2.0586 - val_loss: 8.2350 - val_mae: 1.9752\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.9138 - mae: 2.0895 - val_loss: 8.4203 - val_mae: 1.9585\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.7665 - mae: 2.0662 - val_loss: 8.5312 - val_mae: 2.1274\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.7564 - mae: 2.0908 - val_loss: 8.4034 - val_mae: 2.0889\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.4736 - mae: 2.0413 - val_loss: 9.0049 - val_mae: 2.2512\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.7045 - mae: 2.0277 - val_loss: 8.2795 - val_mae: 2.0775\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 8.5597 - mae: 2.0328 - val_loss: 8.0359 - val_mae: 2.0006\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.2800 - mae: 1.9981 - val_loss: 8.5688 - val_mae: 2.1465\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.5460 - mae: 2.0528 - val_loss: 8.4837 - val_mae: 1.9902\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.3914 - mae: 1.9909 - val_loss: 8.0974 - val_mae: 2.0536\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 8.1077 - mae: 1.9683 - val_loss: 7.7290 - val_mae: 1.9120\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.3983 - mae: 2.0109 - val_loss: 7.8068 - val_mae: 1.9040\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.1014 - mae: 2.0125 - val_loss: 7.6266 - val_mae: 1.8904\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0239 - mae: 1.9426 - val_loss: 7.9417 - val_mae: 2.0350\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 1s 5ms/step - loss: 7.9741 - mae: 1.9837 - val_loss: 7.6818 - val_mae: 1.9315\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.0287 - mae: 1.9830 - val_loss: 7.7889 - val_mae: 1.9892\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.7358 - mae: 1.9522 - val_loss: 7.5250 - val_mae: 1.8801\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.6761 - mae: 1.9163 - val_loss: 7.7048 - val_mae: 2.0151\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0553 - mae: 1.9450 - val_loss: 7.7384 - val_mae: 2.0435\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.6372 - mae: 1.9201 - val_loss: 7.8212 - val_mae: 2.0326\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.7430 - mae: 1.9547 - val_loss: 7.5661 - val_mae: 1.9108\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.6630 - mae: 1.9688 - val_loss: 7.2968 - val_mae: 1.9184\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 7.4787 - mae: 1.9041 - val_loss: 7.4707 - val_mae: 1.9597\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.4252 - mae: 1.8831 - val_loss: 7.7391 - val_mae: 2.0635\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.2321 - mae: 1.8805 - val_loss: 7.9404 - val_mae: 2.0328\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.6622 - mae: 1.9599 - val_loss: 7.3066 - val_mae: 1.9090\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.2506 - mae: 1.8669 - val_loss: 7.1609 - val_mae: 1.8715\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3412 - mae: 1.8673 - val_loss: 7.1955 - val_mae: 1.9068\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.4092 - mae: 1.8906 - val_loss: 7.1037 - val_mae: 1.8946\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 7.0278 - mae: 1.8445 - val_loss: 7.8273 - val_mae: 1.9661\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 7.1380 - mae: 1.8312 - val_loss: 7.6783 - val_mae: 2.0817\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 7.2183 - mae: 1.8915 - val_loss: 7.2164 - val_mae: 1.9514\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 7.1451 - mae: 1.8646 - val_loss: 7.2186 - val_mae: 1.9544\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 7.2860 - mae: 1.8379 - val_loss: 7.3011 - val_mae: 1.9666\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 7.0313 - mae: 1.8326 - val_loss: 7.3707 - val_mae: 1.9584\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 6.8991 - mae: 1.8240 - val_loss: 7.2038 - val_mae: 1.9767\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.7663 - mae: 1.8184 - val_loss: 6.8480 - val_mae: 1.8352\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 6.7303 - mae: 1.8248 - val_loss: 6.7498 - val_mae: 1.8334\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 6.6511 - mae: 1.7739 - val_loss: 7.5944 - val_mae: 2.0961\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.8948 - mae: 1.8255 - val_loss: 7.5913 - val_mae: 1.9974\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 6.5238 - mae: 1.8012 - val_loss: 7.1897 - val_mae: 1.9102\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.8334 - mae: 1.8123 - val_loss: 6.8674 - val_mae: 1.8718\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5895 - mae: 1.8029 - val_loss: 6.9049 - val_mae: 1.9144\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5585 - mae: 1.7509 - val_loss: 7.3824 - val_mae: 2.0221\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3825 - mae: 1.7657 - val_loss: 6.9245 - val_mae: 1.8549\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3676 - mae: 1.7388 - val_loss: 8.0210 - val_mae: 2.1401\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5725 - mae: 1.7959 - val_loss: 6.7231 - val_mae: 1.8582\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.2722 - mae: 1.7529 - val_loss: 6.6082 - val_mae: 1.8405\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.4042 - mae: 1.7321 - val_loss: 6.8514 - val_mae: 1.9135\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.1962 - mae: 1.7287 - val_loss: 6.8530 - val_mae: 1.8930\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.4193 - mae: 1.7609 - val_loss: 6.6566 - val_mae: 1.8858\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.2446 - mae: 1.7334 - val_loss: 6.8941 - val_mae: 1.9420\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 6.1542 - mae: 1.7070 - val_loss: 7.4601 - val_mae: 2.0601\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0982 - mae: 1.7217 - val_loss: 6.7313 - val_mae: 1.8740\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7288 - mae: 1.6781 - val_loss: 6.6036 - val_mae: 1.8462\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.0058 - mae: 1.7011 - val_loss: 7.6264 - val_mae: 2.0959\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9790 - mae: 1.7015 - val_loss: 6.9163 - val_mae: 1.9614\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.0547 - mae: 1.7042 - val_loss: 7.4731 - val_mae: 2.0889\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8973 - mae: 1.6824 - val_loss: 7.1306 - val_mae: 2.0053\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8907 - mae: 1.7039 - val_loss: 6.6238 - val_mae: 1.8376\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8884 - mae: 1.6589 - val_loss: 6.9817 - val_mae: 1.9621\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7614 - mae: 1.7240 - val_loss: 7.0342 - val_mae: 1.9802\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 5.6120 - mae: 1.6731 - val_loss: 6.5424 - val_mae: 1.8700\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8527 - mae: 1.6865 - val_loss: 6.8937 - val_mae: 1.8971\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 5.4969 - mae: 1.6307 - val_loss: 8.5255 - val_mae: 2.2874\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.8301 - mae: 1.6893 - val_loss: 6.6950 - val_mae: 1.9014\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.6600 - mae: 1.6457 - val_loss: 6.9519 - val_mae: 1.8970\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.7076 - mae: 1.6435 - val_loss: 6.5669 - val_mae: 1.8725\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 5.5365 - mae: 1.6411 - val_loss: 7.2499 - val_mae: 2.0166\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.5579 - mae: 1.6367 - val_loss: 6.5671 - val_mae: 1.8743\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 5.4253 - mae: 1.6366 - val_loss: 7.4072 - val_mae: 2.0976\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.5570 - mae: 1.6256 - val_loss: 7.0323 - val_mae: 2.0080\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 5.4680 - mae: 1.6476 - val_loss: 6.8152 - val_mae: 1.9533\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 5.5731 - mae: 1.6502 - val_loss: 6.5146 - val_mae: 1.8576\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 5.1740 - mae: 1.6111 - val_loss: 6.7304 - val_mae: 1.8922\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 5.1874 - mae: 1.6176 - val_loss: 6.8342 - val_mae: 1.8798\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.2599 - mae: 1.6062 - val_loss: 7.5089 - val_mae: 2.0864\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 5.4701 - mae: 1.6309 - val_loss: 6.5427 - val_mae: 1.8760\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 5.1851 - mae: 1.6025 - val_loss: 6.7894 - val_mae: 1.9344\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 5.2344 - mae: 1.5786 - val_loss: 6.4784 - val_mae: 1.8578\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 5.1350 - mae: 1.5881 - val_loss: 6.5955 - val_mae: 1.8870\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 5.1091 - mae: 1.5669 - val_loss: 6.8759 - val_mae: 1.9524\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 5.1929 - mae: 1.6093 - val_loss: 6.6285 - val_mae: 1.9310\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 5.0968 - mae: 1.5619 - val_loss: 6.8909 - val_mae: 1.9847\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 5.0658 - mae: 1.5710 - val_loss: 7.1172 - val_mae: 1.9908\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 4.9180 - mae: 1.5831 - val_loss: 8.1123 - val_mae: 2.2432\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 4.9834 - mae: 1.5782 - val_loss: 6.4558 - val_mae: 1.8188\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 4.8577 - mae: 1.5284 - val_loss: 7.2084 - val_mae: 2.0694\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 4.7848 - mae: 1.5044 - val_loss: 6.4730 - val_mae: 1.8084\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 4.9526 - mae: 1.5312 - val_loss: 6.7602 - val_mae: 1.9374\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 4.7653 - mae: 1.5030 - val_loss: 7.2800 - val_mae: 2.0067\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 4.8328 - mae: 1.5668 - val_loss: 6.5242 - val_mae: 1.8454\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 4.8773 - mae: 1.5340 - val_loss: 6.4109 - val_mae: 1.8282\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7276 - mae: 1.5294 - val_loss: 6.5085 - val_mae: 1.8179\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.8535 - mae: 1.5380 - val_loss: 6.7333 - val_mae: 1.9711\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6929 - mae: 1.5408 - val_loss: 7.2210 - val_mae: 1.9518\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6196 - mae: 1.4948 - val_loss: 6.7682 - val_mae: 1.9720\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6288 - mae: 1.4870 - val_loss: 6.7586 - val_mae: 1.9246\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6656 - mae: 1.5034 - val_loss: 6.4156 - val_mae: 1.8818\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3807 - mae: 1.4943 - val_loss: 7.9409 - val_mae: 2.1940\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5740 - mae: 1.5174 - val_loss: 6.7224 - val_mae: 1.8837\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4270 - mae: 1.4892 - val_loss: 6.4184 - val_mae: 1.8432\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7477 - mae: 1.5395 - val_loss: 6.8252 - val_mae: 1.9639\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5657 - mae: 1.4926 - val_loss: 6.9412 - val_mae: 1.8747\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4625 - mae: 1.4764 - val_loss: 7.1169 - val_mae: 1.9949\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4647 - mae: 1.4730 - val_loss: 7.4655 - val_mae: 2.0266\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4523 - mae: 1.4874 - val_loss: 7.6879 - val_mae: 2.1168\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2540 - mae: 1.4563 - val_loss: 7.7694 - val_mae: 2.1970\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5512 - mae: 1.4848 - val_loss: 7.5785 - val_mae: 2.1108\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4294 - mae: 1.4740 - val_loss: 6.6757 - val_mae: 1.8987\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1937 - mae: 1.4314 - val_loss: 6.5521 - val_mae: 1.9037\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 4.2046 - mae: 1.4484 - val_loss: 6.5877 - val_mae: 1.8969\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2539 - mae: 1.4379 - val_loss: 7.7773 - val_mae: 2.1099\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1074 - mae: 1.4592 - val_loss: 6.9670 - val_mae: 2.0204\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1451 - mae: 1.4365 - val_loss: 7.4235 - val_mae: 2.0098\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2909 - mae: 1.4439 - val_loss: 6.7265 - val_mae: 1.8301\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4315 - mae: 1.5012 - val_loss: 6.7367 - val_mae: 1.8503\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1572 - mae: 1.4288 - val_loss: 7.1197 - val_mae: 2.0696\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 4.1325 - mae: 1.4270 - val_loss: 6.7528 - val_mae: 1.9440\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0821 - mae: 1.4027 - val_loss: 7.9645 - val_mae: 2.2238\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1053 - mae: 1.4426 - val_loss: 6.6078 - val_mae: 1.9595\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0984 - mae: 1.4062 - val_loss: 6.9225 - val_mae: 2.0060\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9813 - mae: 1.3864 - val_loss: 6.6259 - val_mae: 1.8797\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1804 - mae: 1.4422 - val_loss: 7.0124 - val_mae: 1.9420\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9440 - mae: 1.4146 - val_loss: 6.8501 - val_mae: 1.9514\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9253 - mae: 1.4049 - val_loss: 7.3716 - val_mae: 1.9623\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 4.1331 - mae: 1.4230 - val_loss: 7.2381 - val_mae: 1.9674\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8110 - mae: 1.3821 - val_loss: 7.0429 - val_mae: 1.9263\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8117 - mae: 1.3778 - val_loss: 7.2326 - val_mae: 1.9971\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 3.9005 - mae: 1.4114 - val_loss: 6.8351 - val_mae: 1.8470\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 3.8493 - mae: 1.4298 - val_loss: 6.8254 - val_mae: 1.9557\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.7284 - mae: 1.3449 - val_loss: 7.4829 - val_mae: 2.1204\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7850 - mae: 1.3785 - val_loss: 6.7869 - val_mae: 1.9302\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6521 - mae: 1.3583 - val_loss: 6.5994 - val_mae: 1.8988\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7731 - mae: 1.3930 - val_loss: 6.9990 - val_mae: 2.0096\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6088 - mae: 1.3603 - val_loss: 6.9713 - val_mae: 2.0209\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8378 - mae: 1.4462 - val_loss: 7.4986 - val_mae: 2.0694\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6644 - mae: 1.3452 - val_loss: 7.0119 - val_mae: 1.9568\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7275 - mae: 1.3663 - val_loss: 6.7039 - val_mae: 1.9121\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5757 - mae: 1.3122 - val_loss: 6.8224 - val_mae: 1.9428\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4813 - mae: 1.3308 - val_loss: 6.9880 - val_mae: 1.9834\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 3.5644 - mae: 1.3388 - val_loss: 6.9376 - val_mae: 1.9954\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5747 - mae: 1.3600 - val_loss: 6.8941 - val_mae: 1.9738\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5929 - mae: 1.3495 - val_loss: 6.9934 - val_mae: 1.9676\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4979 - mae: 1.3223 - val_loss: 8.8375 - val_mae: 2.3213\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3550 - mae: 1.2899 - val_loss: 6.8681 - val_mae: 1.8945\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4775 - mae: 1.3443 - val_loss: 7.0248 - val_mae: 1.9370\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4784 - mae: 1.3768 - val_loss: 7.1341 - val_mae: 1.9309\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3957 - mae: 1.3171 - val_loss: 7.4512 - val_mae: 1.9676\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3392 - mae: 1.3270 - val_loss: 6.8413 - val_mae: 1.8309\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2679 - mae: 1.3042 - val_loss: 7.4595 - val_mae: 2.0142\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5162 - mae: 1.3388 - val_loss: 7.1550 - val_mae: 2.0142\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3345 - mae: 1.3179 - val_loss: 6.9955 - val_mae: 1.9624\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 3.3506 - mae: 1.3220 - val_loss: 7.2641 - val_mae: 2.0556\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3008 - mae: 1.2985 - val_loss: 6.7249 - val_mae: 1.9056\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.2759 - mae: 1.2882 - val_loss: 7.0555 - val_mae: 1.9933\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 3.4242 - mae: 1.3175 - val_loss: 6.9165 - val_mae: 1.9895\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.2018 - mae: 1.2745 - val_loss: 8.0607 - val_mae: 2.1871\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 3.1542 - mae: 1.2623 - val_loss: 6.9045 - val_mae: 1.9176\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 3.1675 - mae: 1.2768 - val_loss: 7.2703 - val_mae: 2.1305\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.1574 - mae: 1.3040 - val_loss: 6.8949 - val_mae: 1.9820\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.3402 - mae: 1.3039 - val_loss: 7.1989 - val_mae: 2.0303\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.2236 - mae: 1.2698 - val_loss: 6.9214 - val_mae: 1.9555\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9685 - mae: 1.2502 - val_loss: 7.7964 - val_mae: 2.1138\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1118 - mae: 1.2557 - val_loss: 6.7537 - val_mae: 1.9808\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 3.1031 - mae: 1.2636 - val_loss: 7.3087 - val_mae: 1.9700\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9511 - mae: 1.2158 - val_loss: 7.2669 - val_mae: 1.9167\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0672 - mae: 1.2513 - val_loss: 7.0687 - val_mae: 1.9070\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.0692 - mae: 1.2707 - val_loss: 7.0350 - val_mae: 1.9550\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 3.0201 - mae: 1.2467 - val_loss: 7.2311 - val_mae: 2.0337\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1156 - mae: 1.2660 - val_loss: 7.1972 - val_mae: 2.0374\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9738 - mae: 1.2267 - val_loss: 7.5477 - val_mae: 2.1281\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.8290 - mae: 1.2055 - val_loss: 7.2629 - val_mae: 2.0787\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.8703 - mae: 1.2136 - val_loss: 7.3359 - val_mae: 2.0262\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 2.9777 - mae: 1.2281 - val_loss: 7.7359 - val_mae: 2.1472\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.9362 - mae: 1.2306 - val_loss: 7.9226 - val_mae: 2.1509\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9033 - mae: 1.2149 - val_loss: 7.5963 - val_mae: 2.0948\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7184 - mae: 1.1721 - val_loss: 7.3093 - val_mae: 2.0483\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9780 - mae: 1.2758 - val_loss: 6.9801 - val_mae: 1.9292\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8010 - mae: 1.2195 - val_loss: 7.0726 - val_mae: 2.0712\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 2.7749 - mae: 1.2239 - val_loss: 7.1404 - val_mae: 1.9093\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8863 - mae: 1.2204 - val_loss: 7.6356 - val_mae: 2.0818\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6345 - mae: 1.1596 - val_loss: 7.5840 - val_mae: 2.0958\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7525 - mae: 1.1670 - val_loss: 7.3323 - val_mae: 2.0585\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 2.6499 - mae: 1.1852 - val_loss: 7.3627 - val_mae: 2.1023\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8365 - mae: 1.2306 - val_loss: 7.3436 - val_mae: 1.9351\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7892 - mae: 1.1749 - val_loss: 7.8130 - val_mae: 2.1217\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.6356 - mae: 1.1821 - val_loss: 8.0662 - val_mae: 2.2150\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7472 - mae: 1.1916 - val_loss: 7.5619 - val_mae: 2.0961\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7479 - mae: 1.1801 - val_loss: 7.3385 - val_mae: 2.0212\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5982 - mae: 1.1571 - val_loss: 7.1895 - val_mae: 1.9428\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7081 - mae: 1.1826 - val_loss: 7.1135 - val_mae: 2.0181\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 2.6876 - mae: 1.1482 - val_loss: 7.4194 - val_mae: 1.9905\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.6050 - mae: 1.1641 - val_loss: 8.3925 - val_mae: 2.1895\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7380 - mae: 1.1802 - val_loss: 7.2510 - val_mae: 1.9805\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4616 - mae: 1.1342 - val_loss: 7.6523 - val_mae: 2.1207\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.4736 - mae: 1.1450 - val_loss: 7.1799 - val_mae: 1.9805\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.5718 - mae: 1.1663 - val_loss: 7.4191 - val_mae: 2.0072\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.4030 - mae: 1.1115 - val_loss: 7.9696 - val_mae: 2.1437\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5014 - mae: 1.1320 - val_loss: 7.4970 - val_mae: 2.0612\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5144 - mae: 1.1570 - val_loss: 8.3856 - val_mae: 2.0287\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.5097 - mae: 1.1595 - val_loss: 7.5745 - val_mae: 2.0668\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.4254 - mae: 1.1464 - val_loss: 7.4567 - val_mae: 1.9964\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 2.4339 - mae: 1.1403 - val_loss: 7.6517 - val_mae: 2.0794\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6061 - mae: 1.1625 - val_loss: 8.1641 - val_mae: 2.1939\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.3810 - mae: 1.0899 - val_loss: 7.3752 - val_mae: 2.0114\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.3435 - mae: 1.0819 - val_loss: 7.6664 - val_mae: 2.0253\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 2.4234 - mae: 1.1418 - val_loss: 7.7483 - val_mae: 2.1278\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.4625 - mae: 1.1464 - val_loss: 7.7676 - val_mae: 2.1412\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4174 - mae: 1.1114 - val_loss: 7.1570 - val_mae: 2.0052\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 2.3746 - mae: 1.1334 - val_loss: 7.4580 - val_mae: 2.0293\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2810 - mae: 1.0742 - val_loss: 7.9180 - val_mae: 2.1389\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4029 - mae: 1.1346 - val_loss: 7.3401 - val_mae: 2.0584\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.2835 - mae: 1.0940 - val_loss: 7.9733 - val_mae: 2.0525\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.3596 - mae: 1.0803 - val_loss: 8.2731 - val_mae: 2.2432\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.3414 - mae: 1.1042 - val_loss: 7.3335 - val_mae: 2.0290\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 2.3323 - mae: 1.0991 - val_loss: 7.5228 - val_mae: 1.9842\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2725 - mae: 1.0961 - val_loss: 7.6138 - val_mae: 2.0898\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3109 - mae: 1.0858 - val_loss: 7.4503 - val_mae: 1.9764\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.2786 - mae: 1.0830 - val_loss: 7.7645 - val_mae: 2.0790\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2751 - mae: 1.0409 - val_loss: 7.5936 - val_mae: 2.0770\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1893 - mae: 1.0330 - val_loss: 7.7399 - val_mae: 2.0596\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.3006 - mae: 1.0798 - val_loss: 8.0361 - val_mae: 2.1196\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.1290 - mae: 1.0531 - val_loss: 7.7001 - val_mae: 2.0402\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.1488 - mae: 1.0596 - val_loss: 7.7691 - val_mae: 1.9368\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.3436 - mae: 1.0859 - val_loss: 7.4573 - val_mae: 1.9862\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0562 - mae: 1.0476 - val_loss: 8.0194 - val_mae: 2.1021\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2564 - mae: 1.0886 - val_loss: 7.6839 - val_mae: 2.0063\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0954 - mae: 1.0314 - val_loss: 7.9424 - val_mae: 2.0842\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0624 - mae: 1.0541 - val_loss: 7.4383 - val_mae: 2.0025\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0987 - mae: 1.0636 - val_loss: 7.7371 - val_mae: 2.0777\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1834 - mae: 1.0510 - val_loss: 7.9673 - val_mae: 2.0913\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1772 - mae: 1.0670 - val_loss: 7.9240 - val_mae: 1.9711\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.9726 - mae: 0.9942 - val_loss: 8.0529 - val_mae: 2.0805\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.1487 - mae: 1.0621 - val_loss: 7.5307 - val_mae: 2.0281\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.1208 - mae: 1.0719 - val_loss: 7.8934 - val_mae: 2.0532\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.9559 - mae: 1.0123 - val_loss: 8.1690 - val_mae: 2.0342\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9267 - mae: 1.0047 - val_loss: 8.0736 - val_mae: 2.0812\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1720 - mae: 1.0615 - val_loss: 7.7578 - val_mae: 1.9571\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0006 - mae: 1.0380 - val_loss: 7.8951 - val_mae: 2.1124\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.0346 - mae: 1.0308 - val_loss: 7.9861 - val_mae: 1.9993\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.9726 - mae: 1.0178 - val_loss: 8.1274 - val_mae: 2.1705\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 2.1388 - mae: 1.0708 - val_loss: 8.0062 - val_mae: 2.1097\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.9073 - mae: 1.0109 - val_loss: 7.9320 - val_mae: 2.0079\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.0529 - mae: 1.0533 - val_loss: 8.0440 - val_mae: 2.0405\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.8967 - mae: 0.9935 - val_loss: 8.5999 - val_mae: 2.2089\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9581 - mae: 1.0080 - val_loss: 7.7774 - val_mae: 1.9591\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9728 - mae: 1.0168 - val_loss: 8.1028 - val_mae: 2.1280\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9417 - mae: 1.0300 - val_loss: 7.6031 - val_mae: 2.0532\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9246 - mae: 0.9767 - val_loss: 8.5983 - val_mae: 2.1775\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9336 - mae: 1.0158 - val_loss: 8.2741 - val_mae: 2.1102\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9551 - mae: 0.9991 - val_loss: 7.8704 - val_mae: 1.9524\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7984 - mae: 0.9693 - val_loss: 8.0235 - val_mae: 2.1150\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9951 - mae: 0.9936 - val_loss: 8.6258 - val_mae: 2.2070\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.8938 - mae: 1.0075 - val_loss: 8.1941 - val_mae: 2.1131\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.8765 - mae: 0.9977 - val_loss: 7.8939 - val_mae: 2.0608\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.8506 - mae: 0.9815 - val_loss: 7.7361 - val_mae: 2.0039\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1.6273 - mae: 0.9306 - val_loss: 9.2840 - val_mae: 2.3474\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9044 - mae: 1.0119 - val_loss: 8.6680 - val_mae: 2.1757\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7655 - mae: 0.9676 - val_loss: 8.2897 - val_mae: 2.1269\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8954 - mae: 1.0140 - val_loss: 7.7753 - val_mae: 2.0411\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.6818 - mae: 0.9295 - val_loss: 8.1460 - val_mae: 2.1075\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.7764 - mae: 0.9871 - val_loss: 7.8829 - val_mae: 2.0083\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8992 - mae: 0.9623 - val_loss: 8.3804 - val_mae: 2.0633\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7385 - mae: 0.9293 - val_loss: 8.3313 - val_mae: 2.0235\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.8014 - mae: 0.9765 - val_loss: 8.9052 - val_mae: 2.2674\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7960 - mae: 0.9731 - val_loss: 8.6695 - val_mae: 2.2396\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6570 - mae: 0.9601 - val_loss: 10.2832 - val_mae: 2.4794\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.8379 - mae: 0.9681 - val_loss: 8.1403 - val_mae: 2.1232\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.6322 - mae: 0.9148 - val_loss: 8.8012 - val_mae: 2.2433\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9012 - mae: 0.9986 - val_loss: 8.6049 - val_mae: 2.1473\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.6598 - mae: 0.9379 - val_loss: 8.2699 - val_mae: 2.1364\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7335 - mae: 0.9413 - val_loss: 8.3611 - val_mae: 2.1014\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5496 - mae: 0.8952 - val_loss: 8.6964 - val_mae: 2.1302\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.8271 - mae: 0.9803 - val_loss: 8.0447 - val_mae: 2.1049\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.7222 - mae: 0.9180 - val_loss: 8.3079 - val_mae: 2.0357\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.6043 - mae: 0.9073 - val_loss: 8.2732 - val_mae: 2.1186\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6535 - mae: 0.9350 - val_loss: 8.2858 - val_mae: 2.0826\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6559 - mae: 0.9477 - val_loss: 8.8012 - val_mae: 2.0514\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.6488 - mae: 0.9402 - val_loss: 8.0650 - val_mae: 1.9994\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.6379 - mae: 0.8821 - val_loss: 8.9949 - val_mae: 2.2438\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.6334 - mae: 0.9275 - val_loss: 8.0136 - val_mae: 2.0772\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6565 - mae: 0.8924 - val_loss: 8.5509 - val_mae: 2.1614\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6440 - mae: 0.9308 - val_loss: 8.0969 - val_mae: 2.0358\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.6813 - mae: 0.9400 - val_loss: 8.5174 - val_mae: 2.0588\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5377 - mae: 0.8878 - val_loss: 8.1627 - val_mae: 2.0508\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5400 - mae: 0.9083 - val_loss: 8.9684 - val_mae: 2.2547\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5177 - mae: 0.8945 - val_loss: 8.8762 - val_mae: 2.2270\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6178 - mae: 0.9106 - val_loss: 8.5369 - val_mae: 2.0953\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6620 - mae: 0.9673 - val_loss: 8.2671 - val_mae: 2.0774\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5855 - mae: 0.8802 - val_loss: 8.6406 - val_mae: 2.1989\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4805 - mae: 0.8685 - val_loss: 8.5702 - val_mae: 2.1599\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5746 - mae: 0.9196 - val_loss: 8.5794 - val_mae: 2.1159\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5873 - mae: 0.8932 - val_loss: 8.2923 - val_mae: 1.9971\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.4860 - mae: 0.8516 - val_loss: 8.1109 - val_mae: 2.0468\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4421 - mae: 0.8687 - val_loss: 8.4788 - val_mae: 2.0618\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5610 - mae: 0.9092 - val_loss: 9.9747 - val_mae: 2.4012\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5764 - mae: 0.9139 - val_loss: 8.3501 - val_mae: 2.1042\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5196 - mae: 0.8762 - val_loss: 9.0391 - val_mae: 2.1709\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5130 - mae: 0.8778 - val_loss: 9.2498 - val_mae: 2.2874\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6241 - mae: 0.9179 - val_loss: 8.4287 - val_mae: 2.0983\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4026 - mae: 0.8616 - val_loss: 9.2487 - val_mae: 2.2071\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5137 - mae: 0.8750 - val_loss: 8.7032 - val_mae: 2.0258\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.5015 - mae: 0.8729 - val_loss: 8.4589 - val_mae: 2.1154\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.4696 - mae: 0.8746 - val_loss: 8.3148 - val_mae: 2.0685\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.4690 - mae: 0.8763 - val_loss: 8.6432 - val_mae: 2.0757\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.3962 - mae: 0.8305 - val_loss: 9.1327 - val_mae: 2.1652\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.4986 - mae: 0.8904 - val_loss: 8.9408 - val_mae: 2.0461\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4719 - mae: 0.8668 - val_loss: 9.6736 - val_mae: 2.2487\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4315 - mae: 0.8749 - val_loss: 8.8600 - val_mae: 2.0930\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.4209 - mae: 0.8700 - val_loss: 9.5159 - val_mae: 2.2719\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.3884 - mae: 0.8399 - val_loss: 8.5946 - val_mae: 2.1602\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.5144 - mae: 0.8876 - val_loss: 8.6259 - val_mae: 2.0663\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.4228 - mae: 0.8399 - val_loss: 9.1063 - val_mae: 2.1693\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4431 - mae: 0.8900 - val_loss: 8.4990 - val_mae: 2.0434\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3195 - mae: 0.8324 - val_loss: 9.2910 - val_mae: 2.1822\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3788 - mae: 0.8158 - val_loss: 9.7191 - val_mae: 2.2634\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.3758 - mae: 0.8508 - val_loss: 8.9016 - val_mae: 2.1635\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3154 - mae: 0.8327 - val_loss: 8.7731 - val_mae: 2.1500\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.4006 - mae: 0.8293 - val_loss: 9.3303 - val_mae: 2.1684\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.3255 - mae: 0.8378 - val_loss: 8.9331 - val_mae: 2.1602\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4930 - mae: 0.8638 - val_loss: 8.6208 - val_mae: 2.1110\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3232 - mae: 0.8196 - val_loss: 8.7512 - val_mae: 2.0951\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4305 - mae: 0.8502 - val_loss: 9.2652 - val_mae: 2.2172\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.4296 - mae: 0.8509 - val_loss: 8.5840 - val_mae: 2.1306\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1.2806 - mae: 0.8133 - val_loss: 8.4666 - val_mae: 2.0830\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3846 - mae: 0.8459 - val_loss: 8.7826 - val_mae: 2.1180\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3847 - mae: 0.8567 - val_loss: 8.4148 - val_mae: 2.0529\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.3185 - mae: 0.8162 - val_loss: 8.6604 - val_mae: 2.0526\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2666 - mae: 0.7975 - val_loss: 8.6107 - val_mae: 2.0842\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1976 - mae: 0.7853 - val_loss: 8.4778 - val_mae: 2.0420\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.3201 - mae: 0.8290 - val_loss: 8.6269 - val_mae: 2.0799\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4101 - mae: 0.8461 - val_loss: 8.5176 - val_mae: 2.0676\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.3541 - mae: 0.8216 - val_loss: 8.5008 - val_mae: 2.0931\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.2350 - mae: 0.7959 - val_loss: 8.9134 - val_mae: 2.1310\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2654 - mae: 0.7972 - val_loss: 8.9524 - val_mae: 2.1590\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.2369 - mae: 0.7896 - val_loss: 8.7720 - val_mae: 2.0840\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2083 - mae: 0.7869 - val_loss: 9.2584 - val_mae: 2.2496\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3417 - mae: 0.8353 - val_loss: 8.5017 - val_mae: 2.0189\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3811 - mae: 0.8297 - val_loss: 8.3895 - val_mae: 2.0769\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3436 - mae: 0.8353 - val_loss: 9.5771 - val_mae: 2.2708\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.2457 - mae: 0.7932 - val_loss: 8.9896 - val_mae: 2.1717\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.1798 - mae: 0.8027 - val_loss: 9.4010 - val_mae: 2.1529\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.3396 - mae: 0.8175 - val_loss: 8.9532 - val_mae: 2.1193\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3143 - mae: 0.8352 - val_loss: 8.4761 - val_mae: 2.0534\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2104 - mae: 0.7701 - val_loss: 8.5072 - val_mae: 2.0265\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3123 - mae: 0.8180 - val_loss: 9.0475 - val_mae: 2.1922\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2900 - mae: 0.7987 - val_loss: 9.5225 - val_mae: 2.1903\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2978 - mae: 0.8086 - val_loss: 8.9344 - val_mae: 2.0744\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.1972 - mae: 0.7697 - val_loss: 10.0124 - val_mae: 2.4002\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3435 - mae: 0.8392 - val_loss: 8.7869 - val_mae: 2.1677\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.1489 - mae: 0.7663 - val_loss: 8.4786 - val_mae: 2.0292\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2207 - mae: 0.7871 - val_loss: 8.5409 - val_mae: 1.9871\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1867 - mae: 0.7907 - val_loss: 9.9891 - val_mae: 2.3383\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1345 - mae: 0.7375 - val_loss: 8.7859 - val_mae: 2.1100\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2533 - mae: 0.8255 - val_loss: 8.8594 - val_mae: 2.0372\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3472 - mae: 0.8413 - val_loss: 8.6175 - val_mae: 2.0970\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1094 - mae: 0.7419 - val_loss: 9.9667 - val_mae: 2.2866\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1058 - mae: 0.7520 - val_loss: 9.5401 - val_mae: 2.2437\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2222 - mae: 0.7865 - val_loss: 9.1646 - val_mae: 2.0797\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1349 - mae: 0.7716 - val_loss: 8.7886 - val_mae: 2.0695\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1995 - mae: 0.8037 - val_loss: 8.7382 - val_mae: 2.0937\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2539 - mae: 0.7983 - val_loss: 10.4162 - val_mae: 2.4137\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2420 - mae: 0.7928 - val_loss: 8.8260 - val_mae: 2.0698\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.1454 - mae: 0.7505 - val_loss: 9.3881 - val_mae: 2.1338\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.1660 - mae: 0.7761 - val_loss: 9.5453 - val_mae: 2.1590\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.1327 - mae: 0.7366 - val_loss: 9.2787 - val_mae: 2.1300\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3461 - mae: 0.8412 - val_loss: 8.7996 - val_mae: 2.0699\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0460 - mae: 0.7436 - val_loss: 8.8772 - val_mae: 2.0650\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1152 - mae: 0.7525 - val_loss: 8.8835 - val_mae: 2.1240\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.1854 - mae: 0.7784 - val_loss: 9.2917 - val_mae: 2.1860\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 0.9992 - mae: 0.7036 - val_loss: 8.8456 - val_mae: 2.1390\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1819 - mae: 0.7744 - val_loss: 8.7931 - val_mae: 2.0776\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0531 - mae: 0.7365 - val_loss: 9.2470 - val_mae: 2.1003\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1527 - mae: 0.7747 - val_loss: 8.6628 - val_mae: 2.1014\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.1287 - mae: 0.7438 - val_loss: 9.5131 - val_mae: 2.2080\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0901 - mae: 0.7699 - val_loss: 8.9679 - val_mae: 2.1666\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1751 - mae: 0.7917 - val_loss: 9.4619 - val_mae: 2.2402\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1466 - mae: 0.7640 - val_loss: 8.7684 - val_mae: 2.0386\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0466 - mae: 0.7212 - val_loss: 9.6885 - val_mae: 2.2630\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1717 - mae: 0.7662 - val_loss: 9.2056 - val_mae: 2.0559\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1328 - mae: 0.7629 - val_loss: 8.7503 - val_mae: 2.0168\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0792 - mae: 0.7512 - val_loss: 9.5719 - val_mae: 2.1650\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0339 - mae: 0.7205 - val_loss: 9.1841 - val_mae: 2.1152\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2137 - mae: 0.8011 - val_loss: 9.0731 - val_mae: 2.0774\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0676 - mae: 0.7174 - val_loss: 8.7810 - val_mae: 2.1303\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 1s 50ms/step - loss: 0.9616 - mae: 0.6938 - val_loss: 9.0418 - val_mae: 2.0801\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1036 - mae: 0.7426 - val_loss: 9.6821 - val_mae: 2.2669\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0989 - mae: 0.7291 - val_loss: 8.7081 - val_mae: 2.0614\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0672 - mae: 0.7539 - val_loss: 8.8855 - val_mae: 2.1703\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0499 - mae: 0.7253 - val_loss: 9.1630 - val_mae: 2.1053\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.9913 - mae: 0.7517 - val_loss: 10.3124 - val_mae: 2.3215\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0060 - mae: 0.7289 - val_loss: 9.6365 - val_mae: 2.1327\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.2180 - mae: 0.8099 - val_loss: 9.2925 - val_mae: 2.1255\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1278 - mae: 0.7491 - val_loss: 9.3836 - val_mae: 2.2456\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.9844 - mae: 0.6915 - val_loss: 8.8648 - val_mae: 2.0940\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.1524 - mae: 0.7665 - val_loss: 9.1694 - val_mae: 2.1228\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 1s 71ms/step - loss: 0.9943 - mae: 0.7390 - val_loss: 10.4891 - val_mae: 2.3739\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2183 - mae: 0.7960 - val_loss: 9.0096 - val_mae: 2.0714\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0612 - mae: 0.7247 - val_loss: 8.9731 - val_mae: 2.1106\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9845 - mae: 0.7040 - val_loss: 9.2872 - val_mae: 2.1127\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9480 - mae: 0.6986 - val_loss: 9.4349 - val_mae: 2.1546\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.0720 - mae: 0.7518 - val_loss: 9.4182 - val_mae: 2.1942\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.0029 - mae: 0.7339 - val_loss: 8.9549 - val_mae: 2.0359\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0687 - mae: 0.7531 - val_loss: 9.2317 - val_mae: 2.1111\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9637 - mae: 0.7019 - val_loss: 9.1030 - val_mae: 2.1783\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 1.0158 - mae: 0.7541 - val_loss: 9.2321 - val_mae: 2.1522\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.9369 - mae: 0.6908 - val_loss: 8.7710 - val_mae: 2.0620\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9840 - mae: 0.6858 - val_loss: 9.0802 - val_mae: 2.1251\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 1.0513 - mae: 0.7360 - val_loss: 9.0440 - val_mae: 2.1184\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9683 - mae: 0.7135 - val_loss: 8.7783 - val_mae: 2.0951\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1389 - mae: 0.7581 - val_loss: 9.3350 - val_mae: 2.2143\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9897 - mae: 0.6947 - val_loss: 9.2170 - val_mae: 2.0945\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0085 - mae: 0.7170 - val_loss: 9.4439 - val_mae: 2.2117\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9741 - mae: 0.7173 - val_loss: 9.3322 - val_mae: 2.1399\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0038 - mae: 0.7405 - val_loss: 9.3259 - val_mae: 2.2023\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0728 - mae: 0.7362 - val_loss: 9.2219 - val_mae: 2.1019\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9109 - mae: 0.6718 - val_loss: 9.2078 - val_mae: 2.0770\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1.2124 - mae: 0.7627 - val_loss: 9.4208 - val_mae: 2.1636\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.8814 - mae: 0.6727 - val_loss: 9.0688 - val_mae: 2.0450\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0620 - mae: 0.7256 - val_loss: 9.5143 - val_mae: 2.1625\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0828 - mae: 0.7429 - val_loss: 9.5636 - val_mae: 2.1472\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0428 - mae: 0.7367 - val_loss: 9.3853 - val_mae: 2.1545\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9198 - mae: 0.6669 - val_loss: 9.1724 - val_mae: 2.1486\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0405 - mae: 0.7332 - val_loss: 9.1508 - val_mae: 2.0963\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0209 - mae: 0.7261 - val_loss: 9.2895 - val_mae: 2.1550\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9017 - mae: 0.6677 - val_loss: 9.5311 - val_mae: 2.1615\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9506 - mae: 0.7186 - val_loss: 9.6295 - val_mae: 2.1980\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8753 - mae: 0.6641 - val_loss: 9.7911 - val_mae: 2.2812\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.9594 - mae: 0.7242 - val_loss: 9.1736 - val_mae: 2.1052\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.9595 - mae: 0.6969 - val_loss: 9.6396 - val_mae: 2.1052\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.0059 - mae: 0.7130 - val_loss: 9.3002 - val_mae: 2.1213\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9219 - mae: 0.6725 - val_loss: 9.5302 - val_mae: 2.2189\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9679 - mae: 0.7202 - val_loss: 9.8802 - val_mae: 2.1857\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.9949 - mae: 0.7005 - val_loss: 9.2414 - val_mae: 2.1037\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.8251 - mae: 0.6509 - val_loss: 9.6983 - val_mae: 2.2837\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0384 - mae: 0.7273 - val_loss: 9.8328 - val_mae: 2.2411\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9229 - mae: 0.7101 - val_loss: 9.6260 - val_mae: 2.1065\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.9697 - mae: 0.6847 - val_loss: 9.6997 - val_mae: 2.1772\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9106 - mae: 0.6796 - val_loss: 9.6754 - val_mae: 2.2285\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9992 - mae: 0.7211 - val_loss: 9.5408 - val_mae: 2.2516\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8484 - mae: 0.6602 - val_loss: 10.5044 - val_mae: 2.2948\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9210 - mae: 0.6809 - val_loss: 9.4286 - val_mae: 2.1463\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9943 - mae: 0.7095 - val_loss: 9.4075 - val_mae: 2.1047\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9044 - mae: 0.6722 - val_loss: 9.6998 - val_mae: 2.2007\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9089 - mae: 0.6828 - val_loss: 9.4534 - val_mae: 2.1745\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9472 - mae: 0.7015 - val_loss: 9.2298 - val_mae: 2.0869\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8157 - mae: 0.6511 - val_loss: 9.2038 - val_mae: 2.0812\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8651 - mae: 0.6655 - val_loss: 9.6655 - val_mae: 2.1576\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8877 - mae: 0.6954 - val_loss: 9.1267 - val_mae: 2.0975\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0024 - mae: 0.7181 - val_loss: 9.8318 - val_mae: 2.2042\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8165 - mae: 0.6364 - val_loss: 9.6009 - val_mae: 2.1300\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8809 - mae: 0.6705 - val_loss: 9.5194 - val_mae: 2.1814\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9421 - mae: 0.6877 - val_loss: 9.3274 - val_mae: 2.1787\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8585 - mae: 0.6717 - val_loss: 9.5274 - val_mae: 2.1352\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8669 - mae: 0.6527 - val_loss: 9.3806 - val_mae: 2.1523\n",
            "Processing fold #1\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 520.4988 - mae: 20.8047 - val_loss: 411.3264 - val_mae: 18.4984\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 367.6961 - mae: 17.0075 - val_loss: 255.8362 - val_mae: 14.0912\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 206.1591 - mae: 12.1351 - val_loss: 118.6335 - val_mae: 8.9278\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 96.1852 - mae: 7.4094 - val_loss: 54.5797 - val_mae: 5.7122\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 51.2142 - mae: 5.2478 - val_loss: 33.6751 - val_mae: 4.5856\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 35.2919 - mae: 4.1501 - val_loss: 27.3131 - val_mae: 4.2352\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 28.5443 - mae: 3.6935 - val_loss: 23.8060 - val_mae: 3.8839\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 24.4125 - mae: 3.4196 - val_loss: 21.6466 - val_mae: 3.5911\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 21.8159 - mae: 3.2448 - val_loss: 20.4036 - val_mae: 3.4146\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 19.7494 - mae: 3.0787 - val_loss: 19.2156 - val_mae: 3.3528\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 18.0827 - mae: 2.8967 - val_loss: 18.0249 - val_mae: 3.2118\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 16.7882 - mae: 2.7856 - val_loss: 17.6162 - val_mae: 3.1520\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 15.7242 - mae: 2.7081 - val_loss: 17.2390 - val_mae: 3.1664\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 14.6766 - mae: 2.6353 - val_loss: 16.1964 - val_mae: 3.0334\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 13.8484 - mae: 2.5139 - val_loss: 16.3972 - val_mae: 3.0545\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 13.1999 - mae: 2.4535 - val_loss: 15.2886 - val_mae: 2.9588\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.5083 - mae: 2.4046 - val_loss: 16.2319 - val_mae: 3.1391\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.0948 - mae: 2.3684 - val_loss: 15.0863 - val_mae: 3.0065\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.7024 - mae: 2.3382 - val_loss: 13.5131 - val_mae: 2.8083\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.2551 - mae: 2.2912 - val_loss: 13.5210 - val_mae: 2.7922\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.8433 - mae: 2.2620 - val_loss: 13.3109 - val_mae: 2.7698\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 10.5896 - mae: 2.2309 - val_loss: 13.6835 - val_mae: 2.8646\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.3572 - mae: 2.2429 - val_loss: 12.8895 - val_mae: 2.7368\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.1465 - mae: 2.1889 - val_loss: 12.8847 - val_mae: 2.7753\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.9589 - mae: 2.1102 - val_loss: 12.4582 - val_mae: 2.6979\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.7895 - mae: 2.1492 - val_loss: 12.4767 - val_mae: 2.7176\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.5358 - mae: 2.1012 - val_loss: 13.5229 - val_mae: 2.8757\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.7339 - mae: 2.1188 - val_loss: 12.6600 - val_mae: 2.7327\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.1617 - mae: 2.0954 - val_loss: 12.2279 - val_mae: 2.6934\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.3365 - mae: 2.0875 - val_loss: 12.6213 - val_mae: 2.7639\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.9583 - mae: 2.0817 - val_loss: 11.7063 - val_mae: 2.6308\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.0340 - mae: 2.0874 - val_loss: 11.9777 - val_mae: 2.6765\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.8660 - mae: 2.0415 - val_loss: 11.4582 - val_mae: 2.6153\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.6103 - mae: 2.0272 - val_loss: 11.7451 - val_mae: 2.6420\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.6443 - mae: 2.0364 - val_loss: 12.3533 - val_mae: 2.7222\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.4977 - mae: 1.9913 - val_loss: 11.6111 - val_mae: 2.6279\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.4185 - mae: 2.0079 - val_loss: 12.1990 - val_mae: 2.7246\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.2751 - mae: 1.9938 - val_loss: 11.6843 - val_mae: 2.6448\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.2610 - mae: 1.9911 - val_loss: 13.4106 - val_mae: 2.8958\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.9934 - mae: 1.9731 - val_loss: 11.3731 - val_mae: 2.5962\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.1675 - mae: 1.9747 - val_loss: 11.4534 - val_mae: 2.6340\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0184 - mae: 1.9966 - val_loss: 11.7445 - val_mae: 2.6674\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0181 - mae: 1.9423 - val_loss: 11.9301 - val_mae: 2.6937\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.6279 - mae: 1.9331 - val_loss: 11.3995 - val_mae: 2.6339\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.8376 - mae: 1.9585 - val_loss: 11.7432 - val_mae: 2.6787\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.4550 - mae: 1.9335 - val_loss: 10.4550 - val_mae: 2.5023\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.7469 - mae: 1.9446 - val_loss: 10.9700 - val_mae: 2.5689\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.3822 - mae: 1.9043 - val_loss: 11.2372 - val_mae: 2.6235\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.5249 - mae: 1.9017 - val_loss: 10.8009 - val_mae: 2.5538\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.4734 - mae: 1.9055 - val_loss: 11.2753 - val_mae: 2.6245\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.5111 - mae: 1.8732 - val_loss: 11.9479 - val_mae: 2.7071\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 7.2392 - mae: 1.9036 - val_loss: 12.2534 - val_mae: 2.7415\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.3701 - mae: 1.9012 - val_loss: 11.0550 - val_mae: 2.5976\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.2562 - mae: 1.8650 - val_loss: 12.9305 - val_mae: 2.8360\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.0990 - mae: 1.8773 - val_loss: 11.8784 - val_mae: 2.7100\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.1574 - mae: 1.8622 - val_loss: 11.0234 - val_mae: 2.5972\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9838 - mae: 1.8184 - val_loss: 11.7138 - val_mae: 2.6790\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.0645 - mae: 1.8682 - val_loss: 10.9622 - val_mae: 2.5919\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.8444 - mae: 1.8216 - val_loss: 12.4624 - val_mae: 2.7778\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9724 - mae: 1.8865 - val_loss: 10.8223 - val_mae: 2.5800\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9322 - mae: 1.8580 - val_loss: 10.6976 - val_mae: 2.5603\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.7092 - mae: 1.8094 - val_loss: 11.6559 - val_mae: 2.6812\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.7158 - mae: 1.8034 - val_loss: 11.2347 - val_mae: 2.6384\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.5961 - mae: 1.7608 - val_loss: 10.7350 - val_mae: 2.5540\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5670 - mae: 1.7993 - val_loss: 10.2787 - val_mae: 2.4930\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 6.5868 - mae: 1.7904 - val_loss: 10.9350 - val_mae: 2.5775\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6589 - mae: 1.7698 - val_loss: 10.5005 - val_mae: 2.5180\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.6031 - mae: 1.7937 - val_loss: 11.4034 - val_mae: 2.6545\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2294 - mae: 1.7637 - val_loss: 10.9615 - val_mae: 2.5841\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3007 - mae: 1.7327 - val_loss: 11.2231 - val_mae: 2.6426\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3036 - mae: 1.8009 - val_loss: 10.5674 - val_mae: 2.5282\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2361 - mae: 1.7286 - val_loss: 11.2092 - val_mae: 2.6239\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.1004 - mae: 1.7339 - val_loss: 11.7165 - val_mae: 2.6672\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9887 - mae: 1.7330 - val_loss: 10.1146 - val_mae: 2.4451\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.0094 - mae: 1.6851 - val_loss: 9.9496 - val_mae: 2.4486\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0141 - mae: 1.7049 - val_loss: 12.0580 - val_mae: 2.7379\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0359 - mae: 1.6943 - val_loss: 10.1037 - val_mae: 2.4724\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9003 - mae: 1.7507 - val_loss: 11.3167 - val_mae: 2.6133\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0014 - mae: 1.7311 - val_loss: 10.6465 - val_mae: 2.5509\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.7742 - mae: 1.6557 - val_loss: 11.6241 - val_mae: 2.6555\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7425 - mae: 1.6839 - val_loss: 11.6469 - val_mae: 2.6736\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7982 - mae: 1.6972 - val_loss: 10.1052 - val_mae: 2.4870\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8734 - mae: 1.6924 - val_loss: 11.2675 - val_mae: 2.6080\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.6905 - mae: 1.6693 - val_loss: 9.8690 - val_mae: 2.4362\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.6046 - mae: 1.6634 - val_loss: 9.8706 - val_mae: 2.4465\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8229 - mae: 1.6946 - val_loss: 10.5722 - val_mae: 2.5289\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 5.5240 - mae: 1.6261 - val_loss: 9.9431 - val_mae: 2.4518\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.5245 - mae: 1.6479 - val_loss: 11.0717 - val_mae: 2.5551\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 5.4073 - mae: 1.6374 - val_loss: 10.2556 - val_mae: 2.4701\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5086 - mae: 1.6344 - val_loss: 10.5027 - val_mae: 2.5260\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3952 - mae: 1.6454 - val_loss: 11.3191 - val_mae: 2.5881\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4454 - mae: 1.6224 - val_loss: 10.7184 - val_mae: 2.5208\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 5.2821 - mae: 1.6034 - val_loss: 11.5115 - val_mae: 2.6131\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.2604 - mae: 1.6080 - val_loss: 11.5396 - val_mae: 2.6133\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.4487 - mae: 1.6443 - val_loss: 11.1157 - val_mae: 2.5564\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1895 - mae: 1.6237 - val_loss: 10.9188 - val_mae: 2.5343\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 5.1337 - mae: 1.5811 - val_loss: 10.4813 - val_mae: 2.4718\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0478 - mae: 1.5234 - val_loss: 11.4824 - val_mae: 2.6019\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1521 - mae: 1.5933 - val_loss: 10.4268 - val_mae: 2.4762\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0550 - mae: 1.5566 - val_loss: 11.1064 - val_mae: 2.5438\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0955 - mae: 1.5824 - val_loss: 11.5664 - val_mae: 2.6092\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.9759 - mae: 1.5626 - val_loss: 10.8722 - val_mae: 2.5152\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7924 - mae: 1.5497 - val_loss: 10.0949 - val_mae: 2.4285\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8528 - mae: 1.5754 - val_loss: 11.2385 - val_mae: 2.5458\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8443 - mae: 1.5234 - val_loss: 13.2166 - val_mae: 2.7863\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7337 - mae: 1.5286 - val_loss: 10.9890 - val_mae: 2.5434\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8416 - mae: 1.5411 - val_loss: 11.2542 - val_mae: 2.5572\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7812 - mae: 1.5090 - val_loss: 11.5594 - val_mae: 2.5816\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8268 - mae: 1.5226 - val_loss: 10.7798 - val_mae: 2.5206\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5911 - mae: 1.4782 - val_loss: 12.9921 - val_mae: 2.7240\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7924 - mae: 1.5583 - val_loss: 9.9607 - val_mae: 2.3864\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4761 - mae: 1.4630 - val_loss: 10.8839 - val_mae: 2.5091\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5039 - mae: 1.4757 - val_loss: 11.7070 - val_mae: 2.6010\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5804 - mae: 1.4914 - val_loss: 11.4907 - val_mae: 2.5533\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 4.5004 - mae: 1.4803 - val_loss: 10.7044 - val_mae: 2.4615\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4452 - mae: 1.4731 - val_loss: 12.9049 - val_mae: 2.7357\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3315 - mae: 1.4575 - val_loss: 10.5125 - val_mae: 2.4646\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4228 - mae: 1.4702 - val_loss: 10.6500 - val_mae: 2.4605\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2976 - mae: 1.4441 - val_loss: 11.3030 - val_mae: 2.5948\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5448 - mae: 1.5092 - val_loss: 11.6017 - val_mae: 2.5420\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2183 - mae: 1.4401 - val_loss: 11.5141 - val_mae: 2.5427\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1541 - mae: 1.4545 - val_loss: 10.8107 - val_mae: 2.4665\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3505 - mae: 1.4634 - val_loss: 10.9689 - val_mae: 2.4896\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0754 - mae: 1.4080 - val_loss: 10.7287 - val_mae: 2.4658\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1295 - mae: 1.4540 - val_loss: 11.8826 - val_mae: 2.6331\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3862 - mae: 1.4685 - val_loss: 12.0023 - val_mae: 2.5854\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0924 - mae: 1.4071 - val_loss: 11.2645 - val_mae: 2.4884\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1171 - mae: 1.4363 - val_loss: 11.5899 - val_mae: 2.5686\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8731 - mae: 1.3923 - val_loss: 12.3253 - val_mae: 2.5944\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2167 - mae: 1.4391 - val_loss: 10.8760 - val_mae: 2.4693\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1206 - mae: 1.4035 - val_loss: 10.5935 - val_mae: 2.4471\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0794 - mae: 1.4110 - val_loss: 11.1471 - val_mae: 2.4568\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7202 - mae: 1.3611 - val_loss: 14.9808 - val_mae: 2.9437\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0769 - mae: 1.3764 - val_loss: 11.4192 - val_mae: 2.4956\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7500 - mae: 1.3406 - val_loss: 14.8347 - val_mae: 2.9004\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7453 - mae: 1.3795 - val_loss: 11.6949 - val_mae: 2.5358\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8550 - mae: 1.3905 - val_loss: 10.7753 - val_mae: 2.4568\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7567 - mae: 1.3444 - val_loss: 11.2177 - val_mae: 2.5022\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7719 - mae: 1.3121 - val_loss: 11.7576 - val_mae: 2.5476\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8510 - mae: 1.3640 - val_loss: 11.4653 - val_mae: 2.5077\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4896 - mae: 1.3418 - val_loss: 12.7702 - val_mae: 2.6531\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6102 - mae: 1.3164 - val_loss: 11.9505 - val_mae: 2.5893\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6155 - mae: 1.3666 - val_loss: 13.3105 - val_mae: 2.7886\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6008 - mae: 1.3196 - val_loss: 10.6039 - val_mae: 2.4097\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4807 - mae: 1.3201 - val_loss: 11.5916 - val_mae: 2.5198\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 3.5220 - mae: 1.2994 - val_loss: 13.2131 - val_mae: 2.7233\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5146 - mae: 1.3095 - val_loss: 11.6473 - val_mae: 2.5315\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2691 - mae: 1.3134 - val_loss: 10.4843 - val_mae: 2.4230\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6656 - mae: 1.3280 - val_loss: 12.1112 - val_mae: 2.5841\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4115 - mae: 1.2905 - val_loss: 11.1082 - val_mae: 2.4718\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3455 - mae: 1.2731 - val_loss: 11.8180 - val_mae: 2.5325\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 3.4820 - mae: 1.3479 - val_loss: 10.1357 - val_mae: 2.3531\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3802 - mae: 1.2794 - val_loss: 11.9002 - val_mae: 2.5213\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2766 - mae: 1.2960 - val_loss: 10.4252 - val_mae: 2.3630\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3185 - mae: 1.2970 - val_loss: 11.6250 - val_mae: 2.4843\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3546 - mae: 1.2489 - val_loss: 11.5871 - val_mae: 2.5140\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3820 - mae: 1.2879 - val_loss: 11.7300 - val_mae: 2.5302\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2439 - mae: 1.2856 - val_loss: 12.3638 - val_mae: 2.6223\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2839 - mae: 1.2417 - val_loss: 12.8101 - val_mae: 2.6688\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2642 - mae: 1.2354 - val_loss: 11.8901 - val_mae: 2.5188\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2163 - mae: 1.2778 - val_loss: 10.2725 - val_mae: 2.3495\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 3.1133 - mae: 1.2108 - val_loss: 11.5998 - val_mae: 2.4898\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0324 - mae: 1.2413 - val_loss: 12.4411 - val_mae: 2.6112\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1274 - mae: 1.2329 - val_loss: 14.6413 - val_mae: 2.7999\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0648 - mae: 1.2458 - val_loss: 12.7302 - val_mae: 2.6100\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0704 - mae: 1.2564 - val_loss: 12.7986 - val_mae: 2.6328\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1240 - mae: 1.2483 - val_loss: 12.1943 - val_mae: 2.5595\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 3.1479 - mae: 1.2819 - val_loss: 11.5175 - val_mae: 2.4943\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9298 - mae: 1.1868 - val_loss: 11.4590 - val_mae: 2.4852\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 3.0818 - mae: 1.2304 - val_loss: 11.6663 - val_mae: 2.4917\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0339 - mae: 1.2360 - val_loss: 12.8328 - val_mae: 2.6010\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9558 - mae: 1.2098 - val_loss: 11.1762 - val_mae: 2.4242\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7263 - mae: 1.1755 - val_loss: 10.5097 - val_mae: 2.3770\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9645 - mae: 1.2367 - val_loss: 12.9990 - val_mae: 2.6323\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9598 - mae: 1.2433 - val_loss: 12.4352 - val_mae: 2.5595\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8508 - mae: 1.2052 - val_loss: 11.7580 - val_mae: 2.4996\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0118 - mae: 1.1974 - val_loss: 12.3693 - val_mae: 2.5407\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7046 - mae: 1.1584 - val_loss: 13.3406 - val_mae: 2.6405\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8921 - mae: 1.2105 - val_loss: 14.7909 - val_mae: 2.8091\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.9740 - mae: 1.2194 - val_loss: 13.0342 - val_mae: 2.6346\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7994 - mae: 1.1663 - val_loss: 12.5977 - val_mae: 2.5994\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 2.7956 - mae: 1.1896 - val_loss: 13.0372 - val_mae: 2.6280\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6882 - mae: 1.1739 - val_loss: 13.0866 - val_mae: 2.6445\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7291 - mae: 1.1407 - val_loss: 12.6147 - val_mae: 2.5816\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7379 - mae: 1.1895 - val_loss: 12.8224 - val_mae: 2.6067\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7095 - mae: 1.1850 - val_loss: 12.5788 - val_mae: 2.5879\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6570 - mae: 1.1562 - val_loss: 11.6911 - val_mae: 2.4728\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7396 - mae: 1.1752 - val_loss: 12.0008 - val_mae: 2.5077\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6773 - mae: 1.1336 - val_loss: 14.4787 - val_mae: 2.7898\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5581 - mae: 1.1373 - val_loss: 11.3197 - val_mae: 2.4258\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5421 - mae: 1.1098 - val_loss: 13.2448 - val_mae: 2.6610\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5754 - mae: 1.1511 - val_loss: 13.8123 - val_mae: 2.7216\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 2.6073 - mae: 1.1566 - val_loss: 11.4016 - val_mae: 2.4310\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5706 - mae: 1.1048 - val_loss: 12.5641 - val_mae: 2.5518\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6303 - mae: 1.1397 - val_loss: 11.7259 - val_mae: 2.4659\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5167 - mae: 1.1079 - val_loss: 12.7346 - val_mae: 2.5593\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5092 - mae: 1.1116 - val_loss: 15.2899 - val_mae: 2.8554\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4125 - mae: 1.0761 - val_loss: 11.8116 - val_mae: 2.5095\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6283 - mae: 1.1599 - val_loss: 12.2669 - val_mae: 2.5461\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4357 - mae: 1.1071 - val_loss: 12.5657 - val_mae: 2.5636\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4941 - mae: 1.1670 - val_loss: 14.8871 - val_mae: 2.8087\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5294 - mae: 1.1320 - val_loss: 12.1798 - val_mae: 2.4935\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3143 - mae: 1.0907 - val_loss: 13.3763 - val_mae: 2.6920\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2799 - mae: 1.0827 - val_loss: 13.5383 - val_mae: 2.6709\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 1s 52ms/step - loss: 2.5376 - mae: 1.1089 - val_loss: 12.5821 - val_mae: 2.5624\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2944 - mae: 1.0720 - val_loss: 11.9817 - val_mae: 2.4370\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3395 - mae: 1.0818 - val_loss: 11.7814 - val_mae: 2.4716\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3737 - mae: 1.0849 - val_loss: 12.0956 - val_mae: 2.5183\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2584 - mae: 1.0985 - val_loss: 12.5415 - val_mae: 2.5140\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2597 - mae: 1.0637 - val_loss: 11.9672 - val_mae: 2.4478\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2086 - mae: 1.0462 - val_loss: 14.7569 - val_mae: 2.7862\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3587 - mae: 1.0957 - val_loss: 13.5976 - val_mae: 2.6547\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2794 - mae: 1.0884 - val_loss: 12.9898 - val_mae: 2.5527\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3059 - mae: 1.0798 - val_loss: 11.9406 - val_mae: 2.4742\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2833 - mae: 1.0948 - val_loss: 11.9490 - val_mae: 2.4453\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4010 - mae: 1.0978 - val_loss: 11.9463 - val_mae: 2.4710\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0120 - mae: 1.0114 - val_loss: 13.1117 - val_mae: 2.6323\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2134 - mae: 1.0955 - val_loss: 12.3331 - val_mae: 2.5168\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1832 - mae: 1.0718 - val_loss: 11.0579 - val_mae: 2.3784\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0234 - mae: 1.0282 - val_loss: 13.3297 - val_mae: 2.6449\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 2.1662 - mae: 1.0615 - val_loss: 12.9767 - val_mae: 2.5894\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0160 - mae: 1.0045 - val_loss: 12.9662 - val_mae: 2.5777\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1772 - mae: 1.0328 - val_loss: 12.4362 - val_mae: 2.5470\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1929 - mae: 1.0841 - val_loss: 13.7491 - val_mae: 2.6633\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9594 - mae: 1.0178 - val_loss: 12.4676 - val_mae: 2.4912\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1762 - mae: 1.0528 - val_loss: 11.7904 - val_mae: 2.4284\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0553 - mae: 1.0380 - val_loss: 13.5192 - val_mae: 2.6513\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0408 - mae: 1.0165 - val_loss: 11.5091 - val_mae: 2.4367\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0239 - mae: 1.0568 - val_loss: 13.6463 - val_mae: 2.6459\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 2.0535 - mae: 1.0350 - val_loss: 11.9437 - val_mae: 2.4773\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9876 - mae: 1.0200 - val_loss: 12.4039 - val_mae: 2.5509\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0446 - mae: 1.0252 - val_loss: 13.8136 - val_mae: 2.6589\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0025 - mae: 1.0205 - val_loss: 14.1513 - val_mae: 2.7278\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9819 - mae: 1.0276 - val_loss: 11.0925 - val_mae: 2.3880\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9235 - mae: 0.9985 - val_loss: 13.2120 - val_mae: 2.5771\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9659 - mae: 1.0195 - val_loss: 11.4044 - val_mae: 2.4281\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8939 - mae: 0.9975 - val_loss: 15.5294 - val_mae: 2.8742\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8386 - mae: 0.9975 - val_loss: 14.1159 - val_mae: 2.7559\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0643 - mae: 1.0317 - val_loss: 12.4956 - val_mae: 2.5408\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7900 - mae: 0.9433 - val_loss: 14.6532 - val_mae: 2.7589\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.9406 - mae: 1.0343 - val_loss: 12.5363 - val_mae: 2.5442\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8852 - mae: 1.0193 - val_loss: 12.2093 - val_mae: 2.4814\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8445 - mae: 0.9498 - val_loss: 12.9059 - val_mae: 2.5439\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8784 - mae: 0.9809 - val_loss: 13.5589 - val_mae: 2.6055\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9075 - mae: 1.0003 - val_loss: 12.5475 - val_mae: 2.5365\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8870 - mae: 0.9964 - val_loss: 14.1662 - val_mae: 2.6903\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7634 - mae: 0.9535 - val_loss: 14.2125 - val_mae: 2.6616\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7693 - mae: 1.0027 - val_loss: 12.5334 - val_mae: 2.5189\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7735 - mae: 0.9727 - val_loss: 14.2833 - val_mae: 2.6409\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9455 - mae: 0.9973 - val_loss: 12.3350 - val_mae: 2.4765\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8727 - mae: 0.9825 - val_loss: 13.5725 - val_mae: 2.5645\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8068 - mae: 0.9563 - val_loss: 12.2631 - val_mae: 2.4895\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7468 - mae: 0.9556 - val_loss: 14.1409 - val_mae: 2.6340\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7423 - mae: 0.9730 - val_loss: 12.9742 - val_mae: 2.5354\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7193 - mae: 0.9523 - val_loss: 13.0502 - val_mae: 2.5723\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6958 - mae: 0.9646 - val_loss: 15.0515 - val_mae: 2.7541\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8020 - mae: 0.9668 - val_loss: 13.0658 - val_mae: 2.6055\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7326 - mae: 0.9559 - val_loss: 13.1892 - val_mae: 2.5635\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7925 - mae: 0.9785 - val_loss: 14.3768 - val_mae: 2.6528\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8101 - mae: 0.9875 - val_loss: 14.3598 - val_mae: 2.7035\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7316 - mae: 0.9613 - val_loss: 11.7114 - val_mae: 2.4253\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8190 - mae: 0.9937 - val_loss: 12.9480 - val_mae: 2.5536\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5769 - mae: 0.9043 - val_loss: 12.6734 - val_mae: 2.5098\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1.6628 - mae: 0.9200 - val_loss: 12.6520 - val_mae: 2.4870\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8210 - mae: 0.9750 - val_loss: 12.4985 - val_mae: 2.4914\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6573 - mae: 0.9383 - val_loss: 13.0089 - val_mae: 2.5430\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6209 - mae: 0.9235 - val_loss: 14.2690 - val_mae: 2.6685\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6270 - mae: 0.9269 - val_loss: 14.3130 - val_mae: 2.6630\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7366 - mae: 0.9609 - val_loss: 12.1712 - val_mae: 2.4957\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.5664 - mae: 0.9195 - val_loss: 12.2685 - val_mae: 2.4861\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6775 - mae: 0.9387 - val_loss: 11.6156 - val_mae: 2.3973\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5442 - mae: 0.9297 - val_loss: 13.8703 - val_mae: 2.6443\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 1.6378 - mae: 0.9296 - val_loss: 12.5382 - val_mae: 2.4687\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5845 - mae: 0.9064 - val_loss: 15.9538 - val_mae: 2.7852\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5996 - mae: 0.9451 - val_loss: 12.9031 - val_mae: 2.5391\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5653 - mae: 0.8970 - val_loss: 13.2475 - val_mae: 2.5527\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.5104 - mae: 0.8945 - val_loss: 13.3929 - val_mae: 2.5356\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5192 - mae: 0.9045 - val_loss: 12.4306 - val_mae: 2.4539\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4337 - mae: 0.8943 - val_loss: 12.6302 - val_mae: 2.4772\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5953 - mae: 0.9326 - val_loss: 15.8043 - val_mae: 2.7830\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5350 - mae: 0.8896 - val_loss: 14.6861 - val_mae: 2.6986\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5857 - mae: 0.9189 - val_loss: 14.7349 - val_mae: 2.6687\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5918 - mae: 0.9342 - val_loss: 11.6859 - val_mae: 2.3872\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4178 - mae: 0.8651 - val_loss: 12.6738 - val_mae: 2.4533\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5776 - mae: 0.9261 - val_loss: 12.5372 - val_mae: 2.4802\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5381 - mae: 0.8904 - val_loss: 14.6148 - val_mae: 2.6564\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4254 - mae: 0.8701 - val_loss: 12.3848 - val_mae: 2.4491\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 1s 63ms/step - loss: 1.5032 - mae: 0.8848 - val_loss: 15.9418 - val_mae: 2.8542\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4624 - mae: 0.8918 - val_loss: 13.4657 - val_mae: 2.5682\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4457 - mae: 0.8847 - val_loss: 13.3822 - val_mae: 2.5733\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6001 - mae: 0.9179 - val_loss: 14.4493 - val_mae: 2.6649\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2014 - mae: 0.8040 - val_loss: 14.4466 - val_mae: 2.6471\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5885 - mae: 0.9523 - val_loss: 14.7264 - val_mae: 2.6812\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4813 - mae: 0.8824 - val_loss: 13.3585 - val_mae: 2.5705\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4531 - mae: 0.8879 - val_loss: 15.1219 - val_mae: 2.7218\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4203 - mae: 0.8659 - val_loss: 12.6687 - val_mae: 2.5337\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.5075 - mae: 0.9087 - val_loss: 14.6803 - val_mae: 2.6504\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4534 - mae: 0.8805 - val_loss: 15.1867 - val_mae: 2.7138\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3210 - mae: 0.8486 - val_loss: 14.8635 - val_mae: 2.7191\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3927 - mae: 0.8670 - val_loss: 13.1801 - val_mae: 2.5311\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3234 - mae: 0.8356 - val_loss: 17.9890 - val_mae: 2.9856\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4923 - mae: 0.8607 - val_loss: 14.2491 - val_mae: 2.5685\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4141 - mae: 0.8603 - val_loss: 13.1830 - val_mae: 2.5397\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3366 - mae: 0.8703 - val_loss: 12.8852 - val_mae: 2.4784\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4670 - mae: 0.8669 - val_loss: 14.2321 - val_mae: 2.6310\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3212 - mae: 0.8471 - val_loss: 15.6356 - val_mae: 2.7216\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3484 - mae: 0.8321 - val_loss: 13.4535 - val_mae: 2.5070\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3164 - mae: 0.8516 - val_loss: 14.3959 - val_mae: 2.6623\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3880 - mae: 0.8723 - val_loss: 15.8357 - val_mae: 2.7834\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2002 - mae: 0.8081 - val_loss: 13.4190 - val_mae: 2.5518\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2869 - mae: 0.8468 - val_loss: 13.4165 - val_mae: 2.5176\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2788 - mae: 0.8083 - val_loss: 15.2936 - val_mae: 2.7320\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.3484 - mae: 0.8633 - val_loss: 13.3461 - val_mae: 2.5267\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2751 - mae: 0.8286 - val_loss: 17.1290 - val_mae: 2.9353\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.2212 - mae: 0.8088 - val_loss: 16.1326 - val_mae: 2.8213\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2370 - mae: 0.8081 - val_loss: 16.6052 - val_mae: 2.8212\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2913 - mae: 0.8289 - val_loss: 15.4922 - val_mae: 2.7288\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2126 - mae: 0.8115 - val_loss: 14.4950 - val_mae: 2.7007\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4818 - mae: 0.8878 - val_loss: 13.1171 - val_mae: 2.5414\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2073 - mae: 0.7994 - val_loss: 14.7883 - val_mae: 2.6606\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2180 - mae: 0.7785 - val_loss: 13.3623 - val_mae: 2.5462\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3469 - mae: 0.8519 - val_loss: 14.5500 - val_mae: 2.6454\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3042 - mae: 0.8448 - val_loss: 15.3084 - val_mae: 2.6592\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2851 - mae: 0.8211 - val_loss: 15.0142 - val_mae: 2.7202\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2557 - mae: 0.8231 - val_loss: 16.6943 - val_mae: 2.8607\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2894 - mae: 0.8247 - val_loss: 14.0206 - val_mae: 2.5821\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 1s 6ms/step - loss: 1.1545 - mae: 0.8077 - val_loss: 15.5667 - val_mae: 2.7348\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2367 - mae: 0.7793 - val_loss: 15.4321 - val_mae: 2.7478\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3528 - mae: 0.8570 - val_loss: 15.3770 - val_mae: 2.6481\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2088 - mae: 0.8059 - val_loss: 14.3972 - val_mae: 2.6031\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2042 - mae: 0.7864 - val_loss: 15.5096 - val_mae: 2.7232\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2559 - mae: 0.8298 - val_loss: 17.1898 - val_mae: 2.8499\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2496 - mae: 0.8195 - val_loss: 14.2883 - val_mae: 2.5692\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2332 - mae: 0.8105 - val_loss: 15.7577 - val_mae: 2.7113\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2538 - mae: 0.8264 - val_loss: 15.9933 - val_mae: 2.7332\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1338 - mae: 0.7666 - val_loss: 14.7342 - val_mae: 2.6403\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.2021 - mae: 0.8186 - val_loss: 15.8404 - val_mae: 2.7645\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2330 - mae: 0.8072 - val_loss: 16.9304 - val_mae: 2.7891\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1739 - mae: 0.8116 - val_loss: 14.8172 - val_mae: 2.6153\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2773 - mae: 0.8143 - val_loss: 14.9323 - val_mae: 2.6330\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2830 - mae: 0.8316 - val_loss: 16.5077 - val_mae: 2.7585\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0512 - mae: 0.7630 - val_loss: 14.6868 - val_mae: 2.6778\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1331 - mae: 0.7901 - val_loss: 13.8778 - val_mae: 2.5630\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 1.2077 - mae: 0.8127 - val_loss: 12.8446 - val_mae: 2.4482\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2134 - mae: 0.8092 - val_loss: 16.7915 - val_mae: 2.7814\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2255 - mae: 0.8338 - val_loss: 14.1391 - val_mae: 2.5960\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2203 - mae: 0.7912 - val_loss: 15.9509 - val_mae: 2.7426\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2549 - mae: 0.8180 - val_loss: 15.0217 - val_mae: 2.6567\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1897 - mae: 0.7887 - val_loss: 14.0599 - val_mae: 2.5236\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1503 - mae: 0.8014 - val_loss: 13.0785 - val_mae: 2.4568\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1872 - mae: 0.7837 - val_loss: 13.9889 - val_mae: 2.5683\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1149 - mae: 0.7612 - val_loss: 14.8723 - val_mae: 2.6275\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.2027 - mae: 0.8134 - val_loss: 16.8669 - val_mae: 2.7761\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0573 - mae: 0.7460 - val_loss: 16.1979 - val_mae: 2.6852\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1487 - mae: 0.8109 - val_loss: 15.9079 - val_mae: 2.7542\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0221 - mae: 0.7314 - val_loss: 17.1027 - val_mae: 2.7910\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0816 - mae: 0.7765 - val_loss: 17.8216 - val_mae: 2.8412\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1408 - mae: 0.7587 - val_loss: 13.5868 - val_mae: 2.5345\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0426 - mae: 0.7710 - val_loss: 16.7010 - val_mae: 2.7885\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 1.2766 - mae: 0.8276 - val_loss: 15.9302 - val_mae: 2.6755\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0410 - mae: 0.7482 - val_loss: 15.6646 - val_mae: 2.7097\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1549 - mae: 0.7652 - val_loss: 14.7714 - val_mae: 2.6152\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1067 - mae: 0.7614 - val_loss: 15.2106 - val_mae: 2.6491\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0274 - mae: 0.7289 - val_loss: 17.3140 - val_mae: 2.8468\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 1.0021 - mae: 0.7384 - val_loss: 13.8866 - val_mae: 2.5332\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9670 - mae: 0.7210 - val_loss: 15.5377 - val_mae: 2.6901\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0777 - mae: 0.7714 - val_loss: 16.7360 - val_mae: 2.8401\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.0733 - mae: 0.7411 - val_loss: 17.5321 - val_mae: 2.8047\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0750 - mae: 0.7741 - val_loss: 15.3574 - val_mae: 2.6376\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1100 - mae: 0.7582 - val_loss: 15.4453 - val_mae: 2.6677\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1207 - mae: 0.7677 - val_loss: 15.2073 - val_mae: 2.6014\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0890 - mae: 0.7881 - val_loss: 16.1966 - val_mae: 2.7028\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0543 - mae: 0.7374 - val_loss: 14.8858 - val_mae: 2.6580\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0496 - mae: 0.7584 - val_loss: 17.3692 - val_mae: 2.8995\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9437 - mae: 0.7141 - val_loss: 16.0866 - val_mae: 2.6617\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0682 - mae: 0.7535 - val_loss: 15.7310 - val_mae: 2.6873\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9442 - mae: 0.7188 - val_loss: 16.0116 - val_mae: 2.6947\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1498 - mae: 0.7839 - val_loss: 15.5804 - val_mae: 2.7285\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.1524 - mae: 0.7936 - val_loss: 15.8370 - val_mae: 2.6775\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9612 - mae: 0.7282 - val_loss: 17.3338 - val_mae: 2.7994\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9591 - mae: 0.7012 - val_loss: 18.0060 - val_mae: 2.8359\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.9746 - mae: 0.7083 - val_loss: 15.9819 - val_mae: 2.6883\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0943 - mae: 0.7795 - val_loss: 17.3046 - val_mae: 2.8334\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0225 - mae: 0.7390 - val_loss: 16.2514 - val_mae: 2.7170\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0736 - mae: 0.7328 - val_loss: 16.9775 - val_mae: 2.8062\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0143 - mae: 0.7404 - val_loss: 15.8012 - val_mae: 2.6852\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9754 - mae: 0.7323 - val_loss: 19.0808 - val_mae: 2.9627\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9988 - mae: 0.7575 - val_loss: 19.0367 - val_mae: 2.9895\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9149 - mae: 0.7059 - val_loss: 14.3591 - val_mae: 2.5932\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9630 - mae: 0.7193 - val_loss: 16.4482 - val_mae: 2.7178\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1.0604 - mae: 0.7382 - val_loss: 17.4186 - val_mae: 2.7511\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0206 - mae: 0.7078 - val_loss: 16.3195 - val_mae: 2.7000\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9275 - mae: 0.7030 - val_loss: 15.4546 - val_mae: 2.6488\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0091 - mae: 0.7355 - val_loss: 16.2300 - val_mae: 2.7100\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8588 - mae: 0.6742 - val_loss: 17.4950 - val_mae: 2.8185\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0255 - mae: 0.7563 - val_loss: 15.9777 - val_mae: 2.6527\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.8867 - mae: 0.7050 - val_loss: 16.2226 - val_mae: 2.7232\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0035 - mae: 0.7386 - val_loss: 16.0276 - val_mae: 2.6941\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8816 - mae: 0.6895 - val_loss: 14.4106 - val_mae: 2.5867\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9692 - mae: 0.7130 - val_loss: 17.2191 - val_mae: 2.7901\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9882 - mae: 0.7267 - val_loss: 17.0077 - val_mae: 2.8092\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9888 - mae: 0.7255 - val_loss: 16.8029 - val_mae: 2.7791\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8991 - mae: 0.7068 - val_loss: 18.2022 - val_mae: 2.8515\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0122 - mae: 0.7152 - val_loss: 17.7387 - val_mae: 2.8444\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8925 - mae: 0.6867 - val_loss: 17.5910 - val_mae: 2.7981\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.9372 - mae: 0.6918 - val_loss: 15.2168 - val_mae: 2.6341\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9513 - mae: 0.7004 - val_loss: 17.4099 - val_mae: 2.7699\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7846 - mae: 0.6523 - val_loss: 15.1227 - val_mae: 2.5990\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0862 - mae: 0.7600 - val_loss: 16.9113 - val_mae: 2.6922\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8716 - mae: 0.6625 - val_loss: 16.8809 - val_mae: 2.7254\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9628 - mae: 0.7076 - val_loss: 16.8914 - val_mae: 2.7753\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9576 - mae: 0.7009 - val_loss: 14.4610 - val_mae: 2.5748\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8067 - mae: 0.6417 - val_loss: 16.0842 - val_mae: 2.7032\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9502 - mae: 0.7069 - val_loss: 15.1040 - val_mae: 2.6125\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.8139 - mae: 0.6709 - val_loss: 19.1034 - val_mae: 2.8543\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8635 - mae: 0.6855 - val_loss: 17.4332 - val_mae: 2.7505\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8500 - mae: 0.6983 - val_loss: 18.1809 - val_mae: 2.8119\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0189 - mae: 0.7386 - val_loss: 16.6537 - val_mae: 2.7117\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9234 - mae: 0.6816 - val_loss: 15.4837 - val_mae: 2.6518\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8391 - mae: 0.6399 - val_loss: 18.6883 - val_mae: 2.8553\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9657 - mae: 0.7073 - val_loss: 18.5435 - val_mae: 2.8721\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9833 - mae: 0.7374 - val_loss: 17.0764 - val_mae: 2.6744\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8503 - mae: 0.6786 - val_loss: 17.3812 - val_mae: 2.7565\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.8574 - mae: 0.6972 - val_loss: 18.0027 - val_mae: 2.8266\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 0.8227 - mae: 0.6621 - val_loss: 16.9841 - val_mae: 2.7097\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8362 - mae: 0.6857 - val_loss: 22.8420 - val_mae: 3.1808\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0533 - mae: 0.7397 - val_loss: 15.8105 - val_mae: 2.6263\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8865 - mae: 0.6747 - val_loss: 14.7395 - val_mae: 2.5302\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 0.8402 - mae: 0.6593 - val_loss: 19.6063 - val_mae: 2.9563\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8841 - mae: 0.6888 - val_loss: 16.1901 - val_mae: 2.6940\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9229 - mae: 0.7053 - val_loss: 19.5063 - val_mae: 2.9307\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7485 - mae: 0.6489 - val_loss: 16.7818 - val_mae: 2.6676\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8994 - mae: 0.7137 - val_loss: 17.6193 - val_mae: 2.7703\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8528 - mae: 0.6766 - val_loss: 17.5254 - val_mae: 2.8188\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7966 - mae: 0.6508 - val_loss: 17.3856 - val_mae: 2.7114\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8843 - mae: 0.6910 - val_loss: 17.0852 - val_mae: 2.7653\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8591 - mae: 0.6668 - val_loss: 16.5524 - val_mae: 2.6604\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8696 - mae: 0.6796 - val_loss: 17.6082 - val_mae: 2.6931\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7331 - mae: 0.6177 - val_loss: 17.4762 - val_mae: 2.7747\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8337 - mae: 0.6859 - val_loss: 19.2221 - val_mae: 2.8472\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8400 - mae: 0.6907 - val_loss: 19.4722 - val_mae: 2.8593\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8074 - mae: 0.6785 - val_loss: 19.6854 - val_mae: 2.8725\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7596 - mae: 0.6362 - val_loss: 16.1196 - val_mae: 2.6579\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7598 - mae: 0.6661 - val_loss: 19.7680 - val_mae: 2.8893\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8761 - mae: 0.6984 - val_loss: 20.2188 - val_mae: 2.9570\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8246 - mae: 0.6516 - val_loss: 18.7612 - val_mae: 2.7800\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8086 - mae: 0.6501 - val_loss: 18.5071 - val_mae: 2.8194\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7664 - mae: 0.6332 - val_loss: 19.3312 - val_mae: 2.8492\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8349 - mae: 0.6660 - val_loss: 21.0634 - val_mae: 2.9456\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8915 - mae: 0.7024 - val_loss: 17.7748 - val_mae: 2.7223\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7825 - mae: 0.6210 - val_loss: 17.4459 - val_mae: 2.7368\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8707 - mae: 0.6878 - val_loss: 18.5761 - val_mae: 2.8151\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7839 - mae: 0.6377 - val_loss: 19.9856 - val_mae: 2.8614\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7643 - mae: 0.6331 - val_loss: 17.1209 - val_mae: 2.6817\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.7629 - mae: 0.6426 - val_loss: 18.8740 - val_mae: 2.8348\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7512 - mae: 0.6474 - val_loss: 17.4889 - val_mae: 2.6725\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8732 - mae: 0.6828 - val_loss: 15.6517 - val_mae: 2.6130\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7542 - mae: 0.6355 - val_loss: 16.4386 - val_mae: 2.6139\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7913 - mae: 0.6793 - val_loss: 17.6780 - val_mae: 2.7095\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7781 - mae: 0.6645 - val_loss: 18.5131 - val_mae: 2.8107\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7506 - mae: 0.6320 - val_loss: 18.2761 - val_mae: 2.7625\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7742 - mae: 0.6433 - val_loss: 20.2782 - val_mae: 2.9452\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.7428 - mae: 0.6455 - val_loss: 19.5901 - val_mae: 2.8158\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7347 - mae: 0.6471 - val_loss: 20.0404 - val_mae: 2.8758\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8931 - mae: 0.6623 - val_loss: 16.9493 - val_mae: 2.7071\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6742 - mae: 0.5880 - val_loss: 16.9644 - val_mae: 2.6547\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7482 - mae: 0.6275 - val_loss: 18.2645 - val_mae: 2.7710\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6451 - mae: 0.6076 - val_loss: 18.0991 - val_mae: 2.7874\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8005 - mae: 0.6766 - val_loss: 18.4439 - val_mae: 2.8147\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7344 - mae: 0.6066 - val_loss: 16.8151 - val_mae: 2.6982\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7599 - mae: 0.6683 - val_loss: 15.8373 - val_mae: 2.6054\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6931 - mae: 0.6272 - val_loss: 18.6115 - val_mae: 2.8320\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.7024 - mae: 0.6073 - val_loss: 16.1731 - val_mae: 2.6341\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.7502 - mae: 0.6368 - val_loss: 18.6349 - val_mae: 2.7982\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 1s 50ms/step - loss: 0.8016 - mae: 0.6596 - val_loss: 17.2083 - val_mae: 2.6627\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6623 - mae: 0.5832 - val_loss: 19.3807 - val_mae: 2.8032\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.7116 - mae: 0.6005 - val_loss: 18.1971 - val_mae: 2.7692\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7805 - mae: 0.6720 - val_loss: 19.9512 - val_mae: 2.9176\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6959 - mae: 0.6032 - val_loss: 17.7784 - val_mae: 2.7770\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8029 - mae: 0.6712 - val_loss: 18.5610 - val_mae: 2.7730\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6284 - mae: 0.5607 - val_loss: 16.8535 - val_mae: 2.6775\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6847 - mae: 0.6199 - val_loss: 17.5987 - val_mae: 2.7078\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8293 - mae: 0.6398 - val_loss: 18.9422 - val_mae: 2.8363\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7135 - mae: 0.6098 - val_loss: 18.9227 - val_mae: 2.7555\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6816 - mae: 0.6272 - val_loss: 19.1989 - val_mae: 2.8576\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6997 - mae: 0.6199 - val_loss: 17.8460 - val_mae: 2.7592\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7313 - mae: 0.6021 - val_loss: 17.9890 - val_mae: 2.7504\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8901 - mae: 0.7100 - val_loss: 17.6563 - val_mae: 2.7183\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6373 - mae: 0.5682 - val_loss: 19.6582 - val_mae: 2.8501\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6629 - mae: 0.5817 - val_loss: 19.1800 - val_mae: 2.8842\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6954 - mae: 0.6092 - val_loss: 18.1186 - val_mae: 2.7432\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.6643 - mae: 0.5866 - val_loss: 17.0434 - val_mae: 2.6520\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7320 - mae: 0.6304 - val_loss: 17.5984 - val_mae: 2.7444\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.7432 - mae: 0.6232 - val_loss: 18.4382 - val_mae: 2.8217\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6898 - mae: 0.5982 - val_loss: 18.1520 - val_mae: 2.7453\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7978 - mae: 0.6451 - val_loss: 18.2879 - val_mae: 2.7836\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6908 - mae: 0.6130 - val_loss: 16.7956 - val_mae: 2.6574\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8037 - mae: 0.6448 - val_loss: 19.1316 - val_mae: 2.7941\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8145 - mae: 0.6510 - val_loss: 21.2367 - val_mae: 2.9611\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6146 - mae: 0.5598 - val_loss: 19.6170 - val_mae: 2.8099\n",
            "Processing fold #2\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 11ms/step - loss: 550.8151 - mae: 21.4949 - val_loss: 418.7576 - val_mae: 18.9116\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 421.2273 - mae: 18.4805 - val_loss: 294.6478 - val_mae: 15.5435\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 269.0156 - mae: 14.1492 - val_loss: 169.5036 - val_mae: 11.1606\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 141.2903 - mae: 9.3058 - val_loss: 85.7815 - val_mae: 7.2135\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 78.3057 - mae: 6.3966 - val_loss: 54.8659 - val_mae: 5.4146\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 53.1403 - mae: 5.1779 - val_loss: 41.2723 - val_mae: 4.4812\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 39.0319 - mae: 4.4184 - val_loss: 35.3182 - val_mae: 4.0686\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 31.7201 - mae: 4.0000 - val_loss: 32.4026 - val_mae: 3.9183\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 27.1332 - mae: 3.7022 - val_loss: 30.2516 - val_mae: 3.7358\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 23.8741 - mae: 3.4931 - val_loss: 28.3378 - val_mae: 3.5738\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 21.5339 - mae: 3.2595 - val_loss: 25.9949 - val_mae: 3.4251\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 19.3651 - mae: 3.1566 - val_loss: 24.2287 - val_mae: 3.3030\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 17.6444 - mae: 3.0307 - val_loss: 22.7151 - val_mae: 3.1389\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 16.0125 - mae: 2.8682 - val_loss: 21.5297 - val_mae: 3.0377\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 14.6679 - mae: 2.7719 - val_loss: 20.3879 - val_mae: 2.9103\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 14.0217 - mae: 2.6535 - val_loss: 19.7510 - val_mae: 2.8826\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 13.1748 - mae: 2.5684 - val_loss: 19.2143 - val_mae: 2.8149\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 12.2561 - mae: 2.5036 - val_loss: 19.2813 - val_mae: 2.8709\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.8708 - mae: 2.4657 - val_loss: 18.1012 - val_mae: 2.7763\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.0364 - mae: 2.3568 - val_loss: 18.9752 - val_mae: 2.8553\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.0385 - mae: 2.3723 - val_loss: 17.7256 - val_mae: 2.7388\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 10.6188 - mae: 2.3502 - val_loss: 17.4228 - val_mae: 2.6866\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.1886 - mae: 2.3248 - val_loss: 17.2054 - val_mae: 2.6673\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.8257 - mae: 2.2507 - val_loss: 16.7795 - val_mae: 2.6387\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.9612 - mae: 2.2541 - val_loss: 16.6346 - val_mae: 2.6842\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 9.4511 - mae: 2.2102 - val_loss: 16.6075 - val_mae: 2.6135\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.2150 - mae: 2.1917 - val_loss: 16.4636 - val_mae: 2.6463\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.0646 - mae: 2.1966 - val_loss: 16.2465 - val_mae: 2.6023\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.9175 - mae: 2.2101 - val_loss: 16.2638 - val_mae: 2.6464\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.8647 - mae: 2.1678 - val_loss: 16.0638 - val_mae: 2.5816\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 8.6432 - mae: 2.1272 - val_loss: 15.9778 - val_mae: 2.6257\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.3568 - mae: 2.0589 - val_loss: 15.7033 - val_mae: 2.5784\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.3144 - mae: 2.0993 - val_loss: 15.8370 - val_mae: 2.6536\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 8.4009 - mae: 2.1093 - val_loss: 15.3494 - val_mae: 2.6054\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.0707 - mae: 2.0672 - val_loss: 15.2726 - val_mae: 2.5773\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.9077 - mae: 2.0293 - val_loss: 15.0375 - val_mae: 2.5193\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.7758 - mae: 2.0743 - val_loss: 15.5506 - val_mae: 2.6314\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.8352 - mae: 2.0374 - val_loss: 15.0877 - val_mae: 2.5341\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.8945 - mae: 2.0598 - val_loss: 15.0363 - val_mae: 2.5576\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.5758 - mae: 1.9994 - val_loss: 14.7363 - val_mae: 2.5409\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.5676 - mae: 2.0177 - val_loss: 14.7070 - val_mae: 2.5082\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.2977 - mae: 1.9564 - val_loss: 15.2541 - val_mae: 2.5675\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 7.3943 - mae: 1.9988 - val_loss: 14.5204 - val_mae: 2.5208\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 7.3079 - mae: 1.9333 - val_loss: 14.7632 - val_mae: 2.6037\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.1180 - mae: 1.9331 - val_loss: 14.6733 - val_mae: 2.5281\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.1278 - mae: 1.9746 - val_loss: 15.1381 - val_mae: 2.5745\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.0665 - mae: 1.9445 - val_loss: 14.7716 - val_mae: 2.4998\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9294 - mae: 1.9006 - val_loss: 15.1710 - val_mae: 2.6083\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.8440 - mae: 1.9736 - val_loss: 14.9401 - val_mae: 2.5396\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9932 - mae: 1.9342 - val_loss: 14.7032 - val_mae: 2.5386\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.8435 - mae: 1.9365 - val_loss: 15.0360 - val_mae: 2.6455\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.7312 - mae: 1.8832 - val_loss: 14.9062 - val_mae: 2.5370\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9252 - mae: 1.9184 - val_loss: 14.4481 - val_mae: 2.5106\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 1s 55ms/step - loss: 6.5779 - mae: 1.8787 - val_loss: 14.7502 - val_mae: 2.5881\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6250 - mae: 1.8692 - val_loss: 15.4633 - val_mae: 2.7039\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.5283 - mae: 1.8759 - val_loss: 14.6176 - val_mae: 2.5397\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3601 - mae: 1.8459 - val_loss: 15.2471 - val_mae: 2.5581\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.2175 - mae: 1.8328 - val_loss: 15.1940 - val_mae: 2.7242\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1614 - mae: 1.8205 - val_loss: 14.4837 - val_mae: 2.5284\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.4405 - mae: 1.8472 - val_loss: 14.4510 - val_mae: 2.5271\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2857 - mae: 1.8011 - val_loss: 14.4416 - val_mae: 2.5012\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1198 - mae: 1.8403 - val_loss: 14.2456 - val_mae: 2.4688\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1862 - mae: 1.8166 - val_loss: 14.4560 - val_mae: 2.6237\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0849 - mae: 1.7903 - val_loss: 14.3947 - val_mae: 2.5554\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.2279 - mae: 1.7968 - val_loss: 14.2738 - val_mae: 2.4734\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0281 - mae: 1.7660 - val_loss: 14.4121 - val_mae: 2.5046\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.9151 - mae: 1.7946 - val_loss: 14.4914 - val_mae: 2.5950\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.9561 - mae: 1.7735 - val_loss: 14.5450 - val_mae: 2.5789\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 1s 51ms/step - loss: 5.9531 - mae: 1.7892 - val_loss: 14.4170 - val_mae: 2.4979\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.8378 - mae: 1.7636 - val_loss: 14.3513 - val_mae: 2.4922\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7684 - mae: 1.7765 - val_loss: 14.2867 - val_mae: 2.5941\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9510 - mae: 1.7980 - val_loss: 14.0228 - val_mae: 2.5275\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.6845 - mae: 1.7698 - val_loss: 14.1661 - val_mae: 2.5151\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.7693 - mae: 1.7760 - val_loss: 14.3231 - val_mae: 2.5429\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.6276 - mae: 1.7359 - val_loss: 14.2092 - val_mae: 2.5754\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.5910 - mae: 1.7639 - val_loss: 14.1672 - val_mae: 2.5086\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.7083 - mae: 1.7316 - val_loss: 14.1099 - val_mae: 2.5076\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.4772 - mae: 1.7168 - val_loss: 14.1185 - val_mae: 2.4901\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.5806 - mae: 1.7157 - val_loss: 14.0691 - val_mae: 2.5182\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3328 - mae: 1.7093 - val_loss: 14.6539 - val_mae: 2.5489\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3314 - mae: 1.6549 - val_loss: 16.2726 - val_mae: 2.8509\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.6114 - mae: 1.7324 - val_loss: 14.5060 - val_mae: 2.5018\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.5596 - mae: 1.7050 - val_loss: 13.9837 - val_mae: 2.4559\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 5.3211 - mae: 1.6979 - val_loss: 14.0086 - val_mae: 2.5341\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.2898 - mae: 1.6743 - val_loss: 14.5746 - val_mae: 2.5010\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.3786 - mae: 1.6887 - val_loss: 14.1406 - val_mae: 2.5013\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1608 - mae: 1.6873 - val_loss: 14.2536 - val_mae: 2.4616\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.1407 - mae: 1.6476 - val_loss: 13.9720 - val_mae: 2.4852\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1243 - mae: 1.6548 - val_loss: 14.0428 - val_mae: 2.5260\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1354 - mae: 1.6527 - val_loss: 14.1591 - val_mae: 2.4710\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1110 - mae: 1.6514 - val_loss: 14.3695 - val_mae: 2.5006\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.2084 - mae: 1.6582 - val_loss: 14.3915 - val_mae: 2.4889\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 4.9701 - mae: 1.6186 - val_loss: 14.7744 - val_mae: 2.6062\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0757 - mae: 1.6699 - val_loss: 14.2402 - val_mae: 2.4873\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7520 - mae: 1.5990 - val_loss: 13.9291 - val_mae: 2.4597\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.9559 - mae: 1.6185 - val_loss: 13.9985 - val_mae: 2.4482\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8727 - mae: 1.6307 - val_loss: 13.9342 - val_mae: 2.4760\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8942 - mae: 1.6221 - val_loss: 14.0141 - val_mae: 2.4708\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.7586 - mae: 1.6208 - val_loss: 14.0055 - val_mae: 2.4500\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.7539 - mae: 1.5905 - val_loss: 14.4491 - val_mae: 2.6153\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 4.8384 - mae: 1.6240 - val_loss: 14.4344 - val_mae: 2.4889\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5849 - mae: 1.5757 - val_loss: 14.0455 - val_mae: 2.5191\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6772 - mae: 1.6082 - val_loss: 14.0212 - val_mae: 2.5270\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5938 - mae: 1.5857 - val_loss: 14.2973 - val_mae: 2.4784\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7340 - mae: 1.5510 - val_loss: 14.5000 - val_mae: 2.5381\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6954 - mae: 1.5928 - val_loss: 14.2470 - val_mae: 2.5841\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4807 - mae: 1.5319 - val_loss: 14.3211 - val_mae: 2.4942\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8035 - mae: 1.6362 - val_loss: 14.2965 - val_mae: 2.4910\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6233 - mae: 1.5693 - val_loss: 13.9552 - val_mae: 2.4628\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.5821 - mae: 1.5759 - val_loss: 14.0297 - val_mae: 2.4689\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.5370 - mae: 1.5629 - val_loss: 14.1376 - val_mae: 2.5208\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4840 - mae: 1.5460 - val_loss: 13.9167 - val_mae: 2.4525\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4150 - mae: 1.5443 - val_loss: 14.2095 - val_mae: 2.5242\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6238 - mae: 1.5847 - val_loss: 14.3419 - val_mae: 2.5242\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3935 - mae: 1.5328 - val_loss: 14.1563 - val_mae: 2.5189\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.3258 - mae: 1.5246 - val_loss: 14.7183 - val_mae: 2.6162\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5165 - mae: 1.5238 - val_loss: 14.6104 - val_mae: 2.6248\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1925 - mae: 1.5030 - val_loss: 15.3105 - val_mae: 2.6526\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3488 - mae: 1.5190 - val_loss: 14.4347 - val_mae: 2.4879\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2790 - mae: 1.5221 - val_loss: 14.2153 - val_mae: 2.4596\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2582 - mae: 1.5162 - val_loss: 14.3336 - val_mae: 2.5112\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 4.2300 - mae: 1.5387 - val_loss: 14.1848 - val_mae: 2.4698\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0284 - mae: 1.5049 - val_loss: 14.1236 - val_mae: 2.4673\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2570 - mae: 1.5041 - val_loss: 14.0490 - val_mae: 2.4898\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1165 - mae: 1.5089 - val_loss: 13.9215 - val_mae: 2.4523\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0151 - mae: 1.4513 - val_loss: 14.0152 - val_mae: 2.4544\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2237 - mae: 1.4872 - val_loss: 14.0992 - val_mae: 2.4573\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 4.0639 - mae: 1.4904 - val_loss: 13.8799 - val_mae: 2.4476\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1030 - mae: 1.4909 - val_loss: 14.2239 - val_mae: 2.4963\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9818 - mae: 1.4972 - val_loss: 14.0476 - val_mae: 2.4908\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0417 - mae: 1.4775 - val_loss: 14.5771 - val_mae: 2.5637\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1938 - mae: 1.4999 - val_loss: 14.3848 - val_mae: 2.5039\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7347 - mae: 1.4288 - val_loss: 14.4669 - val_mae: 2.5299\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0552 - mae: 1.4638 - val_loss: 14.2723 - val_mae: 2.4579\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8086 - mae: 1.4414 - val_loss: 14.6081 - val_mae: 2.5243\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8955 - mae: 1.4353 - val_loss: 14.6129 - val_mae: 2.5172\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8523 - mae: 1.4249 - val_loss: 14.0475 - val_mae: 2.4569\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6584 - mae: 1.3991 - val_loss: 14.1252 - val_mae: 2.5045\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.9192 - mae: 1.4457 - val_loss: 14.1860 - val_mae: 2.4930\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7822 - mae: 1.4377 - val_loss: 14.3014 - val_mae: 2.5269\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9463 - mae: 1.4578 - val_loss: 14.5572 - val_mae: 2.5366\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7205 - mae: 1.4327 - val_loss: 14.1710 - val_mae: 2.4657\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7799 - mae: 1.4029 - val_loss: 14.8418 - val_mae: 2.5396\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5757 - mae: 1.4076 - val_loss: 14.4487 - val_mae: 2.5183\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7676 - mae: 1.4222 - val_loss: 14.1148 - val_mae: 2.4548\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6310 - mae: 1.4119 - val_loss: 14.3274 - val_mae: 2.5128\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5687 - mae: 1.4024 - val_loss: 14.3838 - val_mae: 2.4963\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6899 - mae: 1.4159 - val_loss: 14.3277 - val_mae: 2.4725\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5896 - mae: 1.4018 - val_loss: 15.0205 - val_mae: 2.5909\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6565 - mae: 1.3793 - val_loss: 14.2035 - val_mae: 2.4713\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 3.4919 - mae: 1.3697 - val_loss: 14.5118 - val_mae: 2.4936\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4526 - mae: 1.3952 - val_loss: 14.5477 - val_mae: 2.5302\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 3.5960 - mae: 1.3810 - val_loss: 14.4264 - val_mae: 2.4877\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4485 - mae: 1.3651 - val_loss: 14.5751 - val_mae: 2.4815\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3924 - mae: 1.3470 - val_loss: 14.4746 - val_mae: 2.5322\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3241 - mae: 1.3366 - val_loss: 14.3933 - val_mae: 2.4357\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5079 - mae: 1.3766 - val_loss: 15.2243 - val_mae: 2.6104\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3794 - mae: 1.3687 - val_loss: 14.5022 - val_mae: 2.4968\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3265 - mae: 1.3412 - val_loss: 14.5053 - val_mae: 2.4905\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4493 - mae: 1.3521 - val_loss: 14.8041 - val_mae: 2.5214\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3317 - mae: 1.3143 - val_loss: 14.5711 - val_mae: 2.5010\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3466 - mae: 1.3466 - val_loss: 14.4675 - val_mae: 2.4767\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1397 - mae: 1.3283 - val_loss: 14.6102 - val_mae: 2.4969\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3301 - mae: 1.2967 - val_loss: 15.0387 - val_mae: 2.5355\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1649 - mae: 1.2984 - val_loss: 14.3692 - val_mae: 2.4661\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1386 - mae: 1.2726 - val_loss: 14.4798 - val_mae: 2.5002\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2686 - mae: 1.3051 - val_loss: 14.5927 - val_mae: 2.5155\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2258 - mae: 1.2955 - val_loss: 14.5379 - val_mae: 2.5069\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2276 - mae: 1.3101 - val_loss: 14.7794 - val_mae: 2.5061\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0716 - mae: 1.2702 - val_loss: 15.0305 - val_mae: 2.5859\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9855 - mae: 1.2771 - val_loss: 15.1425 - val_mae: 2.6178\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2638 - mae: 1.3264 - val_loss: 14.5730 - val_mae: 2.5460\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9888 - mae: 1.2531 - val_loss: 14.7932 - val_mae: 2.5822\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1132 - mae: 1.3034 - val_loss: 14.8777 - val_mae: 2.5070\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 3.1066 - mae: 1.3006 - val_loss: 15.1116 - val_mae: 2.5630\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8426 - mae: 1.2566 - val_loss: 14.9570 - val_mae: 2.5814\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9288 - mae: 1.2635 - val_loss: 14.8280 - val_mae: 2.5504\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0001 - mae: 1.2535 - val_loss: 14.8410 - val_mae: 2.5161\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9812 - mae: 1.2596 - val_loss: 14.9530 - val_mae: 2.5231\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9344 - mae: 1.2504 - val_loss: 14.6173 - val_mae: 2.4873\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9290 - mae: 1.2394 - val_loss: 14.9231 - val_mae: 2.5280\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9450 - mae: 1.2813 - val_loss: 15.2363 - val_mae: 2.6390\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7924 - mae: 1.2271 - val_loss: 14.7832 - val_mae: 2.5368\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8466 - mae: 1.2274 - val_loss: 15.0386 - val_mae: 2.5575\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8122 - mae: 1.1931 - val_loss: 14.6991 - val_mae: 2.4859\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7460 - mae: 1.2012 - val_loss: 15.1037 - val_mae: 2.5319\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0124 - mae: 1.2698 - val_loss: 15.2269 - val_mae: 2.5771\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7176 - mae: 1.1896 - val_loss: 15.0468 - val_mae: 2.5343\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6932 - mae: 1.1783 - val_loss: 15.0698 - val_mae: 2.5587\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7237 - mae: 1.2031 - val_loss: 14.8957 - val_mae: 2.5149\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8534 - mae: 1.2125 - val_loss: 15.4253 - val_mae: 2.5521\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7773 - mae: 1.2210 - val_loss: 14.9661 - val_mae: 2.6040\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7380 - mae: 1.2408 - val_loss: 15.0048 - val_mae: 2.4966\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6574 - mae: 1.1918 - val_loss: 15.3083 - val_mae: 2.5948\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6529 - mae: 1.1979 - val_loss: 15.2695 - val_mae: 2.5991\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6939 - mae: 1.1906 - val_loss: 15.3820 - val_mae: 2.5356\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6346 - mae: 1.1948 - val_loss: 15.1013 - val_mae: 2.5739\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5707 - mae: 1.1759 - val_loss: 15.5680 - val_mae: 2.6283\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7134 - mae: 1.1992 - val_loss: 14.7241 - val_mae: 2.4948\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6164 - mae: 1.1789 - val_loss: 15.0007 - val_mae: 2.5176\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6086 - mae: 1.1880 - val_loss: 15.0944 - val_mae: 2.5676\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 2.5958 - mae: 1.1652 - val_loss: 15.3760 - val_mae: 2.5657\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5282 - mae: 1.1556 - val_loss: 14.9944 - val_mae: 2.5124\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5992 - mae: 1.1850 - val_loss: 15.0718 - val_mae: 2.5579\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5347 - mae: 1.1570 - val_loss: 15.1498 - val_mae: 2.5318\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5616 - mae: 1.1242 - val_loss: 15.0424 - val_mae: 2.5610\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4297 - mae: 1.1538 - val_loss: 16.1865 - val_mae: 2.6242\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5157 - mae: 1.1617 - val_loss: 15.4195 - val_mae: 2.5523\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4992 - mae: 1.1566 - val_loss: 15.3216 - val_mae: 2.5413\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3365 - mae: 1.0849 - val_loss: 15.4570 - val_mae: 2.6224\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.5499 - mae: 1.2122 - val_loss: 15.8624 - val_mae: 2.6086\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4514 - mae: 1.1555 - val_loss: 15.4118 - val_mae: 2.5665\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3478 - mae: 1.1327 - val_loss: 15.3374 - val_mae: 2.5636\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5040 - mae: 1.1702 - val_loss: 15.8767 - val_mae: 2.6553\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4047 - mae: 1.0966 - val_loss: 16.0933 - val_mae: 2.6307\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3396 - mae: 1.0904 - val_loss: 15.4346 - val_mae: 2.5383\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3428 - mae: 1.0959 - val_loss: 15.4131 - val_mae: 2.5330\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.4174 - mae: 1.1383 - val_loss: 16.1922 - val_mae: 2.7324\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3810 - mae: 1.1353 - val_loss: 15.7085 - val_mae: 2.5906\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2536 - mae: 1.1181 - val_loss: 15.1260 - val_mae: 2.5504\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2502 - mae: 1.1083 - val_loss: 15.6102 - val_mae: 2.6184\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.2375 - mae: 1.1107 - val_loss: 16.0230 - val_mae: 2.6014\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.2536 - mae: 1.0952 - val_loss: 15.6132 - val_mae: 2.5945\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1689 - mae: 1.0929 - val_loss: 15.8808 - val_mae: 2.6285\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3901 - mae: 1.1249 - val_loss: 15.6773 - val_mae: 2.6286\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3418 - mae: 1.1364 - val_loss: 15.6537 - val_mae: 2.6391\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3375 - mae: 1.1255 - val_loss: 15.7064 - val_mae: 2.5703\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1885 - mae: 1.1057 - val_loss: 16.1741 - val_mae: 2.5805\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1223 - mae: 1.0584 - val_loss: 15.3088 - val_mae: 2.5545\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2872 - mae: 1.0919 - val_loss: 15.8430 - val_mae: 2.5691\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 2.1780 - mae: 1.0778 - val_loss: 15.7044 - val_mae: 2.5818\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1185 - mae: 1.0545 - val_loss: 15.7064 - val_mae: 2.5768\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0798 - mae: 1.0590 - val_loss: 16.0690 - val_mae: 2.6375\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1085 - mae: 1.0847 - val_loss: 16.0204 - val_mae: 2.6733\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 2.1841 - mae: 1.0872 - val_loss: 15.6904 - val_mae: 2.5762\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9881 - mae: 1.0193 - val_loss: 15.7434 - val_mae: 2.5751\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0730 - mae: 1.0778 - val_loss: 15.8094 - val_mae: 2.6012\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0108 - mae: 1.0332 - val_loss: 16.0549 - val_mae: 2.6568\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0828 - mae: 1.0819 - val_loss: 15.7378 - val_mae: 2.5961\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0257 - mae: 1.0649 - val_loss: 16.1625 - val_mae: 2.6478\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8892 - mae: 1.0370 - val_loss: 16.3985 - val_mae: 2.6355\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.2468 - mae: 1.1122 - val_loss: 15.7622 - val_mae: 2.6229\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.9918 - mae: 1.0415 - val_loss: 16.6630 - val_mae: 2.6461\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.0007 - mae: 1.0525 - val_loss: 16.0470 - val_mae: 2.5995\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.0949 - mae: 1.0614 - val_loss: 15.9603 - val_mae: 2.6245\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9382 - mae: 1.0130 - val_loss: 16.3261 - val_mae: 2.6538\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9767 - mae: 1.0241 - val_loss: 15.8865 - val_mae: 2.6305\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9877 - mae: 1.0344 - val_loss: 16.1588 - val_mae: 2.6722\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9269 - mae: 1.0118 - val_loss: 16.1604 - val_mae: 2.6137\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8390 - mae: 1.0041 - val_loss: 16.6642 - val_mae: 2.6793\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9760 - mae: 1.0287 - val_loss: 16.4626 - val_mae: 2.6864\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.9985 - mae: 1.0291 - val_loss: 16.4563 - val_mae: 2.6410\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 2.0426 - mae: 1.0519 - val_loss: 16.1087 - val_mae: 2.6341\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8778 - mae: 1.0025 - val_loss: 16.6821 - val_mae: 2.6516\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8306 - mae: 0.9867 - val_loss: 17.4624 - val_mae: 2.8037\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9155 - mae: 0.9968 - val_loss: 16.3122 - val_mae: 2.6658\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8418 - mae: 0.9944 - val_loss: 16.7484 - val_mae: 2.7660\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0848 - mae: 1.0594 - val_loss: 16.0587 - val_mae: 2.6323\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8329 - mae: 1.0027 - val_loss: 16.3499 - val_mae: 2.6617\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9203 - mae: 1.0203 - val_loss: 16.7050 - val_mae: 2.6947\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7829 - mae: 0.9903 - val_loss: 16.8672 - val_mae: 2.7012\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9203 - mae: 0.9929 - val_loss: 16.4901 - val_mae: 2.6628\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9209 - mae: 1.0412 - val_loss: 16.6979 - val_mae: 2.7472\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8621 - mae: 1.0030 - val_loss: 17.2502 - val_mae: 2.7485\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7123 - mae: 0.9846 - val_loss: 17.0843 - val_mae: 2.7104\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.8309 - mae: 1.0192 - val_loss: 16.1036 - val_mae: 2.6396\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.8703 - mae: 0.9883 - val_loss: 16.2849 - val_mae: 2.6636\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.7846 - mae: 0.9762 - val_loss: 16.1771 - val_mae: 2.6509\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.6632 - mae: 0.9832 - val_loss: 16.4319 - val_mae: 2.7511\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6801 - mae: 0.9594 - val_loss: 16.4106 - val_mae: 2.6734\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6080 - mae: 0.9342 - val_loss: 16.5711 - val_mae: 2.7019\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7983 - mae: 0.9750 - val_loss: 16.3997 - val_mae: 2.6407\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7298 - mae: 0.9605 - val_loss: 16.7228 - val_mae: 2.7166\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8060 - mae: 0.9783 - val_loss: 16.5808 - val_mae: 2.6913\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8208 - mae: 1.0094 - val_loss: 16.1634 - val_mae: 2.6524\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.7159 - mae: 0.9735 - val_loss: 17.2195 - val_mae: 2.8403\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7945 - mae: 0.9746 - val_loss: 17.6626 - val_mae: 2.7940\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7553 - mae: 1.0030 - val_loss: 16.7086 - val_mae: 2.6991\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7673 - mae: 0.9798 - val_loss: 16.6483 - val_mae: 2.7262\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7072 - mae: 0.9547 - val_loss: 16.9264 - val_mae: 2.7184\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5712 - mae: 0.9200 - val_loss: 17.3452 - val_mae: 2.7605\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7678 - mae: 0.9914 - val_loss: 16.7967 - val_mae: 2.6856\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5879 - mae: 0.9484 - val_loss: 16.6757 - val_mae: 2.6738\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6154 - mae: 0.9212 - val_loss: 16.3950 - val_mae: 2.6779\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7182 - mae: 0.9752 - val_loss: 16.6431 - val_mae: 2.7108\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6588 - mae: 0.9607 - val_loss: 17.1394 - val_mae: 2.7352\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6977 - mae: 0.9572 - val_loss: 16.8382 - val_mae: 2.7260\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6780 - mae: 0.9545 - val_loss: 17.0579 - val_mae: 2.8184\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7356 - mae: 0.9640 - val_loss: 16.4200 - val_mae: 2.6917\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5820 - mae: 0.9153 - val_loss: 16.8134 - val_mae: 2.6905\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7593 - mae: 0.9806 - val_loss: 16.5892 - val_mae: 2.7222\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5774 - mae: 0.9466 - val_loss: 16.8883 - val_mae: 2.7453\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6109 - mae: 0.9300 - val_loss: 16.4934 - val_mae: 2.6753\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4406 - mae: 0.8893 - val_loss: 16.9933 - val_mae: 2.7312\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6565 - mae: 0.9540 - val_loss: 17.0654 - val_mae: 2.7215\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7356 - mae: 0.9724 - val_loss: 16.5241 - val_mae: 2.6752\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 1.5005 - mae: 0.9114 - val_loss: 16.9726 - val_mae: 2.7734\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5696 - mae: 0.9179 - val_loss: 17.1339 - val_mae: 2.7971\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7213 - mae: 0.9736 - val_loss: 16.8476 - val_mae: 2.7298\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4194 - mae: 0.8984 - val_loss: 17.2898 - val_mae: 2.7763\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5958 - mae: 0.9323 - val_loss: 16.5541 - val_mae: 2.7034\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5232 - mae: 0.9141 - val_loss: 16.8579 - val_mae: 2.7014\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5506 - mae: 0.9065 - val_loss: 16.8664 - val_mae: 2.7177\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4322 - mae: 0.8857 - val_loss: 17.8552 - val_mae: 2.8413\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.5385 - mae: 0.9469 - val_loss: 17.0930 - val_mae: 2.7460\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4544 - mae: 0.9004 - val_loss: 16.9385 - val_mae: 2.7308\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4695 - mae: 0.8946 - val_loss: 18.1622 - val_mae: 2.8811\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5160 - mae: 0.9136 - val_loss: 16.8857 - val_mae: 2.7138\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4724 - mae: 0.8919 - val_loss: 17.0631 - val_mae: 2.8082\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5158 - mae: 0.8990 - val_loss: 16.7905 - val_mae: 2.7165\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4089 - mae: 0.9107 - val_loss: 16.9331 - val_mae: 2.7119\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4286 - mae: 0.9106 - val_loss: 16.6739 - val_mae: 2.7199\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4829 - mae: 0.9002 - val_loss: 17.2480 - val_mae: 2.7553\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1.4678 - mae: 0.8959 - val_loss: 17.4470 - val_mae: 2.7802\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4659 - mae: 0.9231 - val_loss: 16.9890 - val_mae: 2.7333\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3014 - mae: 0.8232 - val_loss: 17.4480 - val_mae: 2.7963\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4602 - mae: 0.9007 - val_loss: 17.1281 - val_mae: 2.7909\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4397 - mae: 0.9232 - val_loss: 16.8971 - val_mae: 2.7382\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4766 - mae: 0.8847 - val_loss: 17.3420 - val_mae: 2.7641\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4738 - mae: 0.8866 - val_loss: 16.9027 - val_mae: 2.7315\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4275 - mae: 0.8768 - val_loss: 16.4748 - val_mae: 2.7019\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 1.4934 - mae: 0.8998 - val_loss: 17.0674 - val_mae: 2.7645\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3522 - mae: 0.8588 - val_loss: 17.0296 - val_mae: 2.7589\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4677 - mae: 0.8965 - val_loss: 16.5649 - val_mae: 2.7581\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2519 - mae: 0.8388 - val_loss: 16.8043 - val_mae: 2.7576\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3619 - mae: 0.8564 - val_loss: 17.1257 - val_mae: 2.7833\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3227 - mae: 0.8394 - val_loss: 17.6658 - val_mae: 2.7990\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4503 - mae: 0.8856 - val_loss: 17.4840 - val_mae: 2.8440\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3595 - mae: 0.8749 - val_loss: 17.5296 - val_mae: 2.7923\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3707 - mae: 0.8978 - val_loss: 17.3789 - val_mae: 2.7758\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2712 - mae: 0.8332 - val_loss: 17.1383 - val_mae: 2.7758\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3536 - mae: 0.8817 - val_loss: 17.2582 - val_mae: 2.7552\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3847 - mae: 0.8469 - val_loss: 17.1495 - val_mae: 2.7761\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3180 - mae: 0.8445 - val_loss: 17.5126 - val_mae: 2.8159\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3547 - mae: 0.8753 - val_loss: 17.2016 - val_mae: 2.7889\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5395 - mae: 0.9090 - val_loss: 17.2365 - val_mae: 2.7608\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2151 - mae: 0.8042 - val_loss: 17.3142 - val_mae: 2.7549\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2358 - mae: 0.8286 - val_loss: 17.0223 - val_mae: 2.7130\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3955 - mae: 0.8885 - val_loss: 16.8320 - val_mae: 2.7463\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2030 - mae: 0.8112 - val_loss: 17.4403 - val_mae: 2.7559\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3510 - mae: 0.8624 - val_loss: 16.8707 - val_mae: 2.7636\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 1s 50ms/step - loss: 1.3835 - mae: 0.8590 - val_loss: 17.2581 - val_mae: 2.7705\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2702 - mae: 0.8259 - val_loss: 17.3181 - val_mae: 2.7446\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1595 - mae: 0.8260 - val_loss: 18.0309 - val_mae: 2.9247\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3313 - mae: 0.8577 - val_loss: 17.4532 - val_mae: 2.8745\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3645 - mae: 0.8694 - val_loss: 17.3606 - val_mae: 2.8412\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3613 - mae: 0.8883 - val_loss: 17.5803 - val_mae: 2.8098\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2144 - mae: 0.8134 - val_loss: 17.5783 - val_mae: 2.8101\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1989 - mae: 0.8096 - val_loss: 17.4173 - val_mae: 2.7852\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2400 - mae: 0.8518 - val_loss: 16.9089 - val_mae: 2.7380\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2414 - mae: 0.7852 - val_loss: 17.0002 - val_mae: 2.7560\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4001 - mae: 0.8724 - val_loss: 18.3005 - val_mae: 2.8318\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1779 - mae: 0.8116 - val_loss: 17.9933 - val_mae: 2.8932\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3637 - mae: 0.8776 - val_loss: 17.8194 - val_mae: 2.8024\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1889 - mae: 0.7969 - val_loss: 17.6830 - val_mae: 2.7923\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2091 - mae: 0.8233 - val_loss: 17.6214 - val_mae: 2.7726\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1557 - mae: 0.7982 - val_loss: 18.1981 - val_mae: 2.8495\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2187 - mae: 0.8334 - val_loss: 17.3759 - val_mae: 2.7739\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1176 - mae: 0.7724 - val_loss: 18.7404 - val_mae: 3.0066\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.3382 - mae: 0.8488 - val_loss: 17.7549 - val_mae: 2.8283\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2919 - mae: 0.8530 - val_loss: 17.6842 - val_mae: 2.7978\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2424 - mae: 0.8303 - val_loss: 17.9507 - val_mae: 2.8465\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0941 - mae: 0.7605 - val_loss: 18.3382 - val_mae: 2.8710\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2839 - mae: 0.8472 - val_loss: 17.7048 - val_mae: 2.8294\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1787 - mae: 0.8109 - val_loss: 17.0714 - val_mae: 2.7772\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1997 - mae: 0.8347 - val_loss: 17.6149 - val_mae: 2.8329\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1565 - mae: 0.7872 - val_loss: 17.8185 - val_mae: 2.8053\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.2885 - mae: 0.8592 - val_loss: 18.6987 - val_mae: 2.9001\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0758 - mae: 0.7553 - val_loss: 17.7870 - val_mae: 2.8352\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1740 - mae: 0.7987 - val_loss: 17.4445 - val_mae: 2.7590\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1539 - mae: 0.7812 - val_loss: 17.3380 - val_mae: 2.7944\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1709 - mae: 0.8109 - val_loss: 17.6916 - val_mae: 2.8507\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0397 - mae: 0.7670 - val_loss: 18.3005 - val_mae: 2.8942\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2075 - mae: 0.8246 - val_loss: 18.3262 - val_mae: 2.8640\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0856 - mae: 0.7796 - val_loss: 17.9231 - val_mae: 2.8842\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1182 - mae: 0.8090 - val_loss: 18.1429 - val_mae: 2.8679\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.0713 - mae: 0.7791 - val_loss: 17.9280 - val_mae: 2.8343\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1354 - mae: 0.7766 - val_loss: 17.9196 - val_mae: 2.8318\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0984 - mae: 0.8004 - val_loss: 17.9793 - val_mae: 2.8631\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2224 - mae: 0.8231 - val_loss: 17.7580 - val_mae: 2.8164\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1675 - mae: 0.8034 - val_loss: 17.7040 - val_mae: 2.8080\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0012 - mae: 0.7291 - val_loss: 17.9967 - val_mae: 2.8050\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1735 - mae: 0.8104 - val_loss: 17.9607 - val_mae: 2.8100\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2524 - mae: 0.8061 - val_loss: 18.0562 - val_mae: 2.8331\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1120 - mae: 0.7825 - val_loss: 17.8857 - val_mae: 2.8151\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1457 - mae: 0.7987 - val_loss: 17.8979 - val_mae: 2.8532\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0081 - mae: 0.7364 - val_loss: 17.9996 - val_mae: 2.8424\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9997 - mae: 0.7740 - val_loss: 18.1475 - val_mae: 2.8478\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1560 - mae: 0.8100 - val_loss: 17.8468 - val_mae: 2.8349\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1234 - mae: 0.7826 - val_loss: 18.0487 - val_mae: 2.8390\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.9642 - mae: 0.7263 - val_loss: 18.4056 - val_mae: 2.9159\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2702 - mae: 0.8548 - val_loss: 18.0697 - val_mae: 2.8288\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9698 - mae: 0.7309 - val_loss: 17.7149 - val_mae: 2.8002\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0780 - mae: 0.7750 - val_loss: 17.7882 - val_mae: 2.8084\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0920 - mae: 0.7855 - val_loss: 18.2554 - val_mae: 2.8491\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9807 - mae: 0.7345 - val_loss: 18.2202 - val_mae: 2.8147\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 1.1733 - mae: 0.8214 - val_loss: 18.0367 - val_mae: 2.8051\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9846 - mae: 0.7340 - val_loss: 18.6037 - val_mae: 2.8748\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1312 - mae: 0.7870 - val_loss: 17.8093 - val_mae: 2.8350\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0415 - mae: 0.7474 - val_loss: 17.9689 - val_mae: 2.7994\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0804 - mae: 0.7718 - val_loss: 18.9594 - val_mae: 2.9195\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2026 - mae: 0.8055 - val_loss: 18.0839 - val_mae: 2.8443\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.9146 - mae: 0.7141 - val_loss: 18.5470 - val_mae: 2.8798\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0956 - mae: 0.7803 - val_loss: 17.7056 - val_mae: 2.8132\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0019 - mae: 0.7438 - val_loss: 17.8795 - val_mae: 2.8031\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0522 - mae: 0.7526 - val_loss: 18.6089 - val_mae: 2.9073\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0954 - mae: 0.7752 - val_loss: 18.3558 - val_mae: 2.8451\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0900 - mae: 0.7961 - val_loss: 17.5693 - val_mae: 2.8332\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0606 - mae: 0.7401 - val_loss: 18.2250 - val_mae: 2.7931\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1063 - mae: 0.7962 - val_loss: 18.0291 - val_mae: 2.7986\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9584 - mae: 0.7308 - val_loss: 18.6499 - val_mae: 2.9586\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8791 - mae: 0.7066 - val_loss: 18.4390 - val_mae: 2.8557\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1437 - mae: 0.8019 - val_loss: 18.0837 - val_mae: 2.8370\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9975 - mae: 0.7541 - val_loss: 18.4251 - val_mae: 2.9010\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9704 - mae: 0.7356 - val_loss: 18.0551 - val_mae: 2.8936\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.1132 - mae: 0.7607 - val_loss: 18.2041 - val_mae: 2.8953\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0222 - mae: 0.7442 - val_loss: 18.0435 - val_mae: 2.8843\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1707 - mae: 0.8087 - val_loss: 18.4906 - val_mae: 2.8177\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8783 - mae: 0.6819 - val_loss: 18.2452 - val_mae: 2.8635\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0058 - mae: 0.7269 - val_loss: 18.2082 - val_mae: 2.8358\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9258 - mae: 0.7476 - val_loss: 18.2067 - val_mae: 2.8476\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0172 - mae: 0.7659 - val_loss: 18.1734 - val_mae: 2.8361\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9926 - mae: 0.7208 - val_loss: 19.2932 - val_mae: 2.9406\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9458 - mae: 0.7266 - val_loss: 18.1569 - val_mae: 2.8735\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9311 - mae: 0.7025 - val_loss: 18.7146 - val_mae: 2.8968\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.9756 - mae: 0.7349 - val_loss: 18.1655 - val_mae: 2.8684\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8483 - mae: 0.6931 - val_loss: 18.4214 - val_mae: 2.8693\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9124 - mae: 0.7166 - val_loss: 19.4874 - val_mae: 2.9713\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8999 - mae: 0.7069 - val_loss: 18.6325 - val_mae: 2.9111\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0533 - mae: 0.7683 - val_loss: 18.8980 - val_mae: 2.8908\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9880 - mae: 0.7381 - val_loss: 18.4243 - val_mae: 2.8748\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0523 - mae: 0.7478 - val_loss: 18.6942 - val_mae: 2.9095\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8742 - mae: 0.6842 - val_loss: 18.1929 - val_mae: 2.8180\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9608 - mae: 0.7163 - val_loss: 18.7439 - val_mae: 2.9503\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8453 - mae: 0.6780 - val_loss: 17.9128 - val_mae: 2.8771\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.9093 - mae: 0.7288 - val_loss: 18.1123 - val_mae: 2.8594\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8982 - mae: 0.7219 - val_loss: 18.1638 - val_mae: 2.8209\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8727 - mae: 0.7127 - val_loss: 17.8541 - val_mae: 2.8287\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9285 - mae: 0.7241 - val_loss: 18.0115 - val_mae: 2.7932\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 1s 6ms/step - loss: 1.0267 - mae: 0.7444 - val_loss: 18.4345 - val_mae: 2.8474\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9247 - mae: 0.7322 - val_loss: 18.2640 - val_mae: 2.8745\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9833 - mae: 0.7115 - val_loss: 18.5173 - val_mae: 2.8642\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0275 - mae: 0.7437 - val_loss: 18.3703 - val_mae: 2.8330\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.8895 - mae: 0.6912 - val_loss: 18.4768 - val_mae: 2.8722\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9807 - mae: 0.7143 - val_loss: 18.0836 - val_mae: 2.8100\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8680 - mae: 0.6957 - val_loss: 18.4357 - val_mae: 2.9133\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9318 - mae: 0.7246 - val_loss: 19.0461 - val_mae: 2.9123\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.8838 - mae: 0.7150 - val_loss: 19.0138 - val_mae: 2.9750\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0478 - mae: 0.7446 - val_loss: 18.7330 - val_mae: 2.9145\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8201 - mae: 0.6798 - val_loss: 18.5162 - val_mae: 2.8572\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9694 - mae: 0.7325 - val_loss: 19.0342 - val_mae: 2.9355\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9203 - mae: 0.6893 - val_loss: 19.2928 - val_mae: 2.9604\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9521 - mae: 0.7207 - val_loss: 18.7314 - val_mae: 2.8610\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.8038 - mae: 0.6687 - val_loss: 18.7316 - val_mae: 2.8817\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9311 - mae: 0.7224 - val_loss: 18.2541 - val_mae: 2.8375\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.9037 - mae: 0.7199 - val_loss: 18.5782 - val_mae: 2.8816\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7518 - mae: 0.6520 - val_loss: 18.4339 - val_mae: 2.9063\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0171 - mae: 0.7275 - val_loss: 18.0533 - val_mae: 2.8695\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7169 - mae: 0.6177 - val_loss: 18.7993 - val_mae: 2.9433\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9350 - mae: 0.7222 - val_loss: 18.8612 - val_mae: 2.8453\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7544 - mae: 0.6573 - val_loss: 18.4815 - val_mae: 2.8904\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7633 - mae: 0.6547 - val_loss: 18.6804 - val_mae: 2.8827\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0064 - mae: 0.7447 - val_loss: 18.5776 - val_mae: 2.8729\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9950 - mae: 0.7536 - val_loss: 18.8319 - val_mae: 2.9205\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.8317 - mae: 0.6592 - val_loss: 18.8592 - val_mae: 2.8689\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9281 - mae: 0.7099 - val_loss: 18.4694 - val_mae: 2.8637\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.7489 - mae: 0.6506 - val_loss: 18.9292 - val_mae: 2.9553\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9113 - mae: 0.7215 - val_loss: 18.7748 - val_mae: 2.8907\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8181 - mae: 0.6921 - val_loss: 18.6695 - val_mae: 2.8726\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.8335 - mae: 0.6889 - val_loss: 18.5129 - val_mae: 2.9195\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7030 - mae: 0.6508 - val_loss: 19.0248 - val_mae: 2.9255\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9339 - mae: 0.7059 - val_loss: 19.1826 - val_mae: 2.9449\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8849 - mae: 0.6910 - val_loss: 18.8541 - val_mae: 2.9124\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7948 - mae: 0.6863 - val_loss: 18.9211 - val_mae: 2.9014\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8275 - mae: 0.6612 - val_loss: 19.0369 - val_mae: 2.9418\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.7696 - mae: 0.6523 - val_loss: 18.8887 - val_mae: 2.9334\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8532 - mae: 0.6920 - val_loss: 19.0107 - val_mae: 2.9048\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8703 - mae: 0.6968 - val_loss: 18.3575 - val_mae: 2.8561\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 1s 65ms/step - loss: 0.7287 - mae: 0.6162 - val_loss: 18.9191 - val_mae: 2.8591\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8575 - mae: 0.6892 - val_loss: 19.0966 - val_mae: 2.9525\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8188 - mae: 0.6794 - val_loss: 19.0668 - val_mae: 2.9023\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8376 - mae: 0.6594 - val_loss: 18.9682 - val_mae: 2.9018\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7938 - mae: 0.6469 - val_loss: 18.7876 - val_mae: 2.9292\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8962 - mae: 0.7011 - val_loss: 19.5620 - val_mae: 3.0284\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8500 - mae: 0.6700 - val_loss: 18.9174 - val_mae: 2.9048\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7458 - mae: 0.6299 - val_loss: 18.3978 - val_mae: 2.8439\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7974 - mae: 0.6700 - val_loss: 18.9658 - val_mae: 2.9055\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8673 - mae: 0.6879 - val_loss: 19.1224 - val_mae: 2.9348\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7783 - mae: 0.6457 - val_loss: 19.0228 - val_mae: 2.9343\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8612 - mae: 0.6913 - val_loss: 19.7146 - val_mae: 3.0423\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7404 - mae: 0.6411 - val_loss: 18.9935 - val_mae: 2.8843\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8986 - mae: 0.6631 - val_loss: 18.9667 - val_mae: 2.9458\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 1s 51ms/step - loss: 0.8401 - mae: 0.6742 - val_loss: 18.5463 - val_mae: 2.8614\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8170 - mae: 0.6932 - val_loss: 18.9951 - val_mae: 2.9045\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7376 - mae: 0.6392 - val_loss: 19.0081 - val_mae: 2.8966\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8696 - mae: 0.6925 - val_loss: 19.2392 - val_mae: 2.9715\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.7595 - mae: 0.6260 - val_loss: 19.0169 - val_mae: 2.9190\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7163 - mae: 0.6274 - val_loss: 19.0791 - val_mae: 2.9283\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8536 - mae: 0.6755 - val_loss: 18.8962 - val_mae: 2.8885\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8320 - mae: 0.6380 - val_loss: 19.1866 - val_mae: 2.9630\n",
            "Processing fold #3\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 23ms/step - loss: 489.6364 - mae: 20.3110 - val_loss: 553.3671 - val_mae: 21.3633\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 375.1711 - mae: 17.3664 - val_loss: 418.4828 - val_mae: 18.1169\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 252.7468 - mae: 13.7991 - val_loss: 275.1122 - val_mae: 13.9448\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 143.8147 - mae: 9.8354 - val_loss: 163.0352 - val_mae: 9.7376\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 79.8913 - mae: 6.9609 - val_loss: 107.6604 - val_mae: 7.7332\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 53.6900 - mae: 5.3967 - val_loss: 80.2852 - val_mae: 6.4864\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 40.3469 - mae: 4.4902 - val_loss: 61.3033 - val_mae: 5.5911\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 32.4300 - mae: 3.8904 - val_loss: 50.0505 - val_mae: 4.9722\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 27.5738 - mae: 3.5544 - val_loss: 44.2231 - val_mae: 4.5629\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 24.9090 - mae: 3.3280 - val_loss: 38.1515 - val_mae: 4.1975\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 22.5882 - mae: 3.1322 - val_loss: 33.3573 - val_mae: 3.9625\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 21.0736 - mae: 3.0043 - val_loss: 31.4217 - val_mae: 3.7856\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 19.4487 - mae: 2.9080 - val_loss: 28.9061 - val_mae: 3.6091\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 18.1666 - mae: 2.7620 - val_loss: 26.9272 - val_mae: 3.5058\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 17.3994 - mae: 2.7009 - val_loss: 24.7786 - val_mae: 3.3726\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 16.2315 - mae: 2.6491 - val_loss: 24.3006 - val_mae: 3.3175\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 15.4358 - mae: 2.5299 - val_loss: 22.5632 - val_mae: 3.2116\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 14.5403 - mae: 2.4490 - val_loss: 21.2615 - val_mae: 3.2374\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 13.9846 - mae: 2.4574 - val_loss: 20.3303 - val_mae: 3.1116\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 13.2198 - mae: 2.3549 - val_loss: 19.0741 - val_mae: 3.0467\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 12.8488 - mae: 2.3610 - val_loss: 18.6396 - val_mae: 3.0932\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 12.3979 - mae: 2.3142 - val_loss: 18.1396 - val_mae: 2.9206\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 12.0144 - mae: 2.2373 - val_loss: 17.0831 - val_mae: 2.9383\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.7782 - mae: 2.2526 - val_loss: 16.9771 - val_mae: 2.8278\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.4153 - mae: 2.2358 - val_loss: 16.5698 - val_mae: 2.9097\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.9207 - mae: 2.1384 - val_loss: 17.1944 - val_mae: 2.8197\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.7988 - mae: 2.1721 - val_loss: 15.9227 - val_mae: 2.8887\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.6824 - mae: 2.1791 - val_loss: 15.4495 - val_mae: 2.8242\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.3594 - mae: 2.1361 - val_loss: 15.1206 - val_mae: 2.7626\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.3268 - mae: 2.1801 - val_loss: 14.7461 - val_mae: 2.7384\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.1282 - mae: 2.1593 - val_loss: 14.4960 - val_mae: 2.7146\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.9641 - mae: 2.1169 - val_loss: 14.3371 - val_mae: 2.7038\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.8004 - mae: 2.1359 - val_loss: 14.0067 - val_mae: 2.6723\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 9.5847 - mae: 2.0966 - val_loss: 14.0310 - val_mae: 2.6621\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.6123 - mae: 2.1094 - val_loss: 14.1844 - val_mae: 2.6517\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.4578 - mae: 2.0782 - val_loss: 13.9652 - val_mae: 2.6189\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 9.0934 - mae: 2.0821 - val_loss: 14.0584 - val_mae: 2.7451\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.1741 - mae: 2.0831 - val_loss: 13.0311 - val_mae: 2.5845\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.1607 - mae: 2.0536 - val_loss: 12.8804 - val_mae: 2.5335\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.0483 - mae: 2.0500 - val_loss: 12.8595 - val_mae: 2.5743\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.8120 - mae: 2.0314 - val_loss: 12.5805 - val_mae: 2.5146\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.9214 - mae: 2.0333 - val_loss: 12.6821 - val_mae: 2.5570\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 8.6787 - mae: 1.9805 - val_loss: 12.4551 - val_mae: 2.4982\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.7158 - mae: 2.0351 - val_loss: 12.7856 - val_mae: 2.6276\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.5811 - mae: 2.0136 - val_loss: 12.4275 - val_mae: 2.5355\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.3654 - mae: 1.9678 - val_loss: 12.5977 - val_mae: 2.5323\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.3816 - mae: 1.9770 - val_loss: 12.6105 - val_mae: 2.5054\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.2769 - mae: 1.9821 - val_loss: 12.0182 - val_mae: 2.5036\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.1607 - mae: 1.9533 - val_loss: 11.9153 - val_mae: 2.4459\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 8.2712 - mae: 1.9538 - val_loss: 12.0604 - val_mae: 2.4633\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 8.0733 - mae: 1.9637 - val_loss: 11.8381 - val_mae: 2.4631\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.9479 - mae: 1.9180 - val_loss: 11.8990 - val_mae: 2.4062\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 8.0810 - mae: 1.9563 - val_loss: 11.6774 - val_mae: 2.4331\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.7183 - mae: 1.8882 - val_loss: 11.9771 - val_mae: 2.4877\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.9480 - mae: 1.9172 - val_loss: 11.7481 - val_mae: 2.4494\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.7802 - mae: 1.9147 - val_loss: 11.4654 - val_mae: 2.3914\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 7.7382 - mae: 1.9322 - val_loss: 11.2989 - val_mae: 2.3963\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 7.7485 - mae: 1.8836 - val_loss: 11.4408 - val_mae: 2.4259\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 7.5432 - mae: 1.9042 - val_loss: 11.5839 - val_mae: 2.4739\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 7.5872 - mae: 1.8891 - val_loss: 11.4032 - val_mae: 2.3822\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.5529 - mae: 1.8534 - val_loss: 11.8057 - val_mae: 2.4773\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.4698 - mae: 1.8659 - val_loss: 11.5769 - val_mae: 2.4347\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.4348 - mae: 1.8568 - val_loss: 11.0418 - val_mae: 2.3635\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.1565 - mae: 1.8752 - val_loss: 11.7834 - val_mae: 2.5241\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 7.3071 - mae: 1.8306 - val_loss: 11.1833 - val_mae: 2.4292\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.1961 - mae: 1.8638 - val_loss: 11.1915 - val_mae: 2.3959\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.2454 - mae: 1.8377 - val_loss: 11.3773 - val_mae: 2.4120\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.1529 - mae: 1.8334 - val_loss: 11.1103 - val_mae: 2.4266\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9887 - mae: 1.8223 - val_loss: 10.8641 - val_mae: 2.3409\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 7.1622 - mae: 1.8112 - val_loss: 11.3049 - val_mae: 2.4257\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.0330 - mae: 1.8000 - val_loss: 10.8471 - val_mae: 2.3231\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9083 - mae: 1.8117 - val_loss: 10.9289 - val_mae: 2.3781\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 6.9966 - mae: 1.8041 - val_loss: 10.7729 - val_mae: 2.3705\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.8558 - mae: 1.7731 - val_loss: 10.6875 - val_mae: 2.3517\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.8013 - mae: 1.8131 - val_loss: 10.6753 - val_mae: 2.3482\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.8630 - mae: 1.8023 - val_loss: 10.6422 - val_mae: 2.3272\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6267 - mae: 1.7661 - val_loss: 10.4405 - val_mae: 2.2909\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6112 - mae: 1.7864 - val_loss: 10.7536 - val_mae: 2.3169\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 6.5276 - mae: 1.7655 - val_loss: 10.6876 - val_mae: 2.3394\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.5819 - mae: 1.7481 - val_loss: 10.5391 - val_mae: 2.3110\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.7499 - mae: 1.7530 - val_loss: 10.7331 - val_mae: 2.3455\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.5979 - mae: 1.7349 - val_loss: 10.7594 - val_mae: 2.4078\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.4397 - mae: 1.7475 - val_loss: 10.5956 - val_mae: 2.3443\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.4263 - mae: 1.7551 - val_loss: 10.3256 - val_mae: 2.2915\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.5579 - mae: 1.7566 - val_loss: 10.1968 - val_mae: 2.2871\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.2892 - mae: 1.7123 - val_loss: 10.4845 - val_mae: 2.3267\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.3751 - mae: 1.7058 - val_loss: 10.4106 - val_mae: 2.3152\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.3027 - mae: 1.7487 - val_loss: 10.4689 - val_mae: 2.3365\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.3898 - mae: 1.7102 - val_loss: 10.4002 - val_mae: 2.3644\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2849 - mae: 1.7205 - val_loss: 9.9825 - val_mae: 2.2759\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2955 - mae: 1.7032 - val_loss: 10.0367 - val_mae: 2.2335\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0806 - mae: 1.6836 - val_loss: 9.9178 - val_mae: 2.2501\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2056 - mae: 1.7262 - val_loss: 10.0159 - val_mae: 2.2688\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.0505 - mae: 1.6480 - val_loss: 10.0855 - val_mae: 2.2734\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1474 - mae: 1.7125 - val_loss: 10.1863 - val_mae: 2.2879\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1481 - mae: 1.6982 - val_loss: 10.0984 - val_mae: 2.2859\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.9789 - mae: 1.6663 - val_loss: 10.2196 - val_mae: 2.2685\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.9685 - mae: 1.6673 - val_loss: 10.1898 - val_mae: 2.2699\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.7432 - mae: 1.6698 - val_loss: 10.0850 - val_mae: 2.2325\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.9593 - mae: 1.6632 - val_loss: 9.8523 - val_mae: 2.2504\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.8095 - mae: 1.6515 - val_loss: 9.7353 - val_mae: 2.2420\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.8214 - mae: 1.6187 - val_loss: 9.8212 - val_mae: 2.2379\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.6763 - mae: 1.6587 - val_loss: 9.8070 - val_mae: 2.2524\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.5896 - mae: 1.5924 - val_loss: 9.6617 - val_mae: 2.2306\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.6318 - mae: 1.6316 - val_loss: 10.6280 - val_mae: 2.3657\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.6014 - mae: 1.5997 - val_loss: 10.1519 - val_mae: 2.3047\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 5.5520 - mae: 1.5675 - val_loss: 10.1173 - val_mae: 2.3355\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.6325 - mae: 1.6123 - val_loss: 9.5914 - val_mae: 2.2350\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.5437 - mae: 1.5992 - val_loss: 9.5933 - val_mae: 2.2447\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.6134 - mae: 1.6147 - val_loss: 9.7644 - val_mae: 2.2565\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.4072 - mae: 1.5701 - val_loss: 9.9757 - val_mae: 2.2428\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.5652 - mae: 1.6103 - val_loss: 9.7534 - val_mae: 2.2385\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.1701 - mae: 1.5266 - val_loss: 10.9854 - val_mae: 2.4327\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.2342 - mae: 1.5754 - val_loss: 9.6398 - val_mae: 2.2277\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.5752 - mae: 1.5836 - val_loss: 9.5861 - val_mae: 2.1678\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.4313 - mae: 1.6026 - val_loss: 9.5399 - val_mae: 2.1932\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.2970 - mae: 1.5494 - val_loss: 10.2174 - val_mae: 2.2812\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3339 - mae: 1.5840 - val_loss: 9.8230 - val_mae: 2.2451\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1316 - mae: 1.5569 - val_loss: 10.5819 - val_mae: 2.4074\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 5.2360 - mae: 1.5563 - val_loss: 9.8568 - val_mae: 2.2981\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 5.1379 - mae: 1.5222 - val_loss: 9.6120 - val_mae: 2.2327\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.0134 - mae: 1.5308 - val_loss: 9.4080 - val_mae: 2.1860\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.2291 - mae: 1.5193 - val_loss: 9.4610 - val_mae: 2.1730\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0315 - mae: 1.5044 - val_loss: 9.3877 - val_mae: 2.1828\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0329 - mae: 1.5439 - val_loss: 9.4245 - val_mae: 2.1898\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.0590 - mae: 1.5119 - val_loss: 9.8608 - val_mae: 2.2481\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0263 - mae: 1.5048 - val_loss: 9.6211 - val_mae: 2.2485\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.8506 - mae: 1.5018 - val_loss: 9.9745 - val_mae: 2.2584\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0514 - mae: 1.4952 - val_loss: 9.1099 - val_mae: 2.1419\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.9695 - mae: 1.5296 - val_loss: 9.5041 - val_mae: 2.2231\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6798 - mae: 1.4503 - val_loss: 9.4411 - val_mae: 2.1572\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.7808 - mae: 1.5262 - val_loss: 9.7053 - val_mae: 2.2366\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.7756 - mae: 1.4935 - val_loss: 9.7420 - val_mae: 2.2386\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6849 - mae: 1.4735 - val_loss: 9.1182 - val_mae: 2.1173\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6348 - mae: 1.4728 - val_loss: 9.0922 - val_mae: 2.1381\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8149 - mae: 1.4714 - val_loss: 9.0958 - val_mae: 2.1140\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5674 - mae: 1.4416 - val_loss: 9.6466 - val_mae: 2.2374\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 4.8914 - mae: 1.5014 - val_loss: 8.9615 - val_mae: 2.1158\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5727 - mae: 1.4402 - val_loss: 9.2511 - val_mae: 2.1410\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6444 - mae: 1.4393 - val_loss: 9.0128 - val_mae: 2.1426\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.4613 - mae: 1.4305 - val_loss: 10.0763 - val_mae: 2.2961\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2374 - mae: 1.4160 - val_loss: 9.6855 - val_mae: 2.2279\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3100 - mae: 1.4156 - val_loss: 9.2363 - val_mae: 2.1576\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4013 - mae: 1.4161 - val_loss: 9.8672 - val_mae: 2.2910\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5255 - mae: 1.4325 - val_loss: 9.1049 - val_mae: 2.1126\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3670 - mae: 1.4290 - val_loss: 9.1871 - val_mae: 2.1261\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3215 - mae: 1.4064 - val_loss: 9.7141 - val_mae: 2.2310\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3342 - mae: 1.4491 - val_loss: 9.1416 - val_mae: 2.1569\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2488 - mae: 1.3965 - val_loss: 8.9520 - val_mae: 2.0949\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 4.4331 - mae: 1.4335 - val_loss: 8.9876 - val_mae: 2.1046\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.3372 - mae: 1.3737 - val_loss: 9.4955 - val_mae: 2.2027\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2226 - mae: 1.3954 - val_loss: 8.8143 - val_mae: 2.0841\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2692 - mae: 1.4089 - val_loss: 8.7326 - val_mae: 2.1307\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2432 - mae: 1.4019 - val_loss: 9.1466 - val_mae: 2.1587\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0646 - mae: 1.3675 - val_loss: 8.9317 - val_mae: 2.0747\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0792 - mae: 1.3344 - val_loss: 8.8231 - val_mae: 2.0731\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2225 - mae: 1.3970 - val_loss: 8.6746 - val_mae: 2.0476\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 1s 50ms/step - loss: 4.0598 - mae: 1.3726 - val_loss: 8.9977 - val_mae: 2.0922\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.9647 - mae: 1.3550 - val_loss: 8.8888 - val_mae: 2.1043\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0401 - mae: 1.3917 - val_loss: 9.1112 - val_mae: 2.1558\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0029 - mae: 1.3587 - val_loss: 8.7607 - val_mae: 2.0700\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.9628 - mae: 1.3922 - val_loss: 9.1562 - val_mae: 2.1450\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0767 - mae: 1.3465 - val_loss: 8.8769 - val_mae: 2.0649\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8421 - mae: 1.3323 - val_loss: 8.9272 - val_mae: 2.0733\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0108 - mae: 1.3336 - val_loss: 8.7664 - val_mae: 2.0623\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8040 - mae: 1.3326 - val_loss: 8.6787 - val_mae: 2.0757\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 3.8851 - mae: 1.3401 - val_loss: 8.9324 - val_mae: 2.1283\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8366 - mae: 1.3375 - val_loss: 9.2843 - val_mae: 2.1905\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.8658 - mae: 1.3093 - val_loss: 8.8172 - val_mae: 2.0878\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7709 - mae: 1.3208 - val_loss: 8.9892 - val_mae: 2.1361\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8236 - mae: 1.3443 - val_loss: 8.6858 - val_mae: 2.0631\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.9306 - mae: 1.3223 - val_loss: 9.2082 - val_mae: 2.1826\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6420 - mae: 1.2780 - val_loss: 8.8442 - val_mae: 2.1155\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6857 - mae: 1.3046 - val_loss: 8.6688 - val_mae: 2.0911\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8284 - mae: 1.3199 - val_loss: 8.7847 - val_mae: 2.1211\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 3.7389 - mae: 1.3262 - val_loss: 8.8521 - val_mae: 2.1162\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5045 - mae: 1.2798 - val_loss: 8.7881 - val_mae: 2.0982\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.6069 - mae: 1.2821 - val_loss: 9.4433 - val_mae: 2.2195\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.7241 - mae: 1.2940 - val_loss: 8.7590 - val_mae: 2.0885\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5157 - mae: 1.2846 - val_loss: 9.0568 - val_mae: 2.1585\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5621 - mae: 1.2736 - val_loss: 9.4776 - val_mae: 2.2334\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5797 - mae: 1.2784 - val_loss: 8.6360 - val_mae: 2.0731\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4627 - mae: 1.2912 - val_loss: 9.0952 - val_mae: 2.1493\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5159 - mae: 1.2535 - val_loss: 8.5787 - val_mae: 2.0563\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.7231 - mae: 1.2976 - val_loss: 8.5297 - val_mae: 2.0632\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2407 - mae: 1.2339 - val_loss: 8.5480 - val_mae: 2.0403\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3900 - mae: 1.2833 - val_loss: 8.4694 - val_mae: 2.0255\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 3.5388 - mae: 1.2694 - val_loss: 8.6140 - val_mae: 2.0705\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3488 - mae: 1.2321 - val_loss: 8.4625 - val_mae: 2.0423\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.4100 - mae: 1.2705 - val_loss: 8.4392 - val_mae: 2.0533\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3638 - mae: 1.2742 - val_loss: 8.8352 - val_mae: 2.1216\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4293 - mae: 1.2576 - val_loss: 8.5097 - val_mae: 2.0364\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2268 - mae: 1.2312 - val_loss: 8.5580 - val_mae: 2.0397\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3026 - mae: 1.2601 - val_loss: 8.4047 - val_mae: 2.0261\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2430 - mae: 1.2162 - val_loss: 8.3169 - val_mae: 2.0544\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2829 - mae: 1.2481 - val_loss: 8.4277 - val_mae: 2.0283\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.3216 - mae: 1.2450 - val_loss: 9.0388 - val_mae: 2.1633\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3237 - mae: 1.2426 - val_loss: 8.3631 - val_mae: 2.0139\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2524 - mae: 1.1972 - val_loss: 8.2963 - val_mae: 2.0246\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0393 - mae: 1.1982 - val_loss: 8.7556 - val_mae: 2.1343\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2258 - mae: 1.2340 - val_loss: 8.6103 - val_mae: 2.0611\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0218 - mae: 1.1807 - val_loss: 8.4302 - val_mae: 2.0604\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1093 - mae: 1.2158 - val_loss: 8.9856 - val_mae: 2.1479\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9861 - mae: 1.2210 - val_loss: 8.5321 - val_mae: 2.0394\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0770 - mae: 1.2225 - val_loss: 8.6429 - val_mae: 2.0872\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.0735 - mae: 1.1675 - val_loss: 8.5353 - val_mae: 2.0622\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9744 - mae: 1.1698 - val_loss: 8.3175 - val_mae: 2.0302\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1040 - mae: 1.2050 - val_loss: 8.2864 - val_mae: 2.0212\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1807 - mae: 1.1881 - val_loss: 8.7657 - val_mae: 2.0916\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9643 - mae: 1.1988 - val_loss: 8.2682 - val_mae: 2.0086\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9399 - mae: 1.1127 - val_loss: 8.5200 - val_mae: 2.0470\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9213 - mae: 1.1751 - val_loss: 9.0615 - val_mae: 2.1526\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 2.9908 - mae: 1.1813 - val_loss: 8.3460 - val_mae: 2.0234\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9054 - mae: 1.1539 - val_loss: 8.4645 - val_mae: 2.0419\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9091 - mae: 1.1710 - val_loss: 8.5100 - val_mae: 2.0876\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8591 - mae: 1.1496 - val_loss: 8.4215 - val_mae: 2.0714\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8996 - mae: 1.1543 - val_loss: 8.1527 - val_mae: 1.9909\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7833 - mae: 1.1298 - val_loss: 8.6515 - val_mae: 2.0655\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.8221 - mae: 1.1716 - val_loss: 8.3298 - val_mae: 2.0242\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8403 - mae: 1.1852 - val_loss: 8.4973 - val_mae: 2.0784\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.8294 - mae: 1.1649 - val_loss: 8.2977 - val_mae: 2.0736\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.7979 - mae: 1.1673 - val_loss: 8.4527 - val_mae: 2.0385\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7968 - mae: 1.1416 - val_loss: 8.3625 - val_mae: 2.0335\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8401 - mae: 1.1447 - val_loss: 8.3203 - val_mae: 2.0154\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.7233 - mae: 1.1355 - val_loss: 8.3191 - val_mae: 2.0208\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7848 - mae: 1.1341 - val_loss: 8.2611 - val_mae: 2.0576\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7951 - mae: 1.1688 - val_loss: 8.1409 - val_mae: 2.0139\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6293 - mae: 1.1147 - val_loss: 8.4355 - val_mae: 2.0339\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6296 - mae: 1.0995 - val_loss: 8.2730 - val_mae: 2.0056\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.8394 - mae: 1.1551 - val_loss: 8.2766 - val_mae: 2.0442\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7479 - mae: 1.1347 - val_loss: 8.1714 - val_mae: 1.9895\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6601 - mae: 1.0948 - val_loss: 8.0393 - val_mae: 2.0015\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7097 - mae: 1.1107 - val_loss: 8.2481 - val_mae: 2.0081\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5818 - mae: 1.1114 - val_loss: 8.2499 - val_mae: 2.0353\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6323 - mae: 1.1213 - val_loss: 8.0942 - val_mae: 1.9992\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 2.6789 - mae: 1.1350 - val_loss: 8.1090 - val_mae: 1.9980\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.4957 - mae: 1.0705 - val_loss: 8.4175 - val_mae: 2.0763\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6458 - mae: 1.1095 - val_loss: 7.7710 - val_mae: 1.9706\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.4522 - mae: 1.0681 - val_loss: 8.3460 - val_mae: 2.0451\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4491 - mae: 1.0415 - val_loss: 8.0190 - val_mae: 1.9681\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5528 - mae: 1.1213 - val_loss: 8.4654 - val_mae: 2.0787\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5524 - mae: 1.0879 - val_loss: 7.8477 - val_mae: 1.9884\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6320 - mae: 1.1057 - val_loss: 8.0583 - val_mae: 1.9754\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5132 - mae: 1.0787 - val_loss: 8.2697 - val_mae: 2.0357\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.5447 - mae: 1.0685 - val_loss: 8.2862 - val_mae: 2.0723\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 1s 54ms/step - loss: 2.5255 - mae: 1.0936 - val_loss: 7.8508 - val_mae: 1.9509\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.4986 - mae: 1.0993 - val_loss: 8.0287 - val_mae: 1.9920\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5071 - mae: 1.0382 - val_loss: 8.1723 - val_mae: 2.0074\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.4366 - mae: 1.0320 - val_loss: 8.0833 - val_mae: 2.0265\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3723 - mae: 1.0580 - val_loss: 8.1239 - val_mae: 1.9974\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3751 - mae: 1.0466 - val_loss: 8.0217 - val_mae: 1.9742\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4259 - mae: 1.0480 - val_loss: 8.5755 - val_mae: 2.0970\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3901 - mae: 1.0855 - val_loss: 8.1579 - val_mae: 2.0073\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3766 - mae: 1.0635 - val_loss: 8.1451 - val_mae: 2.0213\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 2.4287 - mae: 1.0554 - val_loss: 8.6212 - val_mae: 2.0777\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.3279 - mae: 1.0575 - val_loss: 8.6518 - val_mae: 2.1050\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2686 - mae: 1.0191 - val_loss: 8.1745 - val_mae: 2.0051\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.3924 - mae: 1.0636 - val_loss: 8.2709 - val_mae: 2.0443\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.4080 - mae: 1.0766 - val_loss: 8.1911 - val_mae: 1.9945\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1502 - mae: 1.0160 - val_loss: 8.2359 - val_mae: 2.0145\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2557 - mae: 1.0110 - val_loss: 8.4455 - val_mae: 2.0522\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1427 - mae: 1.0115 - val_loss: 8.0823 - val_mae: 2.0049\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0676 - mae: 1.0088 - val_loss: 8.1085 - val_mae: 1.9700\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1012 - mae: 1.0080 - val_loss: 8.6366 - val_mae: 2.0464\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.1899 - mae: 1.0057 - val_loss: 7.9554 - val_mae: 1.9720\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.1882 - mae: 1.0012 - val_loss: 8.1077 - val_mae: 2.0283\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.2097 - mae: 1.0078 - val_loss: 7.8855 - val_mae: 1.9768\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2471 - mae: 1.0134 - val_loss: 8.6355 - val_mae: 2.0896\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 2.1560 - mae: 1.0167 - val_loss: 8.3178 - val_mae: 2.0286\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2237 - mae: 1.0444 - val_loss: 8.8874 - val_mae: 2.1278\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0645 - mae: 1.0054 - val_loss: 8.1462 - val_mae: 1.9941\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1771 - mae: 1.0114 - val_loss: 8.3318 - val_mae: 2.0599\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3284 - mae: 1.0236 - val_loss: 8.5198 - val_mae: 2.0586\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1637 - mae: 1.0162 - val_loss: 7.9766 - val_mae: 1.9974\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1557 - mae: 0.9680 - val_loss: 8.0894 - val_mae: 1.9879\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0855 - mae: 0.9881 - val_loss: 9.0749 - val_mae: 2.1384\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.0569 - mae: 0.9906 - val_loss: 8.4670 - val_mae: 2.0846\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9940 - mae: 0.9778 - val_loss: 8.5331 - val_mae: 2.0723\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2340 - mae: 1.0249 - val_loss: 8.1381 - val_mae: 2.0044\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2204 - mae: 1.0179 - val_loss: 8.2072 - val_mae: 1.9976\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0506 - mae: 0.9764 - val_loss: 8.2400 - val_mae: 2.0242\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8734 - mae: 0.9529 - val_loss: 8.6739 - val_mae: 2.0537\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 2.2002 - mae: 0.9934 - val_loss: 8.3125 - val_mae: 2.0483\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.0264 - mae: 0.9643 - val_loss: 8.1462 - val_mae: 2.0280\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.9854 - mae: 0.9689 - val_loss: 7.9953 - val_mae: 2.0116\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1469 - mae: 0.9897 - val_loss: 8.3421 - val_mae: 2.0200\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8650 - mae: 0.9342 - val_loss: 7.9783 - val_mae: 1.9948\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9343 - mae: 0.9261 - val_loss: 8.2578 - val_mae: 2.0188\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9135 - mae: 0.9505 - val_loss: 8.6387 - val_mae: 2.0886\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9878 - mae: 0.9582 - val_loss: 8.8817 - val_mae: 2.1399\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 1.9052 - mae: 0.9640 - val_loss: 8.3062 - val_mae: 2.0412\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8745 - mae: 0.9709 - val_loss: 8.8112 - val_mae: 2.0830\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0199 - mae: 0.9733 - val_loss: 8.4241 - val_mae: 2.0393\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8401 - mae: 0.9396 - val_loss: 8.4001 - val_mae: 2.0417\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9929 - mae: 0.9582 - val_loss: 8.2539 - val_mae: 2.0452\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9629 - mae: 0.9225 - val_loss: 9.0625 - val_mae: 2.1621\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.7862 - mae: 0.9355 - val_loss: 9.0896 - val_mae: 2.1431\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8601 - mae: 0.9493 - val_loss: 8.5354 - val_mae: 2.1099\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8382 - mae: 0.9184 - val_loss: 8.3698 - val_mae: 2.0738\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8375 - mae: 0.9644 - val_loss: 8.2508 - val_mae: 2.0076\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8680 - mae: 0.9363 - val_loss: 8.1652 - val_mae: 2.0038\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8230 - mae: 0.9380 - val_loss: 8.2205 - val_mae: 2.0491\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9082 - mae: 0.9483 - val_loss: 8.3154 - val_mae: 2.0203\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7997 - mae: 0.9231 - val_loss: 8.4076 - val_mae: 2.0285\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8577 - mae: 0.9125 - val_loss: 8.5110 - val_mae: 2.0177\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7321 - mae: 0.8970 - val_loss: 8.5470 - val_mae: 2.0611\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8267 - mae: 0.9547 - val_loss: 8.3340 - val_mae: 2.0416\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.7537 - mae: 0.9237 - val_loss: 9.1086 - val_mae: 2.1137\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8774 - mae: 0.9557 - val_loss: 8.4475 - val_mae: 2.0384\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8051 - mae: 0.9205 - val_loss: 9.3593 - val_mae: 2.1666\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6776 - mae: 0.8837 - val_loss: 8.2974 - val_mae: 2.0592\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8914 - mae: 0.9680 - val_loss: 8.6998 - val_mae: 2.0730\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6930 - mae: 0.8917 - val_loss: 8.8904 - val_mae: 2.1260\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.6845 - mae: 0.8731 - val_loss: 8.4572 - val_mae: 2.0548\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6755 - mae: 0.8804 - val_loss: 8.1730 - val_mae: 2.0249\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6791 - mae: 0.9145 - val_loss: 8.7856 - val_mae: 2.1230\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7313 - mae: 0.8771 - val_loss: 8.8908 - val_mae: 2.0944\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7174 - mae: 0.8757 - val_loss: 8.9015 - val_mae: 2.0909\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7763 - mae: 0.9007 - val_loss: 9.3006 - val_mae: 2.1264\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.7038 - mae: 0.8856 - val_loss: 8.5924 - val_mae: 2.0540\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7821 - mae: 0.9093 - val_loss: 8.9917 - val_mae: 2.1302\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6289 - mae: 0.8870 - val_loss: 9.2936 - val_mae: 2.2091\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6018 - mae: 0.8487 - val_loss: 8.5672 - val_mae: 2.0496\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6795 - mae: 0.8760 - val_loss: 8.8059 - val_mae: 2.0862\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.5926 - mae: 0.8633 - val_loss: 8.4526 - val_mae: 2.0730\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.6342 - mae: 0.8730 - val_loss: 8.3840 - val_mae: 2.0782\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5851 - mae: 0.8549 - val_loss: 8.3396 - val_mae: 2.0306\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6726 - mae: 0.9082 - val_loss: 8.3457 - val_mae: 2.0330\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.5703 - mae: 0.8920 - val_loss: 8.6007 - val_mae: 2.0586\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6657 - mae: 0.8748 - val_loss: 8.8670 - val_mae: 2.1189\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4240 - mae: 0.8098 - val_loss: 8.7313 - val_mae: 2.1526\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8211 - mae: 0.9505 - val_loss: 8.9546 - val_mae: 2.1366\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3882 - mae: 0.8235 - val_loss: 8.9604 - val_mae: 2.1825\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5956 - mae: 0.8839 - val_loss: 8.7668 - val_mae: 2.0973\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5158 - mae: 0.8516 - val_loss: 9.2451 - val_mae: 2.1830\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5607 - mae: 0.8509 - val_loss: 8.9891 - val_mae: 2.1032\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4882 - mae: 0.8419 - val_loss: 9.3351 - val_mae: 2.1575\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 1.5528 - mae: 0.8842 - val_loss: 8.6930 - val_mae: 2.0915\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5238 - mae: 0.8449 - val_loss: 8.3931 - val_mae: 2.0324\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6184 - mae: 0.8899 - val_loss: 8.6300 - val_mae: 2.0915\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5809 - mae: 0.8825 - val_loss: 8.3266 - val_mae: 2.0259\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4949 - mae: 0.8395 - val_loss: 8.5695 - val_mae: 2.0490\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5733 - mae: 0.8753 - val_loss: 8.3424 - val_mae: 2.0107\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 1.5079 - mae: 0.8431 - val_loss: 8.6179 - val_mae: 2.0523\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5679 - mae: 0.8714 - val_loss: 8.7205 - val_mae: 2.0616\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5125 - mae: 0.8495 - val_loss: 9.6915 - val_mae: 2.2794\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3241 - mae: 0.7595 - val_loss: 8.8982 - val_mae: 2.1417\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5012 - mae: 0.8619 - val_loss: 8.4890 - val_mae: 2.0492\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4970 - mae: 0.8283 - val_loss: 8.4864 - val_mae: 2.0789\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4982 - mae: 0.8651 - val_loss: 8.7427 - val_mae: 2.0712\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4823 - mae: 0.8352 - val_loss: 8.9068 - val_mae: 2.0865\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4704 - mae: 0.8693 - val_loss: 9.2206 - val_mae: 2.1285\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4225 - mae: 0.8078 - val_loss: 8.7800 - val_mae: 2.0982\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4753 - mae: 0.8651 - val_loss: 8.7098 - val_mae: 2.0962\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4315 - mae: 0.8124 - val_loss: 8.8801 - val_mae: 2.0706\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3921 - mae: 0.8028 - val_loss: 10.0388 - val_mae: 2.2252\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2999 - mae: 0.7912 - val_loss: 9.0820 - val_mae: 2.1510\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5026 - mae: 0.8752 - val_loss: 8.9929 - val_mae: 2.1543\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3203 - mae: 0.7711 - val_loss: 9.0110 - val_mae: 2.0963\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4026 - mae: 0.8244 - val_loss: 8.8468 - val_mae: 2.1269\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4260 - mae: 0.8455 - val_loss: 8.7714 - val_mae: 2.1118\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4580 - mae: 0.8352 - val_loss: 9.1053 - val_mae: 2.1222\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 1.3873 - mae: 0.8105 - val_loss: 8.9029 - val_mae: 2.1200\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5741 - mae: 0.8727 - val_loss: 9.2676 - val_mae: 2.2287\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3907 - mae: 0.7795 - val_loss: 8.6495 - val_mae: 2.1261\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5059 - mae: 0.8654 - val_loss: 8.9539 - val_mae: 2.1484\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3266 - mae: 0.7988 - val_loss: 8.9048 - val_mae: 2.1307\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3561 - mae: 0.7851 - val_loss: 9.6649 - val_mae: 2.2134\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3330 - mae: 0.7585 - val_loss: 9.1743 - val_mae: 2.1219\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4028 - mae: 0.8207 - val_loss: 8.7090 - val_mae: 2.0984\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.4310 - mae: 0.8187 - val_loss: 8.6704 - val_mae: 2.0911\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2586 - mae: 0.7598 - val_loss: 8.8035 - val_mae: 2.1204\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2177 - mae: 0.7529 - val_loss: 9.5649 - val_mae: 2.2351\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3656 - mae: 0.8221 - val_loss: 8.8938 - val_mae: 2.1371\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2947 - mae: 0.7913 - val_loss: 8.7230 - val_mae: 2.0617\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3566 - mae: 0.8152 - val_loss: 8.9787 - val_mae: 2.1042\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2929 - mae: 0.7906 - val_loss: 8.8673 - val_mae: 2.1442\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2728 - mae: 0.7777 - val_loss: 9.2386 - val_mae: 2.1170\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2437 - mae: 0.7751 - val_loss: 8.6958 - val_mae: 2.0927\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.3267 - mae: 0.8145 - val_loss: 8.5050 - val_mae: 2.0576\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.2751 - mae: 0.7927 - val_loss: 8.9437 - val_mae: 2.1078\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2181 - mae: 0.7549 - val_loss: 8.7957 - val_mae: 2.1909\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4133 - mae: 0.8305 - val_loss: 8.9993 - val_mae: 2.1277\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3772 - mae: 0.7897 - val_loss: 8.9932 - val_mae: 2.1312\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1663 - mae: 0.7554 - val_loss: 9.5422 - val_mae: 2.1480\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3026 - mae: 0.7744 - val_loss: 8.9434 - val_mae: 2.1259\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2594 - mae: 0.7914 - val_loss: 8.7112 - val_mae: 2.0911\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.2455 - mae: 0.7740 - val_loss: 8.9995 - val_mae: 2.1400\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2566 - mae: 0.7686 - val_loss: 9.4108 - val_mae: 2.1349\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2568 - mae: 0.7729 - val_loss: 8.9545 - val_mae: 2.1648\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2125 - mae: 0.7499 - val_loss: 9.5878 - val_mae: 2.2740\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 1s 6ms/step - loss: 1.2596 - mae: 0.7993 - val_loss: 8.7959 - val_mae: 2.0806\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3419 - mae: 0.7926 - val_loss: 9.0101 - val_mae: 2.1145\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2735 - mae: 0.7732 - val_loss: 9.2437 - val_mae: 2.1428\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2856 - mae: 0.8114 - val_loss: 8.8040 - val_mae: 2.0686\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2822 - mae: 0.7751 - val_loss: 9.0853 - val_mae: 2.1705\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2704 - mae: 0.7787 - val_loss: 9.3280 - val_mae: 2.2156\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3626 - mae: 0.7937 - val_loss: 9.1849 - val_mae: 2.1136\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1897 - mae: 0.7428 - val_loss: 10.3158 - val_mae: 2.3417\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2007 - mae: 0.7707 - val_loss: 9.5515 - val_mae: 2.1611\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2376 - mae: 0.7860 - val_loss: 9.0128 - val_mae: 2.1570\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 1.2639 - mae: 0.7697 - val_loss: 9.8996 - val_mae: 2.2675\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9731 - mae: 0.6935 - val_loss: 10.3334 - val_mae: 2.2610\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2282 - mae: 0.7842 - val_loss: 8.8307 - val_mae: 2.1433\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1131 - mae: 0.7332 - val_loss: 9.2647 - val_mae: 2.1435\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3331 - mae: 0.8158 - val_loss: 9.2162 - val_mae: 2.1546\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2040 - mae: 0.7503 - val_loss: 9.1003 - val_mae: 2.2048\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 1.1936 - mae: 0.7400 - val_loss: 8.9903 - val_mae: 2.1522\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2452 - mae: 0.7538 - val_loss: 9.0363 - val_mae: 2.1622\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0978 - mae: 0.7237 - val_loss: 9.0008 - val_mae: 2.1630\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1582 - mae: 0.7350 - val_loss: 9.1950 - val_mae: 2.1577\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2355 - mae: 0.7738 - val_loss: 8.8477 - val_mae: 2.1272\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0145 - mae: 0.7161 - val_loss: 9.2861 - val_mae: 2.2273\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 1.2083 - mae: 0.7607 - val_loss: 9.6299 - val_mae: 2.2027\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2270 - mae: 0.7712 - val_loss: 9.1146 - val_mae: 2.1254\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1209 - mae: 0.7208 - val_loss: 9.0741 - val_mae: 2.0935\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.2170 - mae: 0.7549 - val_loss: 9.5311 - val_mae: 2.1889\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1025 - mae: 0.7054 - val_loss: 9.1518 - val_mae: 2.2087\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1608 - mae: 0.7369 - val_loss: 9.0493 - val_mae: 2.1132\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1675 - mae: 0.7322 - val_loss: 9.7612 - val_mae: 2.2055\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1034 - mae: 0.7155 - val_loss: 8.9921 - val_mae: 2.1604\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1799 - mae: 0.7522 - val_loss: 8.8650 - val_mae: 2.1701\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1180 - mae: 0.7223 - val_loss: 8.9932 - val_mae: 2.1555\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9748 - mae: 0.6936 - val_loss: 9.7704 - val_mae: 2.1988\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3040 - mae: 0.8004 - val_loss: 8.8351 - val_mae: 2.1222\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1.0796 - mae: 0.7193 - val_loss: 8.9198 - val_mae: 2.1271\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9948 - mae: 0.6993 - val_loss: 8.9117 - val_mae: 2.1016\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0197 - mae: 0.6697 - val_loss: 10.2615 - val_mae: 2.2792\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2503 - mae: 0.7759 - val_loss: 9.1797 - val_mae: 2.1775\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0598 - mae: 0.7199 - val_loss: 9.1505 - val_mae: 2.1349\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1872 - mae: 0.7209 - val_loss: 9.1874 - val_mae: 2.1283\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1.1439 - mae: 0.7488 - val_loss: 8.9150 - val_mae: 2.0906\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.9287 - mae: 0.6693 - val_loss: 9.2248 - val_mae: 2.1671\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 1s 11ms/step - loss: 1.1199 - mae: 0.7469 - val_loss: 9.0310 - val_mae: 2.1402\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1.0685 - mae: 0.7126 - val_loss: 9.3285 - val_mae: 2.1811\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1.0226 - mae: 0.7160 - val_loss: 9.9965 - val_mae: 2.2391\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1.1003 - mae: 0.7436 - val_loss: 9.2553 - val_mae: 2.2131\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0909 - mae: 0.7095 - val_loss: 9.3686 - val_mae: 2.2548\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1263 - mae: 0.7195 - val_loss: 9.3957 - val_mae: 2.2386\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1191 - mae: 0.7090 - val_loss: 9.2194 - val_mae: 2.1311\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0440 - mae: 0.6862 - val_loss: 9.6942 - val_mae: 2.1961\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.9627 - mae: 0.6545 - val_loss: 10.0588 - val_mae: 2.2221\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.0513 - mae: 0.7147 - val_loss: 9.1756 - val_mae: 2.1525\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1020 - mae: 0.7141 - val_loss: 9.3087 - val_mae: 2.1692\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0517 - mae: 0.7122 - val_loss: 10.3204 - val_mae: 2.2893\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0063 - mae: 0.6983 - val_loss: 9.6003 - val_mae: 2.2073\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9995 - mae: 0.6909 - val_loss: 9.6781 - val_mae: 2.1973\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0454 - mae: 0.6830 - val_loss: 9.9953 - val_mae: 2.2025\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0481 - mae: 0.7053 - val_loss: 10.3988 - val_mae: 2.2190\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0338 - mae: 0.7085 - val_loss: 9.7417 - val_mae: 2.1728\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0633 - mae: 0.6994 - val_loss: 9.3603 - val_mae: 2.2102\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 1.0315 - mae: 0.7218 - val_loss: 9.2931 - val_mae: 2.1479\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9839 - mae: 0.6793 - val_loss: 9.6329 - val_mae: 2.2298\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0942 - mae: 0.7525 - val_loss: 10.1422 - val_mae: 2.2015\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0500 - mae: 0.6977 - val_loss: 9.7587 - val_mae: 2.2277\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8716 - mae: 0.6617 - val_loss: 9.9239 - val_mae: 2.2274\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2092 - mae: 0.7719 - val_loss: 9.7359 - val_mae: 2.2107\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.9462 - mae: 0.6784 - val_loss: 10.3814 - val_mae: 2.3204\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1846 - mae: 0.7405 - val_loss: 9.4659 - val_mae: 2.1784\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9431 - mae: 0.6640 - val_loss: 9.4091 - val_mae: 2.1788\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1197 - mae: 0.7233 - val_loss: 9.2472 - val_mae: 2.1302\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9822 - mae: 0.6794 - val_loss: 9.7418 - val_mae: 2.2790\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9838 - mae: 0.6834 - val_loss: 9.3205 - val_mae: 2.1753\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.9577 - mae: 0.6698 - val_loss: 9.0771 - val_mae: 2.1792\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8727 - mae: 0.6393 - val_loss: 10.0309 - val_mae: 2.3050\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.9858 - mae: 0.7226 - val_loss: 9.1704 - val_mae: 2.1365\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9894 - mae: 0.6672 - val_loss: 9.7056 - val_mae: 2.1732\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0979 - mae: 0.7260 - val_loss: 10.0276 - val_mae: 2.2777\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9089 - mae: 0.6190 - val_loss: 9.3217 - val_mae: 2.2172\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0453 - mae: 0.7186 - val_loss: 10.2505 - val_mae: 2.2523\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0065 - mae: 0.7094 - val_loss: 9.7356 - val_mae: 2.3032\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9006 - mae: 0.6761 - val_loss: 9.8728 - val_mae: 2.2928\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.9308 - mae: 0.6685 - val_loss: 10.6621 - val_mae: 2.3375\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9497 - mae: 0.6834 - val_loss: 9.5025 - val_mae: 2.2163\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8983 - mae: 0.6731 - val_loss: 9.2240 - val_mae: 2.1675\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9089 - mae: 0.6687 - val_loss: 9.6398 - val_mae: 2.2470\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8461 - mae: 0.6440 - val_loss: 9.9586 - val_mae: 2.1879\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8907 - mae: 0.6635 - val_loss: 11.4544 - val_mae: 2.3624\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.0316 - mae: 0.7250 - val_loss: 9.7180 - val_mae: 2.2880\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0290 - mae: 0.6932 - val_loss: 10.4108 - val_mae: 2.3529\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8721 - mae: 0.6436 - val_loss: 9.9882 - val_mae: 2.2577\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0468 - mae: 0.7071 - val_loss: 10.0780 - val_mae: 2.2242\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8894 - mae: 0.6487 - val_loss: 11.3358 - val_mae: 2.3602\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0154 - mae: 0.6981 - val_loss: 10.2195 - val_mae: 2.2836\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8904 - mae: 0.6290 - val_loss: 10.3174 - val_mae: 2.2919\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.8970 - mae: 0.6424 - val_loss: 10.7921 - val_mae: 2.3509\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0667 - mae: 0.7009 - val_loss: 10.2480 - val_mae: 2.2319\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9209 - mae: 0.6532 - val_loss: 9.8464 - val_mae: 2.1768\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8769 - mae: 0.6341 - val_loss: 9.7518 - val_mae: 2.2056\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8241 - mae: 0.6206 - val_loss: 10.0749 - val_mae: 2.2448\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.9419 - mae: 0.6773 - val_loss: 10.1301 - val_mae: 2.2953\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8865 - mae: 0.6367 - val_loss: 9.6681 - val_mae: 2.1709\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9522 - mae: 0.6971 - val_loss: 10.4185 - val_mae: 2.3183\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8100 - mae: 0.6531 - val_loss: 9.8078 - val_mae: 2.2518\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.9040 - mae: 0.6511 - val_loss: 11.3221 - val_mae: 2.3036\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9162 - mae: 0.6766 - val_loss: 10.2329 - val_mae: 2.2633\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8598 - mae: 0.6331 - val_loss: 10.2764 - val_mae: 2.2512\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.9312 - mae: 0.6730 - val_loss: 10.0572 - val_mae: 2.3230\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9216 - mae: 0.6607 - val_loss: 10.3203 - val_mae: 2.2166\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.8351 - mae: 0.6275 - val_loss: 10.0373 - val_mae: 2.2805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxjP0zY6MP0h",
        "outputId": "2fe2d340-3c12-4154-edc9-add3a603d6ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 64)                896       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "metadata": {
        "id": "D0Vzwvxw0_HO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(average_mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vkSuFUDIJNn",
        "outputId": "76a3369e-dd2a-4c01-fd41-4adfe5b168ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_mae_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FisnsYzSBFB5",
        "outputId": "fb34fcce-efee-430f-85f0-1eb9732fb1cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19.142247200012207,\n",
              " 15.327553033828735,\n",
              " 10.700769662857056,\n",
              " 7.0130733251571655,\n",
              " 5.454574942588806,\n",
              " 4.7011436223983765,\n",
              " 4.248166024684906,\n",
              " 3.9593061208724976,\n",
              " 3.7256081104278564,\n",
              " 3.547416031360626,\n",
              " 3.426893413066864,\n",
              " 3.3134610652923584,\n",
              " 3.2042881846427917,\n",
              " 3.062356650829315,\n",
              " 3.007704734802246,\n",
              " 2.9396342635154724,\n",
              " 2.9438436031341553,\n",
              " 2.9089996218681335,\n",
              " 2.7892608046531677,\n",
              " 2.8169206380844116,\n",
              " 2.7475637197494507,\n",
              " 2.7082607746124268,\n",
              " 2.675617516040802,\n",
              " 2.623228430747986,\n",
              " 2.64769583940506,\n",
              " 2.5947539806365967,\n",
              " 2.657393455505371,\n",
              " 2.659130096435547,\n",
              " 2.593321919441223,\n",
              " 2.5664945244789124,\n",
              " 2.524509906768799,\n",
              " 2.5394167304039,\n",
              " 2.514582335948944,\n",
              " 2.52817302942276,\n",
              " 2.515795648097992,\n",
              " 2.4613752365112305,\n",
              " 2.5551562309265137,\n",
              " 2.467925548553467,\n",
              " 2.5407687425613403,\n",
              " 2.4703394770622253,\n",
              " 2.422700822353363,\n",
              " 2.458666682243347,\n",
              " 2.457096517086029,\n",
              " 2.476432979106903,\n",
              " 2.429387867450714,\n",
              " 2.391879826784134,\n",
              " 2.425384223461151,\n",
              " 2.456084907054901,\n",
              " 2.447623908519745,\n",
              " 2.425976872444153,\n",
              " 2.454066753387451,\n",
              " 2.4577853083610535,\n",
              " 2.382883906364441,\n",
              " 2.4913666248321533,\n",
              " 2.443827986717224,\n",
              " 2.3580848574638367,\n",
              " 2.3809394538402557,\n",
              " 2.4442291855812073,\n",
              " 2.4278854429721832,\n",
              " 2.369630455970764,\n",
              " 2.3547369837760925,\n",
              " 2.399932563304901,\n",
              " 2.417276442050934,\n",
              " 2.416521668434143,\n",
              " 2.326592594385147,\n",
              " 2.349112570285797,\n",
              " 2.371196687221527,\n",
              " 2.4308773279190063,\n",
              " 2.3639250993728638,\n",
              " 2.3673588931560516,\n",
              " 2.32922026515007,\n",
              " 2.3590757846832275,\n",
              " 2.3618423342704773,\n",
              " 2.326465368270874,\n",
              " 2.3634644150733948,\n",
              " 2.381256878376007,\n",
              " 2.306333363056183,\n",
              " 2.3467240631580353,\n",
              " 2.341736614704132,\n",
              " 2.373039424419403,\n",
              " 2.4262993335723877,\n",
              " 2.307493895292282,\n",
              " 2.376064419746399,\n",
              " 2.314812034368515,\n",
              " 2.286213457584381,\n",
              " 2.307184875011444,\n",
              " 2.2857522070407867,\n",
              " 2.3497490286827087,\n",
              " 2.303828477859497,\n",
              " 2.3532192707061768,\n",
              " 2.2951117753982544,\n",
              " 2.275082439184189,\n",
              " 2.350389003753662,\n",
              " 2.3167372047901154,\n",
              " 2.2974457144737244,\n",
              " 2.3026126623153687,\n",
              " 2.319095194339752,\n",
              " 2.3041701912879944,\n",
              " 2.251244992017746,\n",
              " 2.3763508796691895,\n",
              " 2.3253652155399323,\n",
              " 2.3402727842330933,\n",
              " 2.30328232049942,\n",
              " 2.2730956971645355,\n",
              " 2.4130553603172302,\n",
              " 2.3531300723552704,\n",
              " 2.314229518175125,\n",
              " 2.3011851012706757,\n",
              " 2.378874182701111,\n",
              " 2.3376744389533997,\n",
              " 2.2617533802986145,\n",
              " 2.268131047487259,\n",
              " 2.3936216831207275,\n",
              " 2.294864535331726,\n",
              " 2.3114617466926575,\n",
              " 2.3882675766944885,\n",
              " 2.3309711813926697,\n",
              " 2.3039802610874176,\n",
              " 2.3455913960933685,\n",
              " 2.294889450073242,\n",
              " 2.3432371020317078,\n",
              " 2.249588280916214,\n",
              " 2.2660736441612244,\n",
              " 2.249052971601486,\n",
              " 2.2905213534832,\n",
              " 2.310066342353821,\n",
              " 2.281298816204071,\n",
              " 2.3148202002048492,\n",
              " 2.3058340549468994,\n",
              " 2.3566052317619324,\n",
              " 2.246679425239563,\n",
              " 2.3166856169700623,\n",
              " 2.380152463912964,\n",
              " 2.25203999876976,\n",
              " 2.392392933368683,\n",
              " 2.253102868795395,\n",
              " 2.2448253333568573,\n",
              " 2.2351134121418,\n",
              " 2.2881560027599335,\n",
              " 2.282237261533737,\n",
              " 2.3644430935382843,\n",
              " 2.3018569946289062,\n",
              " 2.341909646987915,\n",
              " 2.353231728076935,\n",
              " 2.242712289094925,\n",
              " 2.301327019929886,\n",
              " 2.305687516927719,\n",
              " 2.231782078742981,\n",
              " 2.316203534603119,\n",
              " 2.268582761287689,\n",
              " 2.336392819881439,\n",
              " 2.2911022901535034,\n",
              " 2.3126426339149475,\n",
              " 2.225481629371643,\n",
              " 2.2487324476242065,\n",
              " 2.2299109399318695,\n",
              " 2.3245246410369873,\n",
              " 2.3079185485839844,\n",
              " 2.3183399438858032,\n",
              " 2.2565208673477173,\n",
              " 2.1927134096622467,\n",
              " 2.2952672839164734,\n",
              " 2.2792364060878754,\n",
              " 2.4081262350082397,\n",
              " 2.274456709623337,\n",
              " 2.303664207458496,\n",
              " 2.2707343697547913,\n",
              " 2.2834343910217285,\n",
              " 2.25761741399765,\n",
              " 2.29399910569191,\n",
              " 2.312351882457733,\n",
              " 2.269787460565567,\n",
              " 2.2679269313812256,\n",
              " 2.2693627178668976,\n",
              " 2.2998061180114746,\n",
              " 2.3294150829315186,\n",
              " 2.27985417842865,\n",
              " 2.3187186419963837,\n",
              " 2.3576104640960693,\n",
              " 2.3253276348114014,\n",
              " 2.3575469851493835,\n",
              " 2.324221760034561,\n",
              " 2.3106954395771027,\n",
              " 2.2845563292503357,\n",
              " 2.284827381372452,\n",
              " 2.288868248462677,\n",
              " 2.2622889280319214,\n",
              " 2.270023435354233,\n",
              " 2.428044617176056,\n",
              " 2.222106397151947,\n",
              " 2.317912071943283,\n",
              " 2.3232447803020477,\n",
              " 2.233696937561035,\n",
              " 2.250886470079422,\n",
              " 2.2833950519561768,\n",
              " 2.2843729853630066,\n",
              " 2.38873228430748,\n",
              " 2.301821231842041,\n",
              " 2.2427786886692047,\n",
              " 2.3021948635578156,\n",
              " 2.3567369282245636,\n",
              " 2.3266796469688416,\n",
              " 2.31745707988739,\n",
              " 2.349680185317993,\n",
              " 2.290871024131775,\n",
              " 2.2726051807403564,\n",
              " 2.270374894142151,\n",
              " 2.3013997673988342,\n",
              " 2.2819308638572693,\n",
              " 2.2622070908546448,\n",
              " 2.339614123106003,\n",
              " 2.3201742470264435,\n",
              " 2.27368426322937,\n",
              " 2.301262378692627,\n",
              " 2.3002416491508484,\n",
              " 2.3021830916404724,\n",
              " 2.3087321519851685,\n",
              " 2.335234522819519,\n",
              " 2.285112500190735,\n",
              " 2.356157958507538,\n",
              " 2.3440592288970947,\n",
              " 2.31649911403656,\n",
              " 2.2760578989982605,\n",
              " 2.3445791006088257,\n",
              " 2.262496590614319,\n",
              " 2.3017311096191406,\n",
              " 2.3328202962875366,\n",
              " 2.2773998379707336,\n",
              " 2.327065944671631,\n",
              " 2.256439685821533,\n",
              " 2.310967266559601,\n",
              " 2.3630608916282654,\n",
              " 2.3673874139785767,\n",
              " 2.279443860054016,\n",
              " 2.273821085691452,\n",
              " 2.2548162937164307,\n",
              " 2.385532557964325,\n",
              " 2.3932147920131683,\n",
              " 2.290620267391205,\n",
              " 2.373887002468109,\n",
              " 2.309747725725174,\n",
              " 2.2749865353107452,\n",
              " 2.3272717893123627,\n",
              " 2.3254653215408325,\n",
              " 2.3154743909835815,\n",
              " 2.340449631214142,\n",
              " 2.3201598525047302,\n",
              " 2.3194708228111267,\n",
              " 2.368740975856781,\n",
              " 2.291140466928482,\n",
              " 2.312598615884781,\n",
              " 2.3388238549232483,\n",
              " 2.3541436195373535,\n",
              " 2.3033597469329834,\n",
              " 2.370743751525879,\n",
              " 2.4159618616104126,\n",
              " 2.3587635159492493,\n",
              " 2.3231488466262817,\n",
              " 2.3880573213100433,\n",
              " 2.36041122674942,\n",
              " 2.29070907831192,\n",
              " 2.3277673721313477,\n",
              " 2.300839364528656,\n",
              " 2.3402169942855835,\n",
              " 2.312668204307556,\n",
              " 2.317630887031555,\n",
              " 2.3571167290210724,\n",
              " 2.3609196543693542,\n",
              " 2.3030662536621094,\n",
              " 2.3183772563934326,\n",
              " 2.2988577485084534,\n",
              " 2.3378066420555115,\n",
              " 2.332028329372406,\n",
              " 2.3691030144691467,\n",
              " 2.3142592906951904,\n",
              " 2.405697524547577,\n",
              " 2.346336007118225,\n",
              " 2.3264294862747192,\n",
              " 2.3089698553085327,\n",
              " 2.388058990240097,\n",
              " 2.3793984055519104,\n",
              " 2.3722839951515198,\n",
              " 2.2665978968143463,\n",
              " 2.3178844451904297,\n",
              " 2.3004565238952637,\n",
              " 2.395520567893982,\n",
              " 2.3198921978473663,\n",
              " 2.4248266220092773,\n",
              " 2.3472715616226196,\n",
              " 2.4031331539154053,\n",
              " 2.346871793270111,\n",
              " 2.4008477926254272,\n",
              " 2.3622413277626038,\n",
              " 2.380228817462921,\n",
              " 2.3996759057044983,\n",
              " 2.330841064453125,\n",
              " 2.4204569458961487,\n",
              " 2.456925928592682,\n",
              " 2.408958613872528,\n",
              " 2.3439429998397827,\n",
              " 2.424171030521393,\n",
              " 2.416608691215515,\n",
              " 2.3633540272712708,\n",
              " 2.3687886595726013,\n",
              " 2.3589335680007935,\n",
              " 2.405236303806305,\n",
              " 2.3595030903816223,\n",
              " 2.3882787823677063,\n",
              " 2.413386344909668,\n",
              " 2.425555646419525,\n",
              " 2.382093131542206,\n",
              " 2.5010745525360107,\n",
              " 2.382788360118866,\n",
              " 2.503390848636627,\n",
              " 2.4317177534103394,\n",
              " 2.4691948294639587,\n",
              " 2.4288452863693237,\n",
              " 2.414999306201935,\n",
              " 2.384202301502228,\n",
              " 2.3704764246940613,\n",
              " 2.3742377758026123,\n",
              " 2.425422430038452,\n",
              " 2.3797558546066284,\n",
              " 2.3910028636455536,\n",
              " 2.4837647676467896,\n",
              " 2.380198836326599,\n",
              " 2.4314640760421753,\n",
              " 2.4151763319969177,\n",
              " 2.38944673538208,\n",
              " 2.3871623873710632,\n",
              " 2.4765567779541016,\n",
              " 2.492187798023224,\n",
              " 2.405801832675934,\n",
              " 2.4254796504974365,\n",
              " 2.476015567779541,\n",
              " 2.4160764813423157,\n",
              " 2.448196589946747,\n",
              " 2.3976915180683136,\n",
              " 2.3601951003074646,\n",
              " 2.3855507373809814,\n",
              " 2.4872817397117615,\n",
              " 2.4003663063049316,\n",
              " 2.372291922569275,\n",
              " 2.4281598925590515,\n",
              " 2.453950345516205,\n",
              " 2.480934262275696,\n",
              " 2.4299874305725098,\n",
              " 2.40784227848053,\n",
              " 2.364046096801758,\n",
              " 2.3354169130325317,\n",
              " 2.3939866423606873,\n",
              " 2.408465325832367,\n",
              " 2.504050374031067,\n",
              " 2.419212818145752,\n",
              " 2.472228169441223,\n",
              " 2.4872308373451233,\n",
              " 2.476992964744568,\n",
              " 2.4079959392547607,\n",
              " 2.4836882948875427,\n",
              " 2.453216016292572,\n",
              " 2.470699667930603,\n",
              " 2.436859607696533,\n",
              " 2.4475162625312805,\n",
              " 2.518303871154785,\n",
              " 2.3992053866386414,\n",
              " 2.4456067085266113,\n",
              " 2.467806339263916,\n",
              " 2.5338443517684937,\n",
              " 2.4313400387763977,\n",
              " 2.402028203010559,\n",
              " 2.4012030959129333,\n",
              " 2.431686580181122,\n",
              " 2.4599461555480957,\n",
              " 2.4962156414985657,\n",
              " 2.4123908281326294,\n",
              " 2.4348166584968567,\n",
              " 2.4352193474769592,\n",
              " 2.4425904154777527,\n",
              " 2.4410706162452698,\n",
              " 2.458074688911438,\n",
              " 2.458951950073242,\n",
              " 2.4834492206573486,\n",
              " 2.4474951028823853,\n",
              " 2.439546287059784,\n",
              " 2.510011851787567,\n",
              " 2.4589931964874268,\n",
              " 2.5122637152671814,\n",
              " 2.5241501331329346,\n",
              " 2.4041098952293396,\n",
              " 2.437040090560913,\n",
              " 2.53328275680542,\n",
              " 2.449921727180481,\n",
              " 2.409450590610504,\n",
              " 2.5153549313545227,\n",
              " 2.4759644269943237,\n",
              " 2.4167966842651367,\n",
              " 2.4327375292778015,\n",
              " 2.5051903128623962,\n",
              " 2.4683464765548706,\n",
              " 2.4469577074050903,\n",
              " 2.4956820607185364,\n",
              " 2.5443572998046875,\n",
              " 2.5590165853500366,\n",
              " 2.4701384902000427,\n",
              " 2.453561305999756,\n",
              " 2.4474120140075684,\n",
              " 2.558367967605591,\n",
              " 2.413532316684723,\n",
              " 2.4453328251838684,\n",
              " 2.4614973068237305,\n",
              " 2.505393087863922,\n",
              " 2.40688294172287,\n",
              " 2.4580989480018616,\n",
              " 2.4600337743759155,\n",
              " 2.514829397201538,\n",
              " 2.4695738554000854,\n",
              " 2.490663170814514,\n",
              " 2.459615647792816,\n",
              " 2.432488739490509,\n",
              " 2.5261539220809937,\n",
              " 2.5116491317749023,\n",
              " 2.4802030324935913,\n",
              " 2.4728031754493713,\n",
              " 2.540480852127075,\n",
              " 2.4461714029312134,\n",
              " 2.548268437385559,\n",
              " 2.4405561089515686,\n",
              " 2.4739553332328796,\n",
              " 2.5306003093719482,\n",
              " 2.4624611735343933,\n",
              " 2.503488302230835,\n",
              " 2.4836639165878296,\n",
              " 2.4542133808135986,\n",
              " 2.5199065804481506,\n",
              " 2.4687145352363586,\n",
              " 2.546328842639923,\n",
              " 2.45679634809494,\n",
              " 2.4755001068115234,\n",
              " 2.513014853000641,\n",
              " 2.4799068570137024,\n",
              " 2.513184666633606,\n",
              " 2.5831741094589233,\n",
              " 2.4286943078041077,\n",
              " 2.5103214979171753,\n",
              " 2.5422508120536804,\n",
              " 2.5138043761253357,\n",
              " 2.5307832956314087,\n",
              " 2.515665590763092,\n",
              " 2.5475650429725647,\n",
              " 2.4826512932777405,\n",
              " 2.5086775422096252,\n",
              " 2.496333062648773,\n",
              " 2.519308030605316,\n",
              " 2.470806837081909,\n",
              " 2.4987744092941284,\n",
              " 2.4989452362060547,\n",
              " 2.4561054706573486,\n",
              " 2.503867983818054,\n",
              " 2.492779314517975,\n",
              " 2.5092756152153015,\n",
              " 2.47125643491745,\n",
              " 2.5460010766983032,\n",
              " 2.5069097876548767,\n",
              " 2.505133867263794,\n",
              " 2.510871112346649,\n",
              " 2.4505118131637573,\n",
              " 2.513506770133972,\n",
              " 2.526094436645508,\n",
              " 2.5001630187034607,\n",
              " 2.50624418258667,\n",
              " 2.498897671699524,\n",
              " 2.5669583082199097,\n",
              " 2.541294515132904,\n",
              " 2.505258858203888,\n",
              " 2.4693163633346558,\n",
              " 2.5262357592582703,\n",
              " 2.520207464694977,\n",
              " 2.5804412961006165,\n",
              " 2.506977081298828,\n",
              " 2.5905168652534485,\n",
              " 2.519646465778351,\n",
              " 2.4850769639015198,\n",
              " 2.5757290720939636,\n",
              " 2.5740060806274414,\n",
              " 2.5764652490615845,\n",
              " 2.5622183084487915,\n",
              " 2.50852769613266,\n",
              " 2.4836575388908386,\n",
              " 2.5476794242858887,\n",
              " 2.586451768875122,\n",
              " 2.5024317502975464,\n",
              " 2.4624820351600647,\n",
              " 2.5204455852508545,\n",
              " 2.518870770931244,\n",
              " 2.537438452243805,\n",
              " 2.5371108651161194,\n",
              " 2.502271831035614,\n",
              " 2.556026875972748,\n",
              " 2.550355017185211,\n",
              " 2.5514193773269653]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bZ_CjphBHXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "37705611-6d96-4bff-e1d5-c94c0565bdbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc5X3v8c9vZrQvli3JQl5lGwM2q4lwgEBi1oJDQpPQBJreACV1Qmib3tymSZqbkDZt781tmyaEFOIACSlLdhIgKUsMwQQCxgZMzOZ9XyRblqxdmpnf/eMcyTPSSBayR2Pk7/v1mpfOPOfMmeeYYb7zPOc5zzF3R0REZKBIrisgIiJHJwWEiIhkpIAQEZGMFBAiIpKRAkJERDKK5boCR1JVVZXX1dXluhoiIm8bq1at2uvu1ZnWjauAqKurY+XKlbmuhojI24aZbRlqnbqYREQkIwWEiIhkpIAQEZGMFBAiIpKRAkJERDJSQIiISEYKCBERyUgBAdyybB1PrW3MdTVERI4qCgjgtt9u4Jn1e3NdDRGRo4oCAohGjHhCN04SEUmlgCAIiKTurCcikkYBQdiCSCZzXQ0RkaOKAoIgIBLKBxGRNAoIIGpGQi0IEZE0CgjUghARyUQBQV9AKCFERFIpIIBYxNAoVxGRdAoIIKIWhIjIIAoIwhZEUk0IEZFUCgggYgoIEZGBFBBALKqAEBEZSAFB0IKIKyBERNIoINA5CBGRTBQQ9I1iUkCIiKSKZWvHZnYXcAXQ4O6nhGU/Ak4MN6kAmt39jAyv3Qy0Agkg7u712aonBC2InriGuYqIpMpaQADfB24FftBX4O4f6Vs2s38HWoZ5/QXuPiZ38YlGjISm+xYRSZO1gHD35WZWl2mdmRnwYeDCbL3/WxFVF5OIyCC5OgdxPrDH3dcNsd6Bx8xslZktGW5HZrbEzFaa2crGxtHdV1onqUVEBstVQFwD3D/M+vPc/UzgcuAmM3v3UBu6+1J3r3f3+urq6lFVRhfKiYgMNuYBYWYx4IPAj4baxt13hH8bgAeAhdmsky6UExEZLBctiIuBN9x9e6aVZlZiZmV9y8ClwJpsVkgtCBGRwbIWEGZ2P/B74EQz225mN4SrrmZA95KZTTGzX4dPa4DfmdlqYAXwK3d/JFv1hL7pvhUQIiKpsjmK6Zohyq/LULYTWBwubwROz1a9MolEjLhuCCEikkZXUhO0IJJqQYiIpFFAEFwHocn6RETSKSAIAiKpgBARSaOAAKKa7ltEZBAFBBCNRNSCEBEZQAEBRCOoBSEiMoACgqAFoesgRETSKSAIWhC6klpEJJ0CgrAFkXRcrQgRkX4KCIJRTABqRIiIHKSAIJjNFdTNJCKSSgFBMJsrKCBERFIpIAjmYgI0kklEJIUCgmA2V4CEZnQVEemngEAtCBGRTBQQHGxBxJPJHNdEROTooYDgYAtC+SAicpACgoPXQagFISJykAKC4H4QoBaEiEgqBQQHA0ItCBGRg7IWEGZ2l5k1mNmalLKvmNkOM3s5fCwe4rWXmdmbZrbezD6frTr26TtJrftSi4gclM0WxPeByzKU/4e7nxE+fj1wpZlFgW8DlwPzgWvMbH4W69l/DiKhBoSISL+sBYS7LweaRvHShcB6d9/o7j3AD4Erj2jlBoiG/wqaakNE5KBcnIP4SzN7JeyCmphh/VRgW8rz7WFZ1kRMXUwiIgONdUDcBswBzgB2Af9+uDs0syVmttLMVjY2No5qH30nqdWCEBE5aEwDwt33uHvC3ZPAdwm6kwbaAUxPeT4tLBtqn0vdvd7d66urq0dVr4im2hARGWRMA8LMalOefgBYk2GzF4C5ZjbLzPKBq4EHs1mv/hsGqQUhItIvlq0dm9n9wCKgysy2AzcDi8zsDMCBzcAnwm2nAHe4+2J3j5vZXwKPAlHgLnd/NVv1hNRzENl8FxGRt5esBYS7X5Oh+M4htt0JLE55/mtg0BDYbIloFJOIyCC6kprUe1IrIERE+igg0CgmEZFMFBBoFJOISCYKCDSKSUQkEwUE6mISEclEAYGm2hARyUQBQWoLIscVERE5iiggODibq1oQIiIHKSAAUxeTiMggCghSbxikgBAR6TNkQJjZj1OWvzZg3WPZrNRY0ygmEZHBhmtBzE1ZvmTAutHNq32U0j2pRUQGGy4ghvu2HFffpLontYjIYMPN5lpsZgsIQqQoXLbwUTQWlRsr/bO5qgUhItJvuIDYBXw9XN6dstz3fNzQVBsiIoMNGRDufsFQ68wsLzvVyQ2dpBYRGWzEw1wtcJGZ3Qlsz2KdxpxOUouIDHbIgDCzs83sFmAL8EtgOXBStis2ljQXk4jIYMNdB/EvZrYO+GfgFWAB0Ojud7v7/rGq4FjQKCYRkcGGO0n9cWAtcBvwkLt3m9m4/Ikd0VxMIiKDDNfFVAv8E/A+YIOZ/RfBcNfhQuVtSVNtiIgMNtwopgTwCPCImRUAVxBc/7DDzJa5+58Ot2Mzuyt8TYO7nxKW/StB4PQAG4Dr3b05w2s3A61AAoi7e/0ojm3ENIpJRGSwEY1icvdud/+Zu18FHE8QHIfyfeCyAWWPA6e4+2kE3VdfGOb1F7j7GdkOBwhmczVTF5OISKohWxBm9pnD2bG7LzezugFlqZP8PQdcdTjvcSRFzdSCEBFJMVwL4t+APwMqgVKgLOVRegTe+8+B/x5inQOPmdkqM1sy3E7MbImZrTSzlY2NjaOuTCRimmpDRCTFcCecFwDXAO8FVgH3A8vcD/9b1My+CMSBe4fY5Dx332Fmk4HHzewNd1+eaUN3XwosBaivrx913aJmKB9ERA4asgXh7qvd/fPufgZwJ3Al8JqZvf9w3tDMriM4ef3RocLG3XeEfxuAB4CFh/OeIxExnaQWEUk1kiupqwlaE6cSTLHRMNo3M7PLgL8D3u/uHUNsU2JmZX3LwKXAmtG+50hFIjoHISKSariT1H8OfBgoBH4KfDj8RT8iZnY/sAioMrPtwM0Eo5YKCLqNAJ5z90+a2RTgDndfDNQAD4TrY8B97j6SUVOHJRoxjWISEUkx3DmIOwh+uW8B/gi4NPzSBsDdh+1qcvdrMhTfOcS2O4HF4fJG4PRha50FGsUkIpJuuIAYcrrv8SiiFoSISJrhrqR+aiwrkmtqQYiIpBvx/SDGu2jENJuriEgKBUQoEtFUGyIiqRQQIXUxiYikO+TU3WZ2AvBZYGbq9u5+YRbrNeYippPUIiKpRnJvh58AtwPfJZh+e1zSKCYRkXQjCYi4u9+W9ZrkmLqYRETSjeQcxENm9ikzqzWzSX2PrNdsjEU0iklEJM1IWhDXhn8/m1LmwOwjX53ciWoUk4hImkMGhLvPGouK5Jq6mERE0o1kFFMecCPw7rDot8B33L03i/UaczpJLSKSbiRdTLcBecB/hs//R1j28WxVKhfUghARSTeSgDjL3VNnV33CzFZnq0K5ovtBiIikG8kopoSZzel7YmazGYfXQ0R1oZyISJqRtCA+CzxpZhsBI7ii+vqs1ioHohGjO66AEBHpM5JRTMvMbC5wYlj0prt3Z7daYy8aMRLKBxGRfsPdcvRCd3/CzD44YNXxZoa7/zzLdRtTsYiRSOpKORGRPsO1IN4DPAG8L8M6B8ZVQEQiRlxNCBGRfsPdUe7mcPEf3X1T6jozG3cXz8V0HYSISJqRjGL6WYayn45k52Z2l5k1mNmalLJJZva4ma0L/04c4rXXhtusM7NrM21zJEUiRlzDXEVE+g0ZEGZ2kpl9CJhgZh9MeVwHFI5w/98HLhtQ9nlgmbvPBZaFzwe+9yTgZuCdwELg5qGC5EiJRYykAkJEpN9w5yBOBK4AKkg/D9EK/MVIdu7uy82sbkDxlcCicPlugqk7Pjdgmz8CHnf3JgAze5wgaO4fyfuORlQtCBGRNMOdg/gl8EszO8fdf38E37PG3XeFy7uBmgzbTAW2pTzfHpYNYmZLgCUAM2bMGHWlNNWGiEi6kVwo95KZ3QScTErXkrv/+eG+ubu7mR3Wt7K7LwWWAtTX1496X7GoAkJEJNVITlL/F3AcQbfPU8A0gm6m0dpjZrUA4d+GDNvsAKanPJ8WlmVNVHMxiYikGUlAHO/uXwLa3f1u4L0EJ49H60EO3oToWuCXGbZ5FLjUzCaGJ6cvDcuyJmo6ByEikmokAdF334dmMzsFmABMHsnOzex+4PfAiWa23cxuAP4vcImZrQMuDp9jZvVmdgdAeHL6q8AL4eMf+05YZ0s0EtEoJhGRFCM5B7E0/BX/JYJf/6XAl0eyc3e/ZohVF2XYdiUp95hw97uAu0byPkdCLKoWhIhIqpFM1ndHuPgU4+w+1KkiZiR0JbWISL/hJuv7zHAvdPevH/nq5E5MJ6lFRNIM14IoC/+eCJxF0L0EwUVzK7JZqVzoG8Xk7phZrqsjIpJzw10o9w8AZrYcONPdW8PnXwF+NSa1G0PRSBAKSYeo8kFEZESjmGqAnpTnPWS++vltrS8g4ronhIgIMLJRTD8AVpjZA+HzPyaYhG9ciYUBofMQIiKBkYxi+mcz+2/g/LDoend/KbvVGntRBYSISJrhRjGVu/uBcOrtzeGjb92kbF+4NtYUECIi6YZrQdxHMN33KoJbjPax8Pm4uiZCXUwiIumGG8V0Rfh33N1eNJOIAkJEJM1wXUxnDvdCd3/xyFcnd2L9o5gUECIiMHwX078Ps86BC49wXXIqYmpBiIikGq6L6YKxrEiuxaIKCBGRVCO5DoJwmu/5pN9R7gfZqlQuRCPBNYPqYhIRCRwyIMzsZmARQUD8Grgc+B3BBXTjRtT6ptpQQIiIwMim2riK4P4Nu939euB0gpsGjSv9U20kFBAiIjCygOh09yQQN7NygntITz/Ea952YhG1IEREUo3kHMRKM6sAvktw0VwbwW1Ex5WohrmKiKQZ7jqIbwP3ufunwqLbzewRoNzdXxmT2o2hg1NtaDZXEREYvgWxFvg3M6sFfgzcPx4n6etzcKqNHFdEROQoMeQ5CHf/prufA7wH2AfcZWZvmNnNZnbCaN/QzE40s5dTHgfM7G8GbLPIzFpStvnyaN9vpCK6H4SISJqRTPe9Bfga8DUzWwDcBXwZiI7mDd39TeAMADOLAjuABzJs+nTffFBjQZP1iYikO+QoJjOLmdn7zOxe4L+BN4EPHqH3vwjYEIZQTmm6bxGRdMOdpL4EuAZYDKwAfggscff2I/j+VwP3D7HuHDNbDewE/tbdXx2inkuAJQAzZswYdUUUECIi6YZrQXwBeBaY5+7vd/f7jmQ4mFk+8H7gJxlWvwjMdPfTgW8BvxhqP+6+1N3r3b2+urp61PXRMFcRkXTDTdaX7dlaLwdedPc9Gd77QMryr83sP82syt33ZqsysXAupqQCQkQEGNmV1NlyDUN0L5nZcWbB5EhmtpCgnvuyWZlo+C+hFoSISGBEs7keaWZWAlwCfCKl7JMA7n47wfxPN5pZHOgErnbP7hwYfbO5aqoNEZFATgIiPJdROaDs9pTlW4Fbx7JOfcNcezVZn4gIkNsupqNKfiz4p+iJ60I5ERFQQPQrCAOiO57IcU1ERI4OCohQYV5wYXhXr1oQIiKggOjX14Lo6lULQkQEFBD9zIz8WIRunYMQEQEUEGkKYxG1IEREQgqIFAV5UbUgRERCCogUhXkRutWCEBEBFBBpCmNRujTMVUQEUECkKciL0K1hriIigAIijVoQIiIHKSBSqAUhInKQAiKFWhAiIgcpIFIU5EU01YaISEgBkaIwFtVkfSIiIQVEioK8qFoQIiIhBUSKgpgulBMR6aOASFGYF6VLU22IiAAKiDRlhTF64kmdhxARQQGRZkJRHgAtnb05romISO7lLCDMbLOZ/cHMXjazlRnWm5ndYmbrzewVMzsz23XqD4gOBYSISCzH73+Bu+8dYt3lwNzw8U7gtvBv1lQUBwHRrBaEiMhR3cV0JfADDzwHVJhZbTbfsKIoH4BmtSBERHIaEA48ZmarzGxJhvVTgW0pz7eHZWnMbImZrTSzlY2NjYdVob4WhM5BiIjkNiDOc/czCbqSbjKzd49mJ+6+1N3r3b2+urr6sCo0oa+LqaPnsPYjIjIe5Cwg3H1H+LcBeABYOGCTHcD0lOfTwrKsKc2PETG1IEREIEcBYWYlZlbWtwxcCqwZsNmDwMfC0UxnAy3uviub9YpEjAlFeTS1qwUhIpKrUUw1wANm1leH+9z9ETP7JIC73w78GlgMrAc6gOvHpGLlhew50DUWbyUiclTLSUC4+0bg9Azlt6csO3DTWNYLYEpFETubFRAiIkfzMNecmFJRyM6WzlxXQ0Qk5xQQA9ROKKK5o5eOnniuqyIiklMKiAGmVhQBsLNZrQgRObYpIAaoqyoBYENje45rIiKSWwqIAU6oKcUMXt91INdVERHJKQXEAMX5MWZVlvDGrtZcV0VEJKcUEBnMm1LOmp0tua6GiEhOKSAyWDC9gu37O2nQBXMicgxTQGRw5syJALy4dX+OayIikjsKiAxOmTKB4vwoT68b6l5GIiLjnwIig/xYhPOOr+LJNxoIZvwQETn2KCCGcNkpx7GzpYtnN+zLdVVERHJCATGExafWUlmSz/ee2ZTrqoiI5IQCYgiFeVE++s4ZLHujgS37dFW1iBx7FBDD+OjZM4macfezW3JdFRGRMaeAGEZNeSHvPa2Wn6zcRlu3ZncVkWOLAuIQrju3jtbuOEuXb8x1VURExpQC4hAWzJjIBxZM5ZZl6/jr+19iQ2NbrqskIjImFBAj8H8+eCoXz6vhwdU7+ch3nmN/e0+uqyQiknUKiBEozItyx7X13Pfxd7K3rZsFX32cFZuacl0tEZGsGvOAMLPpZvakmb1mZq+a2aczbLPIzFrM7OXw8eWxrmcm58yp5OPnzQLg+u+t4JE1u2jp6GXtnlY27dVQWBEZX2ysp5Iws1qg1t1fNLMyYBXwx+7+Wso2i4C/dfcr3sq+6+vrfeXKlUe0vpnsaunkxnte5OVtzf1l0YjxrWsWsPjU2v6yZNKJRCzr9RGRdN3xBBEz8qIRuuMJCmLRI7r/FzY3MbuqhMrSgsPaT2dPgu54gorifABe3tZMa1cvlSUFRCLQ0tFLTXkhdVUlvL7rAL2JJKdNq+h/fSLpdPYmKMqLEh3ld42ZrXL3+kzrYqPa42Fw913ArnC51cxeB6YCrw37wqNI7YQifvSJs/n2kxt4aPVOKorzaO7o5VP3vsjksgLm1pRSnB9j+dpGuuNJbjhvFv/7vfPojifJi0YG/Yds7uihuaO3/3anItnWm0jy2Kt7KMqPcNq0CipL8jFL/1w2tnZTXRZ8AXbHE6zavJ8zZ04kkXRKCmL95c3hl1h3PMGBznj/a3riSZa9vod31E1kW1Mnx08upbMnweSyAv6wo4VXtjdz+am1fOkXa7hx0RxOm1bB3rZuNja2s3DWpP56tHfH6epN8OaeVl7Z3sK6PW1cPG8yj7y6mw8smMor21u46h3T2NrUQV7UWLenja889CqnTavgunPr+NS9L/L4/3w32/d3MqOyGHfnwdW7OHv2JMoL87jtqQ2cO6eSR9bs5tkN+7h0fg1VpQXEosY7Z1Wyu6WT+1ZsZUpFEZefchwvbmnmRyu3ETE4ecoECvMiNHf00tGT4ENnTmV/Ry+zq4Pw6O4N/n1++MJWJpcVsmBGBaWFMV7deYC6ymJ+/uIO9nf08IEFU9na1MEz6zNP7TNjUjFbmzoAuP5ddWxobGfz3vb+ssqSfFZ96ZIj+yEhBy2ItDc3qwOWA6e4+4GU8kXAz4DtwE6C1sSrQ+xjCbAEYMaMGe/YsiU3F7X1xJP852/X8/S6vTS192TscsqLGlWlBVz1jmn86pVdlBbGaGztZldLcN+Jr33oVB5/rYFz51RyxWm1PPraHuoqi1k4axJLn9rI+06fkjFEOnsS3L9iKx96xzQmFOW9pXof6Orlzd2tnFV38H/Irt4EPYkkhbEosYiNqBXk7rR09vb/Ehqtls5etu/v4OQpE97ya9u64/zg95u54bxZab8Ys/ELMlVHT5y2rjiTywsPue3etm5Wbt7PJfNr6E0kKcwbvl7uzqs7DzCvtpx4Mkki6RTnB1/O+9t7WLG5iQlFedROKCSedCYU5bG7pYuvPfIG1WUFnDljIrGI8Sf109nQ2EZFUR7L1+3lG79Zy/b9nf3vc/q0Cdx0wfGcN7eK+57fyuZ97dzz3FbOnVPJ4lNrefTV3WmzG5cVxPjie+fx0Cs7eWb9Pj5/+Ul8/5nN7O/o4eb3ncyf1E/jKw++yr3Pbx10TLGIEU+mf+/Mrirh6oXTufWJ9RzoinNCTSnTJxazo7mTDY1t9Cay8z0VMUgexq6jEWPGpGJ27O+kJ5F8S69LhG88sTiP/R29g7YpyY/yzasX8NTaRv7ruS39P0QBJpcVMLOymDd3t/IX58+muCDGDWH391s1XAsiZwFhZqXAU8A/u/vPB6wrB5Lu3mZmi4FvuvvcQ+1zrLqYRmLNjhbW7mmlKC/K8nWN/H7DPhbOmsRv32ykobWb06dX0NrZS0tnL/sOMSrqlKnlrNkR5Oe82nLyYxFau3rZ2NjOKVPL6YknWbsnGH77qUVzuO5ddfxk5XZe2NzEWXWTKMqLEosa7zmhml0tXby0tZmfrtrGFadNYeWWJp5Zv4/rzq3jkTW7ufKMKaxraOOJNxqoqyympCDGwlmTiJpx3twqFp04mZaOXrriCVZsauKptY3UlBfw7Sc3AHDntfVcNK+GX7y0g+89s4nZ1aXU103kwpMmU5QXZfO+Dl7fdYCz6iZy/OQy1u5pZWdz8Oty2sRiPnTbs6zasp/n//4iasoL6U0k2d3SxbSJRbT3JFj2+h7MjJ+s3IaZceXpU1h8ai1F+VH+8aHXuOuZTdxw3iwumV/D2bMruX/FVr768Gv8+BPncO/zW6kuzae5s5ePnVPH7KoSEu48+upuehNJLppXQ3t3nHV72lixqYm1e1o5f24V8aRz2rQKNu1tp6Ioj+qyAv7tsTfp6k1w65+eyZW3PsPuA13EIsY3rj6DpEN3b4Km9h7W7mkjYrBw1iQeXL0z7Uu2JD/Kn50zk+rSApLu7O/o5cUtQXhMLM5nxaYmfrRyGwCXzq9h+/5OXtt1gIWzJnHp/Br+6Vevj/jzmB+L0BPP/AU2oSiPnniSzt7EiPeXyYk1ZbR1x9nR3JlWPr+2nEtPruEbv1nHrKoS5lSX0NTew4tbm6kqzeePTj6OH76wjUTSOXdOJQ2t3exr62ZKRRGTSvKZU13KvvYe9rZ2c9q0CUwuL+SrD7/G/NpydrZ0UlNWSENrFxOL83nPidXkRyN85tIT+Omq7Ty3sYln1u8lFjFmVhbzwub9XHFaLefPraKtO8Gja3bzsXNnUloQo7UrzrMb9tLY2s0FJ02mJ56kJD/G5n3tnHhcGdv3dzJtYhHHlRfiwFcffo2lH6tnakURENzHvrI0n6b2HnY1d7G9uZPywhgnT5nAln3tXHjSZLY2dXDv81u56YLjyYsaETMK86L8bt1easoLmFtTBgQ/dg509jIl3PeGxjYmlxWw50AXq7bs58P10zELQma0XUt9jrqAMLM84GHgUXf/+gi23wzUu/uwN2g4mgJiKM0dPaxvaOMdMydiZvTEkzy1tpHqsgLu/N0mrju3jmfW7+WN3Qe4/l2z+Kv7XiIWNS6eV8PWpg6Wr21k+oBfLNMnFbGtqfMQ73xkLJhRwZodLUP+ojt5Sjm1Ewr5zesNh9xXavDlxyKUF8bY23YwLGsnFNLU3kN3PMn82nIaWrvZ29Y9aD/5sQhFeVFaOtN/hZ1QU9ofnAOVFcQozI/S0R2nvefwvhjfqrPqJvLC5sw3o8r06xoO/uJ83+lTeGj1zrR1ZQUxMJhZWcy7jq/ily/t5C/ePZt4IskLm/dz/twqXtjcxK6WLiaV5POxc2ZiGD2JBOWFedTXTSKRdB5avZOXtzUzY1IxebEIc6pKyI9FqCjOZ31DKxfPq2Ffew+TywqIJ51bn1hPPBkE67Pr9/Lx82dTEItwz3Nb+OaydVx7Th2feM8c8qKGmdHWHae04GCv9u6WLiYU5VGUH2VncydN7T2cPKWc3oQTMYhFhx5Ds+dAV3+3VsSCL9qhvigTyWB/ZsaBrl7KC99aK3u8O6oCwoKOzruBJnf/myG2OQ7Y4+5uZguBnwIz/RCVfTsExFvVHU+QF4n0d/P0JpLEIkZXb/CLb3dLF/OnlNPRE2dncyert7WweV87xfkx5tWWsbGxnU1727l4fg3bmjqImPGd5Rv416tOpzg/yvee2cxNF8xh2/5OJhbnccfTm9jb1s1F82o4Y/oEqkoLWN/Qxktbm7nn+S24B7+G51SXMru6hKfWNrKzuZNJxfk8vX4vPfEkEYPLT6nl8lOPo7q0gE/es4qywjy2NnWQH4vw4fpp3PPcwa6HT75nDnc9s4meeJLjygtZdGI1ja3dtHXHSbpTV1nCxr3tTCzOY15tOXnRCNe/q468aISVm/fzm9f30NIZdJW9tutg4OCw+NTjOOG4Mr61bD2fu+xELppXQ0NrF3c/u4Xmzl5KC6K0dsU57/gqtoVdWxVFeWza185FJ9Wwdk8rP165ja7eBPV1k1ixqYn9HT38ywdOZUNjGz9dtZ3Kknw+fv5sOnsTPPlGA2fVTWJWVQmTSvKJJ5zl6xqZO7mUaZOKaenoZf6Ucg509dITT/KzVdupLC3g+MmlFOVFqS4r4NkNezGMC06qprMnQWFelJ54kq1NHZw6dQJf/MUfKIhF+XD9dKZNKhr0hafBEfJWHG0BcR7wNPAHoK/N+/fADAB3v93M/hK4EYgDncBn3P3ZQ+17PAbE0a7v89N3grO9O05PPMnEkoPnIvqawXvbuqkKR300d/Swo7mTsoI8ZlQWs7GxjZ+9uJ2/unDuIfvlh9PQ2kVXT5IJRXlYhP4vz3giOewvUpFj1VEVENmkgBAReWuGCwj9pBIRkYwUECIikpECQkREMlJAiIhIRgoIERHJSAEhIiIZKSBERCQjBYSIiGQ0ri6UM7NGYDTTuVYBw87zNA7pmI8NOlxAnFcAAAW4SURBVOZjw+Ec80x3r860YlwFxGiZ2cqhriQcr3TMxwYd87EhW8esLiYREclIASEiIhkpIAJLc12BHNAxHxt0zMeGrByzzkGIiEhGakGIiEhGCggREcnomA8IM7vMzN40s/Vm9vlc1+dIMbO7zKzBzNaklE0ys8fNbF34d2JYbmZ2S/hv8IqZnZm7mo+OmU03syfN7DUze9XMPh2Wj9tjBjCzQjNbYWarw+P+h7B8lpk9Hx7fj8wsPywvCJ+vD9fX5bL+o2VmUTN7ycweDp+P6+MFMLPNZvYHM3vZzFaGZVn9fB/TAWFmUeDbwOXAfOAaM5uf21odMd8HLhtQ9nlgmbvPBZaFzyE4/rnhYwlw2xjV8UiKA//L3ecDZwM3hf8tx/MxA3QDF7r76cAZwGVmdjbwNeA/3P14YD9wQ7j9DcD+sPw/wu3ejj4NvJ7yfLwfb58L3P2MlGsesvv5dvdj9gGcAzya8vwLwBdyXa8jeHx1wJqU528CteFyLfBmuPwd4JpM271dH8AvgUuOsWMuBl4E3klwVW0sLO//nAOPAueEy7FwO8t13d/icU4LvwwvBB4GbDwfb8pxbwaqBpRl9fN9TLcggKnAtpTn28Oy8arG3XeFy7uBmnB5XP07hN0IC4DnOQaOOexueRloAB4HNgDN7h4PN0k9tv7jDte3AJVjW+PD9g3g74Bk+LyS8X28fRx4zMxWmdmSsCyrn+/YaGsqb2/u7mY27sY4m1kp8DPgb9z9gJn1rxuvx+zuCeAMM6sAHgBOynGVssbMrgAa3H2VmS3KdX3G2HnuvsPMJgOPm9kbqSuz8fk+1lsQO4DpKc+nhWXj1R4zqwUI/zaE5ePi38HM8gjC4V53/3lYPK6POZW7NwNPEnSxVJhZ3w/A1GPrP+5w/QRg3xhX9XC8C3i/mW0GfkjQzfRNxu/x9nP3HeHfBoIfAgvJ8uf7WA+IF4C54QiIfOBq4MEc1ymbHgSuDZevJein7yv/WDjy4WygJaXZ+rZgQVPhTuB1d/96yqpxe8wAZlYdthwwsyKC8y6vEwTFVeFmA4+779/jKuAJDzup3w7c/QvuPs3d6wj+f33C3T/KOD3ePmZWYmZlfcvApcAasv35zvWJl1w/gMXAWoJ+2y/muj5H8LjuB3YBvQT9jzcQ9L0uA9YBvwEmhdsawWiuDcAfgPpc138Ux3seQR/tK8DL4WPxeD7m8DhOA14Kj3sN8OWwfDawAlgP/AQoCMsLw+frw/Wzc30Mh3Hsi4CHj4XjDY9vdfh4te+7Ktufb021ISIiGR3rXUwiIjIEBYSIiGSkgBARkYwUECIikpECQkREMlJAiByCmSXCGTT7Hkds1l8zq7OUGXdFjiaaakPk0Drd/YxcV0JkrKkFITJK4fz8/y+co3+FmR0flteZ2RPhPPzLzGxGWF5jZg+E925YbWbnhruKmtl3w/s5PBZeEY2Z/bUF97d4xcx+mKPDlGOYAkLk0IoGdDF9JGVdi7ufCtxKMMsowLeAu939NOBe4Jaw/BbgKQ/u3XAmwRWxEMzZ/213PxloBj4Uln8eWBDu55PZOjiRoehKapFDMLM2dy/NUL6Z4GY9G8OJAne7e6WZ7SWYe783LN/l7lVm1ghMc/fulH3UAY97cMMXzOxzQJ67/5OZPQK0Ab8AfuHubVk+VJE0akGIHB4fYvmt6E5ZTnDw3OB7CebTORN4IWW2UpExoYAQOTwfSfn7+3D5WYKZRgE+CjwdLi8DboT+m/xMGGqnZhYBprv7k8DnCKapHtSKEckm/SIRObSi8I5tfR5x976hrhPN7BWCVsA1YdlfAd8zs88CjcD1YfmngaVmdgNBS+FGghl3M4kC94QhYsAtHtzvQWTM6ByEyCiF5yDq3X1vrusikg3qYhIRkYzUghARkYzUghARkYwUECIikpECQkREMlJAiIhIRgoIERHJ6P8DXvFIrDnxrzYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see better the above plot, let's exclude some first points(20)\n",
        "truncated_mae_history = average_mae_history[20:]\n",
        "plt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "En_MfXGHI2Ho",
        "outputId": "3fc47732-aec4-469e-cada-b47ba9c85c5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see here, after 200 epochs, the model is getting worse. So, let's build a new one with let's say 130 epochs!"
      ],
      "metadata": {
        "id": "rurQ7ZqsKSuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this model\n",
        "results = model.evaluate(test_data, test_targets)  # returns test_mse_score, test_mae_score\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMYS5Jd-KjNP",
        "outputId": "bff93e89-9668-4c9c-b712-8456e9d63564"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 18.9302 - mae: 2.8036\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18.93019676208496, 2.803575038909912]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can also see in evaluation results, mainly in loss(mse), the model is not good, so we need to improve it"
      ],
      "metadata": {
        "id": "dwemZFzPNxNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final model"
      ],
      "metadata": {
        "id": "MwvzSN4WLdT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build and train the final model by limiting the number of epochs to 130\n",
        "model = build_model()\n",
        "\n",
        "history = model.fit(train_data, train_targets,\n",
        "          epochs=130, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2xMaQWOK_RM",
        "outputId": "80dcee86-7516-42aa-c845-ef27c13a769c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/130\n",
            "26/26 [==============================] - 1s 12ms/step - loss: 531.6440 - mae: 21.1361\n",
            "Epoch 2/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 374.9178 - mae: 17.2057\n",
            "Epoch 3/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 206.8637 - mae: 12.0583\n",
            "Epoch 4/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 89.8668 - mae: 7.2498\n",
            "Epoch 5/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 48.7396 - mae: 5.2013\n",
            "Epoch 6/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 32.5085 - mae: 4.1763\n",
            "Epoch 7/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 24.1644 - mae: 3.5032\n",
            "Epoch 8/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 20.2203 - mae: 3.1137\n",
            "Epoch 9/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 17.6646 - mae: 2.9076\n",
            "Epoch 10/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 16.1857 - mae: 2.8034\n",
            "Epoch 11/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 14.8802 - mae: 2.6751\n",
            "Epoch 12/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 13.8084 - mae: 2.6118\n",
            "Epoch 13/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 13.0665 - mae: 2.5285\n",
            "Epoch 14/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 12.2924 - mae: 2.4770\n",
            "Epoch 15/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 12.0097 - mae: 2.4220\n",
            "Epoch 16/130\n",
            "26/26 [==============================] - 5s 189ms/step - loss: 11.5646 - mae: 2.3783\n",
            "Epoch 17/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 11.2756 - mae: 2.3822\n",
            "Epoch 18/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 10.6216 - mae: 2.3003\n",
            "Epoch 19/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 10.4973 - mae: 2.3068\n",
            "Epoch 20/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 10.2698 - mae: 2.3175\n",
            "Epoch 21/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 10.1265 - mae: 2.2789\n",
            "Epoch 22/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 10.1055 - mae: 2.2893\n",
            "Epoch 23/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9.7613 - mae: 2.2259\n",
            "Epoch 24/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9.8361 - mae: 2.2040\n",
            "Epoch 25/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9.4257 - mae: 2.1970\n",
            "Epoch 26/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9.5958 - mae: 2.1976\n",
            "Epoch 27/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9.4359 - mae: 2.1982\n",
            "Epoch 28/130\n",
            "26/26 [==============================] - 2s 92ms/step - loss: 9.1017 - mae: 2.1405\n",
            "Epoch 29/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9.1163 - mae: 2.1599\n",
            "Epoch 30/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.9111 - mae: 2.1184\n",
            "Epoch 31/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.9697 - mae: 2.1477\n",
            "Epoch 32/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.9580 - mae: 2.1152\n",
            "Epoch 33/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.6133 - mae: 2.1159\n",
            "Epoch 34/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.7079 - mae: 2.0909\n",
            "Epoch 35/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.3663 - mae: 2.0392\n",
            "Epoch 36/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.3872 - mae: 2.0616\n",
            "Epoch 37/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.2701 - mae: 2.0509\n",
            "Epoch 38/130\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 8.2634 - mae: 2.0013\n",
            "Epoch 39/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.1223 - mae: 2.0502\n",
            "Epoch 40/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.1839 - mae: 1.9947\n",
            "Epoch 41/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.1188 - mae: 2.0336\n",
            "Epoch 42/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.8118 - mae: 1.9709\n",
            "Epoch 43/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.8740 - mae: 1.9554\n",
            "Epoch 44/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.9007 - mae: 2.0081\n",
            "Epoch 45/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.6895 - mae: 1.9625\n",
            "Epoch 46/130\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 7.6448 - mae: 1.9386\n",
            "Epoch 47/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.7821 - mae: 1.9562\n",
            "Epoch 48/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.4831 - mae: 1.9496\n",
            "Epoch 49/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.6435 - mae: 1.9594\n",
            "Epoch 50/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.3122 - mae: 1.9201\n",
            "Epoch 51/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.5316 - mae: 1.9148\n",
            "Epoch 52/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.1590 - mae: 1.8996\n",
            "Epoch 53/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.3255 - mae: 1.9324\n",
            "Epoch 54/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.1402 - mae: 1.8979\n",
            "Epoch 55/130\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 7.2836 - mae: 1.9127\n",
            "Epoch 56/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.1537 - mae: 1.8587\n",
            "Epoch 57/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.0016 - mae: 1.8694\n",
            "Epoch 58/130\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 7.2251 - mae: 1.8844\n",
            "Epoch 59/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.0739 - mae: 1.8746\n",
            "Epoch 60/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7.0392 - mae: 1.8843\n",
            "Epoch 61/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.9503 - mae: 1.8551\n",
            "Epoch 62/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.9837 - mae: 1.8617\n",
            "Epoch 63/130\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 7.0028 - mae: 1.8750\n",
            "Epoch 64/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.7238 - mae: 1.8374\n",
            "Epoch 65/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.8315 - mae: 1.8613\n",
            "Epoch 66/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.6833 - mae: 1.8363\n",
            "Epoch 67/130\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 6.8854 - mae: 1.8474\n",
            "Epoch 68/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.6154 - mae: 1.8166\n",
            "Epoch 69/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.6660 - mae: 1.8401\n",
            "Epoch 70/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.4703 - mae: 1.8001\n",
            "Epoch 71/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.6163 - mae: 1.8064\n",
            "Epoch 72/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.5135 - mae: 1.7980\n",
            "Epoch 73/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.4049 - mae: 1.7847\n",
            "Epoch 74/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.4561 - mae: 1.7925\n",
            "Epoch 75/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.4393 - mae: 1.7987\n",
            "Epoch 76/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.2917 - mae: 1.7825\n",
            "Epoch 77/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.2620 - mae: 1.7623\n",
            "Epoch 78/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.3295 - mae: 1.7988\n",
            "Epoch 79/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.3777 - mae: 1.7678\n",
            "Epoch 80/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.2037 - mae: 1.7712\n",
            "Epoch 81/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.2742 - mae: 1.7676\n",
            "Epoch 82/130\n",
            "26/26 [==============================] - 1s 34ms/step - loss: 6.1754 - mae: 1.7705\n",
            "Epoch 83/130\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 6.1573 - mae: 1.7547\n",
            "Epoch 84/130\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 6.1612 - mae: 1.7714\n",
            "Epoch 85/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.0232 - mae: 1.7412\n",
            "Epoch 86/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.9763 - mae: 1.7266\n",
            "Epoch 87/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.0258 - mae: 1.7589\n",
            "Epoch 88/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.7557 - mae: 1.6866\n",
            "Epoch 89/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.8601 - mae: 1.7293\n",
            "Epoch 90/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.8371 - mae: 1.7047\n",
            "Epoch 91/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.8607 - mae: 1.7299\n",
            "Epoch 92/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.8450 - mae: 1.7216\n",
            "Epoch 93/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.9145 - mae: 1.7217\n",
            "Epoch 94/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.7169 - mae: 1.6835\n",
            "Epoch 95/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.8405 - mae: 1.7004\n",
            "Epoch 96/130\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 5.6795 - mae: 1.6925\n",
            "Epoch 97/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.7230 - mae: 1.7097\n",
            "Epoch 98/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.6493 - mae: 1.6941\n",
            "Epoch 99/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.5148 - mae: 1.6449\n",
            "Epoch 100/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.4781 - mae: 1.6559\n",
            "Epoch 101/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.6662 - mae: 1.7219\n",
            "Epoch 102/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.5022 - mae: 1.6483\n",
            "Epoch 103/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.4069 - mae: 1.6437\n",
            "Epoch 104/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.3679 - mae: 1.6398\n",
            "Epoch 105/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.4225 - mae: 1.6697\n",
            "Epoch 106/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.0827 - mae: 1.6162\n",
            "Epoch 107/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.2708 - mae: 1.6457\n",
            "Epoch 108/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.3077 - mae: 1.6427\n",
            "Epoch 109/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.4246 - mae: 1.6518\n",
            "Epoch 110/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.4281 - mae: 1.6373\n",
            "Epoch 111/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.2918 - mae: 1.6351\n",
            "Epoch 112/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.1289 - mae: 1.6137\n",
            "Epoch 113/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.2612 - mae: 1.6395\n",
            "Epoch 114/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.9500 - mae: 1.5818\n",
            "Epoch 115/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.2668 - mae: 1.6146\n",
            "Epoch 116/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.9655 - mae: 1.5856\n",
            "Epoch 117/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.1073 - mae: 1.5772\n",
            "Epoch 118/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.2119 - mae: 1.6142\n",
            "Epoch 119/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.1181 - mae: 1.5897\n",
            "Epoch 120/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.0265 - mae: 1.5926\n",
            "Epoch 121/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.0041 - mae: 1.5990\n",
            "Epoch 122/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.9027 - mae: 1.5571\n",
            "Epoch 123/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.8974 - mae: 1.5627\n",
            "Epoch 124/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.9709 - mae: 1.5602\n",
            "Epoch 125/130\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 5.0529 - mae: 1.6028\n",
            "Epoch 126/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.9740 - mae: 1.5776\n",
            "Epoch 127/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.9189 - mae: 1.5427\n",
            "Epoch 128/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.8146 - mae: 1.5479\n",
            "Epoch 129/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.6763 - mae: 1.5360\n",
            "Epoch 130/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.7562 - mae: 1.5257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the final model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-OgOExKMA6_",
        "outputId": "3ce6904f-7940-41c3-d53c-2e9766b976f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this final model\n",
        "results = model.evaluate(test_data, test_targets)  # returns test_mse_score, test_mae_score\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNOFEm5Miox",
        "outputId": "3bbf21e9-04be-49d4-c93e-7decc89d9265"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 16.2499 - mae: 2.7228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16.249860763549805, 2.722780704498291]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mse and mae here are decreased from the previous ones"
      ],
      "metadata": {
        "id": "ce7ZTUCXP1gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions. understand the outputs\n",
        "predictions = model.predict(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfmGEsS9M2q7",
        "outputId": "6aba26a6-e307-4c6e-c723-ca57345576bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV2ROPSCQOOX",
        "outputId": "bfa49659-3583-4f01-ee7c-7b1f7326c405"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every prediction is a scalar\n",
        "predictions[10].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqZm6sAM2nZ",
        "outputId": "0232a2aa-aca3-4b1f-b333-bf8eab453986"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a prediction \n",
        "predictions[10] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMn_Xxq3NQt-",
        "outputId": "0a8f76d3-335d-4723-e7e4-c713bf593d18"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.84524], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and check it manually with its initial test_target \n",
        "test_targets[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdRW6RJYNVc5",
        "outputId": "b54240df-cded-424a-d5f4-2df3769a4d3d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.6"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction[10] and test_target[10] are different, however their distance is small. That's what we are trying to do in all ml and dl problems: to minimize this distance!"
      ],
      "metadata": {
        "id": "KwnSuVa1QdtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, the universal workflow in machine learning(especially when working with NNs):"
      ],
      "metadata": {
        "id": "Chq4Do1_Zyxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the problem and collect the data\n",
        "2. Choose the metrics\n",
        "3. Prepare your data and split to train/val/test sets\n",
        "4. Build, train and evaluate the first model\n",
        "5. Improve the model via addressing overfitting and hyperparameter tuning"
      ],
      "metadata": {
        "id": "cAOOoylVadDf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ff_1urlNNi5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}