{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MFz5awredGSV",
        "ybXGtqNVD2U5",
        "w4BQ3F6wT_QT",
        "WCP4acTg0dlO"
      ],
      "authorship_tag": "ABX9TyOlU3km6f2YE2eMxtSwL3LM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX7000/deep-learning-with-python/blob/main/DeepLearning_with_Python_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning examples from the book 'Deep Learning with Python', Part 1, Francois Chollet"
      ],
      "metadata": {
        "id": "UyI5AtRpc4xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1. Classify grayscale images(28x28) of handwritten digits from mnist dataset into 10 categories"
      ],
      "metadata": {
        "id": "MFz5awredGSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a multi-class Classification problem"
      ],
      "metadata": {
        "id": "1WqEJyKNWUte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand what you really have"
      ],
      "metadata": {
        "id": "uGJrI8r7Wayt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9pHWjjhWgm9",
        "outputId": "d77702d6-ac5a-4ac5-fb4b-c7f73f1715ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "X_train: (60000, 28, 28)\n",
            "y_train: (60000,)\n",
            "X_test: (10000, 28, 28)\n",
            "y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# import the data\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(f'X_train: {train_images.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_images.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pre-process the data: preparing/bringing it to the right form to feed our NN"
      ],
      "metadata": {
        "id": "9NZ9CwrW8DDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorization, value Normalization, handling missing values, feature engineering to name but a few of the steps you need to do during pre-processing of your data!"
      ],
      "metadata": {
        "id": "GbhytbFuXcL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's visualize some examples to see what we have here\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_images[10], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qRRLzG8VNTz1",
        "outputId": "ed4f22fb-0564-4764-d176-0a4d5bae5788"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_images[10], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "t4g_B296PIWs",
        "outputId": "eba85739-ff57-483c-afc3-f18eac6f11c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many times in which we need to shuffle the dataset before split it to train and test sets. This is because of data representativeness(more @page100). This is a step during feature engineering like for example feature redundancy you need to do every time you pre-process the data"
      ],
      "metadata": {
        "id": "XSXLl-S2WjLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we have 60000 examples(images) that are 28x28 each (on greyscale) and they are all filled with numbers between 0-255(the higher the number is the more grey the image is)\n",
        "# so, we transform these images in an array of (60000, 28x28) with values between 0 and 1\n",
        "# and we we actually have 60000 examples of 28*28 length each with values between 0 and 1\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "jQQQ71ZFmVLF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot representation for train and test labels. As we have 10 classes to predict as output(output is a number between 0-9 representing the digits)\n",
        "# we transform the output values from 0-9 to 0-1 one-hot representation\n",
        "\n",
        "print(f'10th element of train_labels before one-hot: {train_labels[10]}')\n",
        "\n",
        "# one-hot encoding for output labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(f'10th element of train_labels after one-hot: {train_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzI-eHCI4bQV",
        "outputId": "39390d30-448e-4f3e-d7dd-eef432095d01"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10th element of train_labels before one-hot: 3\n",
            "10th element of train_labels after one-hot: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the new dimensions now\n",
        "print(f'X_train: {train_images.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_images.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fopOLZFP_Jpk",
        "outputId": "f62d6b0a-b3c9-4f45-808a-0c33c50867b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (60000, 784)\n",
            "y_train: (60000, 10)\n",
            "X_test: (10000, 784)\n",
            "y_test: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define and train the model "
      ],
      "metadata": {
        "id": "nG_-YS1n8ej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# network's architecture\n",
        "# import the aproppriate modules\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# compilation step\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128) \n",
        "\n",
        "# deep learning models don't process an entire dataset at once! they break the data into small batches=> computationaly cheaper\n",
        "# so batch_size=128 means: 1st batch=train_images[:128], 2nd batch: train_images[128:256], ...train_images[128*n:128*(n+1)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcybQF6nuqEP",
        "outputId": "2f912fe3-974c-4894-ab50-571389b1456f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 10s 18ms/step - loss: 0.2559 - accuracy: 0.9254\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.1044 - accuracy: 0.9690\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0689 - accuracy: 0.9793\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0497 - accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0385 - accuracy: 0.9886\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbff08f5490>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some model's info\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9urxNtynCVS-",
        "outputId": "2f054a9a-3706-40ed-da71-77bae60a8596"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Predict and evaluate the model"
      ],
      "metadata": {
        "id": "qSs0VzpI-y5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "# returns a 10-element for each example with the highest probability in the index which represents a digit\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "print(f'\\n the digit-prediction for the first element of test_labels is: {predictions[10]}\\n')\n",
        "print(f'the actual-digit of the first element of test_labels is: {test_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zC1RxAb7StG",
        "outputId": "28d29205-96cb-437c-b151-6aeeb41fa593"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n",
            "\n",
            " the digit-prediction for the first element of test_labels is: [9.99999583e-01 2.16026076e-15 2.68618209e-07 5.64765068e-10\n",
            " 8.18700915e-14 7.29641858e-09 1.17533325e-08 3.82646448e-08\n",
            " 8.99298830e-11 8.67654109e-08]\n",
            "\n",
            "the actual-digit of the first element of test_labels is: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2. Tensors: the inputs of NNs"
      ],
      "metadata": {
        "id": "ybXGtqNVD2U5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks take as inputs Tensors. Tensor is a generalization of matrices to a number of dimensions. \n",
        "Each tensor has 3 attributes: 1) the rank: number of axis(dimensions), 2) the shape: how many dimensions the tensor has along each axis and 3) data type: the type of the data contained in the tensor "
      ],
      "metadata": {
        "id": "z6Nm611fFcf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "l0UiQntBG3lU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar(0D-tensor): rank-0 tensor \n",
        "x=np.array(12)\n",
        "print(x)       \n",
        "\n",
        "# ndim gives us the axis(=>dimension) of the tensor\n",
        "print(x.ndim)"
      ],
      "metadata": {
        "id": "bck-bYz3IZug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2dea7d8-0eb8-459a-8cc1-a46a39c4af48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector(1D-tensor): rank-1 tensor \n",
        "x1 = np.array([12, 3, 6, 14, 7])\n",
        "print(x1)\n",
        "\n",
        "print(f'the rank of the tensor is: {x1.ndim}')\n",
        "print(f'the shape of the tensor is: {x1.shape}') \n",
        "print(f'the data type of the tensor is: {x1.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNMN4RYAGmOH",
        "outputId": "64040220-48e6-4324-b496-a2e4eca28b37"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12  3  6 14  7]\n",
            "the rank of the tensor is: 1\n",
            "the shape of the tensor is: (5,)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(2D-tensor): rank-2 tensor\n",
        "x2 = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "print(x2)\n",
        "\n",
        "print(f'the rank of the tensor is: {x2.ndim}')\n",
        "print(f'the shape of the tensor is: {x2.shape}') \n",
        "print(f'the data type of the tensor is: {x2.dtype}')"
      ],
      "metadata": {
        "id": "6FZP3K08IZr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40500b5-4fb3-4917-bafc-2db437031a90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n",
            "the rank of the tensor is: 2\n",
            "the shape of the tensor is: (3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(3D-tensor): rank-3 tensor\n",
        "x3 = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "print(x3)\n",
        "\n",
        "print(f'the rank of the tensor is: {x3.ndim}')\n",
        "print(f'the shape of the tensor is: {x3.shape}') # the shape of the tensor is the shape of each axis of the tensor\n",
        "print(f'the data type of the tensor is: {x3.dtype}')"
      ],
      "metadata": {
        "id": "jICHuBZJIZpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde52a7b-0bfd-44de-f646-d5b55a6a8162"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]]\n",
            "the rank of the tensor is: 3\n",
            "the shape of the tensor is: (3, 3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice(4D-tensor): rank-4 tensor, the same happens to all higher rank tensors\n",
        "x4 = np.array([\n",
        "    [\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "    ],\n",
        "    [\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],\n",
        "\n",
        "    [[5, 78, 2, 34, 0],\n",
        "    [6, 79, 3, 35, 1],\n",
        "    [7, 80, 4, 36, 2]],  \n",
        "    ]\n",
        "   ])\n",
        "print(x4)\n",
        "\n",
        "print(f'the rank of the tensor is: {x4.ndim}')\n",
        "print(f'the shape of the tensor is: {x4.shape}') # the shape of the tensor is the shape of each axis of the tensor\n",
        "print(f'the data type of the tensor is: {x4.dtype}')"
      ],
      "metadata": {
        "id": "gF0mLMIyIZgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84de3713-b432-4089-9fed-f528537398d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]]\n",
            "\n",
            "\n",
            " [[[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]\n",
            "\n",
            "  [[ 5 78  2 34  0]\n",
            "   [ 6 79  3 35  1]\n",
            "   [ 7 80  4 36  2]]]]\n",
            "the rank of the tensor is: 4\n",
            "the shape of the tensor is: (2, 3, 3, 5)\n",
            "the data type of the tensor is: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 types of operations between tensors: 1) element-wise operations, 2) dot product and 3) reshaping"
      ],
      "metadata": {
        "id": "vocbHZAHcKwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# broadcasting: the smaller tensor will be broadcasted to match the shape of the larger tensor when applying two tensor element-wise operations\n",
        "z1 = np.maximum(x4, x3)\n",
        "z2 = np.minimum(x4, x2)\n",
        "z3 = np.maximum(x3, x2)\n",
        "z4 = np.maximum(x4, x1)"
      ],
      "metadata": {
        "id": "4vOP0LmAZlsm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3. Classifying movie reviews, based on text content, into positive or negative"
      ],
      "metadata": {
        "id": "6JEOWtW9T0-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a Binary Classification problem"
      ],
      "metadata": {
        "id": "CX_jHucQWDBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand it"
      ],
      "metadata": {
        "id": "d7Muxn2qEwXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data\n",
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # num_words=10000 means that we only keep the top 10000 most frequently occuring words in the training data\n",
        " \n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bN_XeAFT4Yj",
        "outputId": "be0b0e99-b329-45bb-c73b-09e9213aa89b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "X_train: (25000,)\n",
            "y_train: (25000,)\n",
            "X_test: (25000,)\n",
            "y_test: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV88-WY2ksTq",
        "outputId": "f4ffab36-34b6-40fd-8478-f4d83b32b478"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [1, 785, 189, 438, 47, 110, 142, 7, 6, 7475, 120, 4, 236, 378, 7, 153, 19, 87, 108, 141, 17, 1004, 5, 2, 883, 2, 23, 8, 4, 136, 2, 2, 4, 7475, 43, 1076, 21, 1407, 419, 5, 5202, 120, 91, 682, 189, 2818, 5, 9, 1348, 31, 7, 4, 118, 785, 189, 108, 126, 93, 2, 16, 540, 324, 23, 6, 364, 352, 21, 14, 9, 93, 56, 18, 11, 230, 53, 771, 74, 31, 34, 4, 2834, 7, 4, 22, 5, 14, 11, 471, 9, 2, 34, 4, 321, 487, 5, 116, 15, 6584, 4, 22, 9, 6, 2286, 4, 114, 2679, 23, 107, 293, 1008, 1172, 5, 328, 1236, 4, 1375, 109, 9, 6, 132, 773, 2, 1412, 8, 1172, 18, 7865, 29, 9, 276, 11, 6, 2768, 19, 289, 409, 4, 5341, 2140, 2, 648, 1430, 2, 8914, 5, 27, 3000, 1432, 7130, 103, 6, 346, 137, 11, 4, 2768, 295, 36, 7740, 725, 6, 3208, 273, 11, 4, 1513, 15, 1367, 35, 154, 2, 103, 2, 173, 7, 12, 36, 515, 3547, 94, 2547, 1722, 5, 3547, 36, 203, 30, 502, 8, 361, 12, 8, 989, 143, 4, 1172, 3404, 10, 10, 328, 1236, 9, 6, 55, 221, 2989, 5, 146, 165, 179, 770, 15, 50, 713, 53, 108, 448, 23, 12, 17, 225, 38, 76, 4397, 18, 183, 8, 81, 19, 12, 45, 1257, 8, 135, 15, 2, 166, 4, 118, 7, 45, 2, 17, 466, 45, 2, 4, 22, 115, 165, 764, 6075, 5, 1030, 8, 2973, 73, 469, 167, 2127, 2, 1568, 6, 87, 841, 18, 4, 22, 4, 192, 15, 91, 7, 12, 304, 273, 1004, 4, 1375, 1172, 2768, 2, 15, 4, 22, 764, 55, 5773, 5, 14, 4233, 7444, 4, 1375, 326, 7, 4, 4760, 1786, 8, 361, 1236, 8, 989, 46, 7, 4, 2768, 45, 55, 776, 8, 79, 496, 98, 45, 400, 301, 15, 4, 1859, 9, 4, 155, 15, 66, 2, 84, 5, 14, 22, 1534, 15, 17, 4, 167, 2, 15, 75, 70, 115, 66, 30, 252, 7, 618, 51, 9, 2161, 4, 3130, 5, 14, 1525, 8, 6584, 15, 2, 165, 127, 1921, 8, 30, 179, 2532, 4, 22, 9, 906, 18, 6, 176, 7, 1007, 1005, 4, 1375, 114, 4, 105, 26, 32, 55, 221, 11, 68, 205, 96, 5, 4, 192, 15, 4, 274, 410, 220, 304, 23, 94, 205, 109, 9, 55, 73, 224, 259, 3786, 15, 4, 22, 528, 1645, 34, 4, 130, 528, 30, 685, 345, 17, 4, 277, 199, 166, 281, 5, 1030, 8, 30, 179, 4442, 444, 2, 9, 6, 371, 87, 189, 22, 5, 31, 7, 4, 118, 7, 4, 2068, 545, 1178, 829]\n",
            "length of 11th example of train_data: 450\n",
            "the label of 11th example of train_labels: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process the data: preparing/bringing it to the right form to feed our NN"
      ],
      "metadata": {
        "id": "bD-h0iUdnddW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our train/test data here is comprised of examples(rows) of text reviews that are represented by a list of 450 integers(integers are the indexes of the word in the 10000 corpus we took from imbd database).\n",
        "We can't feed a NN with lists of integers. we need to turn them into Tensors. 2 ways to do that: a) word embedding and b) one-hot encoding to turn integer lists to vectors of 0s and 1s"
      ],
      "metadata": {
        "id": "JeD6aTZ5tH5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the integer sequences via multi-hot encoding for train and test data: each example now is a 10000 sequence\n",
        "# if a word is on corpus of 10000, then 1 is representing the index of that word in the corpus. if a word is not in the corpus, we put 0 \n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "# vectorize the labels   \n",
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "0jY72gmRlwXy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train after preprocessing: {x_train.shape}')\n",
        "print(f'y_train after preprocessing: {y_train.shape}')\n",
        "print(f'X_test after preprocessing: {x_test.shape}')\n",
        "print(f'y_test after preprocessing: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y-HyQnCu4hY",
        "outputId": "083b91a8-b12b-4c4b-b49f-b74e9038be74"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train after preprocessing: (25000, 10000)\n",
            "y_train after preprocessing: (25000,)\n",
            "X_test after preprocessing: (25000, 10000)\n",
            "y_test after preprocessing: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'length of 11th example of train_data after preprocessing: {x_train[10].shape}')\n",
        "print(f'11th example of train_data after preprocessing:\\n {x_train[10]}')\n",
        "print(f'the label of 11th example of train_labels after preprocessing: {y_train[10]}')\n",
        "\n",
        "print(f'\\n11th example of x_test after preprocessing:\\n {x_test[10]}')\n",
        "print(f'the label of 11th example of test_labels after preprocessing: {y_test[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbfLpf4KuML7",
        "outputId": "4906f9fc-40e7-4b94-a74a-2a0f1eb0c47c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of 11th example of train_data after preprocessing: (10000,)\n",
            "11th example of train_data after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of train_labels after preprocessing: 1.0\n",
            "\n",
            "11th example of x_test after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of test_labels after preprocessing: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define, compile and train the NN model"
      ],
      "metadata": {
        "id": "Z-pcxBOZ63xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every model is not the best initially and always needs improvements via hyperparameter tuning process. So, always create a validation set to test the model and when find the best hyperparameters, train the final model on test set. 3 ways to create a validation set: 1) simple hold-out validation, 2) K-fold validation and 3) iterated K-fold validation with shuffling(more @page98)"
      ],
      "metadata": {
        "id": "YTXEU_w3V5TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# training the model\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=512)\n",
        "\n",
        "# (also in order to monitor during the training the accuracy of the model on data it has never seen before, let's create a validation set) \n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]\n",
        "\n",
        "# training the model by monitoring how the model performs on unseen data\n",
        "print('\\n\\ntraining with validation ...\\n')\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=9,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd-pKZHpvFf-",
        "outputId": "b3c0b959-5e35-4860-9bcb-d6d3c5c0e440"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/5\n",
            "49/49 [==============================] - 9s 161ms/step - loss: 0.4957 - accuracy: 0.8158\n",
            "Epoch 2/5\n",
            "49/49 [==============================] - 3s 66ms/step - loss: 0.2859 - accuracy: 0.9051\n",
            "Epoch 3/5\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.2128 - accuracy: 0.9257\n",
            "Epoch 4/5\n",
            "49/49 [==============================] - 3s 66ms/step - loss: 0.1765 - accuracy: 0.9371\n",
            "Epoch 5/5\n",
            "49/49 [==============================] - 3s 65ms/step - loss: 0.1525 - accuracy: 0.9472\n",
            "\n",
            "\n",
            "training with validation ...\n",
            "\n",
            "Epoch 1/9\n",
            "47/47 [==============================] - 4s 74ms/step - loss: 0.1333 - accuracy: 0.9542 - val_loss: 0.1276 - val_accuracy: 0.9530\n",
            "Epoch 2/9\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 0.1202 - accuracy: 0.9597 - val_loss: 0.1430 - val_accuracy: 0.9480\n",
            "Epoch 3/9\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.1050 - accuracy: 0.9660 - val_loss: 0.1717 - val_accuracy: 0.9340\n",
            "Epoch 4/9\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 0.0954 - accuracy: 0.9706 - val_loss: 0.1814 - val_accuracy: 0.9270\n",
            "Epoch 5/9\n",
            "47/47 [==============================] - 3s 69ms/step - loss: 0.0850 - accuracy: 0.9727 - val_loss: 0.2149 - val_accuracy: 0.9150\n",
            "Epoch 6/9\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 0.0757 - accuracy: 0.9758 - val_loss: 0.2257 - val_accuracy: 0.9170\n",
            "Epoch 7/9\n",
            "47/47 [==============================] - 4s 81ms/step - loss: 0.0656 - accuracy: 0.9810 - val_loss: 0.2520 - val_accuracy: 0.9070\n",
            "Epoch 8/9\n",
            "47/47 [==============================] - 3s 68ms/step - loss: 0.0583 - accuracy: 0.9835 - val_loss: 0.2772 - val_accuracy: 0.9100\n",
            "Epoch 9/9\n",
            "47/47 [==============================] - 3s 67ms/step - loss: 0.0497 - accuracy: 0.9866 - val_loss: 0.3063 - val_accuracy: 0.9060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some model's info\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gxO7x_-5E5C",
        "outputId": "9aff06e3-38cf-432c-e7d2-0c4b69264704"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 16)                160016    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,305\n",
            "Trainable params: 160,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.fit returns a History object, which is a dictionary cantaining data about everything happened during training. Dictionary's elements are all metrics which were being monitored during training"
      ],
      "metadata": {
        "id": "E8LwfR9x8FZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in our case history includes data for loss, accuracy, val_loss and val_accuracy\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aYW1O6s6-H3",
        "outputId": "2af3220f-0d8a-41bb-b61c-d59920a25070"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss and accuracy of the model "
      ],
      "metadata": {
        "id": "tevw8HEB9lEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Asy-Bh-f6-CD",
        "outputId": "1c8824d8-fff0-429a-dc43-10c8381ee8b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we can see, this is an example of overfitting(high variance): our model can't generalize on new, unseen data"
      ],
      "metadata": {
        "id": "kh2NCTdn-UmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "psbvFM0q-DR7",
        "outputId": "282020ec-df71-4d26-b910-8ada704d85b0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model and improve it"
      ],
      "metadata": {
        "id": "XGSzBaH-SQm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "after the 3rd epoch, our model is getting worse in performance, so it needs several improvement steps. Hyperparameter Tuning is a process that helps us make our model better. We can try to add more hidden layers or more units to them, try different loss function where is applicable, try different activation function, try also different numbers of epochs, batch_size, and generally tune all the hyperparameters of the model(we call parameters of the model its weights and bs)"
      ],
      "metadata": {
        "id": "LD0yHPLBMU-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our case here, we just limit our model to 4 epochs(early stop point), as after that it is getting worse. The new model is just the old model trained for 4 epochs! This is what we call manually early stopping"
      ],
      "metadata": {
        "id": "eLXhb6yqNJxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "results = model.evaluate(x_test, y_test)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUUUP5t5RhlM",
        "outputId": "eeed5f58-dd57-44e3-e12b-e37ae7cc3757"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5582 - accuracy: 0.8532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5582346320152283, 0.8532400131225586]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain the model from scratch "
      ],
      "metadata": {
        "id": "5GwFlT7w_CFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the new model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# training the model\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=4,\n",
        "                    batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYw_n5Rn-kP1",
        "outputId": "fcbae9d5-e1d9-490f-c3bc-4264736df8d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/4\n",
            "49/49 [==============================] - 7s 115ms/step - loss: 0.4454 - accuracy: 0.8307\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 4s 79ms/step - loss: 0.2584 - accuracy: 0.9092\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 3s 66ms/step - loss: 0.1992 - accuracy: 0.9283\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 0.1657 - accuracy: 0.9405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the new model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98X7FGVpEjrb",
        "outputId": "fa15a0b1-11bd-4b84-b4b3-41b12bbb73c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 16)                160016    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,305\n",
            "Trainable params: 160,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss and accuracy of the new model"
      ],
      "metadata": {
        "id": "85sP2vZYD4NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, label=\"Training loss\")\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pKxQYYMND6Fw",
        "outputId": "4e598906-14aa-4101-e44f-46f46b5bd2f0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "plt.plot(epochs, acc, label=\"Training accuracy\")\n",
        "plt.title(\"Training accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CNdfTF0mD86U",
        "outputId": "78195729-f561-4445-e8b7-2775a0cd2a8a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c9FWAIEEghhDRgQREEgaASX1qW4oOJCXYBqK7YVd8GlLq21VPu0tY/V6k9raxdxaQW11SpudcFqq1WDCREQBXkQwhpZQgIEsly/P+aA03QgA2RyMpPv+/XKi5lz7jNznZww19zLuW9zd0REROprFXYAIiLSPClBiIhITEoQIiISkxKEiIjEpAQhIiIxKUGIiEhMShCS0szsJTO7qLHLirQEpvsgpLkxs8qopx2A7UBt8PxSd/9T00cl0vIoQUizZmbLgO+6+2sx9rV295qmjyq56Pck+0pNTJI0zOx4Mys1s5vMbA3wsJl1MbPZZlZmZhuDx7lRx7xpZt8NHk82s3+a2V1B2f8zs1P3sWx/M3vLzCrM7DUze8DMHt9N3A3F2NXMHjazVcH+Z6P2nWVmxWa22cw+M7OxwfZlZnZiVLnpO9/fzPLMzM3sO2a2HHgj2P6Uma0xs/Ig9qFRx7c3s1+a2efB/n8G214ws6vrnU+JmY3f2+snyUcJQpJNT6ArcAAwhcjf8MPB837ANuD+PRw/GvgE6Ab8AviDmdk+lP0z8D6QDUwHvrmH92woxseINKUNBboD9wCY2SjgUeB7QBZwLLBsD+9T33HAIcApwfOXgEHBe3wIRDfV3QUcDhxN5Pd7I1AHPAJcuLOQmY0A+gAv7EUckqzcXT/6abY/RD4QTwweHw/sANL3UD4f2Bj1/E0iTVQAk4ElUfs6AA703JuyRD7ka4AOUfsfBx6P85x2xQj0IvJB3CVGud8C9zT0ewmeT9/5/kBeEOuAPcSQFZTJJJLAtgEjYpRLBzYCg4LndwG/DvvvQj9N86MahCSbMnev2vnEzDqY2W+DppHNwFtAlpml7eb4NTsfuPvW4GHGXpbtDWyI2gawYncBNxBj3+C1NsY4tC/w2e5eNw67YjKzNDP7edBMtZkvayLdgp/0WO8V/K5nAReaWStgEpEaj7QAShCSbOqPqrgeGAyMdvfORJphAHbXbNQYVgNdzaxD1La+eyi/pxhXBK+VFeO4FcCBu3nNLURqNTv1jFEm+nf1DeAs4EQitYa8qBi+AKr28F6PABcAY4Ct7v7ubspJilGCkGTXiUjzyCYz6wr8KNFv6O6fA4XAdDNra2ZHAWfsS4zuvppI38Cvg87sNma2M4H8AbjYzMaYWSsz62NmBwf7ioGJQfkC4NwGwu5EZLjweiKJ5adRMdQBfwTuNrPeQW3jKDNrF+x/l0gz2C9R7aFFUYKQZPcroD2Rb8H/Bl5uove9ADiKyAfuT4g0w2zfTdmGYvwmUA0sAtYB0wDc/X3gYiKd1uXAP4h0dAP8kMg3/o3Aj4l0mu/Jo8DnwEpgYRBHtBuAj4APgA3Anfzn58OjwDAifS3SQug+CJFGYGazgEXunvAaTBjM7FvAFHf/StixSNNRDUJkH5jZEWZ2YND0M5ZI+/6zDR2XjIK+liuAh8KORZqWEoTIvulJZFhsJXAfcLm7F4UaUQKY2SlAGbCWhpuxJMWoiUlERGJSDUJERGJqHXYAjaVbt26el5cXdhgiIkll7ty5X7h7Tqx9KZMg8vLyKCwsDDsMEZGkYmaf726fmphERCQmJQgREYlJCUJERGJKmT6IWKqrqyktLaWqqqrhwpLU0tPTyc3NpU2bNmGHIpIyUjpBlJaW0qlTJ/Ly8tj9mjCS7Nyd9evXU1paSv/+/cMORyRlpHQTU1VVFdnZ2UoOKc7MyM7OVk1RpJElNEGY2Vgz+8TMlpjZzTH2H2Bmrwdr3L4ZvU5vsL+zRdYg3tMSkg3FsK+HShLRdRZpfAlLEMFqWQ8ApwJDgElmNqResbuAR919OHA78LN6++8gsvqWiIhEqa6t46PSch57dxl/fm95Qt4jkX0Qo4is6bsUwMxmEpnxcmFUmSHAdcHjOUTNhmlmhwM9iMydX5DAOBNm/fr1jBkzBoA1a9aQlpZGTk7khsX333+ftm3b7vbYwsJCHn30Ue677749vsfRRx/NO++803hBi0iz4+6sKq+iaPlGipdvonjFJj5aWc72mjoADuuXxTdG92v0901kgujDf67TWwqMrldmHvB14F5gPNDJzLKJLILyS+BCIkskxmRmU4ApAP36Nf4vZ39lZ2dTXFwMwPTp08nIyOCGG27Ytb+mpobWrWNfgoKCAgoKGs6LyZgcamtrSUvb3ZLRIlK5vYaS0k0UBcmgeMUmyioi61G1bd2KQ3t35oLRB5DfL4uRfbPI7dI+IXGEPYrpBuB+M5tMpClpJVBLZO75F929dE9ty+7+EMEc9QUFBUkxLe3kyZNJT0+nqKiIY445hokTJzJ16lSqqqpo3749Dz/8MIMHD+bNN9/krrvuYvbs2UyfPp3ly5ezdOlSli9fzrRp07jmmmsAyMjIoLKykjfffJPp06fTrVs35s+fz+GHH87jjz+OmfHiiy9y3XXX0bFjR4455hiWLl3K7Nmz/yOuZcuW8c1vfpMtW7YAcP/993P00UcDcOedd/L444/TqlUrTj31VH7+85+zZMkSLrvsMsrKykhLS+Opp55ixYoVu2IGuOqqqygoKGDy5Mnk5eUxYcIEXn31VW688UYqKip46KGH2LFjBwMHDuSxxx6jQ4cOrF27lssuu4ylS5cC8OCDD/Lyyy/TtWtXpk2bBsAPfvADunfvztSpU5vkmokkUm2ds3hdRSQZBAnh03UV7Jxou3+3jnxlYDfy+2aR3zeLQ3p1pm3rphlflMgEsZL/XMg9N9i2i7uvIlKDwMwygHPcfVOwxu9XzewKIANoa2aV7v5fHd3x+vHzC1i4avO+Hh7TkN6d+dEZQ/f6uNLSUt555x3S0tLYvHkzb7/9Nq1bt+a1117j+9//Pn/5y1/+65hFixYxZ84cKioqGDx4MJdffvl/jfkvKipiwYIF9O7dm2OOOYZ//etfFBQUcOmll/LWW2/Rv39/Jk2aFDOm7t278+qrr5Kens7ixYuZNGkShYWFvPTSS/ztb3/jvffeo0OHDmzYsAGACy64gJtvvpnx48dTVVVFXV0dK1asiPnaO2VnZ/Phhx8Ckea3Sy65BIBbb72VP/zhD1x99dVcc801HHfccTzzzDPU1tZSWVlJ7969+frXv860adOoq6tj5syZvP/++3v9exdpDtZtrqJoxc7awUY+Ki1ny45aADLbtyG/bxZjD+1Jfr8s8nOz6NJx903RiZbIBPEBMMjM+hNJDBOBb0QXMLNuwIZg0fRbiCycjrtfEFVmMlCwP8mhuTnvvPN2NbGUl5dz0UUXsXjxYsyM6urqmMecfvrptGvXjnbt2tG9e3fWrl1Lbu5/DPpi1KhRu7bl5+ezbNkyMjIyGDBgwK77AyZNmsRDD/33wmDV1dVcddVVFBcXk5aWxqeffgrAa6+9xsUXX0yHDh0A6Nq1KxUVFaxcuZLx48cDkZvU4jFhwoRdj+fPn8+tt97Kpk2bqKys5JRTTgHgjTfe4NFHHwUgLS2NzMxMMjMzyc7OpqioiLVr1zJy5Eiys7Pjek+RMG3bUcv8VeUUL99E0YpI/8Gq8shw7NatjCG9O3PO4bm7agf9u3VsViPyEpYg3L3GzK4CXgHSgD+6+wIzux0odPfngOOBn5mZE2liujJR8ezLN/1E6dix467HP/zhDznhhBN45plnWLZsGccff3zMY9q1a7frcVpaGjU1NftUZnfuueceevTowbx586irq4v7Qz9a69atqaur2/W8/n0J0ec9efJknn32WUaMGMGMGTN488039/ja3/3ud5kxYwZr1qzh29/+9l7HJpJodXXO0i+2BH0GGylavolFayqorYu0FeV2ac9hB3Th232zGNkvi6G9M0lv07z74hLaB+HuLwIv1tt2W9Tjp4GnG3iNGcCMBITXLJSXl9OnTx8AZsyY0eivP3jwYJYuXcqyZcvIy8tj1qxZu40jNzeXVq1a8cgjj1BbG6nynnTSSdx+++1ccMEFu5qYunbtSm5uLs8++yxnn30227dvp7a2lgMOOICFCxeyfft2tm3bxuuvv85XvhJ7jfuKigp69epFdXU1f/rTn3b9DsaMGcODDz7ItGnTdjUxZWZmMn78eG677Taqq6v585+18qWEb8OWHRQHtYKiFZuYt2ITm6siX8oy2rVmRN9MLjtuAPl9u5DfN4ucTu0aeMXmJ+xO6hbvxhtv5KKLLuInP/kJp59+eqO/fvv27fn1r3/N2LFj6dixI0cccUTMcldccQXnnHMOjz766K6yAGPHjqW4uJiCggLatm3Laaedxk9/+lMee+wxLr30Um677TbatGnDU089xYABAzj//PM59NBD6d+/PyNHjtxtXHfccQejR48mJyeH0aNHU1FRAcC9997LlClT+MMf/kBaWhoPPvggRx11FG3btuWEE04gKytLI6CkyW2vqWXhqs27RhQVr9jE5+u3AtDK4KAenTh9eG9G9s0iv18WB+ZkkNaq+TQV7auUWZO6oKDA6y8Y9PHHH3PIIYeEFFHzUVlZSUZGBu7OlVdeyaBBg7j22mvDDmuv1NXVcdhhh/HUU08xaNCgmGV0vaUxuDvLN2yleMWXw0wXrtrMjtpI82mPzu3I75vFyH6RmsGwPpl0bJe837XNbK67xxxTn7xnJXH73e9+xyOPPMKOHTsYOXIkl156adgh7ZWFCxcybtw4xo8fv9vkILKvyrdVMy+qZlC8YhMbtuwAIL1NK4b3yeLiY/IiHcn9suiVmZh7Dpoj1SAkZeh6S0NqautYtKaCohU77znYyGdlW3btH9g9I6gdREYVDe7RidZpKT2nacuuQbh7sxo2JomRKl90pPG4O6vLq4Kmoo27pqeoqo40FWV3bEt+3yzOzu/DyH5dGN43k87pWk8kWkoniPT0dNavX68pv1PczvUg9mVorqSOLdtrKCkt/4+EsG7n9BRprRjapzOTRvUjv28Wh/XrQm6X9vpcaEBKJ4jc3FxKS0spKysLOxRJsJ0ryknLUFvnLFlXGRlmGnQmf7q2guCWA/KyO3D0gdm7OpObcnqKVJLSCaJNmzZaYUwkBayrqNo1T1HR8khTUeX2yD0HndNbk9+vCycP7cnIvlmM6JtF1xCnp0glKZ0gRCT5VFXXMn9l0FQUdCav3LQNiExPcUivzowf2WfXqKL+2R1plQL3HDRHShAiEpq6Ouf/1m/ZVTsoXrGJj1dvpiZoK+qT1Z78fl8OMz20T/OfniKVKEGISJPZuGXHlzWDYHqK8m2RCSo7tk1jRN8sphw7YFftoHsnDTwIkxKEiCTEjpo6Pl69edeIouIVm1hWb3qK04b1DGYy7cLA7qkxPUUqUYIQkf3m7pRu3BascxBJCAtWbWZHsCRm906R6SkmHBEZZjo8N7mnp2gpdIVEZK9trqqmZEX5rmmti1dsYn3U9BTD+mRy0VEH7JqvqFdmuu45SEJKECLSoB01dfxzSRmvzF/L3OUb+ayscteSmAfmdOT4wd2/nJ6iZyfapPj0FC2FEoSIxFRTW8c7n61ndskqXlmwlvJt1XRKb80ReV05c0RvRvbLYnhuFpntNT1FqlKCEJFdauuc9/5vPbNLVvPy/DVs2LKDjHatOXlID8aN6MVXBubojuQWRAlCpIWrq3PmLt/I7HmreHH+GsoqttO+TRonDunBuOG9OO6gHN170EIpQYi0QO5O8YpNzC5ZzYsfrWZ1eRXtWrfiawd3Z9zw3nzt4O60b6uk0NIpQYi0EO7OglWbeb5kFS+UrKZ04zbaprXi2INyuPnUgxlzSA8yNPRUouivQSSFuTufrK1g9rzVzC5ZxbL1W2ndyjhmYDemjhnEyUN7qpNZdksJQiQFLVlXyeySVcwuWc2SdZW0MjjqwGwuPe5Axg7tSRfNdipxUIIQSRGfr9/C7JLVPD9vFYvWVGAGR+R15Y6zhjL20F7kdGoXdoiSZJQgRJJY6catvFCymtklq/loZTkAh/XL4rZxQzh9eC96dNZkd7LvlCBEkszazVW8ULKa50tWUbR8EwDDczP5/mkHc/rw3vTJah9yhJIqlCBEkkBZxXZenr+a50tW88GyDbjDIb06871TBjNueC8OyO4YdoiSgpQgRJqpjVt28PKCNcwuWcW7n62nzmFQ9wymjTmIcSN6cWBORtghSopLaIIws7HAvUAa8Ht3/3m9/QcAfwRygA3Ahe5eamb5wINAZ6AW+B93n5XIWEWag/Jt1fx9wRpml6zmX0u+oKbO6d+tI1eeMJBxw3szuGensEOUFiRhCcLM0oAHgJOAUuADM3vO3RdGFbsLeNTdHzGzrwE/A74JbAW+5e6Lzaw3MNfMXnH3TYmKVyQsldtreG3hWmaXrOKtT79gR20duV3a892vDmDc8F4M7d1ZU2VLKBJZgxgFLHH3pQBmNhM4C4hOEEOA64LHc4BnAdz9050F3H2Vma0jUstQgpCUsHVHDW8sWsfseauZ88k6ttfU0SsznW8ddQDjRvRmRG6mkoKELpEJog+wIup5KTC6Xpl5wNeJNEONBzqZWba7r99ZwMxGAW2Bz+q/gZlNAaYA9OvXr1GDF2lsVdW1vPlJGbNLVvH6x+vYVl1LTqd2TDyiL2eM6M1h/brQSktuSjMSdif1DcD9ZjYZeAtYSaTPAQAz6wU8Blzk7nX1D3b3h4CHAAoKCrwpAhbZGztq6nh7cRmzS1bz6sK1VG6voWvHtow/rA/jhvdidP9srcMszVYiE8RKoG/U89xg2y7uvopIDQIzywDO2dnPYGadgReAH7j7vxMYp0ijqt650M68VbyyYA2bq2ronN6a04b1ZNzw3hx9YDatteKaJIFEJogPgEFm1p9IYpgIfCO6gJl1AzYEtYNbiIxowszaAs8Q6cB+OoExijSK2jrnvaXreb5kNS/PX83GrdVaaEeSXsIShLvXmNlVwCtEhrn+0d0XmNntQKG7PwccD/zMzJxIE9OVweHnA8cC2UHzE8Bkdy9OVLwie2vnQjvPz1vFix+t4YvK7XRom8aYQ7TQjqQGc0+NpvuCggIvLCwMOwxJcdEL7bxQspo1m7XQjiQ3M5vr7gWx9oXdSS3S7O1poZ1bTtNCO5K69FctEsPuFtr5yqBuTDvxIE4a0kML7UjKU4IQiRJroZ2jD+zGZccdyClaaEdaGCUIafFiLbQzKq8rF519KKce2pNuGVpoR1omJQhpkXa30M6PzhjCacO00I4IKEFIC6KFdkT2jhKEpDQttCOy75QgJOVooR2RxqEEISlBC+2IND4lCElaWmhHJLGUICSpaKEdkaajBCHN3u4W2pk0qh/jhvfSQjsiCaIEIc1SdW0db32qhXZEwqQEIc2Ou3PZY3N5fdE6LbQjEiIlCGl2ZryzjNcXreN7pwzmkq8O0EI7IiFRgpBm5ePVm/nZi4sYc3B3rjj+QHU4i4RIX82k2di2o5Zrnigis0MbfnHucCUHkZCpBiHNxv+8uJDF6yp57DujyNYMqiKhUw1CmoVXF67l8X8v55Kv9uerg3LCDkdEUIKQZmDt5ipufHoeQ3t35oZTBocdjogElCAkVHV1znVPFlNVXcd9k0bSrnVa2CGJSEAJQkL1u7eX8q8l6/nRGUM0y6pIM6MEIaEpKd3E/77yCace2pMJR/QNOxwRqUcJQkKxZXsNU2cWk9OpHT/7+jANaRVphjTMVUJx+/MLWbZ+C09cciRZHdqGHY6IxKAahDS5F0pWM6twBVccfyBHDsgOOxwR2Q0lCGlSKzdt45a/ljCibxbTTjwo7HBEZA8SmiDMbKyZfWJmS8zs5hj7DzCz182sxMzeNLPcqH0Xmdni4OeiRMYpTaO2zrl2ZjG1dc59E/Npo5lZRZq1hP0PNbM04AHgVGAIMMnMhtQrdhfwqLsPB24HfhYc2xX4ETAaGAX8yMy6JCpWaRq/nrOE95dt4I6zD+WA7I5hhyMiDUjkV7hRwBJ3X+ruO4CZwFn1ygwB3ggez4nafwrwqrtvcPeNwKvA2ATGKgn24fKN/Or1xZyV35vxI/uEHY6IxCGRCaIPsCLqeWmwLdo84OvB4/FAJzPLjvNYzGyKmRWaWWFZWVmjBS6Nq6Kqmqkzi+iVmc4dZx+qIa0iSSLsRuAbgOPMrAg4DlgJ1MZ7sLs/5O4F7l6Qk6MJ3pqr2/62gJUbt3HvxHw6p7cJOxwRiVMi74NYCUTfHpsbbNvF3VcR1CDMLAM4x903mdlK4Ph6x76ZwFglQZ4pKuWZopVce+JBHH5A17DDEZG9kMgaxAfAIDPrb2ZtgYnAc9EFzKybme2M4Rbgj8HjV4CTzaxL0Dl9crBNksjy9Vv54bMLOCKvC1eecGDY4YjIXkpYgnD3GuAqIh/sHwNPuvsCM7vdzM4Mih0PfGJmnwI9gP8Jjt0A3EEkyXwA3B5skyRRXVvH1FlFmME9E/JprSGtIknH3D3sGBpFQUGBFxYWhh2GBO7++yfc98YS/t+kkZwxonfY4YjIbpjZXHcviLWvwa91ZnZGVDOQSIPeW7qe++cs4dzDc5UcRJJYPB/8E4DFZvYLMzs40QFJcivfWs21s4rp17UD088cGnY4IrIfGkwQ7n4hMBL4DJhhZu8G9x90Snh0klTcnVueKWFdxXbunTiSjHaaLFgkmcXVdOTum4GnidwN3YvITW0fmtnVCYxNksxThaW8+NEarj95MCP6ZoUdjojsp3j6IM40s2eI3IfQBhjl7qcCI4DrExueJIulZZVMf34BRx+YzaXHDgg7HBFpBPG0AZwD3OPub0VvdPetZvadxIQlyWRHTR1TZxbTtnUr7j4/n1atNJWGSCqIJ0FMB1bvfGJm7YEe7r7M3V9PVGCSPH756id8tLKc31x4OD0z08MOR0QaSTx9EE8BdVHPa4NtIvxz8Rf89h9L+cbofow9tGfY4YhII4onQbQOpusGIHisRYSFDVt2cN2TxRyY05Efnl5/qQ8RSXbxJIiyqKkxMLOzgC8SF5IkA3fnxqdL2LS1mvsmjaR927SwQxKRRhZPH8RlwJ/M7H7AiKzT8K2ERiXN3p/eW85rH6/l1tMPYWjvzLDDEZEEaDBBuPtnwJHBdNy4e2XCo5JmbfHaCu6YvZBjD8rh28f0DzscEUmQuG51NbPTgaFA+s7VwNz99gTGJc1UVXUtVz9RREa71tx13nANaRVJYQ0mCDP7DdABOAH4PXAu8H6C45Jm6s6XF7FoTQUPTz6C7p00pFUklcXTSX20u38L2OjuPwaOAg5KbFjSHM1ZtI6H/7WMyUfnccLB3cMOR0QSLJ4EURX8u9XMegPVROZjkhakrGI733t6Hgf37MTNp2pSX5GWIJ4+iOfNLAv4X+BDwIHfJTQqaVbq6pwbnppHRVUNf77kSNLbaEirSEuwxwQRLBT0urtvAv5iZrOBdHcvb5LopFmY8c4y/vFpGXecNZSDemiWd5GWYo9NTO5eBzwQ9Xy7kkPLsnDVZn7+0iJOPKQ7Fx55QNjhiEgTiqcP4nUzO8d2jm+VFmPbjlqumVlEVoc2/OLcEehPQKRliSdBXEpkcr7tZrbZzCrMbHOC45Jm4CcvLGTJukruPj+frh01/ZZISxPPndRqdG6B/r5gDX96bzmXHjuArwzqFnY4IhKCeG6UOzbW9voLCEnqWFNexY1/KeHQPp25/uTBYYcjIiGJZ5jr96IepwOjgLnA1xISkYSqrs657slitlfXce/EkbRtHdey5SKSguJpYjoj+rmZ9QV+lbCIJFQPvb2Udz5bz53nDOPAnIywwxGREO3L18NS4JDGDkTCV1K6ibte+YTThvXk/IK+YYcjIiGLpw/i/xG5exoiCSWfyB3VkkK2bK9h6sxiundqx8/GD9eQVhGJqwZRSKTPYS7wLnCTu18Yz4ub2Vgz+8TMlpjZzTH29zOzOWZWZGYlZnZasL2NmT1iZh+Z2cdmdstenJPsgx8/v4Bl67dw94R8Mju0CTscEWkG4umkfhqocvdaADNLM7MO7r51TweZWRqRu7BPItIs9YGZPefuC6OK3Qo86e4PmtkQ4EUgDzgPaOfuw8ysA7DQzJ5w92V7eX4Sh9klq3iysJSrThjIkQOyww5HRJqJuO6kBtpHPW8PvBbHcaOAJe6+1N13ADOBs+qVcaBz8DgTWBW1vaOZtQ7ebwegm/MSoHTjVm7560fk981i6omDwg5HRJqReBJEevQyo8HjDnEc14fI+tU7lQbbok0HLjSzUiK1h6uD7U8DW4DVwHLgLnffUP8NzGyKmRWaWWFZWVkcIUm02jrn2lnFuMN9E0fSJk1DWkXkS/F8Imwxs8N2PjGzw4FtjfT+k4AZ7p4LnAY8FswgOwqoBXoD/YHrzWxA/YPd/SF3L3D3gpycnEYKqeV4YM4SPli2kTvOHkq/7Hhyvoi0JPH0QUwDnjKzVYABPYEJcRy3EogeK5kbbIv2HWAsgLu/a2bpQDfgG8DL7l4NrDOzfwEFwNI43lfiMPfzjdz7+mLOzu/N+JG5YYcjIs1QgzUId/8AOBi4HLgMOMTd58bx2h8Ag8ysv5m1BSYCz9UrsxwYA2BmhxC5U7ss2P61YHtH4EhgUTwnJA3bXFXN1JlF9MpM5/azDw07HBFpphpMEGZ2JdDR3ee7+3wgw8yuaOg4d68BrgJeAT4mMlppgZndbmZnBsWuBy4xs3nAE8Bkd3cio58yzGwBkUTzsLuX7MsJyn+77dn5rC6v4t6JI+mcriGtIhKbRT6P91DArNjd8+ttK3L3kQmNbC8VFBR4YWFh2GE0e88UlXLtrHlcd9JBXDNGo5ZEWjozm+vuBbH2xdNJnRa9WFBwf4MWB0hCn6/fwg+fXcCovK5cecLAsMMRkWYunk7ql4FZZvbb4PmlwEuJC0kSobq2jqkzizGDeybmk9ZKU2mIyJ7FkyBuAqYQ6aAGKCEykkmSyH2vL6Z4xSbu/8ZI+mS1bxAaXBIAABDRSURBVPgAEWnx4hnFVAe8Bywjcn/C14h0OkuS+PfS9dw/ZwnnHZ7LuOG9ww5HRJLEbmsQZnYQkRvZJgFfALMA3P2EpglNGkP51mqunVVMXnZHpp85NOxwRCSJ7KmJaRHwNjDO3ZcAmNm1TRKVNAp355ZnSiir2M5frziaju3iaVEUEYnYUxPT14nMhTTHzH5nZmOI3EktSeLJwhW8+NEabjhlMMNzs8IOR0SSzG4ThLs/6+4TidxFPYfIlBvdzexBMzu5qQKUffNZWSXTn1vI0QdmM+Wr/zWNlYhIg+LppN7i7n8O1qbOBYqIjGySZmpHTR1TZxbRrk0r7j4/n1Ya0ioi+2Cv5nd2943BDKpjEhWQ7L9f/v0T5q/czJ3nDKdnZnrY4YhIktICACnmn4u/4LdvLeWC0f04ZahuVxGRfacEkULWV27nuieLGdg9g1tPHxJ2OCKS5JQgUoS7c9NfSti0tZr7Jo6kfdu0sEMSkSSnBJEiHn9vOa99vI6bTj2YIb07N3yAiEgDlCBSwKdrK/jJ7IUcd1AOFx+dF3Y4IpIilCCSXFV1Ldc8UUSn9Nbcdd4IDWkVkUajuReS3M9fWsSiNRU8PPkIcjq1CzscEUkhqkEksTcWrWXGO8u4+Jg8Tji4e9jhiEiKUYJIUusqqvjeUyUc3LMTN409OOxwRCQFqYkpCdXVOd97qoTK7TXMnHIk6W00pFVEGp9qEEno4XeW8Y9Py7h13BAG9egUdjgikqKUIJLMglXl3PnSIk48pAcXju4XdjgiksKUIJLIth2RIa1ZHdrwi3OHY6YhrSKSOOqDSCJ3vLCQpV9s4fHvjKZrx7ZhhyMiKU41iCTx8vw1/Pm95Uw5dgDHDOwWdjgi0gIoQSSBNeVV3PzXEob1yeT6kwaHHY6ItBBKEM1cbZ1z7axitlfXce/EfNq21iUTkaaR0E8bMxtrZp+Y2RIzuznG/n5mNsfMisysxMxOi9o33MzeNbMFZvaRmbXIpdEeemsp7y5dz4/PHMqAnIywwxGRFiRhndRmlgY8AJwElAIfmNlz7r4wqtitwJPu/qCZDQFeBPLMrDXwOPBNd59nZtlAdaJiba7mrdjEL//+CacP68V5BblhhyMiLUwiaxCjgCXuvtTddwAzgbPqlXFg5+IFmcCq4PHJQIm7zwNw9/XuXpvAWJudLdtrmDqziO6d2vHT8cM0pFVEmlwiE0QfYEXU89JgW7TpwIVmVkqk9nB1sP0gwM3sFTP70MxujPUGZjbFzArNrLCsrKxxow/Z9OcWsHzDVu6ZkE9mhzZhhyMiLVDYPZ6TgBnungucBjxmZq2INH19Bbgg+He8mY2pf7C7P+TuBe5ekJOT05RxJ9Tz81bx1NxSrjxhIKMHZIcdjoi0UIlMECuBvlHPc4Nt0b4DPAng7u8C6UA3IrWNt9z9C3ffSqR2cVgCY202Sjdu5fvPfMTIfllcM2ZQ2OGISAuWyATxATDIzPqbWVtgIvBcvTLLgTEAZnYIkQRRBrwCDDOzDkGH9XHAQlJcTW0d02YW4w73ThhJm7SwK3gi0pIlbBSTu9eY2VVEPuzTgD+6+wIzux0odPfngOuB35nZtUQ6rCe7uwMbzexuIknGgRfd/YVExdpcPDDnMwo/38ivJuTTL7tD2OGISAtnkc/j5FdQUOCFhYVhh7HP5n6+gfN+8y5n5ffhngn5YYcjIi2Emc1194JY+9SG0Qxsrqpm6sxi+nRpz+1nDQ07HBERQLO5hs7dufWZ+awur+LJS4+iU7qGtIpI86AaRMieKVrJc/NWMW3MIA4/oEvY4YiI7KIEEaLP12/hh8/OZ1ReV644YWDY4YiI/AcliJBU19Zxzcxi0loZ90zMJ62VptIQkeZFfRAhufe1xcxbsYkHvnEYfbLahx2OiMh/UQ0iBP9eup4H3lzC+QW5nD68V9jhiIjEpATRxDZt3cG1s4rJy+7Ij87QkFYRab7UxNSE3J2b//IRX1Ru56+XH0PHdvr1i0jzpRpEE5r1wQpeXrCGG04ezLDczLDDERHZIyWIJvJZWSU/fn4hxwzM5pKvDgg7HBGRBilBNIHtNbVc80QR6W1acff5+bTSkFYRSQJqBG8Cv/z7pyxYtZmHvnk4PTqnhx2OiEhcVINIsLcXl/HQW0u58Mh+nDy0Z9jhiIjETQkigdZXbue6J+cxqHsGPzhtSNjhiIjsFTUxJYi7c+PTJZRvq+bRb4+ifdu0sEMSEdkrqkEkyGP//pzXF63jllMP5pBencMOR0RkrylBJMAnayr4nxc+5vjBOUw+Oi/scERE9okSRCOrqo4Mae2U3pr/PXcEZhrSKiLJSX0QjeznLy3ik7UVzLj4CHI6tQs7HBGRfaYaRCN6Y9FaZryzjG8f05/jB3cPOxwRkf2iBNFI1lVUccNTJRzSqzM3nTo47HBERPabEkQjqKtzrn9yHlu213DfxHzatdaQVhFJfkoQjeCP//o/3l78BT8cN4RBPTqFHY6ISKNQgthP81eWc+fLizhpSA8uGN0v7HBERBqNEsR+2Lqjhqkzi+jasS13njNcQ1pFJKVomOt+uGP2xyz9YguPf2c0XTu2DTscEZFGldAahJmNNbNPzGyJmd0cY38/M5tjZkVmVmJmp8XYX2lmNyQyzn3x8vw1PPH+ci499kCOGdgt7HBERBpdwhKEmaUBDwCnAkOASWZWf0rTW4En3X0kMBH4db39dwMvJSrGfbW6fBs3/7WEYX0yue6kg8IOR0QkIRJZgxgFLHH3pe6+A5gJnFWvjAM7Z7LLBFbt3GFmZwP/ByxIYIx7rbbOuW7WPHbU1HHvxHzatlY3joikpkR+uvUBVkQ9Lw22RZsOXGhmpcCLwNUAZpYB3AT8eE9vYGZTzKzQzArLysoaK+49+u1bn/Hu0vVMP3MoA3IymuQ9RUTCEPbX30nADHfPBU4DHjOzVkQSxz3uXrmng939IXcvcPeCnJychAdbvGITd//9U04f3ovzDs9N+PuJiIQpkaOYVgJ9o57nBtuifQcYC+Du75pZOtANGA2ca2a/ALKAOjOrcvf7ExjvHlVujwxp7dE5nZ+ePUxDWkUk5SUyQXwADDKz/kQSw0TgG/XKLAfGADPM7BAgHShz96/uLGBm04HKMJMDwPTnFrBiw1ZmTjmKzA5twgxFRKRJJKyJyd1rgKuAV4CPiYxWWmBmt5vZmUGx64FLzGwe8AQw2d09UTHtq+fmreLpuaVcdcJARvXvGnY4IiJNwprh5/E+KSgo8MLCwkZ/3RUbtnLafW8zqHsGT156FK3Twu62ERFpPGY2190LYu3Tp90e1NTWce2sYtzh3okjlRxEpEXRVBt7cP+cJRR+vpF7J+bTt2uHsMMREWlS+kq8G4XLNnDf64v5+sg+nJVf//YNEZHUpwQRw+aqaqbOLCa3Swd+fNbQsMMREQmFmpjqcXd+8Mx81myu4qnLjqJTuoa0ikjLpBpEPX/9cCXPz1vFtScO4rB+XcIOR0QkNEoQUZZ9sYXb/jafUf27cvnxA8MOR0QkVEoQgeraOqbOLCKtlfGrCfmktdJUGiLSsqkPInDPq58yr7ScX19wGL2z2ocdjohI6FSDAN79bD0P/uMzJhT05bRhvcIOR0SkWWjxCWLT1h1cO6uY/tkdue2M+gveiYi0XC2+iammzjm0T2emjjmIju1a/K9DRGSXFv+J2C2jHb+/6IiwwxARaXZafBOTiIjEpgQhIiIxKUGIiEhMShAiIhKTEoSIiMSkBCEiIjEpQYiISExKECIiEpO5e9gxNAozKwM+34+X6AZ80UjhhClVzgN0Ls1VqpxLqpwH7N+5HODuObF2pEyC2F9mVujuBWHHsb9S5TxA59Jcpcq5pMp5QOLORU1MIiISkxKEiIjEpATxpYfCDqCRpMp5gM6luUqVc0mV84AEnYv6IEREJCbVIEREJCYlCBERialFJQgz+6OZrTOz+bvZb2Z2n5ktMbMSMzusqWOMVxzncryZlZtZcfBzW1PHGA8z62tmc8xsoZktMLOpMcokxXWJ81ya/XUxs3Qze9/M5gXn8eMYZdqZ2azgmrxnZnlNH2nD4jyXyWZWFnVNvhtGrPEyszQzKzKz2TH2Ne51cfcW8wMcCxwGzN/N/tOAlwADjgTeCzvm/TiX44HZYccZx3n0Ag4LHncCPgWGJON1ifNcmv11CX7PGcHjNsB7wJH1ylwB/CZ4PBGYFXbc+3Euk4H7w451L87pOuDPsf6OGvu6tKgahLu/BWzYQ5GzgEc94t9Alpn1apro9k4c55IU3H21u38YPK4APgb61CuWFNclznNp9oLfc2XwtE3wU380y1nAI8Hjp4ExZmZNFGLc4jyXpGFmucDpwO93U6RRr0uLShBx6AOsiHpeShL+B49yVFC1fsnMhoYdTEOC6vBIIt/yoiXdddnDuUASXJegGaMYWAe86u67vSbuXgOUA9lNG2V84jgXgHOC5sunzaxvE4e4N34F3AjU7WZ/o14XJYjU9SGROVZGAP8PeDbkePbIzDKAvwDT3H1z2PHsjwbOJSmui7vXuns+kAuMMrNDw45pX8VxLs8Dee4+HHiVL7+BNytmNg5Y5+5zm+o9lSD+00og+ttDbrAt6bj75p1Va3d/EWhjZt1CDismM2tD5AP1T+7+1xhFkua6NHQuyXRdANx9EzAHGFtv165rYmatgUxgfdNGt3d2dy7uvt7dtwdPfw8c3tSxxekY4EwzWwbMBL5mZo/XK9Oo10UJ4j89B3wrGDVzJFDu7qvDDmpfmFnPnW2PZjaKyLVudv+Bgxj/AHzs7nfvplhSXJd4ziUZrouZ5ZhZVvC4PXASsKheseeAi4LH5wJveNAz2pzEcy71+rPOJNJ31Oy4+y3unuvueUQ6oN9w9wvrFWvU69J6Xw9MRmb2BJFRJN3MrBT4EZFOK9z9N8CLREbMLAG2AheHE2nD4jiXc4HLzawG2AZMbI7/gYl8K/om8FHQTgzwfaAfJN11iedckuG69AIeMbM0IgnsSXefbWa3A4Xu/hyRRPiYmS0hMlhiYnjh7lE853KNmZ0J1BA5l8mhRbsPEnldNNWGiIjEpCYmERGJSQlCRERiUoIQEZGYlCBERCQmJQgREYlJCUKkAWZWGzXTZ7GZ3dyIr51nu5mRVyRsLeo+CJF9tC2YqkGkRVENQmQfmdkyM/uFmX0UrDkwMNieZ2ZvBJO/vW5m/YLtPczsmWCivnlmdnTwUmlm9rtgvYK/B3f8YmbXWGRtiRIzmxnSaUoLpgQh0rD29ZqYJkTtK3f3YcD9RGbahMgkfI8Ek7/9Cbgv2H4f8I9gor7DgAXB9kHAA+4+FNgEnBNsvxkYGbzOZYk6OZHd0Z3UIg0ws0p3z4ixfRnwNXdfGkzSt8bds83sC6CXu1cH21e7ezczKwNyoyaG2zkt+KvuPih4fhPQxt1/YmYvA5VEZnx9NmpdA5EmoRqEyP7x3TzeG9ujHtfyZd/g6cADRGobHwSzc4o0GSUIkf0zIerfd4PH7/DlJGkXAG8Hj18HLoddi9hk7u5FzawV0Nfd5wA3EZm2+b9qMSKJpG8kIg1rHzU7K8DL7r5zqGsXMyshUguYFGy7GnjYzL4HlPHl7LNTgYfM7DtEagqXA7ubtjwNeDxIIgbcF6xnINJk1Achso+CPogCd/8i7FhEEkFNTCIiEpNqECIiEpNqECIiEpMShIiIxKQEISIiMSlBiIhITEoQIiIS0/8Hjjn8AQT4gUYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model and predict"
      ],
      "metadata": {
        "id": "n21hSzVXPVDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "results = model.evaluate(x_test, y_test)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ1wzg-8OrCi",
        "outputId": "8ef4fa5c-303b-416a-c58c-d6c3fc7f0837"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2947 - accuracy: 0.8836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29469603300094604, 0.8835999965667725]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the loss has decreased and the accuracy is improved. So, this new model performs better than the old one"
      ],
      "metadata": {
        "id": "F1LnXtFlSjxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions and explore/understand the results"
      ],
      "metadata": {
        "id": "wU6M0HQfTj-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoKs6JHtPNyN",
        "outputId": "6ef3987a-847f-4877-99a4-9488430ea346"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFY_BRdiTWL3",
        "outputId": "3291ad47-92ea-447b-e985-f1762703431f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19901267],\n",
              "       [0.9997625 ],\n",
              "       [0.71418774],\n",
              "       ...,\n",
              "       [0.08759855],\n",
              "       [0.04182026],\n",
              "       [0.473292  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[10] # which is a close to 1=>a positive review, as we initially have seen it!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YJmKyP3PpUn",
        "outputId": "230889c7-8318-4f21-d150-f811938b72a9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94851595], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, to prevent your model from Overfitting: 1) get more training data, 2) reduce the capacity of the network, 3) add weight regularization and 4) add dropout layers. To prevent your model from Underfitting in NNs just try a bigger network!(from page 104)"
      ],
      "metadata": {
        "id": "iJ3ODB5PZDXD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kpco8jxTP2d"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 4. Classifying newswires, based on text content, into 46 topics"
      ],
      "metadata": {
        "id": "w4BQ3F6wT_QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a multi-class Classification problem"
      ],
      "metadata": {
        "id": "NGu5orJGVuXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and understand it"
      ],
      "metadata": {
        "id": "NXvdvz47W-oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) # num_words=10000 means that we only keep the top 10000 most frequently occuring words in the training data\n",
        " \n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_labels.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwGWmZKwUJVR",
        "outputId": "71fe83bd-a639-4ea0-b841-3ef2a10e3ce9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n",
            "X_train: (8982,)\n",
            "y_train: (8982,)\n",
            "X_test: (2246,)\n",
            "y_test: (2246,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_labels[10]}')\n",
        "print(f'the label of 11th example of test_labels: {test_labels[10]}\\n')\n",
        "print(f'the first 11 elements of train_labels: {train_labels[:11]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvlbhm3jVaWm",
        "outputId": "66ba6c5e-f9f5-4cd3-a084-aa9ed913dca1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n",
            "length of 11th example of train_data: 31\n",
            "the label of 11th example of train_labels: 3\n",
            "the label of 11th example of test_labels: 5\n",
            "\n",
            "the first 11 elements of train_labels: [ 3  4  3  4  4  4  4  3  3 16  3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with the imdb's reviews, each example here is also a list of integers(word indices)"
      ],
      "metadata": {
        "id": "dxborw1AXqe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data for the NN"
      ],
      "metadata": {
        "id": "Xn1nQd_UZW0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the integer sequences via multi-hot encoding for train_data and test_data: each example now is a 10000 sequence of 0s and 1s\n",
        "# if a word is on corpus of 10000, we have 1 and if a word is not in the corpus, we have 0\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "xIjj87rnZDyt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 ways to handle the labels/targets in such cases: 1) one-hot(categorical) encoding in which we use loss=categorical_crossentropy(and dtype is float) and 2) labels as integers in which we use sparse_categorical_crossentropy(dtype here is int, more @page 83)"
      ],
      "metadata": {
        "id": "a_goUT_TzsvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding for the train and test labels\n",
        "# (a 46 dimensional list with 0s and 1s)\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "07IJJhOSzqwb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train after preprocessing: {x_train.shape}')\n",
        "print(f'y_train after preprocessing: {one_hot_train_labels.shape}')\n",
        "print(f'X_test after preprocessing: {x_test.shape}')\n",
        "print(f'y_test after preprocessing: {one_hot_test_labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGK6txb7lVt4",
        "outputId": "5d8bf943-2334-456b-ec6b-54edc9e2f76a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train after preprocessing: (8982, 10000)\n",
            "y_train after preprocessing: (8982, 46)\n",
            "X_test after preprocessing: (2246, 10000)\n",
            "y_test after preprocessing: (2246, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'length of 11th example of train_data after preprocessing: {x_train[10].shape}')\n",
        "print(f'11th example of train_data after preprocessing:\\n {x_train[10]}')\n",
        "print(f'the label of 11th example of train_labels after preprocessing: {one_hot_train_labels[10]}')\n",
        "\n",
        "print(f'\\n11th example of x_test after preprocessing:\\n {x_test[10]}')\n",
        "print(f'the label of 11th example of test_labels after preprocessing: {one_hot_test_labels[10]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiCwu4Rple95",
        "outputId": "fa12e7d7-ad63-4ea7-8d26-6671e88184ae"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of 11th example of train_data after preprocessing: (10000,)\n",
            "11th example of train_data after preprocessing:\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            "the label of 11th example of train_labels after preprocessing: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "11th example of x_test after preprocessing:\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            "the label of 11th example of test_labels after preprocessing: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and train the model"
      ],
      "metadata": {
        "id": "E47YY_Fpc7ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's architecture\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# model's compiling\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# create a validation set \n",
        "# every model is not the best initially and always needs improvements via hyperparameter tuning. So, always create a validation set to test the model and when find the best tuning, train the final model on test set\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]\n",
        "\n",
        "# start training\n",
        "print('training ...\\n')\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCmDLGouZDvW",
        "outputId": "3d991088-18b6-41bd-e7a6-48d5395fc585"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 8s 479ms/step - loss: 2.6293 - accuracy: 0.5229 - val_loss: 1.7221 - val_accuracy: 0.6540\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 1.4128 - accuracy: 0.7092 - val_loss: 1.2814 - val_accuracy: 0.7260\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 1.0448 - accuracy: 0.7777 - val_loss: 1.1089 - val_accuracy: 0.7740\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.8212 - accuracy: 0.8255 - val_loss: 1.0144 - val_accuracy: 0.7840\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.6546 - accuracy: 0.8631 - val_loss: 0.9474 - val_accuracy: 0.7960\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 2s 131ms/step - loss: 0.5209 - accuracy: 0.8936 - val_loss: 0.9094 - val_accuracy: 0.8110\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.4225 - accuracy: 0.9107 - val_loss: 0.8803 - val_accuracy: 0.8150\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 0.3410 - accuracy: 0.9270 - val_loss: 0.8732 - val_accuracy: 0.8150\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.2832 - accuracy: 0.9399 - val_loss: 0.8696 - val_accuracy: 0.8150\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.2389 - accuracy: 0.9446 - val_loss: 0.8705 - val_accuracy: 0.8260\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.2021 - accuracy: 0.9505 - val_loss: 0.8933 - val_accuracy: 0.8140\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.1849 - accuracy: 0.9524 - val_loss: 0.9037 - val_accuracy: 0.8130\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.1651 - accuracy: 0.9544 - val_loss: 0.9666 - val_accuracy: 0.8030\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.1483 - accuracy: 0.9558 - val_loss: 0.9593 - val_accuracy: 0.8130\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.1357 - accuracy: 0.9573 - val_loss: 0.9664 - val_accuracy: 0.8160\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.1312 - accuracy: 0.9567 - val_loss: 0.9605 - val_accuracy: 0.8090\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 0.1259 - accuracy: 0.9569 - val_loss: 1.0122 - val_accuracy: 0.8050\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.1198 - accuracy: 0.9555 - val_loss: 1.0082 - val_accuracy: 0.8110\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.1149 - accuracy: 0.9587 - val_loss: 1.0184 - val_accuracy: 0.8080\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.1108 - accuracy: 0.9584 - val_loss: 1.0922 - val_accuracy: 0.7980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Eb6MLAftY6R",
        "outputId": "79b6c0bd-b333-4eaf-f251-00518622e694"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the training .vs validation loss and accuracy and Evaluating the model"
      ],
      "metadata": {
        "id": "EBXNskY0pe3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see what we have in history\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUqkqi08qi_W",
        "outputId": "4c7e4f4f-5aca-4d51-83f1-9bb1f04a63fd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LUR5KbFiZDsN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "839c671d-58b7-45a6-bad5-b219c3226764"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation accuracy\n",
        "plt.clf() # clear the existing figure\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YOIHJwh1ZDpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8ac2d0af-c75c-4e13-eaf5-7ba85ea0bb3a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the model starts to overfit after 8 epochs. So, we train a new model with 9 epochs"
      ],
      "metadata": {
        "id": "-PMkZzb1qv9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ],
      "metadata": {
        "id": "eiqmudSxZDmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5519c1c-21a0-4f87-849d-54769b5c75a8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 13ms/step - loss: 1.2214 - accuracy: 0.7907\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2213923931121826, 0.790739119052887]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain from scratch a new model, Evaluate it and Predict"
      ],
      "metadata": {
        "id": "P56CPMperQ1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the previous model, we train it again with just 9 epochs only"
      ],
      "metadata": {
        "id": "X31OTDQtr3q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# model's compiling\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# start training\n",
        "print('training ...\\n')\n",
        "history = model.fit(x_train,\n",
        "                    one_hot_train_labels,\n",
        "                    epochs=8,\n",
        "                    batch_size=512)"
      ],
      "metadata": {
        "id": "IfqH8531ZDjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94a149e-e242-466e-f28c-dd3487f6fbbc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training ...\n",
            "\n",
            "Epoch 1/8\n",
            "18/18 [==============================] - 2s 58ms/step - loss: 2.4582 - accuracy: 0.5439\n",
            "Epoch 2/8\n",
            "18/18 [==============================] - 3s 153ms/step - loss: 1.3414 - accuracy: 0.7150\n",
            "Epoch 3/8\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 1.0089 - accuracy: 0.7906\n",
            "Epoch 4/8\n",
            "18/18 [==============================] - 3s 149ms/step - loss: 0.7829 - accuracy: 0.8379\n",
            "Epoch 5/8\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 0.6111 - accuracy: 0.8756\n",
            "Epoch 6/8\n",
            "18/18 [==============================] - 2s 118ms/step - loss: 0.4863 - accuracy: 0.8976\n",
            "Epoch 7/8\n",
            "18/18 [==============================] - 2s 123ms/step - loss: 0.3890 - accuracy: 0.9182\n",
            "Epoch 8/8\n",
            "18/18 [==============================] - 2s 120ms/step - loss: 0.3147 - accuracy: 0.9309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the new model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1XHwTVxtVmU",
        "outputId": "30bea657-3bf1-462c-cacf-911a2d8bb64a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this new model\n",
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilDxbizUsYJq",
        "outputId": "66214896-a5a0-4309-ff9f-467855e42731"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 10ms/step - loss: 0.9480 - accuracy: 0.7894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9479662775993347, 0.7894033789634705]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 models have almost the same accuracy, but the new one has significatly decreased loss"
      ],
      "metadata": {
        "id": "Pfdqp9W5syDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions. understand what the results are\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "ZldgN5ksZDgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e06af3f-abb9-46d1-ff0d-d804f1780601"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 3s 43ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "r4998LAWZDdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4504488-21b7-47d2-97b9-e4b3bea13809"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.45870989e-06, 9.93177237e-05, 2.25430063e-06, ...,\n",
              "        4.61636046e-05, 3.62774995e-06, 1.47937881e-05],\n",
              "       [1.52566703e-03, 7.94575922e-03, 4.17266265e-02, ...,\n",
              "        1.15629184e-04, 1.35848941e-05, 1.25326906e-05],\n",
              "       [1.64027046e-02, 7.03707218e-01, 8.76618735e-03, ...,\n",
              "        2.44049216e-03, 8.75519298e-04, 2.13080129e-04],\n",
              "       ...,\n",
              "       [3.82413509e-06, 2.23297364e-04, 2.50090943e-06, ...,\n",
              "        9.31760678e-06, 8.63630794e-06, 1.07747728e-05],\n",
              "       [9.00465122e-04, 2.63411161e-02, 8.67949857e-04, ...,\n",
              "        2.10439693e-03, 2.92008888e-04, 7.87546276e-04],\n",
              "       [2.61675240e-03, 4.36754972e-01, 2.66705565e-02, ...,\n",
              "        6.30120281e-04, 6.49985159e-04, 1.16810246e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every prediction is comprised of 46 probs vector\n",
        "predictions[10].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv1ewRT6wjCP",
        "outputId": "1d37aacd-0f89-49a2-ca55-1a37d1b93666"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a prediction vector\n",
        "predictions[10] "
      ],
      "metadata": {
        "id": "mYKkApDlZDap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48284aa5-eb4a-4eff-d879-ce52a92d0e6f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.0681438e-03, 7.6033258e-01, 6.5764911e-03, 3.5031661e-02,\n",
              "       3.9737474e-02, 2.1590039e-02, 5.4274220e-04, 1.8972363e-03,\n",
              "       1.2138688e-03, 8.7480783e-04, 8.8586751e-03, 4.9244487e-03,\n",
              "       3.4489024e-03, 8.0279552e-04, 3.0026354e-03, 9.5458102e-04,\n",
              "       6.5662101e-04, 2.3543548e-03, 9.9982671e-04, 1.2111659e-02,\n",
              "       7.3548658e-03, 2.5252954e-04, 1.6428712e-03, 7.0178375e-04,\n",
              "       4.4555083e-02, 2.4114226e-03, 4.8711631e-04, 3.3702797e-03,\n",
              "       2.9820092e-03, 2.1857735e-04, 1.5339400e-03, 4.1127047e-03,\n",
              "       1.3191384e-03, 1.9753806e-04, 5.5604603e-04, 1.0591638e-04,\n",
              "       1.1609535e-03, 1.3424334e-03, 4.8996233e-03, 2.1213933e-03,\n",
              "       1.0687008e-03, 1.0952564e-03, 4.2563248e-03, 4.7779354e-04,\n",
              "       5.4951495e-04, 2.4671285e-04], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index of the highest probability. check it above\n",
        "np.argmax(predictions[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO7otZzLwiT1",
        "outputId": "b67a7bb0-b142-4da8-fbb1-7404ccf87406"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficients of each vector of 46 elements must have sum=1 \n",
        "np.sum(predictions[10])"
      ],
      "metadata": {
        "id": "6UV7DX5lZDXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b6f08e-8b4e-4584-c816-4acf3d8cadcd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and check manually if the prediction is correct \n",
        "one_hot_test_labels[10]"
      ],
      "metadata": {
        "id": "uR29IupWZDU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f838f750-0c37-443b-a534-8b91e5bbb52d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4muV4R33ZI8f"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 5. Predicting house prices"
      ],
      "metadata": {
        "id": "WCP4acTg0dlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a linear regression problem"
      ],
      "metadata": {
        "id": "gNX4DGhV0uS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "ete78P9067Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "print(f'X_train: {train_data.shape}')\n",
        "print(f'y_train: {train_targets.shape}')\n",
        "print(f'X_test: {test_data.shape}')\n",
        "print(f'y_test: {test_targets.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ8RyWph0jPZ",
        "outputId": "46231961-9134-44a4-9866-fb7413811f93"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n",
            "X_train: (404, 13)\n",
            "y_train: (404,)\n",
            "X_test: (102, 13)\n",
            "y_test: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, always explrore your dataset\n",
        "# let's see some examples\n",
        "print(f'11th example of train_data:\\n {train_data[10]}')\n",
        "print(f'length of 11th example of train_data: {len(train_data[10])}')\n",
        "\n",
        "print(f'the label of 11th example of train_labels: {train_targets[10]}')\n",
        "print(f'the label of 11th example of test_labels: {test_targets[10]}\\n')\n",
        "print(f'the first 11 elements of train_labels: {train_targets[:11]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ-AYtSP0_Sr",
        "outputId": "a0967cca-fef0-4944-a29f-a454cf9b3b67"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11th example of train_data:\n",
            " [  9.59571   0.       18.1       0.        0.693     6.404   100.\n",
            "   1.639    24.      666.       20.2     376.11     20.31   ]\n",
            "length of 11th example of train_data: 13\n",
            "the label of 11th example of train_labels: 12.1\n",
            "the label of 11th example of test_labels: 18.6\n",
            "\n",
            "the first 11 elements of train_labels: [15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data"
      ],
      "metadata": {
        "id": "UlrGVwn07n2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization of the train and test data\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "metadata": {
        "id": "YrWIytyT0_P0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build, Train and Evaluate the model using K-fold cross-validation"
      ],
      "metadata": {
        "id": "okjds-Ld9Fy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building function of the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# when little data available for training, we use a small network!\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "pHqgsX150_NF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a best model, we need a validation set in order to use it as an intermediate dataset to improve it, as we always do. However, having so few examples in the train_data, a small validation set does not help, so we split the train_data into k partitions, build, train(on k-1 partitions) and evaluate(on k partition) k models. The final model is the average of k models(more @page87)"
      ],
      "metadata": {
        "id": "RlKCmUnF95Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]  \n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=16)#, verbose=0\n",
        "    mae_history = history.history[\"val_mae\"]\n",
        "    all_mae_histories.append(mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHVWITi30_J_",
        "outputId": "7d125232-a07b-4a3b-ead1-a9ecc2cfd624"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing fold #0\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 502.9174 - mae: 20.6008 - val_loss: 410.7994 - val_mae: 18.0924\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 372.8565 - mae: 17.1826 - val_loss: 272.2120 - val_mae: 14.2231\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 244.3212 - mae: 13.1515 - val_loss: 150.8510 - val_mae: 9.7487\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 145.1294 - mae: 9.3395 - val_loss: 80.3372 - val_mae: 6.5315\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 87.4659 - mae: 6.9889 - val_loss: 50.0494 - val_mae: 5.1978\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 58.5506 - mae: 5.6661 - val_loss: 36.2709 - val_mae: 4.3205\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 40.7858 - mae: 4.7487 - val_loss: 27.4975 - val_mae: 3.5827\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 30.8422 - mae: 4.0654 - val_loss: 22.8426 - val_mae: 3.1739\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 24.9611 - mae: 3.6569 - val_loss: 19.7601 - val_mae: 2.9339\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 22.2597 - mae: 3.4036 - val_loss: 18.1587 - val_mae: 2.8767\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 20.1263 - mae: 3.2261 - val_loss: 16.4996 - val_mae: 2.6672\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 18.5838 - mae: 3.0490 - val_loss: 15.3315 - val_mae: 2.6218\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 17.4337 - mae: 2.9959 - val_loss: 14.3388 - val_mae: 2.5335\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 16.4698 - mae: 2.8590 - val_loss: 13.9844 - val_mae: 2.5318\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 15.9165 - mae: 2.7918 - val_loss: 12.8517 - val_mae: 2.4606\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 15.0838 - mae: 2.6978 - val_loss: 12.9239 - val_mae: 2.5156\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 14.4009 - mae: 2.6594 - val_loss: 12.4210 - val_mae: 2.5075\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.7803 - mae: 2.6091 - val_loss: 11.8771 - val_mae: 2.4067\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.4421 - mae: 2.5543 - val_loss: 10.9979 - val_mae: 2.3677\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 12.9041 - mae: 2.5613 - val_loss: 10.5533 - val_mae: 2.2235\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 12.4420 - mae: 2.4769 - val_loss: 10.1401 - val_mae: 2.2309\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 12.1592 - mae: 2.4785 - val_loss: 9.8581 - val_mae: 2.2069\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 12.1554 - mae: 2.4318 - val_loss: 9.8720 - val_mae: 2.2083\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.7231 - mae: 2.4214 - val_loss: 10.8864 - val_mae: 2.3802\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.4876 - mae: 2.4075 - val_loss: 9.8522 - val_mae: 2.1927\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.1490 - mae: 2.3467 - val_loss: 9.7563 - val_mae: 2.2972\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.0289 - mae: 2.3745 - val_loss: 9.1875 - val_mae: 2.0991\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.8840 - mae: 2.3247 - val_loss: 9.3330 - val_mae: 2.2347\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.6858 - mae: 2.3315 - val_loss: 8.8758 - val_mae: 2.1213\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.2833 - mae: 2.2929 - val_loss: 9.3552 - val_mae: 2.1441\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.3036 - mae: 2.2741 - val_loss: 9.0839 - val_mae: 2.1518\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.3725 - mae: 2.2887 - val_loss: 8.8810 - val_mae: 2.1433\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.8295 - mae: 2.2253 - val_loss: 8.8224 - val_mae: 2.0511\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.2471 - mae: 2.2938 - val_loss: 8.6748 - val_mae: 2.0678\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.6723 - mae: 2.1933 - val_loss: 8.4212 - val_mae: 2.0565\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.6961 - mae: 2.1686 - val_loss: 9.5809 - val_mae: 2.2620\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.6776 - mae: 2.1944 - val_loss: 8.5923 - val_mae: 2.1379\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.5574 - mae: 2.2039 - val_loss: 9.0994 - val_mae: 2.2104\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.4923 - mae: 2.1769 - val_loss: 8.5593 - val_mae: 2.1231\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.3689 - mae: 2.2101 - val_loss: 8.4126 - val_mae: 2.1082\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.1787 - mae: 2.1522 - val_loss: 9.1576 - val_mae: 2.2056\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.1682 - mae: 2.1431 - val_loss: 8.3151 - val_mae: 2.0856\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.1529 - mae: 2.1713 - val_loss: 8.3252 - val_mae: 2.0112\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.0117 - mae: 2.1311 - val_loss: 8.0593 - val_mae: 2.0082\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.6572 - mae: 2.0942 - val_loss: 9.0936 - val_mae: 2.0797\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.9666 - mae: 2.1375 - val_loss: 8.1374 - val_mae: 2.0269\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.6073 - mae: 2.0640 - val_loss: 8.0330 - val_mae: 2.0077\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.4660 - mae: 2.0195 - val_loss: 8.0110 - val_mae: 1.9645\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.7621 - mae: 2.0840 - val_loss: 8.2087 - val_mae: 2.0355\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.3895 - mae: 2.0716 - val_loss: 8.2826 - val_mae: 1.9585\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.5857 - mae: 2.0495 - val_loss: 8.1283 - val_mae: 2.0397\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.9519 - mae: 1.9929 - val_loss: 10.3635 - val_mae: 2.4861\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.5299 - mae: 2.0798 - val_loss: 8.5970 - val_mae: 2.1620\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0115 - mae: 2.0137 - val_loss: 8.2004 - val_mae: 1.9626\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.9483 - mae: 2.0229 - val_loss: 8.2723 - val_mae: 1.9652\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.1361 - mae: 2.0171 - val_loss: 7.9492 - val_mae: 2.0442\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.0179 - mae: 2.0010 - val_loss: 8.2049 - val_mae: 2.0586\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.6469 - mae: 1.9415 - val_loss: 7.9211 - val_mae: 2.0143\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.8878 - mae: 1.9643 - val_loss: 7.9565 - val_mae: 1.9710\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.8241 - mae: 1.9558 - val_loss: 7.8464 - val_mae: 1.9667\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.8740 - mae: 1.9516 - val_loss: 7.8214 - val_mae: 1.9815\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.5957 - mae: 1.9426 - val_loss: 7.9025 - val_mae: 1.9886\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.5620 - mae: 1.9377 - val_loss: 8.0551 - val_mae: 2.0076\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.4794 - mae: 1.9020 - val_loss: 7.8529 - val_mae: 1.9887\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.5596 - mae: 1.9430 - val_loss: 7.8153 - val_mae: 1.9687\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3277 - mae: 1.9190 - val_loss: 7.8424 - val_mae: 1.9818\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.2787 - mae: 1.8863 - val_loss: 7.8508 - val_mae: 1.9809\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.2350 - mae: 1.8816 - val_loss: 8.0517 - val_mae: 2.0641\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3060 - mae: 1.9135 - val_loss: 8.0083 - val_mae: 1.9618\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 7.1626 - mae: 1.8655 - val_loss: 8.3988 - val_mae: 1.9825\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0559 - mae: 1.8997 - val_loss: 8.8370 - val_mae: 2.2429\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0386 - mae: 1.8350 - val_loss: 8.0412 - val_mae: 2.0593\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.8033 - mae: 1.8297 - val_loss: 8.8832 - val_mae: 2.1364\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.9346 - mae: 1.8532 - val_loss: 8.2095 - val_mae: 1.9960\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.8107 - mae: 1.8257 - val_loss: 8.2454 - val_mae: 2.0296\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.7230 - mae: 1.8645 - val_loss: 7.9442 - val_mae: 2.0078\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.7634 - mae: 1.8230 - val_loss: 7.7275 - val_mae: 1.9664\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6474 - mae: 1.8295 - val_loss: 7.8878 - val_mae: 1.9527\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5762 - mae: 1.7677 - val_loss: 8.0461 - val_mae: 2.0507\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.4942 - mae: 1.7873 - val_loss: 8.4121 - val_mae: 2.1367\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5205 - mae: 1.8155 - val_loss: 8.6747 - val_mae: 2.0967\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5330 - mae: 1.8330 - val_loss: 8.9266 - val_mae: 2.2237\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.3497 - mae: 1.7465 - val_loss: 8.1945 - val_mae: 2.0525\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5699 - mae: 1.7946 - val_loss: 8.2052 - val_mae: 2.0076\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.3153 - mae: 1.7528 - val_loss: 8.4954 - val_mae: 2.1146\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.9743 - mae: 1.7618 - val_loss: 8.3150 - val_mae: 2.0534\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.2841 - mae: 1.7588 - val_loss: 8.1120 - val_mae: 2.1123\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 6.4358 - mae: 1.7780 - val_loss: 8.7896 - val_mae: 2.1423\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.0621 - mae: 1.7482 - val_loss: 8.2118 - val_mae: 2.0535\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.1749 - mae: 1.7137 - val_loss: 8.0754 - val_mae: 1.9664\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0633 - mae: 1.7124 - val_loss: 8.3286 - val_mae: 2.0826\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0595 - mae: 1.7325 - val_loss: 8.3238 - val_mae: 1.9676\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.9657 - mae: 1.7345 - val_loss: 8.0993 - val_mae: 2.0048\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0152 - mae: 1.7422 - val_loss: 8.3961 - val_mae: 2.0983\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7351 - mae: 1.7040 - val_loss: 8.5394 - val_mae: 2.0464\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7923 - mae: 1.7032 - val_loss: 8.1604 - val_mae: 2.0150\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 5.9214 - mae: 1.6907 - val_loss: 8.3644 - val_mae: 2.1440\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7886 - mae: 1.7067 - val_loss: 8.8314 - val_mae: 2.1480\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6071 - mae: 1.6770 - val_loss: 8.4343 - val_mae: 2.0031\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.8934 - mae: 1.6936 - val_loss: 8.6395 - val_mae: 2.1602\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 5.6880 - mae: 1.6687 - val_loss: 8.6042 - val_mae: 2.1248\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8012 - mae: 1.6895 - val_loss: 8.5693 - val_mae: 2.0881\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6423 - mae: 1.6652 - val_loss: 8.2270 - val_mae: 2.0444\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.4611 - mae: 1.6408 - val_loss: 9.2553 - val_mae: 2.2506\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5748 - mae: 1.6889 - val_loss: 8.4990 - val_mae: 2.0146\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5030 - mae: 1.6511 - val_loss: 8.4090 - val_mae: 2.0649\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5175 - mae: 1.6467 - val_loss: 9.1748 - val_mae: 2.1549\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.4185 - mae: 1.6532 - val_loss: 8.5784 - val_mae: 2.0897\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.4084 - mae: 1.6358 - val_loss: 8.7001 - val_mae: 2.0812\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3877 - mae: 1.6430 - val_loss: 8.9983 - val_mae: 2.0891\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0953 - mae: 1.5877 - val_loss: 8.5590 - val_mae: 2.0377\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.2833 - mae: 1.6166 - val_loss: 8.9385 - val_mae: 2.0550\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1974 - mae: 1.6279 - val_loss: 8.7514 - val_mae: 2.1005\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.2544 - mae: 1.6337 - val_loss: 8.8124 - val_mae: 2.1271\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1272 - mae: 1.6080 - val_loss: 9.2878 - val_mae: 2.0858\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1700 - mae: 1.6227 - val_loss: 8.6589 - val_mae: 2.0413\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 5.2515 - mae: 1.5936 - val_loss: 9.1763 - val_mae: 2.2969\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9277 - mae: 1.5915 - val_loss: 9.5893 - val_mae: 2.1218\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0789 - mae: 1.5608 - val_loss: 8.7607 - val_mae: 2.1661\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.2795 - mae: 1.6006 - val_loss: 8.6251 - val_mae: 2.0594\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9480 - mae: 1.5738 - val_loss: 8.7171 - val_mae: 2.0613\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.8253 - mae: 1.5349 - val_loss: 9.1018 - val_mae: 2.0590\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9313 - mae: 1.5967 - val_loss: 9.0743 - val_mae: 2.1303\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.9957 - mae: 1.5571 - val_loss: 9.1038 - val_mae: 2.1938\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7730 - mae: 1.5635 - val_loss: 8.9501 - val_mae: 2.1540\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0299 - mae: 1.5980 - val_loss: 8.7920 - val_mae: 2.0836\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7227 - mae: 1.5484 - val_loss: 9.4217 - val_mae: 2.0551\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7755 - mae: 1.5510 - val_loss: 9.1773 - val_mae: 2.1523\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.6594 - mae: 1.5272 - val_loss: 8.7979 - val_mae: 1.9963\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.8235 - mae: 1.5249 - val_loss: 8.8967 - val_mae: 2.0375\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 4.8049 - mae: 1.5384 - val_loss: 9.6633 - val_mae: 2.3044\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4948 - mae: 1.5033 - val_loss: 8.9300 - val_mae: 2.1368\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.6255 - mae: 1.5448 - val_loss: 9.0034 - val_mae: 2.1105\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.6029 - mae: 1.4981 - val_loss: 9.2544 - val_mae: 2.1646\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.8860 - mae: 1.5558 - val_loss: 8.7985 - val_mae: 2.0657\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5327 - mae: 1.5012 - val_loss: 9.0421 - val_mae: 2.1592\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7913 - mae: 1.5486 - val_loss: 8.9305 - val_mae: 2.0656\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4342 - mae: 1.4806 - val_loss: 9.4116 - val_mae: 2.3023\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5673 - mae: 1.5341 - val_loss: 9.3089 - val_mae: 2.1264\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4337 - mae: 1.5000 - val_loss: 8.9998 - val_mae: 2.0602\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4594 - mae: 1.4805 - val_loss: 9.1626 - val_mae: 2.1055\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3973 - mae: 1.4982 - val_loss: 9.0055 - val_mae: 2.1064\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2865 - mae: 1.4448 - val_loss: 9.2061 - val_mae: 2.0859\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.3960 - mae: 1.4629 - val_loss: 9.0906 - val_mae: 2.1316\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 4.3719 - mae: 1.4573 - val_loss: 8.8827 - val_mae: 2.0820\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2756 - mae: 1.4824 - val_loss: 8.9196 - val_mae: 2.0073\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2889 - mae: 1.4457 - val_loss: 9.2349 - val_mae: 2.0315\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2598 - mae: 1.4620 - val_loss: 9.0048 - val_mae: 2.0198\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1979 - mae: 1.4579 - val_loss: 9.3503 - val_mae: 2.0377\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1667 - mae: 1.4509 - val_loss: 8.9867 - val_mae: 2.1239\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1555 - mae: 1.4608 - val_loss: 9.4970 - val_mae: 2.1791\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0599 - mae: 1.4292 - val_loss: 9.2080 - val_mae: 2.1719\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1558 - mae: 1.4639 - val_loss: 9.1611 - val_mae: 2.0427\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1569 - mae: 1.4406 - val_loss: 8.9674 - val_mae: 2.0412\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0513 - mae: 1.4216 - val_loss: 9.1230 - val_mae: 2.0358\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0688 - mae: 1.4528 - val_loss: 9.9236 - val_mae: 2.2260\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8849 - mae: 1.3741 - val_loss: 9.7347 - val_mae: 2.1111\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.1146 - mae: 1.4426 - val_loss: 9.2883 - val_mae: 2.0510\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9093 - mae: 1.3970 - val_loss: 9.6318 - val_mae: 2.1708\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0508 - mae: 1.4622 - val_loss: 9.3680 - val_mae: 2.0702\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9495 - mae: 1.4071 - val_loss: 9.4275 - val_mae: 2.1764\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0221 - mae: 1.4184 - val_loss: 9.0703 - val_mae: 2.0836\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8935 - mae: 1.4322 - val_loss: 9.0758 - val_mae: 2.1143\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0027 - mae: 1.3890 - val_loss: 10.3829 - val_mae: 2.3776\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9352 - mae: 1.4274 - val_loss: 9.1802 - val_mae: 2.0602\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9469 - mae: 1.4065 - val_loss: 9.6210 - val_mae: 2.2552\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6236 - mae: 1.3322 - val_loss: 9.1722 - val_mae: 2.0606\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0074 - mae: 1.3779 - val_loss: 9.9687 - val_mae: 2.1632\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8077 - mae: 1.3823 - val_loss: 9.3150 - val_mae: 2.0790\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7197 - mae: 1.3616 - val_loss: 9.6076 - val_mae: 2.0811\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8876 - mae: 1.3897 - val_loss: 9.6199 - val_mae: 2.1630\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8219 - mae: 1.3914 - val_loss: 10.3440 - val_mae: 2.4308\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8155 - mae: 1.4042 - val_loss: 9.8402 - val_mae: 2.1962\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6646 - mae: 1.3773 - val_loss: 11.5285 - val_mae: 2.5257\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9506 - mae: 1.3898 - val_loss: 9.9064 - val_mae: 2.2151\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6710 - mae: 1.4021 - val_loss: 9.3382 - val_mae: 2.0950\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5091 - mae: 1.3327 - val_loss: 9.4731 - val_mae: 2.2081\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6176 - mae: 1.3484 - val_loss: 9.7541 - val_mae: 2.1171\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7313 - mae: 1.3625 - val_loss: 9.3822 - val_mae: 2.1398\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5135 - mae: 1.3193 - val_loss: 9.3870 - val_mae: 2.0793\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5540 - mae: 1.3905 - val_loss: 9.8281 - val_mae: 2.2731\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5262 - mae: 1.3325 - val_loss: 9.7357 - val_mae: 2.1247\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5712 - mae: 1.3400 - val_loss: 9.4099 - val_mae: 2.0770\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5630 - mae: 1.3550 - val_loss: 9.6677 - val_mae: 2.2027\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4000 - mae: 1.3003 - val_loss: 9.0537 - val_mae: 2.1201\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4437 - mae: 1.3073 - val_loss: 9.0304 - val_mae: 2.0474\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5789 - mae: 1.3611 - val_loss: 9.3496 - val_mae: 2.1500\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3617 - mae: 1.2767 - val_loss: 10.6945 - val_mae: 2.3405\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2923 - mae: 1.2874 - val_loss: 9.3003 - val_mae: 2.1604\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3959 - mae: 1.3015 - val_loss: 10.2498 - val_mae: 2.1653\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4877 - mae: 1.3310 - val_loss: 9.8184 - val_mae: 2.1651\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3375 - mae: 1.2815 - val_loss: 9.3309 - val_mae: 2.1325\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3101 - mae: 1.3054 - val_loss: 9.6704 - val_mae: 2.1802\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4059 - mae: 1.3067 - val_loss: 10.5920 - val_mae: 2.4849\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3463 - mae: 1.3087 - val_loss: 9.4151 - val_mae: 2.1025\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4062 - mae: 1.3002 - val_loss: 9.8423 - val_mae: 2.2149\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 3.2454 - mae: 1.2735 - val_loss: 10.1211 - val_mae: 2.4212\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3208 - mae: 1.3095 - val_loss: 9.4303 - val_mae: 2.1594\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3212 - mae: 1.2626 - val_loss: 9.5646 - val_mae: 2.1354\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1244 - mae: 1.2465 - val_loss: 9.8237 - val_mae: 2.1411\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2718 - mae: 1.2624 - val_loss: 10.4728 - val_mae: 2.3616\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3331 - mae: 1.3073 - val_loss: 9.5835 - val_mae: 2.2065\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2154 - mae: 1.2823 - val_loss: 9.9319 - val_mae: 2.1871\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1274 - mae: 1.2572 - val_loss: 9.5508 - val_mae: 2.1210\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0831 - mae: 1.2456 - val_loss: 10.4869 - val_mae: 2.3938\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3602 - mae: 1.3108 - val_loss: 9.6191 - val_mae: 2.2716\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1906 - mae: 1.2646 - val_loss: 9.6312 - val_mae: 2.2318\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0757 - mae: 1.2148 - val_loss: 9.2996 - val_mae: 2.1059\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1180 - mae: 1.2254 - val_loss: 9.3941 - val_mae: 2.1871\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2040 - mae: 1.2644 - val_loss: 9.4804 - val_mae: 2.0942\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0389 - mae: 1.2365 - val_loss: 10.1648 - val_mae: 2.2385\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9460 - mae: 1.1915 - val_loss: 10.2315 - val_mae: 2.2053\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9917 - mae: 1.2281 - val_loss: 10.0621 - val_mae: 2.2711\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1072 - mae: 1.2503 - val_loss: 10.3824 - val_mae: 2.3940\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8841 - mae: 1.2005 - val_loss: 11.7317 - val_mae: 2.5294\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1723 - mae: 1.2930 - val_loss: 9.9357 - val_mae: 2.1145\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9211 - mae: 1.1880 - val_loss: 9.7293 - val_mae: 2.1146\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9870 - mae: 1.2299 - val_loss: 9.3157 - val_mae: 2.1124\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9551 - mae: 1.2037 - val_loss: 9.4754 - val_mae: 2.1411\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8510 - mae: 1.1928 - val_loss: 9.6344 - val_mae: 2.1487\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9303 - mae: 1.2173 - val_loss: 9.3034 - val_mae: 2.1488\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0596 - mae: 1.2831 - val_loss: 10.0598 - val_mae: 2.2893\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8859 - mae: 1.2044 - val_loss: 9.8226 - val_mae: 2.0991\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8682 - mae: 1.1957 - val_loss: 9.5679 - val_mae: 2.1139\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9523 - mae: 1.2326 - val_loss: 10.1131 - val_mae: 2.2026\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8237 - mae: 1.1904 - val_loss: 9.7246 - val_mae: 2.2966\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7835 - mae: 1.1850 - val_loss: 10.4718 - val_mae: 2.2331\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8706 - mae: 1.1838 - val_loss: 9.2080 - val_mae: 2.1019\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7186 - mae: 1.1792 - val_loss: 10.0531 - val_mae: 2.1675\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6832 - mae: 1.1720 - val_loss: 9.6182 - val_mae: 2.1081\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7987 - mae: 1.1843 - val_loss: 9.8407 - val_mae: 2.1648\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7885 - mae: 1.1921 - val_loss: 9.8250 - val_mae: 2.2273\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7541 - mae: 1.1792 - val_loss: 9.5727 - val_mae: 2.1290\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7095 - mae: 1.1439 - val_loss: 9.6120 - val_mae: 2.2127\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7754 - mae: 1.1834 - val_loss: 9.5403 - val_mae: 2.1145\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7671 - mae: 1.1770 - val_loss: 10.1115 - val_mae: 2.2889\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6320 - mae: 1.1421 - val_loss: 10.2531 - val_mae: 2.3130\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6988 - mae: 1.1503 - val_loss: 9.6009 - val_mae: 2.2059\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5996 - mae: 1.1660 - val_loss: 9.9999 - val_mae: 2.2335\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6585 - mae: 1.1558 - val_loss: 10.0693 - val_mae: 2.2003\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6942 - mae: 1.1877 - val_loss: 10.1639 - val_mae: 2.1791\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6955 - mae: 1.1693 - val_loss: 9.8410 - val_mae: 2.2092\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 2.6253 - mae: 1.1689 - val_loss: 9.8857 - val_mae: 2.2829\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6723 - mae: 1.1759 - val_loss: 10.0422 - val_mae: 2.2038\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6163 - mae: 1.1489 - val_loss: 9.5549 - val_mae: 2.1463\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6304 - mae: 1.1229 - val_loss: 10.4987 - val_mae: 2.4263\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6714 - mae: 1.1516 - val_loss: 10.1413 - val_mae: 2.3421\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4664 - mae: 1.0981 - val_loss: 9.7612 - val_mae: 2.1424\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6280 - mae: 1.1431 - val_loss: 10.4338 - val_mae: 2.2206\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5344 - mae: 1.0959 - val_loss: 9.5944 - val_mae: 2.1442\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5548 - mae: 1.1373 - val_loss: 9.3491 - val_mae: 2.0997\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3892 - mae: 1.0887 - val_loss: 9.7394 - val_mae: 2.2281\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5564 - mae: 1.1331 - val_loss: 9.5024 - val_mae: 2.1456\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6557 - mae: 1.1527 - val_loss: 10.8327 - val_mae: 2.3459\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5053 - mae: 1.1397 - val_loss: 9.4964 - val_mae: 2.0975\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3967 - mae: 1.1155 - val_loss: 10.1749 - val_mae: 2.1726\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.4143 - mae: 1.1318 - val_loss: 9.5720 - val_mae: 2.1128\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6162 - mae: 1.1431 - val_loss: 9.7720 - val_mae: 2.1819\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2713 - mae: 1.0820 - val_loss: 10.3307 - val_mae: 2.2471\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4301 - mae: 1.1016 - val_loss: 10.1563 - val_mae: 2.2142\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4446 - mae: 1.1379 - val_loss: 10.0301 - val_mae: 2.2895\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4124 - mae: 1.0872 - val_loss: 9.8358 - val_mae: 2.1825\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4288 - mae: 1.0887 - val_loss: 10.9110 - val_mae: 2.2854\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 2.4222 - mae: 1.1307 - val_loss: 10.4906 - val_mae: 2.3828\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3780 - mae: 1.1078 - val_loss: 9.6829 - val_mae: 2.1680\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3151 - mae: 1.0787 - val_loss: 10.4822 - val_mae: 2.2367\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2811 - mae: 1.0403 - val_loss: 10.3925 - val_mae: 2.2491\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3777 - mae: 1.0951 - val_loss: 9.5463 - val_mae: 2.2283\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.3122 - mae: 1.0551 - val_loss: 9.9235 - val_mae: 2.1474\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3508 - mae: 1.0871 - val_loss: 9.8402 - val_mae: 2.2001\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3224 - mae: 1.0973 - val_loss: 11.0180 - val_mae: 2.2653\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.2685 - mae: 1.0558 - val_loss: 11.3640 - val_mae: 2.3977\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3201 - mae: 1.1042 - val_loss: 10.0262 - val_mae: 2.2642\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 2.2775 - mae: 1.0969 - val_loss: 9.9263 - val_mae: 2.1940\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2082 - mae: 1.0647 - val_loss: 10.1391 - val_mae: 2.2734\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3043 - mae: 1.0742 - val_loss: 9.9986 - val_mae: 2.1466\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1788 - mae: 1.0379 - val_loss: 9.7886 - val_mae: 2.1702\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1223 - mae: 1.0394 - val_loss: 9.6571 - val_mae: 2.1537\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2134 - mae: 1.0394 - val_loss: 10.1174 - val_mae: 2.2819\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1557 - mae: 1.0791 - val_loss: 9.8130 - val_mae: 2.2134\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1748 - mae: 1.0432 - val_loss: 9.9355 - val_mae: 2.1684\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1793 - mae: 1.0194 - val_loss: 9.7467 - val_mae: 2.1577\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2124 - mae: 1.0453 - val_loss: 10.1092 - val_mae: 2.1690\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3634 - mae: 1.0960 - val_loss: 10.2452 - val_mae: 2.2284\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9798 - mae: 0.9938 - val_loss: 10.3095 - val_mae: 2.1794\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0353 - mae: 1.0603 - val_loss: 10.3503 - val_mae: 2.2259\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0175 - mae: 1.0169 - val_loss: 10.0352 - val_mae: 2.1931\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0616 - mae: 1.0080 - val_loss: 9.9193 - val_mae: 2.2161\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0175 - mae: 1.0191 - val_loss: 9.7005 - val_mae: 2.1469\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2997 - mae: 1.0540 - val_loss: 10.7780 - val_mae: 2.2910\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9191 - mae: 0.9584 - val_loss: 10.6355 - val_mae: 2.2072\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1167 - mae: 1.0601 - val_loss: 10.1194 - val_mae: 2.2081\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9032 - mae: 0.9706 - val_loss: 9.7763 - val_mae: 2.1441\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0321 - mae: 1.0141 - val_loss: 10.4363 - val_mae: 2.2995\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1037 - mae: 1.0434 - val_loss: 9.9275 - val_mae: 2.1625\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9067 - mae: 1.0012 - val_loss: 9.9351 - val_mae: 2.1192\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9927 - mae: 1.0076 - val_loss: 10.7103 - val_mae: 2.2660\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8982 - mae: 0.9926 - val_loss: 10.1401 - val_mae: 2.1983\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0547 - mae: 1.0255 - val_loss: 10.7113 - val_mae: 2.2989\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9817 - mae: 0.9756 - val_loss: 10.0978 - val_mae: 2.2401\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9507 - mae: 1.0020 - val_loss: 11.3791 - val_mae: 2.5446\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1798 - mae: 1.0453 - val_loss: 9.6766 - val_mae: 2.1805\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8358 - mae: 0.9619 - val_loss: 12.1142 - val_mae: 2.5651\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0215 - mae: 0.9841 - val_loss: 10.2269 - val_mae: 2.2174\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1602 - mae: 1.0125 - val_loss: 10.0734 - val_mae: 2.2496\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9411 - mae: 0.9519 - val_loss: 10.1690 - val_mae: 2.1746\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1749 - mae: 1.0582 - val_loss: 10.5297 - val_mae: 2.2335\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7549 - mae: 0.9334 - val_loss: 10.0834 - val_mae: 2.1469\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0188 - mae: 1.0254 - val_loss: 10.0751 - val_mae: 2.2124\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8765 - mae: 0.9525 - val_loss: 10.5465 - val_mae: 2.2074\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0057 - mae: 1.0104 - val_loss: 10.3262 - val_mae: 2.2105\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9331 - mae: 0.9818 - val_loss: 10.0833 - val_mae: 2.1911\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8544 - mae: 0.9686 - val_loss: 10.4462 - val_mae: 2.2175\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8914 - mae: 0.9687 - val_loss: 10.2137 - val_mae: 2.2466\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8036 - mae: 0.9416 - val_loss: 10.3789 - val_mae: 2.2588\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8614 - mae: 0.9748 - val_loss: 10.9062 - val_mae: 2.2211\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8893 - mae: 0.9643 - val_loss: 10.9513 - val_mae: 2.2721\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9040 - mae: 0.9861 - val_loss: 10.0924 - val_mae: 2.2432\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8172 - mae: 0.9368 - val_loss: 12.4292 - val_mae: 2.6804\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0433 - mae: 1.0202 - val_loss: 11.7333 - val_mae: 2.3656\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8144 - mae: 0.9734 - val_loss: 10.8151 - val_mae: 2.2312\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7677 - mae: 0.9229 - val_loss: 10.6630 - val_mae: 2.2828\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8109 - mae: 0.9681 - val_loss: 10.2352 - val_mae: 2.2093\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8149 - mae: 0.9928 - val_loss: 10.6919 - val_mae: 2.2101\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8207 - mae: 0.9662 - val_loss: 10.9880 - val_mae: 2.3193\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7191 - mae: 0.9425 - val_loss: 10.9392 - val_mae: 2.2796\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8994 - mae: 0.9652 - val_loss: 10.5082 - val_mae: 2.2647\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7633 - mae: 0.9673 - val_loss: 10.3276 - val_mae: 2.2832\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6522 - mae: 0.9133 - val_loss: 10.6044 - val_mae: 2.2698\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8118 - mae: 0.9745 - val_loss: 10.2035 - val_mae: 2.2275\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9014 - mae: 0.9638 - val_loss: 10.3711 - val_mae: 2.2281\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7012 - mae: 0.9334 - val_loss: 10.2486 - val_mae: 2.2279\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6967 - mae: 0.9098 - val_loss: 10.5544 - val_mae: 2.2490\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5653 - mae: 0.9252 - val_loss: 10.7878 - val_mae: 2.3063\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7663 - mae: 0.9426 - val_loss: 11.1276 - val_mae: 2.4139\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6708 - mae: 0.9091 - val_loss: 10.0776 - val_mae: 2.2359\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7393 - mae: 0.9266 - val_loss: 11.0861 - val_mae: 2.2899\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6361 - mae: 0.9172 - val_loss: 10.3540 - val_mae: 2.2931\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7914 - mae: 0.9376 - val_loss: 10.6877 - val_mae: 2.2334\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7350 - mae: 0.9208 - val_loss: 10.4382 - val_mae: 2.3116\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7216 - mae: 0.9256 - val_loss: 10.5151 - val_mae: 2.2348\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6764 - mae: 0.9030 - val_loss: 10.5419 - val_mae: 2.3038\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7822 - mae: 0.9764 - val_loss: 10.7779 - val_mae: 2.3530\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6759 - mae: 0.8936 - val_loss: 10.6148 - val_mae: 2.2744\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7375 - mae: 0.9415 - val_loss: 10.1745 - val_mae: 2.3000\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4646 - mae: 0.8580 - val_loss: 10.4688 - val_mae: 2.2614\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7225 - mae: 0.9371 - val_loss: 10.8627 - val_mae: 2.3962\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.5341 - mae: 0.8911 - val_loss: 10.1736 - val_mae: 2.2481\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6978 - mae: 0.9331 - val_loss: 10.3352 - val_mae: 2.2630\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5943 - mae: 0.9141 - val_loss: 10.5910 - val_mae: 2.3567\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7503 - mae: 0.9311 - val_loss: 10.8685 - val_mae: 2.3194\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6277 - mae: 0.9089 - val_loss: 10.9113 - val_mae: 2.2829\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5559 - mae: 0.8911 - val_loss: 10.9016 - val_mae: 2.2697\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8064 - mae: 0.9434 - val_loss: 11.2038 - val_mae: 2.4018\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5341 - mae: 0.8714 - val_loss: 10.7567 - val_mae: 2.2925\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5039 - mae: 0.8806 - val_loss: 11.1828 - val_mae: 2.2907\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7096 - mae: 0.9453 - val_loss: 10.7534 - val_mae: 2.3884\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5371 - mae: 0.8935 - val_loss: 10.8056 - val_mae: 2.3088\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6244 - mae: 0.9034 - val_loss: 11.4623 - val_mae: 2.4552\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5428 - mae: 0.8955 - val_loss: 10.8608 - val_mae: 2.2317\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4680 - mae: 0.8615 - val_loss: 11.5022 - val_mae: 2.5003\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6788 - mae: 0.9391 - val_loss: 10.5647 - val_mae: 2.3295\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5555 - mae: 0.8904 - val_loss: 10.6260 - val_mae: 2.3230\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4682 - mae: 0.8764 - val_loss: 10.2033 - val_mae: 2.3174\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6730 - mae: 0.9254 - val_loss: 10.5428 - val_mae: 2.2863\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4195 - mae: 0.8456 - val_loss: 10.8160 - val_mae: 2.3088\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4593 - mae: 0.8364 - val_loss: 10.8495 - val_mae: 2.2997\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5122 - mae: 0.8600 - val_loss: 10.4995 - val_mae: 2.2789\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6088 - mae: 0.9220 - val_loss: 11.1447 - val_mae: 2.3651\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5236 - mae: 0.8779 - val_loss: 11.3947 - val_mae: 2.4816\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6035 - mae: 0.9055 - val_loss: 10.9984 - val_mae: 2.2717\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4960 - mae: 0.8590 - val_loss: 10.5871 - val_mae: 2.2709\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4470 - mae: 0.8379 - val_loss: 11.3945 - val_mae: 2.3786\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4923 - mae: 0.8629 - val_loss: 10.5299 - val_mae: 2.2727\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4661 - mae: 0.8599 - val_loss: 10.9510 - val_mae: 2.3791\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4816 - mae: 0.8572 - val_loss: 11.2397 - val_mae: 2.4713\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4961 - mae: 0.8815 - val_loss: 11.2078 - val_mae: 2.3672\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5636 - mae: 0.8804 - val_loss: 11.0113 - val_mae: 2.4016\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4742 - mae: 0.8441 - val_loss: 10.5612 - val_mae: 2.2614\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2691 - mae: 0.8007 - val_loss: 11.8539 - val_mae: 2.3624\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5579 - mae: 0.9222 - val_loss: 11.5783 - val_mae: 2.4524\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4243 - mae: 0.8432 - val_loss: 10.9226 - val_mae: 2.3315\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6424 - mae: 0.8968 - val_loss: 10.8906 - val_mae: 2.3571\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3459 - mae: 0.8245 - val_loss: 11.7403 - val_mae: 2.3986\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3993 - mae: 0.8697 - val_loss: 10.9758 - val_mae: 2.3183\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 1.3559 - mae: 0.8144 - val_loss: 11.0618 - val_mae: 2.3540\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5594 - mae: 0.8698 - val_loss: 10.7049 - val_mae: 2.3037\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3744 - mae: 0.8523 - val_loss: 10.8996 - val_mae: 2.3363\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4114 - mae: 0.8525 - val_loss: 12.0421 - val_mae: 2.5502\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5308 - mae: 0.8651 - val_loss: 10.9857 - val_mae: 2.3052\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2685 - mae: 0.8150 - val_loss: 11.1681 - val_mae: 2.3845\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3998 - mae: 0.8323 - val_loss: 11.4052 - val_mae: 2.3946\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4275 - mae: 0.8624 - val_loss: 11.2989 - val_mae: 2.3286\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3722 - mae: 0.8221 - val_loss: 11.4811 - val_mae: 2.4037\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5715 - mae: 0.9108 - val_loss: 11.2613 - val_mae: 2.3290\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3504 - mae: 0.8077 - val_loss: 11.6581 - val_mae: 2.3295\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.4733 - mae: 0.8801 - val_loss: 10.9890 - val_mae: 2.3344\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3918 - mae: 0.8424 - val_loss: 11.2145 - val_mae: 2.3091\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2675 - mae: 0.7946 - val_loss: 11.0899 - val_mae: 2.3623\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4135 - mae: 0.8441 - val_loss: 10.9412 - val_mae: 2.3011\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4081 - mae: 0.8434 - val_loss: 11.2692 - val_mae: 2.3454\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3445 - mae: 0.8361 - val_loss: 11.8118 - val_mae: 2.4351\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3772 - mae: 0.8318 - val_loss: 11.1943 - val_mae: 2.3229\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4225 - mae: 0.8661 - val_loss: 10.5029 - val_mae: 2.2897\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3025 - mae: 0.8409 - val_loss: 10.8549 - val_mae: 2.3378\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4571 - mae: 0.8557 - val_loss: 11.1380 - val_mae: 2.3829\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2722 - mae: 0.8017 - val_loss: 11.3335 - val_mae: 2.3666\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2826 - mae: 0.8227 - val_loss: 11.1604 - val_mae: 2.3508\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3280 - mae: 0.8282 - val_loss: 11.3291 - val_mae: 2.4596\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4640 - mae: 0.8616 - val_loss: 11.1925 - val_mae: 2.3375\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3382 - mae: 0.8427 - val_loss: 11.2065 - val_mae: 2.3870\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3569 - mae: 0.8349 - val_loss: 11.1892 - val_mae: 2.3261\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3084 - mae: 0.8160 - val_loss: 11.6972 - val_mae: 2.4087\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2774 - mae: 0.8167 - val_loss: 11.5555 - val_mae: 2.4147\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3350 - mae: 0.8420 - val_loss: 11.3474 - val_mae: 2.4030\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4115 - mae: 0.8502 - val_loss: 11.3401 - val_mae: 2.3970\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3715 - mae: 0.8552 - val_loss: 10.8077 - val_mae: 2.3542\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1938 - mae: 0.7636 - val_loss: 10.9969 - val_mae: 2.3885\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3608 - mae: 0.8319 - val_loss: 10.9533 - val_mae: 2.3351\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3395 - mae: 0.8065 - val_loss: 11.2059 - val_mae: 2.3746\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2443 - mae: 0.8025 - val_loss: 11.2091 - val_mae: 2.3966\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1807 - mae: 0.7669 - val_loss: 10.8228 - val_mae: 2.3988\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3734 - mae: 0.8658 - val_loss: 11.0971 - val_mae: 2.3699\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2462 - mae: 0.7782 - val_loss: 11.5582 - val_mae: 2.3947\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2803 - mae: 0.8176 - val_loss: 10.9007 - val_mae: 2.3556\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1900 - mae: 0.7770 - val_loss: 10.8383 - val_mae: 2.3411\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3355 - mae: 0.8336 - val_loss: 11.5825 - val_mae: 2.4620\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1015 - mae: 0.7579 - val_loss: 11.6280 - val_mae: 2.3861\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3225 - mae: 0.8169 - val_loss: 10.9915 - val_mae: 2.3366\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1543 - mae: 0.7655 - val_loss: 12.2334 - val_mae: 2.6211\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1067 - mae: 0.7465 - val_loss: 11.4522 - val_mae: 2.3979\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4482 - mae: 0.8293 - val_loss: 11.1453 - val_mae: 2.3501\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2164 - mae: 0.7614 - val_loss: 11.8297 - val_mae: 2.4384\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2582 - mae: 0.7778 - val_loss: 11.2949 - val_mae: 2.3679\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1518 - mae: 0.7556 - val_loss: 11.1370 - val_mae: 2.3822\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2085 - mae: 0.8018 - val_loss: 11.6161 - val_mae: 2.3898\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2455 - mae: 0.8183 - val_loss: 11.2567 - val_mae: 2.3343\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1956 - mae: 0.7694 - val_loss: 11.6150 - val_mae: 2.3991\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1270 - mae: 0.7311 - val_loss: 11.2970 - val_mae: 2.4000\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1932 - mae: 0.7825 - val_loss: 11.9518 - val_mae: 2.5622\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2705 - mae: 0.8128 - val_loss: 11.6183 - val_mae: 2.4025\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2597 - mae: 0.7930 - val_loss: 11.9904 - val_mae: 2.4292\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3346 - mae: 0.7974 - val_loss: 11.3628 - val_mae: 2.3923\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2409 - mae: 0.8012 - val_loss: 11.7478 - val_mae: 2.4116\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1967 - mae: 0.7877 - val_loss: 11.9594 - val_mae: 2.4200\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2984 - mae: 0.8035 - val_loss: 11.6497 - val_mae: 2.3846\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1427 - mae: 0.7492 - val_loss: 10.7893 - val_mae: 2.3557\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1904 - mae: 0.7793 - val_loss: 12.3735 - val_mae: 2.5023\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1282 - mae: 0.7489 - val_loss: 11.6148 - val_mae: 2.4150\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3311 - mae: 0.8391 - val_loss: 11.7718 - val_mae: 2.4342\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1388 - mae: 0.7733 - val_loss: 11.6163 - val_mae: 2.4751\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1329 - mae: 0.7794 - val_loss: 11.6777 - val_mae: 2.3990\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2861 - mae: 0.7825 - val_loss: 11.3097 - val_mae: 2.4077\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1890 - mae: 0.7610 - val_loss: 11.4485 - val_mae: 2.3711\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.1187 - mae: 0.7479 - val_loss: 11.4123 - val_mae: 2.3671\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1481 - mae: 0.7555 - val_loss: 11.4226 - val_mae: 2.4283\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2299 - mae: 0.7927 - val_loss: 11.5357 - val_mae: 2.4156\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1007 - mae: 0.7904 - val_loss: 11.5256 - val_mae: 2.3954\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1663 - mae: 0.7934 - val_loss: 11.6734 - val_mae: 2.4079\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1995 - mae: 0.7917 - val_loss: 11.5721 - val_mae: 2.4150\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1113 - mae: 0.7566 - val_loss: 11.9402 - val_mae: 2.4265\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2103 - mae: 0.8130 - val_loss: 11.8286 - val_mae: 2.4558\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1325 - mae: 0.7540 - val_loss: 11.8266 - val_mae: 2.4334\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0794 - mae: 0.7514 - val_loss: 11.8492 - val_mae: 2.4465\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2410 - mae: 0.7892 - val_loss: 11.3177 - val_mae: 2.3970\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0619 - mae: 0.7332 - val_loss: 12.2251 - val_mae: 2.4787\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1872 - mae: 0.7712 - val_loss: 11.4464 - val_mae: 2.4305\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1806 - mae: 0.8034 - val_loss: 11.7397 - val_mae: 2.4228\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0800 - mae: 0.7359 - val_loss: 11.5003 - val_mae: 2.4320\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1664 - mae: 0.7670 - val_loss: 12.0444 - val_mae: 2.4764\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0782 - mae: 0.7353 - val_loss: 11.9965 - val_mae: 2.4787\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0479 - mae: 0.7378 - val_loss: 11.8047 - val_mae: 2.4141\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0775 - mae: 0.7425 - val_loss: 11.8055 - val_mae: 2.4634\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1532 - mae: 0.7556 - val_loss: 11.9284 - val_mae: 2.4467\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1841 - mae: 0.7819 - val_loss: 11.6562 - val_mae: 2.4777\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0125 - mae: 0.7197 - val_loss: 11.7261 - val_mae: 2.4441\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0996 - mae: 0.7596 - val_loss: 12.1230 - val_mae: 2.4646\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9794 - mae: 0.6952 - val_loss: 12.8133 - val_mae: 2.5049\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0838 - mae: 0.7549 - val_loss: 11.8248 - val_mae: 2.4519\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1061 - mae: 0.7500 - val_loss: 11.9965 - val_mae: 2.4623\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9840 - mae: 0.7133 - val_loss: 11.5027 - val_mae: 2.4191\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0943 - mae: 0.7530 - val_loss: 11.8946 - val_mae: 2.4424\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0676 - mae: 0.7243 - val_loss: 12.2765 - val_mae: 2.5167\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1179 - mae: 0.7337 - val_loss: 12.0557 - val_mae: 2.5369\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0536 - mae: 0.7444 - val_loss: 12.0468 - val_mae: 2.4800\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0576 - mae: 0.7313 - val_loss: 11.8035 - val_mae: 2.4536\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 0.8950 - mae: 0.6866 - val_loss: 12.1447 - val_mae: 2.5043\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0301 - mae: 0.7399 - val_loss: 11.8059 - val_mae: 2.5404\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1342 - mae: 0.7759 - val_loss: 11.8379 - val_mae: 2.4262\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9802 - mae: 0.7072 - val_loss: 12.6557 - val_mae: 2.5583\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1111 - mae: 0.7525 - val_loss: 11.8825 - val_mae: 2.4856\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9396 - mae: 0.6799 - val_loss: 11.9443 - val_mae: 2.5401\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9148 - mae: 0.6896 - val_loss: 11.9673 - val_mae: 2.4915\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1473 - mae: 0.7803 - val_loss: 11.7923 - val_mae: 2.4722\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9497 - mae: 0.6660 - val_loss: 12.6832 - val_mae: 2.6100\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0146 - mae: 0.7227 - val_loss: 12.0691 - val_mae: 2.5055\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8292 - mae: 0.6461 - val_loss: 11.8095 - val_mae: 2.5182\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0281 - mae: 0.7061 - val_loss: 11.7057 - val_mae: 2.4727\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0202 - mae: 0.7371 - val_loss: 12.1525 - val_mae: 2.4839\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9172 - mae: 0.6855 - val_loss: 12.5765 - val_mae: 2.5748\n",
            "Processing fold #1\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 529.9501 - mae: 21.0957 - val_loss: 431.8814 - val_mae: 19.0646\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 402.1244 - mae: 17.9127 - val_loss: 307.0645 - val_mae: 15.6360\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 264.1187 - mae: 14.0290 - val_loss: 178.0028 - val_mae: 11.4259\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 143.7542 - mae: 9.5880 - val_loss: 89.8546 - val_mae: 7.6799\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 76.4003 - mae: 6.6674 - val_loss: 51.0190 - val_mae: 5.6411\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 48.7231 - mae: 5.2195 - val_loss: 34.8878 - val_mae: 4.7264\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 35.3527 - mae: 4.3432 - val_loss: 26.1089 - val_mae: 4.1361\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 27.9348 - mae: 3.7711 - val_loss: 22.8013 - val_mae: 3.7967\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 24.2054 - mae: 3.4305 - val_loss: 21.5000 - val_mae: 3.5161\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 22.0928 - mae: 3.2273 - val_loss: 20.4309 - val_mae: 3.4322\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 20.7810 - mae: 3.1772 - val_loss: 19.3350 - val_mae: 3.3615\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 19.3531 - mae: 3.0081 - val_loss: 18.4288 - val_mae: 3.2262\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 18.2646 - mae: 2.9418 - val_loss: 17.7361 - val_mae: 3.1233\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 17.1265 - mae: 2.8264 - val_loss: 16.8159 - val_mae: 3.0489\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 16.3051 - mae: 2.7175 - val_loss: 16.6285 - val_mae: 3.1060\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 15.3999 - mae: 2.6618 - val_loss: 17.0113 - val_mae: 3.1965\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 14.7478 - mae: 2.6152 - val_loss: 15.3628 - val_mae: 2.9476\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 14.0815 - mae: 2.5204 - val_loss: 15.2329 - val_mae: 2.9500\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.2888 - mae: 2.5086 - val_loss: 14.4613 - val_mae: 2.9036\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 13.0737 - mae: 2.4726 - val_loss: 13.9800 - val_mae: 2.8383\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 12.3521 - mae: 2.3739 - val_loss: 14.2783 - val_mae: 2.8789\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.9316 - mae: 2.3700 - val_loss: 14.0101 - val_mae: 2.8481\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 11.7231 - mae: 2.3265 - val_loss: 14.0609 - val_mae: 2.8848\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 1s 5ms/step - loss: 11.3033 - mae: 2.3306 - val_loss: 12.6417 - val_mae: 2.6749\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.0822 - mae: 2.2675 - val_loss: 12.6547 - val_mae: 2.7186\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.9697 - mae: 2.2478 - val_loss: 12.9164 - val_mae: 2.6990\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.7748 - mae: 2.2185 - val_loss: 12.7719 - val_mae: 2.7013\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.6013 - mae: 2.2506 - val_loss: 12.4514 - val_mae: 2.6634\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.2685 - mae: 2.1751 - val_loss: 12.2641 - val_mae: 2.6794\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 10.2075 - mae: 2.1930 - val_loss: 11.7027 - val_mae: 2.5952\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.1241 - mae: 2.1588 - val_loss: 12.3023 - val_mae: 2.7171\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.6808 - mae: 2.1539 - val_loss: 11.8682 - val_mae: 2.6855\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.7345 - mae: 2.1103 - val_loss: 11.9107 - val_mae: 2.6372\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.6185 - mae: 2.1446 - val_loss: 12.0157 - val_mae: 2.6584\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.5661 - mae: 2.0933 - val_loss: 12.3733 - val_mae: 2.7302\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.3671 - mae: 2.0895 - val_loss: 12.6130 - val_mae: 2.7737\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.2905 - mae: 2.1161 - val_loss: 11.5922 - val_mae: 2.6154\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.1411 - mae: 2.0656 - val_loss: 12.3137 - val_mae: 2.7485\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 9.1908 - mae: 2.1336 - val_loss: 11.3563 - val_mae: 2.6199\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.8702 - mae: 2.0451 - val_loss: 11.8973 - val_mae: 2.6962\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 8.9081 - mae: 2.0259 - val_loss: 12.3914 - val_mae: 2.7463\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.7737 - mae: 2.0697 - val_loss: 11.5998 - val_mae: 2.6340\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.6587 - mae: 2.0519 - val_loss: 11.2436 - val_mae: 2.5821\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.7113 - mae: 2.0835 - val_loss: 11.1719 - val_mae: 2.5866\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.5367 - mae: 2.0443 - val_loss: 11.6711 - val_mae: 2.6314\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.5648 - mae: 2.0379 - val_loss: 11.3180 - val_mae: 2.5721\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.5192 - mae: 2.0296 - val_loss: 11.9164 - val_mae: 2.6912\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.3554 - mae: 1.9707 - val_loss: 12.0745 - val_mae: 2.7366\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.2074 - mae: 2.0189 - val_loss: 11.4636 - val_mae: 2.6170\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.2588 - mae: 2.0276 - val_loss: 11.2112 - val_mae: 2.5829\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0987 - mae: 1.9801 - val_loss: 11.2073 - val_mae: 2.5782\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.0398 - mae: 1.9835 - val_loss: 10.6934 - val_mae: 2.5196\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.1925 - mae: 2.0157 - val_loss: 11.3395 - val_mae: 2.6147\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.9207 - mae: 1.9937 - val_loss: 11.0325 - val_mae: 2.5697\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.0387 - mae: 1.9981 - val_loss: 11.2595 - val_mae: 2.5918\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.6922 - mae: 1.9439 - val_loss: 11.2598 - val_mae: 2.5990\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 7.6637 - mae: 1.9521 - val_loss: 10.8878 - val_mae: 2.5386\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.7151 - mae: 1.9561 - val_loss: 11.2387 - val_mae: 2.5689\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.6134 - mae: 1.9367 - val_loss: 11.2451 - val_mae: 2.6206\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.6320 - mae: 1.9436 - val_loss: 11.8135 - val_mae: 2.6740\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.4748 - mae: 1.9538 - val_loss: 11.7273 - val_mae: 2.6914\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.5305 - mae: 1.9513 - val_loss: 10.3436 - val_mae: 2.4758\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.3339 - mae: 1.8956 - val_loss: 10.5270 - val_mae: 2.4745\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.5248 - mae: 1.9234 - val_loss: 11.0302 - val_mae: 2.5545\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3831 - mae: 1.9323 - val_loss: 10.8609 - val_mae: 2.5718\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3941 - mae: 1.9328 - val_loss: 10.7079 - val_mae: 2.5032\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.3913 - mae: 1.9241 - val_loss: 10.5513 - val_mae: 2.5148\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.1645 - mae: 1.8868 - val_loss: 11.9993 - val_mae: 2.7082\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.2285 - mae: 1.9452 - val_loss: 10.4432 - val_mae: 2.5044\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.1379 - mae: 1.8903 - val_loss: 11.5942 - val_mae: 2.6867\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0217 - mae: 1.8756 - val_loss: 10.4557 - val_mae: 2.4896\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.9438 - mae: 1.8553 - val_loss: 12.0608 - val_mae: 2.7505\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.9311 - mae: 1.8779 - val_loss: 10.4809 - val_mae: 2.4842\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9728 - mae: 1.8816 - val_loss: 10.5301 - val_mae: 2.4996\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.9464 - mae: 1.8555 - val_loss: 11.0372 - val_mae: 2.6045\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.8917 - mae: 1.8621 - val_loss: 10.1496 - val_mae: 2.4610\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.7284 - mae: 1.8400 - val_loss: 10.6224 - val_mae: 2.5248\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.7383 - mae: 1.8428 - val_loss: 9.8903 - val_mae: 2.4155\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 6.7657 - mae: 1.8162 - val_loss: 10.5490 - val_mae: 2.5124\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5283 - mae: 1.7917 - val_loss: 10.9347 - val_mae: 2.5739\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.6732 - mae: 1.8113 - val_loss: 10.6408 - val_mae: 2.4937\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5507 - mae: 1.8160 - val_loss: 12.0464 - val_mae: 2.7372\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5220 - mae: 1.8714 - val_loss: 9.9849 - val_mae: 2.4153\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.3983 - mae: 1.7756 - val_loss: 12.2028 - val_mae: 2.7587\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.5356 - mae: 1.8085 - val_loss: 10.0782 - val_mae: 2.4441\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.4160 - mae: 1.8319 - val_loss: 10.1250 - val_mae: 2.4485\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.4188 - mae: 1.7895 - val_loss: 10.3505 - val_mae: 2.4852\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.5209 - mae: 1.8031 - val_loss: 10.1797 - val_mae: 2.4577\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.4101 - mae: 1.7716 - val_loss: 9.9591 - val_mae: 2.4144\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.2965 - mae: 1.7699 - val_loss: 10.3487 - val_mae: 2.4675\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.1367 - mae: 1.7757 - val_loss: 9.8354 - val_mae: 2.4179\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 6.4014 - mae: 1.7834 - val_loss: 10.1074 - val_mae: 2.4439\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9884 - mae: 1.7121 - val_loss: 11.6974 - val_mae: 2.6779\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.2421 - mae: 1.7786 - val_loss: 10.3195 - val_mae: 2.4615\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.1415 - mae: 1.7650 - val_loss: 9.9147 - val_mae: 2.4020\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.0030 - mae: 1.7210 - val_loss: 9.8844 - val_mae: 2.3998\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.9390 - mae: 1.7549 - val_loss: 10.6103 - val_mae: 2.5199\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.9891 - mae: 1.7594 - val_loss: 10.0037 - val_mae: 2.4184\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9953 - mae: 1.7387 - val_loss: 9.9071 - val_mae: 2.4127\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7306 - mae: 1.7263 - val_loss: 10.1089 - val_mae: 2.4363\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8644 - mae: 1.7677 - val_loss: 9.5201 - val_mae: 2.3705\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8693 - mae: 1.6792 - val_loss: 9.5607 - val_mae: 2.3668\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8038 - mae: 1.6968 - val_loss: 10.3864 - val_mae: 2.4913\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6860 - mae: 1.6802 - val_loss: 9.5497 - val_mae: 2.3673\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7020 - mae: 1.6771 - val_loss: 9.7067 - val_mae: 2.3913\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.7345 - mae: 1.7268 - val_loss: 9.5198 - val_mae: 2.3651\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.6689 - mae: 1.6762 - val_loss: 9.3031 - val_mae: 2.3527\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.7316 - mae: 1.7014 - val_loss: 9.2609 - val_mae: 2.3366\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.3631 - mae: 1.6490 - val_loss: 10.8343 - val_mae: 2.5538\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.5256 - mae: 1.6691 - val_loss: 9.5087 - val_mae: 2.3686\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.4336 - mae: 1.6215 - val_loss: 10.0742 - val_mae: 2.4384\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.6249 - mae: 1.6639 - val_loss: 9.8356 - val_mae: 2.4264\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.3550 - mae: 1.6384 - val_loss: 10.3260 - val_mae: 2.4824\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3879 - mae: 1.6465 - val_loss: 9.1043 - val_mae: 2.3178\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5038 - mae: 1.6692 - val_loss: 9.2761 - val_mae: 2.3318\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3225 - mae: 1.6557 - val_loss: 9.5321 - val_mae: 2.3757\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3350 - mae: 1.6222 - val_loss: 10.3777 - val_mae: 2.4987\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.0939 - mae: 1.6459 - val_loss: 9.3289 - val_mae: 2.3572\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1872 - mae: 1.6152 - val_loss: 9.4140 - val_mae: 2.3482\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.3809 - mae: 1.6310 - val_loss: 9.7577 - val_mae: 2.3949\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1580 - mae: 1.6240 - val_loss: 9.3105 - val_mae: 2.3438\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.9742 - mae: 1.5968 - val_loss: 9.4344 - val_mae: 2.3618\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1342 - mae: 1.6573 - val_loss: 8.9305 - val_mae: 2.2933\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0784 - mae: 1.6011 - val_loss: 10.0538 - val_mae: 2.4492\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0352 - mae: 1.5809 - val_loss: 9.8185 - val_mae: 2.4027\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.0866 - mae: 1.5995 - val_loss: 9.2803 - val_mae: 2.3425\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 5.1261 - mae: 1.6115 - val_loss: 9.2763 - val_mae: 2.3389\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 4.8791 - mae: 1.6099 - val_loss: 9.3664 - val_mae: 2.3490\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.9472 - mae: 1.5988 - val_loss: 9.4055 - val_mae: 2.3702\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.8393 - mae: 1.5817 - val_loss: 10.8303 - val_mae: 2.5409\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7325 - mae: 1.5793 - val_loss: 9.0082 - val_mae: 2.3094\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8229 - mae: 1.5534 - val_loss: 9.3881 - val_mae: 2.3518\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7735 - mae: 1.5624 - val_loss: 8.9774 - val_mae: 2.3200\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.6330 - mae: 1.5254 - val_loss: 9.3797 - val_mae: 2.3545\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7673 - mae: 1.5387 - val_loss: 8.9567 - val_mae: 2.3133\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 4.5915 - mae: 1.5170 - val_loss: 9.3086 - val_mae: 2.3455\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6520 - mae: 1.5645 - val_loss: 9.1268 - val_mae: 2.3389\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.7158 - mae: 1.5513 - val_loss: 10.1668 - val_mae: 2.4524\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.5328 - mae: 1.5310 - val_loss: 9.4412 - val_mae: 2.3760\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5990 - mae: 1.5474 - val_loss: 8.9513 - val_mae: 2.2781\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4621 - mae: 1.5212 - val_loss: 11.4709 - val_mae: 2.6339\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.7500 - mae: 1.5697 - val_loss: 10.7178 - val_mae: 2.5351\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5338 - mae: 1.5258 - val_loss: 9.3580 - val_mae: 2.3900\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.4887 - mae: 1.5042 - val_loss: 9.1824 - val_mae: 2.3203\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 4.4614 - mae: 1.4987 - val_loss: 8.9508 - val_mae: 2.2882\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2722 - mae: 1.4930 - val_loss: 9.9282 - val_mae: 2.4230\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3003 - mae: 1.4688 - val_loss: 8.4945 - val_mae: 2.2506\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3830 - mae: 1.4964 - val_loss: 9.8742 - val_mae: 2.4503\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.3364 - mae: 1.4890 - val_loss: 9.1800 - val_mae: 2.3222\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 4.1996 - mae: 1.4458 - val_loss: 9.0040 - val_mae: 2.3090\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3114 - mae: 1.4698 - val_loss: 8.8265 - val_mae: 2.3142\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1313 - mae: 1.4522 - val_loss: 11.0937 - val_mae: 2.5478\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2261 - mae: 1.4449 - val_loss: 10.1129 - val_mae: 2.4590\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2776 - mae: 1.4841 - val_loss: 9.0392 - val_mae: 2.3089\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.2753 - mae: 1.4450 - val_loss: 9.1431 - val_mae: 2.3084\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0161 - mae: 1.4126 - val_loss: 9.6029 - val_mae: 2.3644\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0382 - mae: 1.4352 - val_loss: 9.7262 - val_mae: 2.3875\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9885 - mae: 1.3967 - val_loss: 8.7537 - val_mae: 2.2903\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0934 - mae: 1.4778 - val_loss: 9.1430 - val_mae: 2.3429\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9550 - mae: 1.4393 - val_loss: 9.3713 - val_mae: 2.3380\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0357 - mae: 1.4348 - val_loss: 10.4593 - val_mae: 2.4562\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 4.0348 - mae: 1.4329 - val_loss: 8.7900 - val_mae: 2.2858\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8690 - mae: 1.4162 - val_loss: 9.5798 - val_mae: 2.3840\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8921 - mae: 1.4180 - val_loss: 9.2605 - val_mae: 2.3084\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 3.7390 - mae: 1.3741 - val_loss: 9.3758 - val_mae: 2.3897\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9359 - mae: 1.4136 - val_loss: 10.2001 - val_mae: 2.4572\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9081 - mae: 1.3797 - val_loss: 9.2904 - val_mae: 2.3109\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7641 - mae: 1.4099 - val_loss: 9.5506 - val_mae: 2.3849\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.7325 - mae: 1.3520 - val_loss: 10.2615 - val_mae: 2.4428\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8680 - mae: 1.4007 - val_loss: 8.5850 - val_mae: 2.2311\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7691 - mae: 1.3880 - val_loss: 9.9717 - val_mae: 2.3982\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7457 - mae: 1.3911 - val_loss: 9.8070 - val_mae: 2.4025\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6708 - mae: 1.3655 - val_loss: 8.9362 - val_mae: 2.2756\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6342 - mae: 1.3318 - val_loss: 12.8279 - val_mae: 2.7699\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.7113 - mae: 1.3632 - val_loss: 12.2076 - val_mae: 2.7221\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5862 - mae: 1.3736 - val_loss: 9.8575 - val_mae: 2.4131\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.6924 - mae: 1.3540 - val_loss: 9.6611 - val_mae: 2.3827\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5079 - mae: 1.3418 - val_loss: 10.7054 - val_mae: 2.4714\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.5631 - mae: 1.3266 - val_loss: 10.6693 - val_mae: 2.5110\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 3.7961 - mae: 1.3729 - val_loss: 10.2415 - val_mae: 2.4071\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4239 - mae: 1.3208 - val_loss: 8.6713 - val_mae: 2.2535\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4367 - mae: 1.3084 - val_loss: 9.2385 - val_mae: 2.3001\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6325 - mae: 1.3709 - val_loss: 10.8910 - val_mae: 2.4767\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3888 - mae: 1.3208 - val_loss: 8.8966 - val_mae: 2.2772\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4373 - mae: 1.3018 - val_loss: 8.9050 - val_mae: 2.2813\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3351 - mae: 1.3104 - val_loss: 8.8884 - val_mae: 2.2696\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3333 - mae: 1.2824 - val_loss: 9.8710 - val_mae: 2.3662\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4602 - mae: 1.3313 - val_loss: 11.3878 - val_mae: 2.5447\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3737 - mae: 1.2957 - val_loss: 9.8543 - val_mae: 2.3739\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.2292 - mae: 1.2856 - val_loss: 9.9395 - val_mae: 2.3446\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.3990 - mae: 1.3142 - val_loss: 9.2970 - val_mae: 2.2976\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.4167 - mae: 1.2998 - val_loss: 9.5690 - val_mae: 2.3351\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0893 - mae: 1.2462 - val_loss: 10.3539 - val_mae: 2.4074\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.1768 - mae: 1.2628 - val_loss: 11.4964 - val_mae: 2.5277\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 3.2055 - mae: 1.2933 - val_loss: 10.7674 - val_mae: 2.4695\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 3.2777 - mae: 1.2879 - val_loss: 11.8132 - val_mae: 2.5562\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0611 - mae: 1.2538 - val_loss: 12.2265 - val_mae: 2.6735\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1539 - mae: 1.2794 - val_loss: 9.3059 - val_mae: 2.3106\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1394 - mae: 1.2951 - val_loss: 9.2637 - val_mae: 2.3171\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2762 - mae: 1.2951 - val_loss: 9.5248 - val_mae: 2.3372\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0661 - mae: 1.2884 - val_loss: 9.0017 - val_mae: 2.2941\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0581 - mae: 1.2566 - val_loss: 11.3691 - val_mae: 2.4980\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0034 - mae: 1.2530 - val_loss: 11.2577 - val_mae: 2.5656\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.0405 - mae: 1.2666 - val_loss: 10.8540 - val_mae: 2.4853\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0080 - mae: 1.2288 - val_loss: 9.4017 - val_mae: 2.3046\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0951 - mae: 1.2379 - val_loss: 9.9112 - val_mae: 2.3435\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1408 - mae: 1.2557 - val_loss: 9.5958 - val_mae: 2.3048\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9474 - mae: 1.2360 - val_loss: 11.3705 - val_mae: 2.5326\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.0193 - mae: 1.2712 - val_loss: 11.5331 - val_mae: 2.5612\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9611 - mae: 1.2039 - val_loss: 10.1772 - val_mae: 2.3997\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9522 - mae: 1.2276 - val_loss: 10.0431 - val_mae: 2.3806\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9080 - mae: 1.1909 - val_loss: 9.9964 - val_mae: 2.3780\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7940 - mae: 1.2019 - val_loss: 10.6973 - val_mae: 2.4952\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0191 - mae: 1.2457 - val_loss: 9.7210 - val_mae: 2.3370\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8223 - mae: 1.2014 - val_loss: 11.5499 - val_mae: 2.5420\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7847 - mae: 1.2198 - val_loss: 11.1157 - val_mae: 2.5286\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9305 - mae: 1.2383 - val_loss: 9.5795 - val_mae: 2.3170\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7740 - mae: 1.2140 - val_loss: 10.3688 - val_mae: 2.4357\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7693 - mae: 1.1704 - val_loss: 10.5992 - val_mae: 2.4117\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6885 - mae: 1.1525 - val_loss: 13.9377 - val_mae: 2.8736\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8738 - mae: 1.1871 - val_loss: 10.2129 - val_mae: 2.3478\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7669 - mae: 1.1931 - val_loss: 9.8602 - val_mae: 2.3501\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7624 - mae: 1.1729 - val_loss: 10.0004 - val_mae: 2.3383\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7439 - mae: 1.2074 - val_loss: 11.0145 - val_mae: 2.4579\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5543 - mae: 1.1325 - val_loss: 10.0229 - val_mae: 2.3380\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7671 - mae: 1.1734 - val_loss: 10.6762 - val_mae: 2.3957\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8369 - mae: 1.1764 - val_loss: 10.7144 - val_mae: 2.4008\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 2.6583 - mae: 1.1407 - val_loss: 11.2664 - val_mae: 2.5148\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.7592 - mae: 1.1905 - val_loss: 11.0827 - val_mae: 2.4538\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5575 - mae: 1.1556 - val_loss: 11.7960 - val_mae: 2.4889\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5275 - mae: 1.1711 - val_loss: 10.8570 - val_mae: 2.4279\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6742 - mae: 1.1710 - val_loss: 11.4961 - val_mae: 2.4626\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.6235 - mae: 1.1552 - val_loss: 10.7978 - val_mae: 2.3804\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5728 - mae: 1.1267 - val_loss: 11.9360 - val_mae: 2.5254\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5405 - mae: 1.1152 - val_loss: 11.6504 - val_mae: 2.5581\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5744 - mae: 1.1633 - val_loss: 10.8979 - val_mae: 2.4120\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5882 - mae: 1.1654 - val_loss: 10.7066 - val_mae: 2.3938\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4368 - mae: 1.1044 - val_loss: 10.3056 - val_mae: 2.3724\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 2.5838 - mae: 1.1418 - val_loss: 11.6329 - val_mae: 2.4884\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4955 - mae: 1.1247 - val_loss: 13.8556 - val_mae: 2.7422\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5020 - mae: 1.1304 - val_loss: 10.5977 - val_mae: 2.4002\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4056 - mae: 1.1362 - val_loss: 10.9259 - val_mae: 2.4103\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4621 - mae: 1.1112 - val_loss: 13.9013 - val_mae: 2.6885\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4557 - mae: 1.1272 - val_loss: 12.2800 - val_mae: 2.5997\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5148 - mae: 1.1647 - val_loss: 9.9947 - val_mae: 2.3169\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3111 - mae: 1.0925 - val_loss: 13.0780 - val_mae: 2.6260\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5238 - mae: 1.1629 - val_loss: 12.0655 - val_mae: 2.5593\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 2.3981 - mae: 1.1066 - val_loss: 10.7188 - val_mae: 2.3950\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2581 - mae: 1.1071 - val_loss: 11.0827 - val_mae: 2.4297\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3346 - mae: 1.1022 - val_loss: 11.4702 - val_mae: 2.4472\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3696 - mae: 1.0960 - val_loss: 10.4364 - val_mae: 2.3725\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2794 - mae: 1.0900 - val_loss: 10.5340 - val_mae: 2.3767\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3486 - mae: 1.0987 - val_loss: 11.9557 - val_mae: 2.4562\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3359 - mae: 1.1161 - val_loss: 10.0939 - val_mae: 2.3358\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2693 - mae: 1.1020 - val_loss: 9.6790 - val_mae: 2.3218\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3465 - mae: 1.0837 - val_loss: 10.9896 - val_mae: 2.3944\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3140 - mae: 1.0971 - val_loss: 11.0055 - val_mae: 2.3985\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3264 - mae: 1.1185 - val_loss: 12.0195 - val_mae: 2.4961\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2695 - mae: 1.0727 - val_loss: 12.2046 - val_mae: 2.5391\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2196 - mae: 1.1183 - val_loss: 12.1699 - val_mae: 2.5126\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1483 - mae: 1.0511 - val_loss: 12.2849 - val_mae: 2.5040\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2820 - mae: 1.0714 - val_loss: 10.7469 - val_mae: 2.3923\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0707 - mae: 1.0369 - val_loss: 13.4145 - val_mae: 2.6312\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1998 - mae: 1.0673 - val_loss: 12.0841 - val_mae: 2.5459\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 2.3724 - mae: 1.1048 - val_loss: 11.1796 - val_mae: 2.4128\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1263 - mae: 1.0489 - val_loss: 11.0648 - val_mae: 2.4250\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0903 - mae: 1.0488 - val_loss: 11.2451 - val_mae: 2.3897\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1525 - mae: 1.0346 - val_loss: 12.6210 - val_mae: 2.5322\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 2.1313 - mae: 1.0766 - val_loss: 12.2968 - val_mae: 2.5299\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0394 - mae: 1.0210 - val_loss: 12.1471 - val_mae: 2.5305\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9960 - mae: 1.0355 - val_loss: 11.6366 - val_mae: 2.4735\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1445 - mae: 1.0805 - val_loss: 12.4570 - val_mae: 2.4928\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 2.0939 - mae: 1.0412 - val_loss: 11.9471 - val_mae: 2.4311\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0360 - mae: 1.0310 - val_loss: 13.2062 - val_mae: 2.5920\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1072 - mae: 1.0547 - val_loss: 12.2807 - val_mae: 2.4985\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1332 - mae: 1.0798 - val_loss: 12.0466 - val_mae: 2.5063\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1682 - mae: 1.0319 - val_loss: 13.3923 - val_mae: 2.5720\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1378 - mae: 1.0529 - val_loss: 12.1331 - val_mae: 2.5031\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9861 - mae: 1.0163 - val_loss: 13.9599 - val_mae: 2.6629\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0018 - mae: 1.0281 - val_loss: 13.7690 - val_mae: 2.6292\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 2.0819 - mae: 1.0520 - val_loss: 11.5584 - val_mae: 2.4250\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9899 - mae: 1.0215 - val_loss: 11.5437 - val_mae: 2.4625\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0262 - mae: 1.0358 - val_loss: 12.0269 - val_mae: 2.4589\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0109 - mae: 1.0051 - val_loss: 15.9249 - val_mae: 2.7839\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9350 - mae: 1.0014 - val_loss: 12.8134 - val_mae: 2.5404\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8819 - mae: 1.0354 - val_loss: 14.2300 - val_mae: 2.6644\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9639 - mae: 1.0015 - val_loss: 12.1072 - val_mae: 2.4586\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9899 - mae: 1.0052 - val_loss: 13.3594 - val_mae: 2.5984\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9609 - mae: 1.0044 - val_loss: 11.8790 - val_mae: 2.4846\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8179 - mae: 0.9674 - val_loss: 12.9702 - val_mae: 2.5633\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9800 - mae: 1.0064 - val_loss: 13.2552 - val_mae: 2.6414\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9484 - mae: 1.0178 - val_loss: 12.6455 - val_mae: 2.5188\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8286 - mae: 0.9545 - val_loss: 12.0559 - val_mae: 2.4873\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.0506 - mae: 1.0407 - val_loss: 11.9910 - val_mae: 2.4985\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8809 - mae: 0.9957 - val_loss: 13.5612 - val_mae: 2.5986\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9269 - mae: 0.9836 - val_loss: 12.9914 - val_mae: 2.5585\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6946 - mae: 0.9587 - val_loss: 11.2175 - val_mae: 2.3557\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9199 - mae: 0.9908 - val_loss: 14.0963 - val_mae: 2.6195\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 1.6445 - mae: 0.9238 - val_loss: 13.9280 - val_mae: 2.5871\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8967 - mae: 1.0166 - val_loss: 15.1872 - val_mae: 2.7898\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7334 - mae: 0.9412 - val_loss: 14.3225 - val_mae: 2.6468\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8205 - mae: 0.9943 - val_loss: 14.4742 - val_mae: 2.6721\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.8221 - mae: 0.9674 - val_loss: 13.5523 - val_mae: 2.5689\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7554 - mae: 0.9658 - val_loss: 13.7001 - val_mae: 2.5842\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7668 - mae: 0.9751 - val_loss: 12.2714 - val_mae: 2.4970\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6715 - mae: 0.9544 - val_loss: 11.6752 - val_mae: 2.4276\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6637 - mae: 0.9529 - val_loss: 13.6438 - val_mae: 2.6343\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7305 - mae: 0.9476 - val_loss: 14.7029 - val_mae: 2.6585\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7273 - mae: 0.9610 - val_loss: 12.9656 - val_mae: 2.5183\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6899 - mae: 0.9590 - val_loss: 12.5021 - val_mae: 2.5002\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7526 - mae: 0.9650 - val_loss: 12.6689 - val_mae: 2.5468\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7010 - mae: 0.9391 - val_loss: 13.3104 - val_mae: 2.5522\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7317 - mae: 0.9466 - val_loss: 13.5804 - val_mae: 2.5603\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5880 - mae: 0.9265 - val_loss: 12.9819 - val_mae: 2.6233\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6209 - mae: 0.9327 - val_loss: 12.7058 - val_mae: 2.4995\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7156 - mae: 0.9484 - val_loss: 14.0513 - val_mae: 2.6379\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6009 - mae: 0.9286 - val_loss: 13.5660 - val_mae: 2.6200\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6691 - mae: 0.9375 - val_loss: 13.9125 - val_mae: 2.6711\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5011 - mae: 0.9083 - val_loss: 12.3413 - val_mae: 2.4918\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5644 - mae: 0.9148 - val_loss: 12.9158 - val_mae: 2.5481\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6334 - mae: 0.9416 - val_loss: 14.1897 - val_mae: 2.6211\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6581 - mae: 0.9325 - val_loss: 12.8221 - val_mae: 2.5277\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4779 - mae: 0.8866 - val_loss: 14.8680 - val_mae: 2.7744\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6374 - mae: 0.9292 - val_loss: 13.2385 - val_mae: 2.5664\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7685 - mae: 0.9495 - val_loss: 13.5132 - val_mae: 2.5646\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5240 - mae: 0.8939 - val_loss: 14.0713 - val_mae: 2.7164\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.5352 - mae: 0.8991 - val_loss: 14.6721 - val_mae: 2.6750\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5809 - mae: 0.8999 - val_loss: 13.6448 - val_mae: 2.5557\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5592 - mae: 0.9007 - val_loss: 14.7958 - val_mae: 2.6244\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5230 - mae: 0.9144 - val_loss: 14.5351 - val_mae: 2.6871\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6074 - mae: 0.9252 - val_loss: 13.8065 - val_mae: 2.6292\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5257 - mae: 0.8827 - val_loss: 14.3967 - val_mae: 2.6131\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5816 - mae: 0.9103 - val_loss: 13.6946 - val_mae: 2.6130\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4160 - mae: 0.8750 - val_loss: 14.0961 - val_mae: 2.6289\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.5502 - mae: 0.9028 - val_loss: 14.3680 - val_mae: 2.6548\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4439 - mae: 0.8973 - val_loss: 13.8674 - val_mae: 2.5384\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5963 - mae: 0.9244 - val_loss: 14.9525 - val_mae: 2.6739\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4414 - mae: 0.8904 - val_loss: 15.6157 - val_mae: 2.7351\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.5506 - mae: 0.9178 - val_loss: 13.6665 - val_mae: 2.6055\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4512 - mae: 0.8885 - val_loss: 13.2858 - val_mae: 2.5292\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4002 - mae: 0.8343 - val_loss: 14.3369 - val_mae: 2.7142\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3443 - mae: 0.8772 - val_loss: 14.2738 - val_mae: 2.6537\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4127 - mae: 0.8653 - val_loss: 16.3623 - val_mae: 2.7671\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3534 - mae: 0.8583 - val_loss: 15.4417 - val_mae: 2.7621\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4183 - mae: 0.8925 - val_loss: 14.1673 - val_mae: 2.6873\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3777 - mae: 0.8382 - val_loss: 14.8839 - val_mae: 2.6555\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3587 - mae: 0.8414 - val_loss: 13.4218 - val_mae: 2.5183\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3896 - mae: 0.8747 - val_loss: 13.9977 - val_mae: 2.6155\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5090 - mae: 0.9144 - val_loss: 13.6509 - val_mae: 2.5654\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3593 - mae: 0.8375 - val_loss: 15.3682 - val_mae: 2.7504\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.3944 - mae: 0.8752 - val_loss: 14.5668 - val_mae: 2.6520\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3294 - mae: 0.8553 - val_loss: 13.4931 - val_mae: 2.5562\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2546 - mae: 0.8087 - val_loss: 14.2933 - val_mae: 2.6343\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5720 - mae: 0.9014 - val_loss: 15.0057 - val_mae: 2.6070\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3829 - mae: 0.8400 - val_loss: 14.0976 - val_mae: 2.5776\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3937 - mae: 0.8664 - val_loss: 15.7247 - val_mae: 2.6972\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3898 - mae: 0.8775 - val_loss: 15.0212 - val_mae: 2.6326\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4320 - mae: 0.8684 - val_loss: 14.7983 - val_mae: 2.6341\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3805 - mae: 0.8717 - val_loss: 14.5503 - val_mae: 2.5676\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3640 - mae: 0.8249 - val_loss: 14.3369 - val_mae: 2.6090\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3919 - mae: 0.8488 - val_loss: 14.8114 - val_mae: 2.6204\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4770 - mae: 0.8888 - val_loss: 14.3716 - val_mae: 2.5586\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3450 - mae: 0.8535 - val_loss: 13.6028 - val_mae: 2.5378\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2815 - mae: 0.8333 - val_loss: 14.0259 - val_mae: 2.5436\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2918 - mae: 0.8394 - val_loss: 15.3056 - val_mae: 2.6524\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2547 - mae: 0.8413 - val_loss: 14.2578 - val_mae: 2.5705\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1883 - mae: 0.7920 - val_loss: 16.3677 - val_mae: 2.7400\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2868 - mae: 0.8455 - val_loss: 16.8181 - val_mae: 2.7447\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3512 - mae: 0.8393 - val_loss: 14.6963 - val_mae: 2.5908\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2671 - mae: 0.8107 - val_loss: 13.1171 - val_mae: 2.5130\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2785 - mae: 0.8390 - val_loss: 13.8948 - val_mae: 2.5538\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1685 - mae: 0.7995 - val_loss: 14.6017 - val_mae: 2.6457\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2067 - mae: 0.8022 - val_loss: 16.7421 - val_mae: 2.7769\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3359 - mae: 0.8550 - val_loss: 14.6630 - val_mae: 2.5354\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.2711 - mae: 0.8163 - val_loss: 14.5422 - val_mae: 2.6240\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1904 - mae: 0.8145 - val_loss: 15.5735 - val_mae: 2.6647\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1810 - mae: 0.7901 - val_loss: 17.2432 - val_mae: 2.7920\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2172 - mae: 0.8153 - val_loss: 13.5710 - val_mae: 2.5659\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1867 - mae: 0.7987 - val_loss: 15.1635 - val_mae: 2.6064\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1643 - mae: 0.8166 - val_loss: 15.7373 - val_mae: 2.6823\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3650 - mae: 0.8394 - val_loss: 13.8331 - val_mae: 2.5289\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1.0796 - mae: 0.7553 - val_loss: 15.4870 - val_mae: 2.6352\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2331 - mae: 0.8090 - val_loss: 14.6005 - val_mae: 2.6394\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1474 - mae: 0.7983 - val_loss: 15.5505 - val_mae: 2.6080\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3114 - mae: 0.8312 - val_loss: 16.6543 - val_mae: 2.7315\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1713 - mae: 0.7946 - val_loss: 14.1025 - val_mae: 2.6084\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2178 - mae: 0.7835 - val_loss: 15.1298 - val_mae: 2.6802\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1678 - mae: 0.7942 - val_loss: 13.9112 - val_mae: 2.6212\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 1.2184 - mae: 0.8099 - val_loss: 14.0194 - val_mae: 2.5159\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1075 - mae: 0.7776 - val_loss: 17.1345 - val_mae: 2.8259\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1980 - mae: 0.7955 - val_loss: 15.4758 - val_mae: 2.6427\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.0868 - mae: 0.7562 - val_loss: 14.3206 - val_mae: 2.5723\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2115 - mae: 0.8035 - val_loss: 16.2496 - val_mae: 2.7295\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1810 - mae: 0.7836 - val_loss: 16.2343 - val_mae: 2.6858\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1338 - mae: 0.7759 - val_loss: 14.5224 - val_mae: 2.5769\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 1.1170 - mae: 0.7961 - val_loss: 14.7458 - val_mae: 2.7163\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0730 - mae: 0.7704 - val_loss: 15.1790 - val_mae: 2.6359\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2036 - mae: 0.7923 - val_loss: 15.1979 - val_mae: 2.7014\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1709 - mae: 0.7998 - val_loss: 15.8763 - val_mae: 2.6801\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.2148 - mae: 0.7918 - val_loss: 15.3460 - val_mae: 2.6689\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0752 - mae: 0.7546 - val_loss: 15.4427 - val_mae: 2.6374\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0732 - mae: 0.7552 - val_loss: 17.3492 - val_mae: 2.7683\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0159 - mae: 0.7432 - val_loss: 14.3211 - val_mae: 2.5839\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1150 - mae: 0.7888 - val_loss: 14.4726 - val_mae: 2.5923\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9648 - mae: 0.7277 - val_loss: 14.4179 - val_mae: 2.6216\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1375 - mae: 0.8024 - val_loss: 15.1767 - val_mae: 2.6721\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0744 - mae: 0.7574 - val_loss: 18.3756 - val_mae: 2.8602\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0708 - mae: 0.7693 - val_loss: 15.1190 - val_mae: 2.6759\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.1716 - mae: 0.8004 - val_loss: 15.9376 - val_mae: 2.6591\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9299 - mae: 0.7164 - val_loss: 14.8835 - val_mae: 2.5441\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0343 - mae: 0.7414 - val_loss: 14.8305 - val_mae: 2.6814\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0303 - mae: 0.7476 - val_loss: 16.7499 - val_mae: 2.7210\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0940 - mae: 0.7976 - val_loss: 16.1619 - val_mae: 2.6965\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9808 - mae: 0.7458 - val_loss: 16.1133 - val_mae: 2.6898\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1911 - mae: 0.7598 - val_loss: 15.9185 - val_mae: 2.6401\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1016 - mae: 0.7554 - val_loss: 14.8412 - val_mae: 2.5918\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0128 - mae: 0.7281 - val_loss: 14.3216 - val_mae: 2.5395\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9855 - mae: 0.7252 - val_loss: 14.6551 - val_mae: 2.5813\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0335 - mae: 0.7371 - val_loss: 17.3513 - val_mae: 2.8303\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1508 - mae: 0.7721 - val_loss: 14.3908 - val_mae: 2.5959\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1031 - mae: 0.7613 - val_loss: 15.9002 - val_mae: 2.6116\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.0849 - mae: 0.7394 - val_loss: 15.3893 - val_mae: 2.6487\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0106 - mae: 0.7201 - val_loss: 16.6864 - val_mae: 2.7734\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0915 - mae: 0.7720 - val_loss: 16.4039 - val_mae: 2.7968\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9861 - mae: 0.7092 - val_loss: 14.7493 - val_mae: 2.5997\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9632 - mae: 0.7149 - val_loss: 15.8692 - val_mae: 2.6725\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9864 - mae: 0.7400 - val_loss: 17.7810 - val_mae: 2.8517\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0819 - mae: 0.7404 - val_loss: 16.7561 - val_mae: 2.8783\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9347 - mae: 0.7128 - val_loss: 14.8002 - val_mae: 2.7454\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0079 - mae: 0.7261 - val_loss: 14.7398 - val_mae: 2.5794\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0851 - mae: 0.7753 - val_loss: 15.7592 - val_mae: 2.6747\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9956 - mae: 0.7168 - val_loss: 14.3591 - val_mae: 2.5681\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9806 - mae: 0.7341 - val_loss: 14.4056 - val_mae: 2.5521\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9118 - mae: 0.7026 - val_loss: 14.0516 - val_mae: 2.5626\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9459 - mae: 0.7235 - val_loss: 14.7489 - val_mae: 2.6782\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0280 - mae: 0.7356 - val_loss: 15.1933 - val_mae: 2.6427\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9626 - mae: 0.7191 - val_loss: 15.4327 - val_mae: 2.6357\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0046 - mae: 0.7341 - val_loss: 16.8626 - val_mae: 2.7421\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.9766 - mae: 0.7200 - val_loss: 15.5623 - val_mae: 2.6347\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9343 - mae: 0.7149 - val_loss: 14.7654 - val_mae: 2.6439\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9823 - mae: 0.7313 - val_loss: 16.3488 - val_mae: 2.6610\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1396 - mae: 0.7583 - val_loss: 14.7589 - val_mae: 2.5835\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.9063 - mae: 0.6884 - val_loss: 14.9568 - val_mae: 2.6303\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0010 - mae: 0.7468 - val_loss: 13.8657 - val_mae: 2.6301\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.8654 - mae: 0.6943 - val_loss: 14.9792 - val_mae: 2.5604\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.9911 - mae: 0.7189 - val_loss: 14.5536 - val_mae: 2.6062\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.9240 - mae: 0.7174 - val_loss: 16.9776 - val_mae: 2.8385\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9392 - mae: 0.7324 - val_loss: 14.9322 - val_mae: 2.6411\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8499 - mae: 0.6665 - val_loss: 17.3161 - val_mae: 2.6963\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0756 - mae: 0.7429 - val_loss: 14.0456 - val_mae: 2.5326\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8522 - mae: 0.6654 - val_loss: 16.0477 - val_mae: 2.6737\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.0557 - mae: 0.7497 - val_loss: 15.4914 - val_mae: 2.6079\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9537 - mae: 0.7279 - val_loss: 14.6148 - val_mae: 2.5629\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8770 - mae: 0.6747 - val_loss: 14.8140 - val_mae: 2.6391\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9969 - mae: 0.7314 - val_loss: 15.7980 - val_mae: 2.6337\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.8569 - mae: 0.6605 - val_loss: 15.0437 - val_mae: 2.6363\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9543 - mae: 0.7257 - val_loss: 16.7965 - val_mae: 2.7447\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9344 - mae: 0.6721 - val_loss: 14.5889 - val_mae: 2.6371\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8273 - mae: 0.6610 - val_loss: 14.1007 - val_mae: 2.6139\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 0.8427 - mae: 0.6785 - val_loss: 15.1495 - val_mae: 2.5752\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8154 - mae: 0.6331 - val_loss: 16.1716 - val_mae: 2.7162\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9868 - mae: 0.7189 - val_loss: 18.9498 - val_mae: 2.8832\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8320 - mae: 0.6446 - val_loss: 16.6251 - val_mae: 2.7110\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8637 - mae: 0.6795 - val_loss: 16.4045 - val_mae: 2.6768\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8736 - mae: 0.6940 - val_loss: 16.5881 - val_mae: 2.7509\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0047 - mae: 0.7132 - val_loss: 14.2165 - val_mae: 2.5758\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8593 - mae: 0.6969 - val_loss: 14.2545 - val_mae: 2.6011\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9750 - mae: 0.7223 - val_loss: 15.1079 - val_mae: 2.6689\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8352 - mae: 0.6699 - val_loss: 14.6371 - val_mae: 2.6820\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8782 - mae: 0.6972 - val_loss: 16.7796 - val_mae: 2.7818\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8731 - mae: 0.6892 - val_loss: 14.5059 - val_mae: 2.5665\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9387 - mae: 0.6875 - val_loss: 16.8793 - val_mae: 2.7101\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8768 - mae: 0.6799 - val_loss: 14.5155 - val_mae: 2.6051\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7700 - mae: 0.6490 - val_loss: 15.7831 - val_mae: 2.6341\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8633 - mae: 0.6836 - val_loss: 15.6235 - val_mae: 2.6888\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9180 - mae: 0.6779 - val_loss: 16.8255 - val_mae: 2.7283\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8460 - mae: 0.6716 - val_loss: 16.6377 - val_mae: 2.7959\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8787 - mae: 0.6917 - val_loss: 14.4234 - val_mae: 2.6893\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8724 - mae: 0.6791 - val_loss: 15.5597 - val_mae: 2.7536\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7920 - mae: 0.6494 - val_loss: 15.3847 - val_mae: 2.6727\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.8867 - mae: 0.6786 - val_loss: 14.3303 - val_mae: 2.5727\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8376 - mae: 0.6816 - val_loss: 13.9545 - val_mae: 2.6199\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9214 - mae: 0.6996 - val_loss: 16.1605 - val_mae: 2.6850\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8082 - mae: 0.6862 - val_loss: 14.8873 - val_mae: 2.6414\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8630 - mae: 0.6944 - val_loss: 14.7315 - val_mae: 2.6826\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8257 - mae: 0.6701 - val_loss: 15.8796 - val_mae: 2.6783\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7442 - mae: 0.6371 - val_loss: 14.1144 - val_mae: 2.5813\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.7902 - mae: 0.6573 - val_loss: 15.4773 - val_mae: 2.7450\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9468 - mae: 0.7347 - val_loss: 15.2497 - val_mae: 2.6049\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7633 - mae: 0.6393 - val_loss: 14.3731 - val_mae: 2.6561\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9214 - mae: 0.6983 - val_loss: 16.1773 - val_mae: 2.7838\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7444 - mae: 0.6300 - val_loss: 13.7108 - val_mae: 2.6080\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8807 - mae: 0.6921 - val_loss: 16.0284 - val_mae: 2.7940\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8465 - mae: 0.6635 - val_loss: 15.7399 - val_mae: 2.6646\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.8364 - mae: 0.6677 - val_loss: 16.3024 - val_mae: 2.7505\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8663 - mae: 0.7025 - val_loss: 15.2594 - val_mae: 2.6218\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7193 - mae: 0.5935 - val_loss: 15.4279 - val_mae: 2.7014\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7959 - mae: 0.6510 - val_loss: 14.2410 - val_mae: 2.5951\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7431 - mae: 0.6225 - val_loss: 16.2083 - val_mae: 2.8155\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7305 - mae: 0.6240 - val_loss: 14.6653 - val_mae: 2.6077\n",
            "Processing fold #2\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 2s 29ms/step - loss: 560.6006 - mae: 21.6668 - val_loss: 436.2110 - val_mae: 19.2384\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 459.7063 - mae: 19.2425 - val_loss: 342.3030 - val_mae: 16.7374\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 336.5710 - mae: 16.0861 - val_loss: 229.8513 - val_mae: 13.2708\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 206.2980 - mae: 11.9462 - val_loss: 130.8251 - val_mae: 9.4282\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 110.4453 - mae: 7.9774 - val_loss: 72.3398 - val_mae: 6.7009\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 64.6883 - mae: 5.9239 - val_loss: 48.0837 - val_mae: 5.1747\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 44.3411 - mae: 4.8426 - val_loss: 36.1598 - val_mae: 4.2998\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 33.3172 - mae: 4.2124 - val_loss: 30.7583 - val_mae: 3.8532\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 27.1778 - mae: 3.7958 - val_loss: 27.5390 - val_mae: 3.5075\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 23.8689 - mae: 3.5097 - val_loss: 25.1901 - val_mae: 3.3158\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 21.4574 - mae: 3.3617 - val_loss: 24.2381 - val_mae: 3.3075\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 19.6725 - mae: 3.1829 - val_loss: 22.1764 - val_mae: 3.1480\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 18.1899 - mae: 3.0917 - val_loss: 20.8903 - val_mae: 2.9979\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 16.6036 - mae: 2.9561 - val_loss: 19.6344 - val_mae: 2.9101\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 15.7171 - mae: 2.8485 - val_loss: 18.9331 - val_mae: 2.8574\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 14.6887 - mae: 2.7652 - val_loss: 18.2149 - val_mae: 2.8156\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 13.6622 - mae: 2.6517 - val_loss: 17.4895 - val_mae: 2.7113\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 12.7359 - mae: 2.5555 - val_loss: 17.5976 - val_mae: 2.7291\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 12.3271 - mae: 2.5121 - val_loss: 16.5367 - val_mae: 2.6190\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.9452 - mae: 2.4981 - val_loss: 16.2847 - val_mae: 2.5851\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.2849 - mae: 2.3899 - val_loss: 16.3727 - val_mae: 2.6484\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.2534 - mae: 2.4149 - val_loss: 15.7481 - val_mae: 2.5637\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 10.5871 - mae: 2.3658 - val_loss: 15.6285 - val_mae: 2.5187\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.3790 - mae: 2.3276 - val_loss: 15.5260 - val_mae: 2.5142\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.2919 - mae: 2.3173 - val_loss: 15.3463 - val_mae: 2.5385\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 10.0792 - mae: 2.2902 - val_loss: 15.1206 - val_mae: 2.4840\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.7616 - mae: 2.2356 - val_loss: 14.9547 - val_mae: 2.5287\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.5144 - mae: 2.2216 - val_loss: 15.1645 - val_mae: 2.6372\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.0596 - mae: 2.1841 - val_loss: 15.3477 - val_mae: 2.5100\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 9.2424 - mae: 2.1867 - val_loss: 14.8339 - val_mae: 2.5287\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.0352 - mae: 2.1644 - val_loss: 14.9007 - val_mae: 2.4785\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 9.0449 - mae: 2.1762 - val_loss: 14.5745 - val_mae: 2.5070\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.5151 - mae: 2.0812 - val_loss: 14.3096 - val_mae: 2.4992\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 8.5435 - mae: 2.1065 - val_loss: 14.4562 - val_mae: 2.5820\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.5435 - mae: 2.0989 - val_loss: 14.3495 - val_mae: 2.5234\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 8.4005 - mae: 2.0986 - val_loss: 14.3377 - val_mae: 2.4932\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.3522 - mae: 2.0661 - val_loss: 14.1025 - val_mae: 2.4741\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.1930 - mae: 2.0693 - val_loss: 14.1996 - val_mae: 2.4629\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.1756 - mae: 2.0380 - val_loss: 14.1239 - val_mae: 2.4893\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.8978 - mae: 2.0315 - val_loss: 13.8835 - val_mae: 2.5629\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.8361 - mae: 2.0279 - val_loss: 13.7636 - val_mae: 2.5236\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 7.8128 - mae: 2.0360 - val_loss: 14.1246 - val_mae: 2.5385\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.6237 - mae: 1.9601 - val_loss: 14.3344 - val_mae: 2.4894\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.7232 - mae: 2.0094 - val_loss: 13.7234 - val_mae: 2.4919\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 7.3906 - mae: 1.9411 - val_loss: 13.8591 - val_mae: 2.5443\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.3577 - mae: 1.9558 - val_loss: 13.9416 - val_mae: 2.5233\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.5800 - mae: 2.0042 - val_loss: 13.5520 - val_mae: 2.4859\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.1635 - mae: 1.9223 - val_loss: 13.6076 - val_mae: 2.4966\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.0926 - mae: 1.9038 - val_loss: 13.4930 - val_mae: 2.5847\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 7.1847 - mae: 1.9156 - val_loss: 13.3221 - val_mae: 2.5194\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.1267 - mae: 1.9152 - val_loss: 13.3592 - val_mae: 2.4726\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 6.9120 - mae: 1.8936 - val_loss: 13.4274 - val_mae: 2.4575\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9067 - mae: 1.9038 - val_loss: 13.7127 - val_mae: 2.4643\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.8745 - mae: 1.8847 - val_loss: 13.3703 - val_mae: 2.5359\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.7424 - mae: 1.8814 - val_loss: 13.3197 - val_mae: 2.4828\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3962 - mae: 1.8181 - val_loss: 15.0562 - val_mae: 2.6547\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.8017 - mae: 1.8793 - val_loss: 13.3214 - val_mae: 2.5161\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6323 - mae: 1.8596 - val_loss: 13.1802 - val_mae: 2.5161\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.5282 - mae: 1.8500 - val_loss: 13.2243 - val_mae: 2.4837\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.3276 - mae: 1.7796 - val_loss: 13.1820 - val_mae: 2.5440\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 6.4440 - mae: 1.8633 - val_loss: 13.2970 - val_mae: 2.4267\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.4652 - mae: 1.8345 - val_loss: 13.0718 - val_mae: 2.5049\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3310 - mae: 1.8189 - val_loss: 13.0599 - val_mae: 2.4413\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1027 - mae: 1.7867 - val_loss: 13.2710 - val_mae: 2.4241\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1662 - mae: 1.7717 - val_loss: 13.2443 - val_mae: 2.5452\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1261 - mae: 1.8126 - val_loss: 13.1307 - val_mae: 2.4317\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 6.0892 - mae: 1.7889 - val_loss: 13.2436 - val_mae: 2.4292\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 6.1204 - mae: 1.8212 - val_loss: 13.1711 - val_mae: 2.4484\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.9850 - mae: 1.7767 - val_loss: 13.2945 - val_mae: 2.4537\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.8818 - mae: 1.7587 - val_loss: 13.4076 - val_mae: 2.4149\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 5.7564 - mae: 1.7306 - val_loss: 13.2070 - val_mae: 2.4307\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7356 - mae: 1.7388 - val_loss: 12.8413 - val_mae: 2.4492\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.8945 - mae: 1.7444 - val_loss: 13.0480 - val_mae: 2.4988\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.5273 - mae: 1.7447 - val_loss: 13.0566 - val_mae: 2.4177\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7224 - mae: 1.7510 - val_loss: 13.2158 - val_mae: 2.4674\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4887 - mae: 1.6920 - val_loss: 13.1911 - val_mae: 2.5323\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5813 - mae: 1.7520 - val_loss: 13.2558 - val_mae: 2.4702\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.5060 - mae: 1.7054 - val_loss: 13.2697 - val_mae: 2.4156\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3640 - mae: 1.7105 - val_loss: 13.6513 - val_mae: 2.4683\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4646 - mae: 1.6811 - val_loss: 13.8276 - val_mae: 2.4792\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.4128 - mae: 1.6859 - val_loss: 12.8841 - val_mae: 2.4279\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.2785 - mae: 1.6836 - val_loss: 13.0018 - val_mae: 2.4765\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 5.3090 - mae: 1.6990 - val_loss: 13.0789 - val_mae: 2.4484\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.2830 - mae: 1.6611 - val_loss: 13.0773 - val_mae: 2.4537\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1826 - mae: 1.6437 - val_loss: 13.1357 - val_mae: 2.4586\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.1282 - mae: 1.6464 - val_loss: 12.9741 - val_mae: 2.4645\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1094 - mae: 1.6356 - val_loss: 12.9550 - val_mae: 2.4721\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.8600 - mae: 1.6211 - val_loss: 13.4325 - val_mae: 2.4466\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8680 - mae: 1.5956 - val_loss: 12.9829 - val_mae: 2.5284\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.9939 - mae: 1.6427 - val_loss: 12.9054 - val_mae: 2.4794\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 4.9602 - mae: 1.6087 - val_loss: 12.8761 - val_mae: 2.4941\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 4.8797 - mae: 1.6507 - val_loss: 12.8161 - val_mae: 2.4653\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.8581 - mae: 1.6259 - val_loss: 12.7301 - val_mae: 2.4486\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8045 - mae: 1.5923 - val_loss: 12.7710 - val_mae: 2.4351\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.9359 - mae: 1.6084 - val_loss: 12.9361 - val_mae: 2.4287\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.6081 - mae: 1.5719 - val_loss: 12.7791 - val_mae: 2.4565\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.6833 - mae: 1.5833 - val_loss: 12.8661 - val_mae: 2.4488\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6408 - mae: 1.5404 - val_loss: 13.2253 - val_mae: 2.4660\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4846 - mae: 1.5731 - val_loss: 12.9860 - val_mae: 2.5510\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.7092 - mae: 1.5754 - val_loss: 13.1493 - val_mae: 2.5757\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.7449 - mae: 1.6128 - val_loss: 13.2021 - val_mae: 2.4617\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5052 - mae: 1.5214 - val_loss: 12.7666 - val_mae: 2.4773\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6193 - mae: 1.5565 - val_loss: 12.8149 - val_mae: 2.4998\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.5287 - mae: 1.5810 - val_loss: 12.6615 - val_mae: 2.4505\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5668 - mae: 1.5661 - val_loss: 13.0568 - val_mae: 2.4373\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4060 - mae: 1.5405 - val_loss: 12.8106 - val_mae: 2.4501\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4334 - mae: 1.5568 - val_loss: 12.7264 - val_mae: 2.4524\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3236 - mae: 1.5396 - val_loss: 12.6839 - val_mae: 2.3958\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3758 - mae: 1.4945 - val_loss: 12.9774 - val_mae: 2.4663\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.3195 - mae: 1.5061 - val_loss: 12.7509 - val_mae: 2.4672\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 4.1210 - mae: 1.4840 - val_loss: 13.4292 - val_mae: 2.5994\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.1732 - mae: 1.4950 - val_loss: 12.7833 - val_mae: 2.4107\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2472 - mae: 1.4927 - val_loss: 12.9332 - val_mae: 2.5082\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.0962 - mae: 1.4755 - val_loss: 13.7806 - val_mae: 2.5633\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1464 - mae: 1.4740 - val_loss: 13.1855 - val_mae: 2.4782\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0802 - mae: 1.4529 - val_loss: 13.2342 - val_mae: 2.4843\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.9833 - mae: 1.4871 - val_loss: 13.1217 - val_mae: 2.4246\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1179 - mae: 1.4618 - val_loss: 12.8581 - val_mae: 2.4939\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1174 - mae: 1.4920 - val_loss: 12.7892 - val_mae: 2.4431\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8464 - mae: 1.4423 - val_loss: 13.3857 - val_mae: 2.4535\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 3.9497 - mae: 1.4343 - val_loss: 13.0277 - val_mae: 2.4447\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.9522 - mae: 1.4276 - val_loss: 12.8541 - val_mae: 2.4221\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 3.8541 - mae: 1.4558 - val_loss: 12.8887 - val_mae: 2.4372\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.9548 - mae: 1.4709 - val_loss: 13.2849 - val_mae: 2.5601\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.8274 - mae: 1.4055 - val_loss: 12.9740 - val_mae: 2.4724\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7077 - mae: 1.4068 - val_loss: 12.6860 - val_mae: 2.4882\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6808 - mae: 1.4283 - val_loss: 13.0600 - val_mae: 2.4434\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8870 - mae: 1.4215 - val_loss: 12.9022 - val_mae: 2.4858\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6105 - mae: 1.3981 - val_loss: 12.7829 - val_mae: 2.4157\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7554 - mae: 1.4108 - val_loss: 12.7661 - val_mae: 2.4162\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6357 - mae: 1.3961 - val_loss: 13.3289 - val_mae: 2.5296\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 3.5757 - mae: 1.3938 - val_loss: 13.3978 - val_mae: 2.5746\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6081 - mae: 1.4089 - val_loss: 12.4296 - val_mae: 2.4088\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5450 - mae: 1.3690 - val_loss: 12.6402 - val_mae: 2.4207\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 3.5747 - mae: 1.3854 - val_loss: 12.9368 - val_mae: 2.4040\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4576 - mae: 1.3602 - val_loss: 12.8360 - val_mae: 2.4491\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3528 - mae: 1.3237 - val_loss: 12.4726 - val_mae: 2.3865\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4942 - mae: 1.3737 - val_loss: 12.6386 - val_mae: 2.4430\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.3422 - mae: 1.3441 - val_loss: 12.8192 - val_mae: 2.4351\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5870 - mae: 1.3773 - val_loss: 12.5380 - val_mae: 2.3968\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3026 - mae: 1.3348 - val_loss: 13.0610 - val_mae: 2.4509\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2880 - mae: 1.3277 - val_loss: 12.4411 - val_mae: 2.4177\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.3430 - mae: 1.3407 - val_loss: 12.4793 - val_mae: 2.4281\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2537 - mae: 1.3497 - val_loss: 13.0449 - val_mae: 2.5276\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1885 - mae: 1.3299 - val_loss: 12.7875 - val_mae: 2.4449\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.2828 - mae: 1.3522 - val_loss: 12.9199 - val_mae: 2.4781\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 3.1951 - mae: 1.3237 - val_loss: 12.5657 - val_mae: 2.3849\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2468 - mae: 1.3253 - val_loss: 12.4661 - val_mae: 2.4200\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1895 - mae: 1.3076 - val_loss: 12.9047 - val_mae: 2.4482\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.2189 - mae: 1.3165 - val_loss: 12.5751 - val_mae: 2.3944\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0573 - mae: 1.2675 - val_loss: 12.4039 - val_mae: 2.3874\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2050 - mae: 1.3043 - val_loss: 12.5883 - val_mae: 2.4166\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0281 - mae: 1.2606 - val_loss: 13.0690 - val_mae: 2.5292\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0264 - mae: 1.2869 - val_loss: 12.4484 - val_mae: 2.4194\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0824 - mae: 1.2902 - val_loss: 12.6495 - val_mae: 2.4262\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1446 - mae: 1.3161 - val_loss: 12.6522 - val_mae: 2.4377\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0127 - mae: 1.2687 - val_loss: 12.7843 - val_mae: 2.4588\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0056 - mae: 1.2605 - val_loss: 12.5511 - val_mae: 2.4299\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.9609 - mae: 1.2581 - val_loss: 12.7770 - val_mae: 2.4625\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9150 - mae: 1.2339 - val_loss: 12.7498 - val_mae: 2.4612\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 2.7928 - mae: 1.2170 - val_loss: 12.7202 - val_mae: 2.4901\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8677 - mae: 1.2525 - val_loss: 12.4847 - val_mae: 2.4163\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8271 - mae: 1.2142 - val_loss: 13.0693 - val_mae: 2.5202\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7761 - mae: 1.2016 - val_loss: 13.6624 - val_mae: 2.6326\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.8925 - mae: 1.2575 - val_loss: 12.4772 - val_mae: 2.4062\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.8417 - mae: 1.2399 - val_loss: 12.8884 - val_mae: 2.4393\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.8106 - mae: 1.2278 - val_loss: 12.6663 - val_mae: 2.4453\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7823 - mae: 1.2073 - val_loss: 13.1409 - val_mae: 2.5230\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8318 - mae: 1.2464 - val_loss: 12.5451 - val_mae: 2.4223\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6303 - mae: 1.1741 - val_loss: 13.0547 - val_mae: 2.4481\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6714 - mae: 1.1674 - val_loss: 12.5089 - val_mae: 2.4285\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.7487 - mae: 1.2139 - val_loss: 12.7506 - val_mae: 2.4509\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7493 - mae: 1.2054 - val_loss: 12.2804 - val_mae: 2.4064\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6899 - mae: 1.1859 - val_loss: 12.5123 - val_mae: 2.4409\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5123 - mae: 1.1591 - val_loss: 12.8292 - val_mae: 2.4847\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 2.7158 - mae: 1.2159 - val_loss: 12.4257 - val_mae: 2.4178\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5609 - mae: 1.1667 - val_loss: 12.6259 - val_mae: 2.4307\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4994 - mae: 1.1584 - val_loss: 12.5635 - val_mae: 2.4513\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5906 - mae: 1.1786 - val_loss: 12.8343 - val_mae: 2.4337\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4940 - mae: 1.1510 - val_loss: 12.2971 - val_mae: 2.4001\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5817 - mae: 1.1802 - val_loss: 12.4919 - val_mae: 2.4298\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5898 - mae: 1.1608 - val_loss: 12.3846 - val_mae: 2.4095\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4708 - mae: 1.1738 - val_loss: 12.3597 - val_mae: 2.4051\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4145 - mae: 1.1324 - val_loss: 12.8656 - val_mae: 2.4607\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4670 - mae: 1.1745 - val_loss: 12.4530 - val_mae: 2.3829\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4559 - mae: 1.1451 - val_loss: 12.5176 - val_mae: 2.4293\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5331 - mae: 1.1559 - val_loss: 12.5846 - val_mae: 2.4582\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3737 - mae: 1.1459 - val_loss: 12.8944 - val_mae: 2.4742\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5059 - mae: 1.1513 - val_loss: 12.4324 - val_mae: 2.4462\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4340 - mae: 1.1504 - val_loss: 12.4708 - val_mae: 2.3987\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.4108 - mae: 1.1266 - val_loss: 12.5261 - val_mae: 2.4356\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4359 - mae: 1.1242 - val_loss: 12.7860 - val_mae: 2.4791\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.3366 - mae: 1.1229 - val_loss: 12.7433 - val_mae: 2.4584\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.3779 - mae: 1.1138 - val_loss: 12.9761 - val_mae: 2.4558\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4895 - mae: 1.1676 - val_loss: 12.5754 - val_mae: 2.4464\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 2.2468 - mae: 1.0990 - val_loss: 12.2540 - val_mae: 2.4143\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4590 - mae: 1.1379 - val_loss: 12.6190 - val_mae: 2.4685\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2986 - mae: 1.1266 - val_loss: 12.4739 - val_mae: 2.4432\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 2.2678 - mae: 1.0824 - val_loss: 12.2235 - val_mae: 2.4151\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3928 - mae: 1.1519 - val_loss: 12.1663 - val_mae: 2.3921\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2350 - mae: 1.0979 - val_loss: 12.6865 - val_mae: 2.4579\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2163 - mae: 1.0949 - val_loss: 12.4957 - val_mae: 2.4525\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 2.2052 - mae: 1.0894 - val_loss: 12.6181 - val_mae: 2.4492\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2968 - mae: 1.0699 - val_loss: 12.4988 - val_mae: 2.4432\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1154 - mae: 1.0810 - val_loss: 13.0885 - val_mae: 2.4932\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1522 - mae: 1.0687 - val_loss: 12.7524 - val_mae: 2.4569\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3477 - mae: 1.1130 - val_loss: 12.8598 - val_mae: 2.4471\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1145 - mae: 1.0658 - val_loss: 12.5558 - val_mae: 2.4466\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1680 - mae: 1.0706 - val_loss: 12.4213 - val_mae: 2.4365\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0698 - mae: 1.0676 - val_loss: 12.9181 - val_mae: 2.5044\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1154 - mae: 1.0296 - val_loss: 12.4683 - val_mae: 2.4327\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0307 - mae: 1.0104 - val_loss: 12.4924 - val_mae: 2.4274\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 2.0976 - mae: 1.0571 - val_loss: 12.7820 - val_mae: 2.4817\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.0852 - mae: 1.0666 - val_loss: 12.7338 - val_mae: 2.4661\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0756 - mae: 1.0651 - val_loss: 12.6652 - val_mae: 2.4776\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.0069 - mae: 1.0266 - val_loss: 12.4864 - val_mae: 2.4426\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.2108 - mae: 1.0793 - val_loss: 12.7274 - val_mae: 2.4129\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9574 - mae: 1.0361 - val_loss: 12.3964 - val_mae: 2.4304\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9986 - mae: 1.0427 - val_loss: 12.5991 - val_mae: 2.4690\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0727 - mae: 1.0505 - val_loss: 12.6392 - val_mae: 2.4505\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9503 - mae: 1.0325 - val_loss: 12.5193 - val_mae: 2.4230\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9124 - mae: 1.0033 - val_loss: 12.7457 - val_mae: 2.5503\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9642 - mae: 1.0197 - val_loss: 12.0404 - val_mae: 2.3917\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8911 - mae: 0.9893 - val_loss: 12.7257 - val_mae: 2.4464\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9269 - mae: 1.0110 - val_loss: 12.5884 - val_mae: 2.4260\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.8836 - mae: 0.9989 - val_loss: 13.1892 - val_mae: 2.5610\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9155 - mae: 1.0120 - val_loss: 12.8156 - val_mae: 2.5096\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.0163 - mae: 1.0333 - val_loss: 12.3595 - val_mae: 2.4311\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8830 - mae: 1.0038 - val_loss: 12.5649 - val_mae: 2.4293\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8588 - mae: 0.9740 - val_loss: 13.0969 - val_mae: 2.5046\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9013 - mae: 0.9927 - val_loss: 12.3901 - val_mae: 2.3979\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9744 - mae: 1.0169 - val_loss: 12.6560 - val_mae: 2.4435\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8473 - mae: 1.0110 - val_loss: 12.6480 - val_mae: 2.4344\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8212 - mae: 0.9800 - val_loss: 12.4478 - val_mae: 2.4305\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 1.9308 - mae: 1.0096 - val_loss: 12.9577 - val_mae: 2.4908\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7437 - mae: 0.9627 - val_loss: 12.5797 - val_mae: 2.4229\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8507 - mae: 0.9967 - val_loss: 12.4833 - val_mae: 2.4263\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7535 - mae: 0.9667 - val_loss: 12.9457 - val_mae: 2.4683\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6901 - mae: 0.9537 - val_loss: 13.3340 - val_mae: 2.5098\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7621 - mae: 0.9921 - val_loss: 12.5985 - val_mae: 2.5074\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8492 - mae: 0.9930 - val_loss: 12.6905 - val_mae: 2.4545\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6938 - mae: 0.9497 - val_loss: 12.5091 - val_mae: 2.4457\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7296 - mae: 0.9740 - val_loss: 12.7675 - val_mae: 2.4748\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7936 - mae: 0.9579 - val_loss: 12.6773 - val_mae: 2.4851\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8562 - mae: 0.9782 - val_loss: 12.6941 - val_mae: 2.4641\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.6724 - mae: 0.9490 - val_loss: 12.8536 - val_mae: 2.4668\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7261 - mae: 0.9558 - val_loss: 12.6323 - val_mae: 2.4687\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7465 - mae: 0.9677 - val_loss: 12.6447 - val_mae: 2.4574\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6997 - mae: 0.9359 - val_loss: 12.6949 - val_mae: 2.4445\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.7289 - mae: 0.9733 - val_loss: 12.4863 - val_mae: 2.4337\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6752 - mae: 0.9290 - val_loss: 12.8975 - val_mae: 2.4907\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6961 - mae: 0.9579 - val_loss: 12.5172 - val_mae: 2.4203\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6407 - mae: 0.9387 - val_loss: 12.7237 - val_mae: 2.4716\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.5983 - mae: 0.9032 - val_loss: 12.8868 - val_mae: 2.4996\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6460 - mae: 0.9433 - val_loss: 12.4726 - val_mae: 2.4312\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6386 - mae: 0.9004 - val_loss: 12.9381 - val_mae: 2.4750\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7358 - mae: 0.9882 - val_loss: 12.7680 - val_mae: 2.5085\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6091 - mae: 0.9401 - val_loss: 12.6234 - val_mae: 2.4888\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6695 - mae: 0.9488 - val_loss: 13.1541 - val_mae: 2.5068\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6194 - mae: 0.9357 - val_loss: 12.2719 - val_mae: 2.4094\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.6045 - mae: 0.9102 - val_loss: 12.8761 - val_mae: 2.4727\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6439 - mae: 0.9258 - val_loss: 12.3140 - val_mae: 2.4129\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6774 - mae: 0.9380 - val_loss: 12.5962 - val_mae: 2.4571\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4969 - mae: 0.8901 - val_loss: 12.3300 - val_mae: 2.4216\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.5800 - mae: 0.9323 - val_loss: 12.3531 - val_mae: 2.4209\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5696 - mae: 0.9298 - val_loss: 12.6198 - val_mae: 2.4476\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5080 - mae: 0.8876 - val_loss: 12.6879 - val_mae: 2.4600\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5601 - mae: 0.8929 - val_loss: 12.2768 - val_mae: 2.4309\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6534 - mae: 0.9309 - val_loss: 12.3997 - val_mae: 2.4014\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.5654 - mae: 0.9003 - val_loss: 12.2689 - val_mae: 2.4111\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4752 - mae: 0.8757 - val_loss: 12.5638 - val_mae: 2.4365\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 1.5363 - mae: 0.8976 - val_loss: 12.7881 - val_mae: 2.4917\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5351 - mae: 0.8958 - val_loss: 12.5032 - val_mae: 2.4149\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5162 - mae: 0.9177 - val_loss: 13.0178 - val_mae: 2.5053\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6043 - mae: 0.9470 - val_loss: 12.3232 - val_mae: 2.4069\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.4344 - mae: 0.8638 - val_loss: 12.6342 - val_mae: 2.4320\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3964 - mae: 0.8604 - val_loss: 12.5045 - val_mae: 2.4475\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4192 - mae: 0.8707 - val_loss: 12.5028 - val_mae: 2.4473\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.5231 - mae: 0.8782 - val_loss: 13.2874 - val_mae: 2.5146\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4555 - mae: 0.8820 - val_loss: 12.7598 - val_mae: 2.4544\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5491 - mae: 0.8825 - val_loss: 12.4487 - val_mae: 2.4225\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5099 - mae: 0.8910 - val_loss: 12.4216 - val_mae: 2.4324\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 1s 6ms/step - loss: 1.4517 - mae: 0.8857 - val_loss: 12.6165 - val_mae: 2.4464\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3736 - mae: 0.8639 - val_loss: 12.6139 - val_mae: 2.4539\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3523 - mae: 0.8407 - val_loss: 12.6672 - val_mae: 2.4539\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 1.4570 - mae: 0.8791 - val_loss: 12.3460 - val_mae: 2.4221\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4587 - mae: 0.8917 - val_loss: 12.5647 - val_mae: 2.4352\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3935 - mae: 0.8559 - val_loss: 12.5312 - val_mae: 2.4398\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4039 - mae: 0.8556 - val_loss: 12.3498 - val_mae: 2.4472\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3772 - mae: 0.8485 - val_loss: 12.8770 - val_mae: 2.4671\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5033 - mae: 0.8874 - val_loss: 12.8518 - val_mae: 2.4936\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3994 - mae: 0.8376 - val_loss: 12.8154 - val_mae: 2.4663\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 1.3023 - mae: 0.8322 - val_loss: 12.6208 - val_mae: 2.4504\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3992 - mae: 0.8591 - val_loss: 12.7288 - val_mae: 2.4609\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3458 - mae: 0.8400 - val_loss: 12.3725 - val_mae: 2.4261\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.3901 - mae: 0.8573 - val_loss: 12.9857 - val_mae: 2.4888\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2453 - mae: 0.8163 - val_loss: 13.0317 - val_mae: 2.5055\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4906 - mae: 0.8731 - val_loss: 12.4374 - val_mae: 2.4126\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3100 - mae: 0.7966 - val_loss: 12.7322 - val_mae: 2.4783\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3570 - mae: 0.8313 - val_loss: 12.4140 - val_mae: 2.4162\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2347 - mae: 0.8308 - val_loss: 12.7419 - val_mae: 2.4529\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2761 - mae: 0.8168 - val_loss: 12.4133 - val_mae: 2.4170\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.4306 - mae: 0.8698 - val_loss: 12.3263 - val_mae: 2.4380\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3477 - mae: 0.8250 - val_loss: 12.4450 - val_mae: 2.4252\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2949 - mae: 0.8338 - val_loss: 12.6232 - val_mae: 2.4378\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3288 - mae: 0.8375 - val_loss: 12.6602 - val_mae: 2.4357\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5022 - mae: 0.8823 - val_loss: 12.6753 - val_mae: 2.4440\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2523 - mae: 0.7877 - val_loss: 12.4699 - val_mae: 2.4314\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1714 - mae: 0.7812 - val_loss: 12.5772 - val_mae: 2.4759\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3372 - mae: 0.8488 - val_loss: 12.3352 - val_mae: 2.4275\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2405 - mae: 0.8128 - val_loss: 12.5729 - val_mae: 2.4237\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2920 - mae: 0.8530 - val_loss: 12.5292 - val_mae: 2.4524\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2305 - mae: 0.8031 - val_loss: 12.1635 - val_mae: 2.3933\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.2323 - mae: 0.8018 - val_loss: 12.3681 - val_mae: 2.4223\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2809 - mae: 0.8293 - val_loss: 12.3650 - val_mae: 2.4010\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 1.1831 - mae: 0.8021 - val_loss: 12.3406 - val_mae: 2.4207\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3625 - mae: 0.8525 - val_loss: 12.6312 - val_mae: 2.4568\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2026 - mae: 0.7987 - val_loss: 12.7097 - val_mae: 2.4777\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2574 - mae: 0.8139 - val_loss: 12.7414 - val_mae: 2.4645\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2114 - mae: 0.7909 - val_loss: 12.5450 - val_mae: 2.4346\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1353 - mae: 0.7783 - val_loss: 12.8596 - val_mae: 2.4828\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3517 - mae: 0.8370 - val_loss: 12.4268 - val_mae: 2.4325\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.1839 - mae: 0.7667 - val_loss: 12.8705 - val_mae: 2.4975\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1992 - mae: 0.8093 - val_loss: 12.4899 - val_mae: 2.4318\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3111 - mae: 0.8187 - val_loss: 12.7151 - val_mae: 2.4209\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1598 - mae: 0.7936 - val_loss: 12.8677 - val_mae: 2.4941\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1251 - mae: 0.7491 - val_loss: 12.6057 - val_mae: 2.4584\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1525 - mae: 0.7719 - val_loss: 12.3793 - val_mae: 2.4446\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1165 - mae: 0.7732 - val_loss: 12.9387 - val_mae: 2.4944\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2113 - mae: 0.8104 - val_loss: 12.5978 - val_mae: 2.4313\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.1798 - mae: 0.7815 - val_loss: 12.8762 - val_mae: 2.5227\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0889 - mae: 0.7853 - val_loss: 12.5302 - val_mae: 2.4530\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1551 - mae: 0.7620 - val_loss: 12.8012 - val_mae: 2.4901\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0912 - mae: 0.7471 - val_loss: 13.0263 - val_mae: 2.4802\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1873 - mae: 0.7982 - val_loss: 12.4935 - val_mae: 2.4226\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1161 - mae: 0.7309 - val_loss: 12.4985 - val_mae: 2.4376\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.1447 - mae: 0.7625 - val_loss: 12.6582 - val_mae: 2.4078\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1840 - mae: 0.7852 - val_loss: 12.6582 - val_mae: 2.4323\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1676 - mae: 0.7635 - val_loss: 12.7906 - val_mae: 2.4675\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1042 - mae: 0.7489 - val_loss: 12.3732 - val_mae: 2.4255\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0814 - mae: 0.7411 - val_loss: 12.8946 - val_mae: 2.4636\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1491 - mae: 0.7545 - val_loss: 12.7713 - val_mae: 2.4741\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0494 - mae: 0.7341 - val_loss: 12.7072 - val_mae: 2.4643\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1177 - mae: 0.7806 - val_loss: 13.1145 - val_mae: 2.5361\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1463 - mae: 0.7386 - val_loss: 12.4312 - val_mae: 2.4352\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1015 - mae: 0.7500 - val_loss: 13.1157 - val_mae: 2.5096\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0907 - mae: 0.7482 - val_loss: 12.4413 - val_mae: 2.4400\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0873 - mae: 0.7475 - val_loss: 12.7922 - val_mae: 2.4606\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0496 - mae: 0.7129 - val_loss: 12.4976 - val_mae: 2.4316\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0935 - mae: 0.7737 - val_loss: 12.6816 - val_mae: 2.4741\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0254 - mae: 0.7271 - val_loss: 12.5658 - val_mae: 2.4515\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1289 - mae: 0.7479 - val_loss: 12.7305 - val_mae: 2.4613\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9862 - mae: 0.6988 - val_loss: 13.5133 - val_mae: 2.5561\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0630 - mae: 0.7447 - val_loss: 12.7830 - val_mae: 2.4849\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9778 - mae: 0.7131 - val_loss: 12.9741 - val_mae: 2.5041\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 1.1257 - mae: 0.7536 - val_loss: 13.1354 - val_mae: 2.5133\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9537 - mae: 0.7016 - val_loss: 12.6518 - val_mae: 2.4732\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.0949 - mae: 0.7393 - val_loss: 12.7125 - val_mae: 2.4456\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1013 - mae: 0.7491 - val_loss: 12.6134 - val_mae: 2.4499\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0275 - mae: 0.7493 - val_loss: 12.8597 - val_mae: 2.4699\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.0464 - mae: 0.7256 - val_loss: 13.1813 - val_mae: 2.5205\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9813 - mae: 0.7398 - val_loss: 12.8100 - val_mae: 2.4488\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0625 - mae: 0.7390 - val_loss: 12.7161 - val_mae: 2.4344\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0712 - mae: 0.7469 - val_loss: 12.9332 - val_mae: 2.4902\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9670 - mae: 0.7027 - val_loss: 13.5187 - val_mae: 2.5203\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0135 - mae: 0.6952 - val_loss: 12.9521 - val_mae: 2.4844\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0034 - mae: 0.7091 - val_loss: 12.7165 - val_mae: 2.4380\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9690 - mae: 0.6836 - val_loss: 12.7986 - val_mae: 2.4450\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9682 - mae: 0.7020 - val_loss: 12.5778 - val_mae: 2.4374\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0241 - mae: 0.7225 - val_loss: 12.6255 - val_mae: 2.4328\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1402 - mae: 0.7870 - val_loss: 13.0779 - val_mae: 2.4968\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9334 - mae: 0.7020 - val_loss: 12.8604 - val_mae: 2.4745\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9258 - mae: 0.6910 - val_loss: 12.8053 - val_mae: 2.4653\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0058 - mae: 0.7182 - val_loss: 13.0937 - val_mae: 2.4912\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9613 - mae: 0.7038 - val_loss: 12.6723 - val_mae: 2.4405\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 1s 5ms/step - loss: 0.8940 - mae: 0.6563 - val_loss: 12.6366 - val_mae: 2.3941\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9749 - mae: 0.6957 - val_loss: 12.8307 - val_mae: 2.4664\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0249 - mae: 0.7088 - val_loss: 12.8468 - val_mae: 2.4710\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0453 - mae: 0.7313 - val_loss: 12.7150 - val_mae: 2.4485\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 1.0285 - mae: 0.7178 - val_loss: 13.0843 - val_mae: 2.4614\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9245 - mae: 0.6827 - val_loss: 12.5731 - val_mae: 2.4101\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9585 - mae: 0.7071 - val_loss: 12.9067 - val_mae: 2.4777\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9514 - mae: 0.7032 - val_loss: 13.0372 - val_mae: 2.4882\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9478 - mae: 0.7044 - val_loss: 12.7484 - val_mae: 2.4569\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8637 - mae: 0.6623 - val_loss: 12.4168 - val_mae: 2.4345\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9847 - mae: 0.6993 - val_loss: 13.0395 - val_mae: 2.5077\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9676 - mae: 0.6879 - val_loss: 12.8683 - val_mae: 2.4712\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9642 - mae: 0.7174 - val_loss: 13.1279 - val_mae: 2.4727\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9828 - mae: 0.7014 - val_loss: 12.7990 - val_mae: 2.4547\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9366 - mae: 0.6732 - val_loss: 12.9344 - val_mae: 2.4726\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9374 - mae: 0.6866 - val_loss: 12.9562 - val_mae: 2.4793\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.9523 - mae: 0.6945 - val_loss: 12.7654 - val_mae: 2.4244\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9558 - mae: 0.7112 - val_loss: 13.3170 - val_mae: 2.5148\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8369 - mae: 0.6473 - val_loss: 13.2311 - val_mae: 2.5686\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9927 - mae: 0.7284 - val_loss: 12.8413 - val_mae: 2.4633\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9289 - mae: 0.6819 - val_loss: 12.8352 - val_mae: 2.4339\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.0020 - mae: 0.6914 - val_loss: 12.8554 - val_mae: 2.4393\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8300 - mae: 0.6414 - val_loss: 13.5377 - val_mae: 2.5681\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0328 - mae: 0.7252 - val_loss: 12.8348 - val_mae: 2.4306\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8622 - mae: 0.6482 - val_loss: 12.8747 - val_mae: 2.4425\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8582 - mae: 0.6693 - val_loss: 12.6001 - val_mae: 2.4139\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9223 - mae: 0.7094 - val_loss: 12.9389 - val_mae: 2.4978\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9617 - mae: 0.6777 - val_loss: 12.7079 - val_mae: 2.4623\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.7904 - mae: 0.6390 - val_loss: 12.9942 - val_mae: 2.4188\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9112 - mae: 0.6622 - val_loss: 13.4985 - val_mae: 2.5301\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9873 - mae: 0.7339 - val_loss: 13.1668 - val_mae: 2.4864\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 0.9201 - mae: 0.6672 - val_loss: 12.8341 - val_mae: 2.4545\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8394 - mae: 0.6516 - val_loss: 12.8742 - val_mae: 2.4280\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8954 - mae: 0.6566 - val_loss: 12.7609 - val_mae: 2.4366\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8362 - mae: 0.6440 - val_loss: 13.2840 - val_mae: 2.5227\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.8619 - mae: 0.6578 - val_loss: 12.7962 - val_mae: 2.4577\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8967 - mae: 0.6710 - val_loss: 12.9999 - val_mae: 2.4979\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8562 - mae: 0.6582 - val_loss: 12.8130 - val_mae: 2.4702\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8303 - mae: 0.6545 - val_loss: 13.0274 - val_mae: 2.4225\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 0.8827 - mae: 0.6566 - val_loss: 12.8581 - val_mae: 2.4467\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7416 - mae: 0.6095 - val_loss: 12.9693 - val_mae: 2.4508\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8825 - mae: 0.6384 - val_loss: 13.2514 - val_mae: 2.5053\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8369 - mae: 0.6714 - val_loss: 12.9277 - val_mae: 2.4603\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.7834 - mae: 0.6442 - val_loss: 13.1199 - val_mae: 2.4388\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9644 - mae: 0.6812 - val_loss: 12.6534 - val_mae: 2.4258\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8382 - mae: 0.6562 - val_loss: 12.8395 - val_mae: 2.4455\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8464 - mae: 0.6452 - val_loss: 13.2324 - val_mae: 2.4638\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8775 - mae: 0.6600 - val_loss: 13.0653 - val_mae: 2.4899\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8482 - mae: 0.6582 - val_loss: 13.1616 - val_mae: 2.4624\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9509 - mae: 0.6900 - val_loss: 13.1262 - val_mae: 2.4929\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7594 - mae: 0.6248 - val_loss: 13.2920 - val_mae: 2.4619\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7603 - mae: 0.6068 - val_loss: 12.6355 - val_mae: 2.4472\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8734 - mae: 0.6611 - val_loss: 13.2172 - val_mae: 2.4740\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.9557 - mae: 0.7007 - val_loss: 12.9798 - val_mae: 2.4618\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7789 - mae: 0.6221 - val_loss: 13.6630 - val_mae: 2.5114\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8857 - mae: 0.6669 - val_loss: 12.7931 - val_mae: 2.4898\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8130 - mae: 0.6335 - val_loss: 12.8324 - val_mae: 2.4708\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8841 - mae: 0.6755 - val_loss: 13.1831 - val_mae: 2.4854\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7509 - mae: 0.6068 - val_loss: 12.6222 - val_mae: 2.4439\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8100 - mae: 0.6584 - val_loss: 12.9340 - val_mae: 2.4574\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.8045 - mae: 0.6467 - val_loss: 13.5690 - val_mae: 2.5392\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7358 - mae: 0.6206 - val_loss: 12.9910 - val_mae: 2.4600\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8176 - mae: 0.6434 - val_loss: 12.7364 - val_mae: 2.4712\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8319 - mae: 0.6508 - val_loss: 13.1538 - val_mae: 2.4232\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.7408 - mae: 0.6251 - val_loss: 12.8403 - val_mae: 2.4282\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7850 - mae: 0.6340 - val_loss: 13.1297 - val_mae: 2.4865\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8248 - mae: 0.6289 - val_loss: 12.9744 - val_mae: 2.4166\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7535 - mae: 0.6246 - val_loss: 12.4172 - val_mae: 2.3797\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7005 - mae: 0.5967 - val_loss: 12.3815 - val_mae: 2.3962\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7977 - mae: 0.6494 - val_loss: 12.9604 - val_mae: 2.4728\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7439 - mae: 0.6429 - val_loss: 12.7428 - val_mae: 2.4234\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8017 - mae: 0.6409 - val_loss: 12.7574 - val_mae: 2.4643\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.8047 - mae: 0.6348 - val_loss: 13.0790 - val_mae: 2.4824\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8013 - mae: 0.6373 - val_loss: 12.6860 - val_mae: 2.4155\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8240 - mae: 0.6324 - val_loss: 12.7798 - val_mae: 2.4727\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6686 - mae: 0.5930 - val_loss: 13.1408 - val_mae: 2.4598\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7936 - mae: 0.6391 - val_loss: 13.1032 - val_mae: 2.4733\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6953 - mae: 0.6005 - val_loss: 12.9887 - val_mae: 2.4596\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8012 - mae: 0.6558 - val_loss: 13.4183 - val_mae: 2.5108\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.7177 - mae: 0.6007 - val_loss: 13.0909 - val_mae: 2.4595\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7957 - mae: 0.6457 - val_loss: 12.8489 - val_mae: 2.4703\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6835 - mae: 0.5847 - val_loss: 12.8419 - val_mae: 2.4679\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6881 - mae: 0.5833 - val_loss: 12.7556 - val_mae: 2.4233\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.7477 - mae: 0.6229 - val_loss: 13.1086 - val_mae: 2.4931\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7348 - mae: 0.6203 - val_loss: 12.9938 - val_mae: 2.4685\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6817 - mae: 0.5976 - val_loss: 13.1541 - val_mae: 2.4557\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.7025 - mae: 0.6031 - val_loss: 13.4609 - val_mae: 2.5458\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7212 - mae: 0.6402 - val_loss: 12.9956 - val_mae: 2.4880\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9123 - mae: 0.6707 - val_loss: 12.7902 - val_mae: 2.4238\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6637 - mae: 0.5482 - val_loss: 12.8232 - val_mae: 2.4549\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6497 - mae: 0.5951 - val_loss: 12.8303 - val_mae: 2.4990\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7318 - mae: 0.6122 - val_loss: 13.0836 - val_mae: 2.4969\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7127 - mae: 0.6144 - val_loss: 13.0364 - val_mae: 2.4674\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 0.7779 - mae: 0.6087 - val_loss: 12.8570 - val_mae: 2.4292\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6527 - mae: 0.5743 - val_loss: 13.1893 - val_mae: 2.4750\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6709 - mae: 0.5912 - val_loss: 13.2425 - val_mae: 2.5140\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.7048 - mae: 0.6159 - val_loss: 13.0394 - val_mae: 2.4893\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7853 - mae: 0.6159 - val_loss: 13.2656 - val_mae: 2.4972\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6526 - mae: 0.5848 - val_loss: 13.1747 - val_mae: 2.4720\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7207 - mae: 0.6100 - val_loss: 12.5447 - val_mae: 2.4193\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.6220 - mae: 0.5736 - val_loss: 13.0123 - val_mae: 2.4599\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6922 - mae: 0.6223 - val_loss: 13.0167 - val_mae: 2.4873\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6643 - mae: 0.5799 - val_loss: 12.7379 - val_mae: 2.4592\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7016 - mae: 0.6078 - val_loss: 12.8229 - val_mae: 2.5012\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6888 - mae: 0.5988 - val_loss: 12.8359 - val_mae: 2.4556\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6499 - mae: 0.5822 - val_loss: 13.4363 - val_mae: 2.5051\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7663 - mae: 0.6278 - val_loss: 12.9376 - val_mae: 2.4705\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6436 - mae: 0.5755 - val_loss: 12.5658 - val_mae: 2.4451\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.6889 - mae: 0.6017 - val_loss: 12.7764 - val_mae: 2.4800\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5771 - mae: 0.5833 - val_loss: 13.2677 - val_mae: 2.4789\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6186 - mae: 0.5589 - val_loss: 13.0194 - val_mae: 2.4726\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.7198 - mae: 0.6216 - val_loss: 12.9295 - val_mae: 2.4570\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5733 - mae: 0.5614 - val_loss: 13.6506 - val_mae: 2.5840\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6974 - mae: 0.5928 - val_loss: 13.3306 - val_mae: 2.4992\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6677 - mae: 0.5764 - val_loss: 13.0282 - val_mae: 2.4747\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6891 - mae: 0.5783 - val_loss: 12.6234 - val_mae: 2.4427\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6923 - mae: 0.5964 - val_loss: 12.9865 - val_mae: 2.5099\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6551 - mae: 0.5976 - val_loss: 13.5104 - val_mae: 2.5083\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.6902 - mae: 0.5847 - val_loss: 13.3589 - val_mae: 2.4824\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6254 - mae: 0.5769 - val_loss: 13.2195 - val_mae: 2.5162\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6216 - mae: 0.5685 - val_loss: 13.2571 - val_mae: 2.4739\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7012 - mae: 0.6233 - val_loss: 12.7448 - val_mae: 2.4686\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.6165 - mae: 0.5765 - val_loss: 12.7445 - val_mae: 2.4305\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6019 - mae: 0.5592 - val_loss: 13.0444 - val_mae: 2.5083\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6009 - mae: 0.5720 - val_loss: 13.0563 - val_mae: 2.5077\n",
            "Processing fold #3\n",
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 15ms/step - loss: 467.8082 - mae: 19.6144 - val_loss: 519.8265 - val_mae: 20.4806\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 335.6761 - mae: 16.0984 - val_loss: 355.4960 - val_mae: 16.4551\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 208.4002 - mae: 12.1768 - val_loss: 212.3995 - val_mae: 11.9847\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 104.6807 - mae: 8.2935 - val_loss: 106.6973 - val_mae: 7.8260\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 53.9511 - mae: 5.7605 - val_loss: 69.2496 - val_mae: 6.1723\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 36.9807 - mae: 4.4958 - val_loss: 48.4644 - val_mae: 5.0721\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 29.0056 - mae: 3.8729 - val_loss: 39.3300 - val_mae: 4.5274\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 24.8237 - mae: 3.5461 - val_loss: 33.7165 - val_mae: 4.1344\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 21.6371 - mae: 3.2763 - val_loss: 29.4475 - val_mae: 3.8510\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 19.5443 - mae: 3.0601 - val_loss: 28.7767 - val_mae: 3.6800\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 18.1730 - mae: 2.9639 - val_loss: 25.0528 - val_mae: 3.5458\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 17.0527 - mae: 2.8534 - val_loss: 23.2365 - val_mae: 3.4241\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 15.7459 - mae: 2.7384 - val_loss: 21.4468 - val_mae: 3.3004\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 14.8353 - mae: 2.6674 - val_loss: 20.5892 - val_mae: 3.2102\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 13.9266 - mae: 2.6075 - val_loss: 19.4350 - val_mae: 3.1110\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 13.4807 - mae: 2.4795 - val_loss: 18.8532 - val_mae: 3.0209\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 12.6599 - mae: 2.4593 - val_loss: 17.6339 - val_mae: 2.9303\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 11.9134 - mae: 2.3970 - val_loss: 18.2144 - val_mae: 2.9673\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 11.8605 - mae: 2.3887 - val_loss: 16.3254 - val_mae: 2.8873\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 11.2354 - mae: 2.3315 - val_loss: 16.0118 - val_mae: 2.9211\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 10.8640 - mae: 2.3357 - val_loss: 16.0855 - val_mae: 2.8927\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 10.7050 - mae: 2.2571 - val_loss: 15.0539 - val_mae: 2.7753\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.2402 - mae: 2.2263 - val_loss: 14.2321 - val_mae: 2.7349\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 10.0903 - mae: 2.2318 - val_loss: 14.3652 - val_mae: 2.7881\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 9.9970 - mae: 2.1938 - val_loss: 14.1294 - val_mae: 2.7498\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.8045 - mae: 2.1910 - val_loss: 13.8995 - val_mae: 2.7205\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.5610 - mae: 2.1370 - val_loss: 13.7034 - val_mae: 2.6798\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 9.2797 - mae: 2.1167 - val_loss: 13.6160 - val_mae: 2.6515\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 9.2599 - mae: 2.1200 - val_loss: 12.8943 - val_mae: 2.5731\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.9672 - mae: 2.0694 - val_loss: 13.2754 - val_mae: 2.6781\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.9932 - mae: 2.0973 - val_loss: 12.6622 - val_mae: 2.5787\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.6263 - mae: 2.0560 - val_loss: 12.4053 - val_mae: 2.5477\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.8313 - mae: 2.0363 - val_loss: 12.4053 - val_mae: 2.5370\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.6164 - mae: 2.0115 - val_loss: 12.3541 - val_mae: 2.5395\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.5372 - mae: 1.9870 - val_loss: 12.5107 - val_mae: 2.5791\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.3922 - mae: 2.0276 - val_loss: 12.2685 - val_mae: 2.5536\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 8.3812 - mae: 2.0018 - val_loss: 12.3695 - val_mae: 2.5656\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.0438 - mae: 1.9692 - val_loss: 12.4775 - val_mae: 2.5831\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.8995 - mae: 1.9306 - val_loss: 12.0765 - val_mae: 2.5229\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 8.1039 - mae: 1.9626 - val_loss: 12.0739 - val_mae: 2.5374\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.9109 - mae: 1.9203 - val_loss: 11.9501 - val_mae: 2.5243\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 7.8711 - mae: 1.9180 - val_loss: 11.6483 - val_mae: 2.4577\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.6895 - mae: 1.9171 - val_loss: 11.8744 - val_mae: 2.5133\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.7941 - mae: 1.9186 - val_loss: 11.8246 - val_mae: 2.5198\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.6294 - mae: 1.9058 - val_loss: 11.6146 - val_mae: 2.4533\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.5509 - mae: 1.8728 - val_loss: 11.5276 - val_mae: 2.4362\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.3530 - mae: 1.8581 - val_loss: 12.0804 - val_mae: 2.5304\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.2331 - mae: 1.8254 - val_loss: 11.3633 - val_mae: 2.4310\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.1448 - mae: 1.8267 - val_loss: 11.4052 - val_mae: 2.4657\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 7.1536 - mae: 1.8269 - val_loss: 11.3385 - val_mae: 2.4082\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 7.1413 - mae: 1.8318 - val_loss: 11.9698 - val_mae: 2.5365\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 7.1906 - mae: 1.8449 - val_loss: 11.5083 - val_mae: 2.4328\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9331 - mae: 1.7858 - val_loss: 11.7390 - val_mae: 2.5124\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9954 - mae: 1.8056 - val_loss: 11.4327 - val_mae: 2.4470\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.8077 - mae: 1.8095 - val_loss: 11.5351 - val_mae: 2.4466\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.9519 - mae: 1.8019 - val_loss: 11.3670 - val_mae: 2.4291\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.4904 - mae: 1.7717 - val_loss: 11.3712 - val_mae: 2.4186\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.9012 - mae: 1.8139 - val_loss: 11.5799 - val_mae: 2.4530\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.6135 - mae: 1.7609 - val_loss: 12.1203 - val_mae: 2.5368\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6825 - mae: 1.7423 - val_loss: 11.1207 - val_mae: 2.3944\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.5005 - mae: 1.7672 - val_loss: 11.3486 - val_mae: 2.4622\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.4654 - mae: 1.7651 - val_loss: 11.4817 - val_mae: 2.4982\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.6522 - mae: 1.7121 - val_loss: 11.3520 - val_mae: 2.4327\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.2720 - mae: 1.7339 - val_loss: 11.4680 - val_mae: 2.5179\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.3710 - mae: 1.7011 - val_loss: 11.6910 - val_mae: 2.4849\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3584 - mae: 1.7083 - val_loss: 11.3112 - val_mae: 2.4313\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.1479 - mae: 1.6958 - val_loss: 11.0319 - val_mae: 2.3653\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.3298 - mae: 1.7016 - val_loss: 11.1921 - val_mae: 2.4359\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.0545 - mae: 1.6902 - val_loss: 10.6900 - val_mae: 2.3596\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 1s 43ms/step - loss: 6.0688 - mae: 1.6602 - val_loss: 10.7681 - val_mae: 2.3811\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 6.0359 - mae: 1.6730 - val_loss: 10.7274 - val_mae: 2.3806\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9172 - mae: 1.6410 - val_loss: 11.0417 - val_mae: 2.4028\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.0423 - mae: 1.6753 - val_loss: 10.9031 - val_mae: 2.3741\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 6.0618 - mae: 1.6550 - val_loss: 10.8429 - val_mae: 2.3593\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7849 - mae: 1.6575 - val_loss: 10.6199 - val_mae: 2.3296\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.9815 - mae: 1.6585 - val_loss: 11.0134 - val_mae: 2.4047\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 5.8285 - mae: 1.6609 - val_loss: 10.7055 - val_mae: 2.3551\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7272 - mae: 1.6380 - val_loss: 10.7040 - val_mae: 2.3695\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7932 - mae: 1.6628 - val_loss: 10.4375 - val_mae: 2.3531\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.7389 - mae: 1.6242 - val_loss: 11.4553 - val_mae: 2.4452\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 5.5749 - mae: 1.6350 - val_loss: 10.6519 - val_mae: 2.3864\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.6501 - mae: 1.6495 - val_loss: 10.8102 - val_mae: 2.3501\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.6912 - mae: 1.6158 - val_loss: 10.6371 - val_mae: 2.3358\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4627 - mae: 1.5999 - val_loss: 10.6526 - val_mae: 2.3518\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5557 - mae: 1.5968 - val_loss: 11.1001 - val_mae: 2.3766\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.4361 - mae: 1.5981 - val_loss: 10.6654 - val_mae: 2.3344\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.5055 - mae: 1.6116 - val_loss: 10.9141 - val_mae: 2.3970\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.4664 - mae: 1.6016 - val_loss: 10.8462 - val_mae: 2.3519\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3068 - mae: 1.5633 - val_loss: 10.6986 - val_mae: 2.3846\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.4465 - mae: 1.6193 - val_loss: 10.7796 - val_mae: 2.3736\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3476 - mae: 1.5693 - val_loss: 10.4921 - val_mae: 2.3626\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.3598 - mae: 1.5732 - val_loss: 10.8613 - val_mae: 2.3869\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1872 - mae: 1.5666 - val_loss: 10.8776 - val_mae: 2.3952\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1557 - mae: 1.5595 - val_loss: 10.7122 - val_mae: 2.3274\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.2046 - mae: 1.5739 - val_loss: 10.8852 - val_mae: 2.4478\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.1114 - mae: 1.5655 - val_loss: 11.0731 - val_mae: 2.4509\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 5.0418 - mae: 1.5592 - val_loss: 11.2595 - val_mae: 2.4723\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 5.1127 - mae: 1.5528 - val_loss: 10.7161 - val_mae: 2.3423\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 5.1088 - mae: 1.5403 - val_loss: 10.8018 - val_mae: 2.4052\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 5.0303 - mae: 1.5120 - val_loss: 11.0053 - val_mae: 2.4609\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.9736 - mae: 1.5098 - val_loss: 10.5779 - val_mae: 2.3270\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.8394 - mae: 1.4698 - val_loss: 10.9383 - val_mae: 2.4486\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6719 - mae: 1.4625 - val_loss: 11.4935 - val_mae: 2.4707\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.9880 - mae: 1.5150 - val_loss: 10.3780 - val_mae: 2.3171\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.7664 - mae: 1.4714 - val_loss: 10.7113 - val_mae: 2.4092\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.8593 - mae: 1.5139 - val_loss: 10.6001 - val_mae: 2.3305\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.9881 - mae: 1.5206 - val_loss: 10.6488 - val_mae: 2.3375\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.7242 - mae: 1.4858 - val_loss: 10.8850 - val_mae: 2.3361\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7577 - mae: 1.4891 - val_loss: 10.7713 - val_mae: 2.3917\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.7054 - mae: 1.4963 - val_loss: 10.9428 - val_mae: 2.3809\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.7299 - mae: 1.4726 - val_loss: 10.6215 - val_mae: 2.3752\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6158 - mae: 1.4478 - val_loss: 10.6085 - val_mae: 2.3155\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6637 - mae: 1.4750 - val_loss: 10.6228 - val_mae: 2.3811\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.6328 - mae: 1.4791 - val_loss: 10.5337 - val_mae: 2.3707\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.5784 - mae: 1.4768 - val_loss: 11.0721 - val_mae: 2.4023\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.6731 - mae: 1.4541 - val_loss: 10.7343 - val_mae: 2.3628\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4645 - mae: 1.4103 - val_loss: 10.8284 - val_mae: 2.4136\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4851 - mae: 1.4505 - val_loss: 11.3062 - val_mae: 2.3812\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3709 - mae: 1.4220 - val_loss: 10.8073 - val_mae: 2.3845\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.4499 - mae: 1.4609 - val_loss: 10.4846 - val_mae: 2.2952\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4169 - mae: 1.4213 - val_loss: 10.9420 - val_mae: 2.3573\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.5631 - mae: 1.4571 - val_loss: 10.3085 - val_mae: 2.3050\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.3006 - mae: 1.3819 - val_loss: 10.4235 - val_mae: 2.3298\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.2613 - mae: 1.4236 - val_loss: 11.0363 - val_mae: 2.3430\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.3323 - mae: 1.4388 - val_loss: 10.7771 - val_mae: 2.4087\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.4133 - mae: 1.4242 - val_loss: 10.6211 - val_mae: 2.3693\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0676 - mae: 1.3697 - val_loss: 10.6497 - val_mae: 2.3547\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 4.3308 - mae: 1.4164 - val_loss: 10.6694 - val_mae: 2.3955\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 4.3908 - mae: 1.4546 - val_loss: 10.4521 - val_mae: 2.3360\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.2905 - mae: 1.4147 - val_loss: 10.9384 - val_mae: 2.3558\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1204 - mae: 1.3986 - val_loss: 10.9831 - val_mae: 2.3831\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 4.1574 - mae: 1.3762 - val_loss: 10.5351 - val_mae: 2.3293\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1227 - mae: 1.4014 - val_loss: 10.4371 - val_mae: 2.3149\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.0447 - mae: 1.3855 - val_loss: 10.9309 - val_mae: 2.4037\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1215 - mae: 1.3898 - val_loss: 11.5263 - val_mae: 2.4674\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 4.1831 - mae: 1.3961 - val_loss: 10.7166 - val_mae: 2.3686\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0266 - mae: 1.3658 - val_loss: 11.0090 - val_mae: 2.4156\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0266 - mae: 1.3597 - val_loss: 10.8834 - val_mae: 2.3080\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.1301 - mae: 1.3979 - val_loss: 10.9627 - val_mae: 2.3751\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0965 - mae: 1.3642 - val_loss: 10.6862 - val_mae: 2.3335\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 4.0346 - mae: 1.3769 - val_loss: 10.6000 - val_mae: 2.3562\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9394 - mae: 1.3673 - val_loss: 10.5762 - val_mae: 2.3424\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8939 - mae: 1.3197 - val_loss: 10.8094 - val_mae: 2.3237\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.9656 - mae: 1.3557 - val_loss: 10.6800 - val_mae: 2.3809\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.8657 - mae: 1.3451 - val_loss: 10.4927 - val_mae: 2.3317\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9567 - mae: 1.3950 - val_loss: 10.7904 - val_mae: 2.3439\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 3.9961 - mae: 1.3797 - val_loss: 10.5185 - val_mae: 2.3245\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 3.8166 - mae: 1.3571 - val_loss: 11.0618 - val_mae: 2.3916\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.9153 - mae: 1.3137 - val_loss: 10.4052 - val_mae: 2.3251\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8306 - mae: 1.3483 - val_loss: 10.5144 - val_mae: 2.3348\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7498 - mae: 1.3209 - val_loss: 10.7050 - val_mae: 2.3668\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 3.6778 - mae: 1.2817 - val_loss: 11.2736 - val_mae: 2.4148\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8777 - mae: 1.3476 - val_loss: 10.5348 - val_mae: 2.3356\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.6826 - mae: 1.3253 - val_loss: 10.3700 - val_mae: 2.3055\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.6669 - mae: 1.2929 - val_loss: 10.5248 - val_mae: 2.3712\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.8018 - mae: 1.3462 - val_loss: 10.9523 - val_mae: 2.4036\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6252 - mae: 1.3218 - val_loss: 10.5975 - val_mae: 2.3159\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6560 - mae: 1.3168 - val_loss: 10.5161 - val_mae: 2.3143\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.7146 - mae: 1.3078 - val_loss: 10.4808 - val_mae: 2.3314\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6373 - mae: 1.3073 - val_loss: 10.4127 - val_mae: 2.3152\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.6066 - mae: 1.2912 - val_loss: 10.5120 - val_mae: 2.3708\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5807 - mae: 1.2999 - val_loss: 10.3438 - val_mae: 2.3126\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5622 - mae: 1.3117 - val_loss: 10.5592 - val_mae: 2.3331\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.5762 - mae: 1.3016 - val_loss: 10.3950 - val_mae: 2.2963\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.4926 - mae: 1.2932 - val_loss: 10.2714 - val_mae: 2.2863\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.5066 - mae: 1.2976 - val_loss: 10.5973 - val_mae: 2.3373\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 3.5341 - mae: 1.2984 - val_loss: 10.3621 - val_mae: 2.3064\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 3.3401 - mae: 1.2652 - val_loss: 10.2921 - val_mae: 2.2969\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 3.3868 - mae: 1.2591 - val_loss: 10.3591 - val_mae: 2.3099\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 3.4338 - mae: 1.2752 - val_loss: 10.1026 - val_mae: 2.2804\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 3.4811 - mae: 1.3015 - val_loss: 10.7789 - val_mae: 2.3217\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 3.3614 - mae: 1.2499 - val_loss: 10.2438 - val_mae: 2.2922\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2133 - mae: 1.2582 - val_loss: 10.5026 - val_mae: 2.3109\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4320 - mae: 1.2713 - val_loss: 10.2694 - val_mae: 2.2795\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2234 - mae: 1.2492 - val_loss: 10.3342 - val_mae: 2.2828\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.4797 - mae: 1.2889 - val_loss: 10.6076 - val_mae: 2.3412\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 3.2969 - mae: 1.2746 - val_loss: 10.5888 - val_mae: 2.3305\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.2912 - mae: 1.2361 - val_loss: 10.2710 - val_mae: 2.3064\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1323 - mae: 1.2385 - val_loss: 11.4956 - val_mae: 2.4940\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.3365 - mae: 1.2273 - val_loss: 10.4541 - val_mae: 2.3030\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3916 - mae: 1.2707 - val_loss: 10.4269 - val_mae: 2.3276\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2144 - mae: 1.2344 - val_loss: 10.6727 - val_mae: 2.3652\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.3091 - mae: 1.2560 - val_loss: 10.8996 - val_mae: 2.4270\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2754 - mae: 1.2331 - val_loss: 10.3529 - val_mae: 2.2751\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1069 - mae: 1.2198 - val_loss: 10.6738 - val_mae: 2.3145\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.2239 - mae: 1.2259 - val_loss: 10.5944 - val_mae: 2.3545\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0997 - mae: 1.2436 - val_loss: 10.1089 - val_mae: 2.2834\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1678 - mae: 1.2450 - val_loss: 10.2445 - val_mae: 2.3060\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.0507 - mae: 1.2117 - val_loss: 10.3044 - val_mae: 2.3019\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1364 - mae: 1.2235 - val_loss: 10.2097 - val_mae: 2.2738\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.1199 - mae: 1.2224 - val_loss: 10.7740 - val_mae: 2.3980\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 3.1457 - mae: 1.2233 - val_loss: 10.0969 - val_mae: 2.2545\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0269 - mae: 1.1980 - val_loss: 10.1792 - val_mae: 2.3091\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0823 - mae: 1.2150 - val_loss: 10.4334 - val_mae: 2.3305\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1019 - mae: 1.1928 - val_loss: 10.3767 - val_mae: 2.3258\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 3.1868 - mae: 1.2523 - val_loss: 10.0721 - val_mae: 2.2814\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.1164 - mae: 1.2309 - val_loss: 10.0665 - val_mae: 2.2761\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 3.0115 - mae: 1.1953 - val_loss: 10.1618 - val_mae: 2.2867\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9036 - mae: 1.1923 - val_loss: 10.1811 - val_mae: 2.2595\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.9273 - mae: 1.1873 - val_loss: 10.2790 - val_mae: 2.3303\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.9687 - mae: 1.1788 - val_loss: 10.5663 - val_mae: 2.2900\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8376 - mae: 1.1706 - val_loss: 10.4311 - val_mae: 2.3107\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 3.0204 - mae: 1.1852 - val_loss: 10.9865 - val_mae: 2.4173\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8497 - mae: 1.1655 - val_loss: 10.0741 - val_mae: 2.2476\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8952 - mae: 1.1710 - val_loss: 10.0624 - val_mae: 2.2521\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8514 - mae: 1.1750 - val_loss: 10.1781 - val_mae: 2.2873\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8333 - mae: 1.1722 - val_loss: 10.4039 - val_mae: 2.3248\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8765 - mae: 1.1686 - val_loss: 10.1747 - val_mae: 2.2920\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.8768 - mae: 1.1404 - val_loss: 10.4157 - val_mae: 2.3353\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8002 - mae: 1.1675 - val_loss: 10.2785 - val_mae: 2.2722\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7580 - mae: 1.1414 - val_loss: 10.4257 - val_mae: 2.2646\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8251 - mae: 1.1785 - val_loss: 10.0877 - val_mae: 2.2702\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7839 - mae: 1.1677 - val_loss: 10.6152 - val_mae: 2.3364\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8163 - mae: 1.1598 - val_loss: 10.3486 - val_mae: 2.2974\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7432 - mae: 1.1624 - val_loss: 10.4701 - val_mae: 2.3236\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 2.7694 - mae: 1.1311 - val_loss: 10.5006 - val_mae: 2.3239\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7833 - mae: 1.1442 - val_loss: 10.1055 - val_mae: 2.2743\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6154 - mae: 1.1230 - val_loss: 11.0364 - val_mae: 2.4197\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6322 - mae: 1.1623 - val_loss: 10.2837 - val_mae: 2.3216\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.8447 - mae: 1.1988 - val_loss: 10.4096 - val_mae: 2.3478\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 2.7009 - mae: 1.1443 - val_loss: 10.3038 - val_mae: 2.2907\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5095 - mae: 1.0755 - val_loss: 10.9392 - val_mae: 2.4131\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7474 - mae: 1.1959 - val_loss: 9.9216 - val_mae: 2.2603\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6307 - mae: 1.1272 - val_loss: 10.6947 - val_mae: 2.3651\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 2.6652 - mae: 1.1326 - val_loss: 10.6834 - val_mae: 2.3889\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7533 - mae: 1.1365 - val_loss: 10.1866 - val_mae: 2.2866\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5821 - mae: 1.1239 - val_loss: 10.1686 - val_mae: 2.2827\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6327 - mae: 1.1410 - val_loss: 10.3251 - val_mae: 2.3287\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5430 - mae: 1.1215 - val_loss: 10.7006 - val_mae: 2.3777\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4848 - mae: 1.1552 - val_loss: 9.9452 - val_mae: 2.2880\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.6762 - mae: 1.1768 - val_loss: 10.5465 - val_mae: 2.3238\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4901 - mae: 1.1015 - val_loss: 10.7370 - val_mae: 2.3561\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5554 - mae: 1.1318 - val_loss: 10.0851 - val_mae: 2.2677\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.7084 - mae: 1.1329 - val_loss: 10.1760 - val_mae: 2.2968\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4520 - mae: 1.0960 - val_loss: 10.1772 - val_mae: 2.2747\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 2.4222 - mae: 1.1133 - val_loss: 10.9969 - val_mae: 2.4039\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.6213 - mae: 1.1431 - val_loss: 10.0139 - val_mae: 2.2843\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4610 - mae: 1.0733 - val_loss: 9.8725 - val_mae: 2.2347\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4965 - mae: 1.1047 - val_loss: 11.0344 - val_mae: 2.4026\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 2.2946 - mae: 1.0632 - val_loss: 10.8298 - val_mae: 2.3356\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5477 - mae: 1.1261 - val_loss: 10.5613 - val_mae: 2.3494\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4408 - mae: 1.1098 - val_loss: 10.1159 - val_mae: 2.2851\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3471 - mae: 1.0782 - val_loss: 10.8879 - val_mae: 2.4084\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.5115 - mae: 1.1115 - val_loss: 10.2898 - val_mae: 2.2999\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4869 - mae: 1.0898 - val_loss: 10.3235 - val_mae: 2.3012\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4433 - mae: 1.0852 - val_loss: 10.5366 - val_mae: 2.3321\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.4283 - mae: 1.0948 - val_loss: 9.8130 - val_mae: 2.2361\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.4415 - mae: 1.1133 - val_loss: 10.3210 - val_mae: 2.3348\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 2.3652 - mae: 1.0805 - val_loss: 10.2797 - val_mae: 2.3032\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2415 - mae: 1.0587 - val_loss: 10.9095 - val_mae: 2.4175\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.5533 - mae: 1.1171 - val_loss: 10.2100 - val_mae: 2.3203\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3004 - mae: 1.0546 - val_loss: 9.9159 - val_mae: 2.2539\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2778 - mae: 1.0453 - val_loss: 10.4050 - val_mae: 2.3947\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.3487 - mae: 1.1215 - val_loss: 10.2454 - val_mae: 2.3239\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.2618 - mae: 1.0218 - val_loss: 11.5338 - val_mae: 2.5477\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.3795 - mae: 1.0788 - val_loss: 9.9305 - val_mae: 2.2827\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 2.2477 - mae: 1.0645 - val_loss: 10.3496 - val_mae: 2.3465\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.2633 - mae: 1.0550 - val_loss: 10.0434 - val_mae: 2.2979\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.3137 - mae: 1.0889 - val_loss: 10.1342 - val_mae: 2.2663\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 2.4241 - mae: 1.0751 - val_loss: 10.2076 - val_mae: 2.2883\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 2.2693 - mae: 1.0474 - val_loss: 9.7174 - val_mae: 2.2428\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 2.1875 - mae: 1.0415 - val_loss: 10.1416 - val_mae: 2.3415\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 2.1634 - mae: 1.0294 - val_loss: 10.6945 - val_mae: 2.3611\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 2.2877 - mae: 1.0523 - val_loss: 10.2043 - val_mae: 2.2896\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 2.3504 - mae: 1.0640 - val_loss: 10.2616 - val_mae: 2.3273\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 2.2457 - mae: 1.0615 - val_loss: 10.0923 - val_mae: 2.2920\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1966 - mae: 1.0456 - val_loss: 10.2753 - val_mae: 2.3333\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1386 - mae: 1.0475 - val_loss: 10.0815 - val_mae: 2.3042\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1183 - mae: 1.0198 - val_loss: 10.5013 - val_mae: 2.3673\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2589 - mae: 1.0149 - val_loss: 10.0843 - val_mae: 2.2933\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1572 - mae: 1.0452 - val_loss: 10.1653 - val_mae: 2.2920\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2271 - mae: 1.0410 - val_loss: 10.1303 - val_mae: 2.2787\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1137 - mae: 0.9948 - val_loss: 9.8881 - val_mae: 2.2588\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1015 - mae: 1.0270 - val_loss: 10.3199 - val_mae: 2.2815\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1671 - mae: 1.0034 - val_loss: 9.8233 - val_mae: 2.2658\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0903 - mae: 1.0104 - val_loss: 9.8853 - val_mae: 2.2591\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1643 - mae: 1.0287 - val_loss: 10.4351 - val_mae: 2.3619\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1050 - mae: 1.0133 - val_loss: 10.0560 - val_mae: 2.2817\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 2.1600 - mae: 1.0274 - val_loss: 10.1133 - val_mae: 2.3404\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.1902 - mae: 1.0479 - val_loss: 10.0014 - val_mae: 2.2699\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9442 - mae: 0.9765 - val_loss: 10.3938 - val_mae: 2.3526\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0475 - mae: 0.9946 - val_loss: 10.3433 - val_mae: 2.3561\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.2214 - mae: 1.0788 - val_loss: 11.3310 - val_mae: 2.5070\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 1s 5ms/step - loss: 2.0446 - mae: 1.0102 - val_loss: 10.8263 - val_mae: 2.4090\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9485 - mae: 1.0038 - val_loss: 10.0089 - val_mae: 2.2883\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0032 - mae: 0.9879 - val_loss: 10.3853 - val_mae: 2.3724\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1740 - mae: 1.0250 - val_loss: 10.1513 - val_mae: 2.3081\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8662 - mae: 0.9978 - val_loss: 10.3677 - val_mae: 2.3555\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0098 - mae: 0.9663 - val_loss: 10.4154 - val_mae: 2.3457\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0011 - mae: 0.9955 - val_loss: 10.2063 - val_mae: 2.3138\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9182 - mae: 1.0111 - val_loss: 10.0421 - val_mae: 2.2895\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9550 - mae: 0.9814 - val_loss: 10.0683 - val_mae: 2.2963\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9702 - mae: 0.9671 - val_loss: 10.4300 - val_mae: 2.3115\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9713 - mae: 0.9631 - val_loss: 11.2822 - val_mae: 2.5101\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.1658 - mae: 0.9869 - val_loss: 9.9470 - val_mae: 2.3104\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8542 - mae: 0.9603 - val_loss: 9.8461 - val_mae: 2.2931\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8610 - mae: 0.9591 - val_loss: 10.3212 - val_mae: 2.2940\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8343 - mae: 0.9407 - val_loss: 10.2894 - val_mae: 2.3259\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9470 - mae: 0.9512 - val_loss: 10.0031 - val_mae: 2.2950\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 2.0570 - mae: 0.9688 - val_loss: 9.9238 - val_mae: 2.2892\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7800 - mae: 0.9094 - val_loss: 10.5000 - val_mae: 2.3887\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9989 - mae: 0.9875 - val_loss: 10.5258 - val_mae: 2.3649\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0201 - mae: 0.9999 - val_loss: 9.8699 - val_mae: 2.2541\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9148 - mae: 0.9408 - val_loss: 10.4512 - val_mae: 2.3566\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7418 - mae: 0.9286 - val_loss: 10.3000 - val_mae: 2.3387\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.7571 - mae: 0.9555 - val_loss: 10.0801 - val_mae: 2.3136\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.8065 - mae: 0.9748 - val_loss: 10.2772 - val_mae: 2.3327\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.9316 - mae: 1.0163 - val_loss: 10.0446 - val_mae: 2.3253\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7080 - mae: 0.8994 - val_loss: 10.5403 - val_mae: 2.4072\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8220 - mae: 0.9469 - val_loss: 10.1305 - val_mae: 2.2924\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.9127 - mae: 0.9766 - val_loss: 10.1792 - val_mae: 2.3261\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.6964 - mae: 0.9183 - val_loss: 10.2009 - val_mae: 2.3010\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7809 - mae: 0.9436 - val_loss: 10.3111 - val_mae: 2.3719\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9363 - mae: 0.9972 - val_loss: 10.0693 - val_mae: 2.3074\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6655 - mae: 0.9124 - val_loss: 11.0328 - val_mae: 2.4463\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9473 - mae: 0.9976 - val_loss: 9.9484 - val_mae: 2.2939\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.5923 - mae: 0.9041 - val_loss: 10.8016 - val_mae: 2.4252\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7586 - mae: 0.9539 - val_loss: 10.0210 - val_mae: 2.2911\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.9190 - mae: 0.9633 - val_loss: 10.1969 - val_mae: 2.3309\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7794 - mae: 0.9368 - val_loss: 10.0368 - val_mae: 2.3363\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7219 - mae: 0.9446 - val_loss: 10.1184 - val_mae: 2.3109\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 1.6966 - mae: 0.9461 - val_loss: 10.0356 - val_mae: 2.3082\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6730 - mae: 0.9107 - val_loss: 9.9515 - val_mae: 2.2740\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7848 - mae: 0.9484 - val_loss: 10.0581 - val_mae: 2.3392\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7632 - mae: 0.9350 - val_loss: 10.5741 - val_mae: 2.3456\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.6810 - mae: 0.9030 - val_loss: 11.1132 - val_mae: 2.4656\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7072 - mae: 0.9434 - val_loss: 10.4342 - val_mae: 2.3239\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7389 - mae: 0.9205 - val_loss: 10.6490 - val_mae: 2.4038\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6889 - mae: 0.9355 - val_loss: 9.8642 - val_mae: 2.3071\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.8153 - mae: 0.9192 - val_loss: 10.1117 - val_mae: 2.3296\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5795 - mae: 0.8920 - val_loss: 10.7931 - val_mae: 2.4315\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5745 - mae: 0.8924 - val_loss: 10.8367 - val_mae: 2.4336\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7789 - mae: 0.9512 - val_loss: 10.3584 - val_mae: 2.3442\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.7094 - mae: 0.9008 - val_loss: 10.1483 - val_mae: 2.3623\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4889 - mae: 0.8426 - val_loss: 10.1905 - val_mae: 2.3609\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7333 - mae: 0.9323 - val_loss: 9.8434 - val_mae: 2.2936\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6317 - mae: 0.9062 - val_loss: 10.5516 - val_mae: 2.3958\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5819 - mae: 0.8885 - val_loss: 10.4332 - val_mae: 2.4070\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6053 - mae: 0.9110 - val_loss: 10.0649 - val_mae: 2.3166\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5654 - mae: 0.8664 - val_loss: 10.4642 - val_mae: 2.3995\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.6373 - mae: 0.8945 - val_loss: 10.4399 - val_mae: 2.4052\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5435 - mae: 0.8772 - val_loss: 9.8266 - val_mae: 2.2939\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5015 - mae: 0.8658 - val_loss: 9.9415 - val_mae: 2.2787\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.4742 - mae: 0.8695 - val_loss: 10.4079 - val_mae: 2.3182\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4696 - mae: 0.8589 - val_loss: 10.0794 - val_mae: 2.3807\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.7332 - mae: 0.9343 - val_loss: 10.4621 - val_mae: 2.3735\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4306 - mae: 0.8576 - val_loss: 10.2616 - val_mae: 2.3792\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6228 - mae: 0.8809 - val_loss: 9.9656 - val_mae: 2.3067\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5015 - mae: 0.8476 - val_loss: 10.4361 - val_mae: 2.3941\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.6455 - mae: 0.8989 - val_loss: 10.2979 - val_mae: 2.3518\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5680 - mae: 0.8576 - val_loss: 10.2540 - val_mae: 2.3243\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4569 - mae: 0.8410 - val_loss: 10.2671 - val_mae: 2.3308\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5280 - mae: 0.8863 - val_loss: 10.1834 - val_mae: 2.3647\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1.6116 - mae: 0.8896 - val_loss: 10.4103 - val_mae: 2.3630\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5000 - mae: 0.8599 - val_loss: 11.0145 - val_mae: 2.4590\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4823 - mae: 0.8517 - val_loss: 10.3513 - val_mae: 2.3362\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5437 - mae: 0.8789 - val_loss: 10.2989 - val_mae: 2.3246\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4217 - mae: 0.8008 - val_loss: 10.2831 - val_mae: 2.3588\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.5184 - mae: 0.8679 - val_loss: 10.9578 - val_mae: 2.4688\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.4671 - mae: 0.8746 - val_loss: 10.9547 - val_mae: 2.4342\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4907 - mae: 0.8503 - val_loss: 10.7122 - val_mae: 2.4521\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.2538 - mae: 0.8208 - val_loss: 10.1687 - val_mae: 2.3496\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4311 - mae: 0.8396 - val_loss: 10.8178 - val_mae: 2.4133\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4436 - mae: 0.8527 - val_loss: 10.5225 - val_mae: 2.4069\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4120 - mae: 0.8529 - val_loss: 11.4898 - val_mae: 2.5145\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4153 - mae: 0.8320 - val_loss: 10.2449 - val_mae: 2.3061\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5174 - mae: 0.8696 - val_loss: 10.5892 - val_mae: 2.4268\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4498 - mae: 0.8412 - val_loss: 10.6855 - val_mae: 2.4298\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4323 - mae: 0.8614 - val_loss: 10.1393 - val_mae: 2.3256\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4010 - mae: 0.8243 - val_loss: 10.0996 - val_mae: 2.3341\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4999 - mae: 0.8421 - val_loss: 10.3610 - val_mae: 2.3570\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3059 - mae: 0.8049 - val_loss: 10.4842 - val_mae: 2.3509\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 1.4199 - mae: 0.8438 - val_loss: 9.7796 - val_mae: 2.3004\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5390 - mae: 0.8522 - val_loss: 10.4569 - val_mae: 2.3431\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4357 - mae: 0.8165 - val_loss: 10.2210 - val_mae: 2.3502\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2698 - mae: 0.7965 - val_loss: 11.0967 - val_mae: 2.4840\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4351 - mae: 0.8198 - val_loss: 10.2410 - val_mae: 2.3372\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.3061 - mae: 0.8097 - val_loss: 11.2838 - val_mae: 2.4896\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3965 - mae: 0.8400 - val_loss: 10.1274 - val_mae: 2.3568\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4768 - mae: 0.8497 - val_loss: 10.6330 - val_mae: 2.3868\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3386 - mae: 0.8331 - val_loss: 10.4411 - val_mae: 2.3993\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.4214 - mae: 0.8542 - val_loss: 10.3982 - val_mae: 2.3760\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1861 - mae: 0.7689 - val_loss: 10.6887 - val_mae: 2.3663\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3287 - mae: 0.8152 - val_loss: 10.3607 - val_mae: 2.3567\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3832 - mae: 0.8431 - val_loss: 10.5359 - val_mae: 2.4367\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2724 - mae: 0.7919 - val_loss: 10.9432 - val_mae: 2.4427\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3906 - mae: 0.8369 - val_loss: 10.4774 - val_mae: 2.3743\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2402 - mae: 0.7947 - val_loss: 10.0979 - val_mae: 2.3683\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3184 - mae: 0.8192 - val_loss: 10.8184 - val_mae: 2.4062\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2257 - mae: 0.8103 - val_loss: 12.3021 - val_mae: 2.6299\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.3874 - mae: 0.8243 - val_loss: 11.8004 - val_mae: 2.5331\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3168 - mae: 0.8160 - val_loss: 11.1280 - val_mae: 2.4557\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3399 - mae: 0.7712 - val_loss: 10.4875 - val_mae: 2.3710\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3320 - mae: 0.8113 - val_loss: 10.6619 - val_mae: 2.3675\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3063 - mae: 0.8029 - val_loss: 10.3966 - val_mae: 2.3663\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3651 - mae: 0.8259 - val_loss: 10.9164 - val_mae: 2.4157\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4062 - mae: 0.7995 - val_loss: 10.7589 - val_mae: 2.4070\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1585 - mae: 0.7635 - val_loss: 10.9319 - val_mae: 2.4236\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.2430 - mae: 0.7845 - val_loss: 10.9057 - val_mae: 2.4534\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2302 - mae: 0.7677 - val_loss: 11.3942 - val_mae: 2.4938\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.3536 - mae: 0.8096 - val_loss: 10.7671 - val_mae: 2.3814\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1246 - mae: 0.7430 - val_loss: 11.3373 - val_mae: 2.5075\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1987 - mae: 0.7860 - val_loss: 11.2623 - val_mae: 2.5350\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.3099 - mae: 0.7741 - val_loss: 11.2184 - val_mae: 2.4311\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 1.2519 - mae: 0.7696 - val_loss: 10.7482 - val_mae: 2.3662\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1432 - mae: 0.7526 - val_loss: 11.4046 - val_mae: 2.5479\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.3316 - mae: 0.8125 - val_loss: 10.9795 - val_mae: 2.4095\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2536 - mae: 0.7938 - val_loss: 10.4520 - val_mae: 2.3631\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2825 - mae: 0.7745 - val_loss: 10.9447 - val_mae: 2.4505\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1890 - mae: 0.7689 - val_loss: 10.8471 - val_mae: 2.4171\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2214 - mae: 0.7661 - val_loss: 10.7022 - val_mae: 2.4617\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2046 - mae: 0.7858 - val_loss: 10.8015 - val_mae: 2.3840\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1448 - mae: 0.7639 - val_loss: 11.2262 - val_mae: 2.4481\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2645 - mae: 0.8050 - val_loss: 10.8703 - val_mae: 2.4264\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1266 - mae: 0.7403 - val_loss: 10.4599 - val_mae: 2.3733\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1890 - mae: 0.7492 - val_loss: 10.7440 - val_mae: 2.4038\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2471 - mae: 0.8059 - val_loss: 11.5569 - val_mae: 2.5356\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2587 - mae: 0.7823 - val_loss: 10.8171 - val_mae: 2.4306\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 1.2747 - mae: 0.7914 - val_loss: 10.7344 - val_mae: 2.4078\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2135 - mae: 0.7823 - val_loss: 11.1220 - val_mae: 2.5130\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2418 - mae: 0.7749 - val_loss: 10.5654 - val_mae: 2.3684\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1325 - mae: 0.7551 - val_loss: 11.3510 - val_mae: 2.5181\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1404 - mae: 0.7604 - val_loss: 10.9902 - val_mae: 2.3952\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2134 - mae: 0.7683 - val_loss: 10.2709 - val_mae: 2.3601\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1224 - mae: 0.7466 - val_loss: 10.7703 - val_mae: 2.4073\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2067 - mae: 0.7680 - val_loss: 11.4003 - val_mae: 2.4694\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1479 - mae: 0.7441 - val_loss: 11.0112 - val_mae: 2.4400\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2023 - mae: 0.7628 - val_loss: 10.7488 - val_mae: 2.3939\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1099 - mae: 0.7328 - val_loss: 11.1191 - val_mae: 2.4632\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.2166 - mae: 0.7653 - val_loss: 11.6990 - val_mae: 2.5004\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1863 - mae: 0.7534 - val_loss: 10.9164 - val_mae: 2.4126\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1763 - mae: 0.7764 - val_loss: 11.1897 - val_mae: 2.4496\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2506 - mae: 0.7851 - val_loss: 11.2274 - val_mae: 2.4858\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.0527 - mae: 0.7324 - val_loss: 11.0103 - val_mae: 2.4408\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1194 - mae: 0.7617 - val_loss: 10.8195 - val_mae: 2.4261\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0875 - mae: 0.7375 - val_loss: 10.6957 - val_mae: 2.4169\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1853 - mae: 0.7613 - val_loss: 11.1086 - val_mae: 2.4405\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 1.1770 - mae: 0.7471 - val_loss: 11.4141 - val_mae: 2.4643\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0465 - mae: 0.7060 - val_loss: 11.3002 - val_mae: 2.5251\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1498 - mae: 0.7681 - val_loss: 11.2222 - val_mae: 2.4739\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0742 - mae: 0.7353 - val_loss: 11.6427 - val_mae: 2.4857\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2451 - mae: 0.7947 - val_loss: 10.9242 - val_mae: 2.4216\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9891 - mae: 0.7135 - val_loss: 11.2035 - val_mae: 2.4380\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2017 - mae: 0.7429 - val_loss: 10.5397 - val_mae: 2.3461\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 1.0707 - mae: 0.7287 - val_loss: 10.8587 - val_mae: 2.4297\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.0635 - mae: 0.7293 - val_loss: 10.9799 - val_mae: 2.4557\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0430 - mae: 0.7215 - val_loss: 10.6836 - val_mae: 2.4168\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.2160 - mae: 0.7847 - val_loss: 11.1196 - val_mae: 2.4295\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0149 - mae: 0.7173 - val_loss: 10.9716 - val_mae: 2.4360\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0207 - mae: 0.7145 - val_loss: 10.7443 - val_mae: 2.3977\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0281 - mae: 0.7501 - val_loss: 12.2032 - val_mae: 2.5734\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 1.0756 - mae: 0.7159 - val_loss: 11.1433 - val_mae: 2.4428\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0531 - mae: 0.7413 - val_loss: 11.1488 - val_mae: 2.4342\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1800 - mae: 0.7453 - val_loss: 10.9870 - val_mae: 2.4406\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.2146 - mae: 0.7664 - val_loss: 11.5733 - val_mae: 2.4975\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0513 - mae: 0.7010 - val_loss: 10.5389 - val_mae: 2.3649\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1500 - mae: 0.7586 - val_loss: 11.2927 - val_mae: 2.4581\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.0595 - mae: 0.7197 - val_loss: 10.9020 - val_mae: 2.4225\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0754 - mae: 0.7206 - val_loss: 11.1597 - val_mae: 2.4609\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1131 - mae: 0.7208 - val_loss: 11.7471 - val_mae: 2.5394\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1814 - mae: 0.7645 - val_loss: 12.0219 - val_mae: 2.5529\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 1.1106 - mae: 0.7252 - val_loss: 11.3746 - val_mae: 2.4892\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0146 - mae: 0.7210 - val_loss: 11.0271 - val_mae: 2.4266\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1241 - mae: 0.7276 - val_loss: 11.0591 - val_mae: 2.4637\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1578 - mae: 0.7495 - val_loss: 10.7918 - val_mae: 2.3780\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0785 - mae: 0.7209 - val_loss: 11.3584 - val_mae: 2.4707\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9740 - mae: 0.6827 - val_loss: 11.3908 - val_mae: 2.5264\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.1722 - mae: 0.7715 - val_loss: 11.9611 - val_mae: 2.6162\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1019 - mae: 0.7187 - val_loss: 11.0924 - val_mae: 2.4692\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9770 - mae: 0.6883 - val_loss: 11.1698 - val_mae: 2.4433\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.2229 - mae: 0.7687 - val_loss: 11.2642 - val_mae: 2.4487\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8829 - mae: 0.6498 - val_loss: 11.6222 - val_mae: 2.5308\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0141 - mae: 0.7192 - val_loss: 12.0683 - val_mae: 2.5427\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0210 - mae: 0.6961 - val_loss: 11.0477 - val_mae: 2.4317\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0289 - mae: 0.7117 - val_loss: 11.6267 - val_mae: 2.5171\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.0742 - mae: 0.7094 - val_loss: 11.0252 - val_mae: 2.4165\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0359 - mae: 0.7270 - val_loss: 11.6284 - val_mae: 2.5201\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0958 - mae: 0.7409 - val_loss: 11.1096 - val_mae: 2.4415\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9751 - mae: 0.6825 - val_loss: 12.1753 - val_mae: 2.5768\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9709 - mae: 0.7193 - val_loss: 11.5804 - val_mae: 2.5005\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0368 - mae: 0.7284 - val_loss: 10.7701 - val_mae: 2.4040\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 1.0984 - mae: 0.7735 - val_loss: 10.9846 - val_mae: 2.4196\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9536 - mae: 0.6927 - val_loss: 10.9249 - val_mae: 2.4735\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0384 - mae: 0.6949 - val_loss: 11.3995 - val_mae: 2.4592\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0139 - mae: 0.7136 - val_loss: 11.3144 - val_mae: 2.4995\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 1.0124 - mae: 0.7090 - val_loss: 10.9837 - val_mae: 2.4188\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.9622 - mae: 0.6977 - val_loss: 11.3999 - val_mae: 2.5594\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0070 - mae: 0.6921 - val_loss: 11.0072 - val_mae: 2.4514\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8779 - mae: 0.6396 - val_loss: 12.0426 - val_mae: 2.5937\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.9804 - mae: 0.6955 - val_loss: 10.8745 - val_mae: 2.3946\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0866 - mae: 0.7143 - val_loss: 11.0270 - val_mae: 2.4328\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0529 - mae: 0.7389 - val_loss: 11.9676 - val_mae: 2.5667\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8869 - mae: 0.6689 - val_loss: 12.8532 - val_mae: 2.6619\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 1s 35ms/step - loss: 1.0158 - mae: 0.7045 - val_loss: 12.4641 - val_mae: 2.5952\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9226 - mae: 0.6849 - val_loss: 11.9210 - val_mae: 2.5920\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9402 - mae: 0.6970 - val_loss: 12.1434 - val_mae: 2.5818\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0048 - mae: 0.6894 - val_loss: 11.1588 - val_mae: 2.4694\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.9763 - mae: 0.6954 - val_loss: 11.8250 - val_mae: 2.5620\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 1.0558 - mae: 0.7150 - val_loss: 11.0909 - val_mae: 2.4679\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9040 - mae: 0.6682 - val_loss: 11.3674 - val_mae: 2.5098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxjP0zY6MP0h",
        "outputId": "eecdbd50-e2c5-49d6-f3f5-a5793eaf9f35"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "metadata": {
        "id": "D0Vzwvxw0_HO"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(average_mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vkSuFUDIJNn",
        "outputId": "23cc48df-f3fc-4da8-c68c-b7920f0fa156"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_mae_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FisnsYzSBFB5",
        "outputId": "b53a21dc-c3a0-4826-c23d-7b57224230ee"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19.218992710113525,\n",
              " 15.762917518615723,\n",
              " 11.607523918151855,\n",
              " 7.866421699523926,\n",
              " 5.928014159202576,\n",
              " 4.823432803153992,\n",
              " 4.136511027812958,\n",
              " 3.739518165588379,\n",
              " 3.45214581489563,\n",
              " 3.3261740803718567,\n",
              " 3.220507860183716,\n",
              " 3.1050212383270264,\n",
              " 2.988781988620758,\n",
              " 2.9252533316612244,\n",
              " 2.883749842643738,\n",
              " 2.8871389031410217,\n",
              " 2.774163603782654,\n",
              " 2.7632877826690674,\n",
              " 2.6943807005882263,\n",
              " 2.641999304294586,\n",
              " 2.6627193093299866,\n",
              " 2.598515570163727,\n",
              " 2.586674392223358,\n",
              " 2.589371919631958,\n",
              " 2.5499038100242615,\n",
              " 2.550150215625763,\n",
              " 2.5022330284118652,\n",
              " 2.546723484992981,\n",
              " 2.470931589603424,\n",
              " 2.4865193367004395,\n",
              " 2.4815226197242737,\n",
              " 2.4708423018455505,\n",
              " 2.4311347603797913,\n",
              " 2.4619237780570984,\n",
              " 2.4723049998283386,\n",
              " 2.5206127166748047,\n",
              " 2.4482502341270447,\n",
              " 2.5012495517730713,\n",
              " 2.438787877559662,\n",
              " 2.476175904273987,\n",
              " 2.499973714351654,\n",
              " 2.428928315639496,\n",
              " 2.39902001619339,\n",
              " 2.401601493358612,\n",
              " 2.4271559715270996,\n",
              " 2.3896586894989014,\n",
              " 2.4287938475608826,\n",
              " 2.407189667224884,\n",
              " 2.425712466239929,\n",
              " 2.367249220609665,\n",
              " 2.4067569971084595,\n",
              " 2.474008321762085,\n",
              " 2.4383274912834167,\n",
              " 2.378800690174103,\n",
              " 2.3716124296188354,\n",
              " 2.431747615337372,\n",
              " 2.382952868938446,\n",
              " 2.3880637288093567,\n",
              " 2.403043210506439,\n",
              " 2.3947774469852448,\n",
              " 2.3904668986797333,\n",
              " 2.366836667060852,\n",
              " 2.339016079902649,\n",
              " 2.3713100254535675,\n",
              " 2.3926598131656647,\n",
              " 2.337017238140106,\n",
              " 2.3225587010383606,\n",
              " 2.414156675338745,\n",
              " 2.3198667466640472,\n",
              " 2.3662750720977783,\n",
              " 2.3859461545944214,\n",
              " 2.4154433012008667,\n",
              " 2.37337189912796,\n",
              " 2.3181724846363068,\n",
              " 2.3577898740768433,\n",
              " 2.3514310717582703,\n",
              " 2.3291302621364594,\n",
              " 2.2883197963237762,\n",
              " 2.3461084961891174,\n",
              " 2.4087377190589905,\n",
              " 2.351194202899933,\n",
              " 2.44688218832016,\n",
              " 2.3129931688308716,\n",
              " 2.3929484486579895,\n",
              " 2.3484849333763123,\n",
              " 2.325200617313385,\n",
              " 2.366665542125702,\n",
              " 2.349617600440979,\n",
              " 2.3452268838882446,\n",
              " 2.32172292470932,\n",
              " 2.339284598827362,\n",
              " 2.315911591053009,\n",
              " 2.3816489577293396,\n",
              " 2.3305786848068237,\n",
              " 2.3312339782714844,\n",
              " 2.33054381608963,\n",
              " 2.3962687849998474,\n",
              " 2.343683958053589,\n",
              " 2.342992901802063,\n",
              " 2.4082601070404053,\n",
              " 2.3209816217422485,\n",
              " 2.3451929092407227,\n",
              " 2.3765448927879333,\n",
              " 2.3463926911354065,\n",
              " 2.313089609146118,\n",
              " 2.302646040916443,\n",
              " 2.324353814125061,\n",
              " 2.289536952972412,\n",
              " 2.3732407093048096,\n",
              " 2.326465427875519,\n",
              " 2.3626835346221924,\n",
              " 2.3018930554389954,\n",
              " 2.3680720925331116,\n",
              " 2.3447203040122986,\n",
              " 2.3245171904563904,\n",
              " 2.3160191774368286,\n",
              " 2.4084393978118896,\n",
              " 2.338510036468506,\n",
              " 2.335497200489044,\n",
              " 2.3007377982139587,\n",
              " 2.3017712235450745,\n",
              " 2.286989986896515,\n",
              " 2.2976510524749756,\n",
              " 2.3865349888801575,\n",
              " 2.3594220876693726,\n",
              " 2.3208991289138794,\n",
              " 2.298024356365204,\n",
              " 2.3456278443336487,\n",
              " 2.2795617878437042,\n",
              " 2.337615728378296,\n",
              " 2.3816375732421875,\n",
              " 2.348113238811493,\n",
              " 2.288543403148651,\n",
              " 2.3358824849128723,\n",
              " 2.31259286403656,\n",
              " 2.33059960603714,\n",
              " 2.301657021045685,\n",
              " 2.3764114379882812,\n",
              " 2.3281449675559998,\n",
              " 2.2671525478363037,\n",
              " 2.3866252303123474,\n",
              " 2.3504136204719543,\n",
              " 2.306920051574707,\n",
              " 2.340110421180725,\n",
              " 2.286691904067993,\n",
              " 2.313099205493927,\n",
              " 2.2478854656219482,\n",
              " 2.3204468488693237,\n",
              " 2.283292770385742,\n",
              " 2.290513038635254,\n",
              " 2.3118832111358643,\n",
              " 2.3877797722816467,\n",
              " 2.341632902622223,\n",
              " 2.268744468688965,\n",
              " 2.2853740453720093,\n",
              " 2.357933759689331,\n",
              " 2.318321704864502,\n",
              " 2.2713761925697327,\n",
              " 2.326897144317627,\n",
              " 2.2961533069610596,\n",
              " 2.3733688592910767,\n",
              " 2.274577021598816,\n",
              " 2.3379286527633667,\n",
              " 2.4037261605262756,\n",
              " 2.2856022119522095,\n",
              " 2.37222957611084,\n",
              " 2.280787169933319,\n",
              " 2.3419845700263977,\n",
              " 2.313492715358734,\n",
              " 2.26017826795578,\n",
              " 2.327833116054535,\n",
              " 2.394084870815277,\n",
              " 2.297284424304962,\n",
              " 2.5040106773376465,\n",
              " 2.4261662364006042,\n",
              " 2.316773533821106,\n",
              " 2.3379857540130615,\n",
              " 2.33653861284256,\n",
              " 2.3946377635002136,\n",
              " 2.2974042892456055,\n",
              " 2.3210256099700928,\n",
              " 2.2998769879341125,\n",
              " 2.346457362174988,\n",
              " 2.3039401173591614,\n",
              " 2.2747000455856323,\n",
              " 2.2751948833465576,\n",
              " 2.314435601234436,\n",
              " 2.416349172592163,\n",
              " 2.3206154704093933,\n",
              " 2.295619547367096,\n",
              " 2.3240737915039062,\n",
              " 2.3003023862838745,\n",
              " 2.3387590050697327,\n",
              " 2.449739456176758,\n",
              " 2.3360602259635925,\n",
              " 2.3666788935661316,\n",
              " 2.45980703830719,\n",
              " 2.2999809980392456,\n",
              " 2.281771421432495,\n",
              " 2.3001866340637207,\n",
              " 2.35091096162796,\n",
              " 2.366911768913269,\n",
              " 2.404815196990967,\n",
              " 2.3242797255516052,\n",
              " 2.360951840877533,\n",
              " 2.3398174047470093,\n",
              " 2.327134430408478,\n",
              " 2.344256639480591,\n",
              " 2.38004606962204,\n",
              " 2.317617177963257,\n",
              " 2.3290833234786987,\n",
              " 2.320237934589386,\n",
              " 2.396082878112793,\n",
              " 2.373636841773987,\n",
              " 2.4681538343429565,\n",
              " 2.352430522441864,\n",
              " 2.2797000408172607,\n",
              " 2.3495360612869263,\n",
              " 2.335849404335022,\n",
              " 2.455147922039032,\n",
              " 2.3025861978530884,\n",
              " 2.400694191455841,\n",
              " 2.272337794303894,\n",
              " 2.3458123803138733,\n",
              " 2.3388818502426147,\n",
              " 2.3849631547927856,\n",
              " 2.3565585613250732,\n",
              " 2.344134747982025,\n",
              " 2.357060194015503,\n",
              " 2.3473910689353943,\n",
              " 2.328591227531433,\n",
              " 2.3723729252815247,\n",
              " 2.302870452404022,\n",
              " 2.3663344979286194,\n",
              " 2.3595134019851685,\n",
              " 2.3819446563720703,\n",
              " 2.3543481826782227,\n",
              " 2.320311665534973,\n",
              " 2.4085920453071594,\n",
              " 2.446378529071808,\n",
              " 2.345784068107605,\n",
              " 2.3375921845436096,\n",
              " 2.4636601209640503,\n",
              " 2.397118330001831,\n",
              " 2.3071393370628357,\n",
              " 2.462797224521637,\n",
              " 2.4015554189682007,\n",
              " 2.3323833346366882,\n",
              " 2.3494877219200134,\n",
              " 2.3606698513031006,\n",
              " 2.3208272457122803,\n",
              " 2.3197311758995056,\n",
              " 2.3670142889022827,\n",
              " 2.376307189464569,\n",
              " 2.3495686650276184,\n",
              " 2.3311516642570496,\n",
              " 2.341570258140564,\n",
              " 2.3661922812461853,\n",
              " 2.389821767807007,\n",
              " 2.3561230301856995,\n",
              " 2.3772364258766174,\n",
              " 2.332319140434265,\n",
              " 2.433696687221527,\n",
              " 2.40996390581131,\n",
              " 2.3322543501853943,\n",
              " 2.3503357768058777,\n",
              " 2.3580284118652344,\n",
              " 2.373903274536133,\n",
              " 2.3614964485168457,\n",
              " 2.3587526082992554,\n",
              " 2.3668093085289,\n",
              " 2.4152145385742188,\n",
              " 2.3422442078590393,\n",
              " 2.3931920528411865,\n",
              " 2.3611412048339844,\n",
              " 2.335996091365814,\n",
              " 2.3879089951515198,\n",
              " 2.3464455008506775,\n",
              " 2.4499548077583313,\n",
              " 2.3917065858840942,\n",
              " 2.342144012451172,\n",
              " 2.3521865010261536,\n",
              " 2.3953344225883484,\n",
              " 2.468790829181671,\n",
              " 2.3654898405075073,\n",
              " 2.421181559562683,\n",
              " 2.348731517791748,\n",
              " 2.4024670720100403,\n",
              " 2.3561187982559204,\n",
              " 2.4088265895843506,\n",
              " 2.4079246520996094,\n",
              " 2.372347116470337,\n",
              " 2.3483017683029175,\n",
              " 2.4422433376312256,\n",
              " 2.3744280338287354,\n",
              " 2.364927649497986,\n",
              " 2.355289876461029,\n",
              " 2.3890820145606995,\n",
              " 2.4148269295692444,\n",
              " 2.4337897300720215,\n",
              " 2.5082463026046753,\n",
              " 2.4086532592773438,\n",
              " 2.4565210342407227,\n",
              " 2.395851254463196,\n",
              " 2.3807852268218994,\n",
              " 2.3378766775131226,\n",
              " 2.4111300706863403,\n",
              " 2.3905161023139954,\n",
              " 2.403423845767975,\n",
              " 2.356898069381714,\n",
              " 2.3767606019973755,\n",
              " 2.3741825222969055,\n",
              " 2.385734796524048,\n",
              " 2.3999027609825134,\n",
              " 2.4013975262641907,\n",
              " 2.3933948278427124,\n",
              " 2.4434885382652283,\n",
              " 2.4207632541656494,\n",
              " 2.491899073123932,\n",
              " 2.4211339354515076,\n",
              " 2.411509335041046,\n",
              " 2.387798488140106,\n",
              " 2.438810646533966,\n",
              " 2.386901617050171,\n",
              " 2.4125843048095703,\n",
              " 2.488942325115204,\n",
              " 2.430505692958832,\n",
              " 2.4218260049819946,\n",
              " 2.4239442348480225,\n",
              " 2.4188932180404663,\n",
              " 2.4528788924217224,\n",
              " 2.4318817257881165,\n",
              " 2.4240902066230774,\n",
              " 2.4444104433059692,\n",
              " 2.4630398750305176,\n",
              " 2.376392662525177,\n",
              " 2.441835582256317,\n",
              " 2.4668796062469482,\n",
              " 2.4057453870773315,\n",
              " 2.4164392948150635,\n",
              " 2.4544397592544556,\n",
              " 2.431396007537842,\n",
              " 2.465759813785553,\n",
              " 2.4727031588554382,\n",
              " 2.45080828666687,\n",
              " 2.4499788880348206,\n",
              " 2.4334221482276917,\n",
              " 2.4077227115631104,\n",
              " 2.4135313034057617,\n",
              " 2.4832515120506287,\n",
              " 2.4367936849594116,\n",
              " 2.407797634601593,\n",
              " 2.45620596408844,\n",
              " 2.464183747768402,\n",
              " 2.4583117961883545,\n",
              " 2.4593639373779297,\n",
              " 2.4546937942504883,\n",
              " 2.436847746372223,\n",
              " 2.4853490591049194,\n",
              " 2.436188280582428,\n",
              " 2.5233455300331116,\n",
              " 2.4216480255126953,\n",
              " 2.4271148443222046,\n",
              " 2.439536154270172,\n",
              " 2.493355929851532,\n",
              " 2.417436361312866,\n",
              " 2.47612065076828,\n",
              " 2.4745948910713196,\n",
              " 2.429736018180847,\n",
              " 2.440407872200012,\n",
              " 2.419829845428467,\n",
              " 2.435476541519165,\n",
              " 2.4803298711776733,\n",
              " 2.410585105419159,\n",
              " 2.448464334011078,\n",
              " 2.5035095810890198,\n",
              " 2.4907215237617493,\n",
              " 2.482033371925354,\n",
              " 2.4182980060577393,\n",
              " 2.473246157169342,\n",
              " 2.4476475715637207,\n",
              " 2.4551035165786743,\n",
              " 2.46273273229599,\n",
              " 2.4550400376319885,\n",
              " 2.4802369475364685,\n",
              " 2.478222668170929,\n",
              " 2.4573665261268616,\n",
              " 2.4496338963508606,\n",
              " 2.4817376732826233,\n",
              " 2.558397591114044,\n",
              " 2.5098875164985657,\n",
              " 2.461748242378235,\n",
              " 2.485968768596649,\n",
              " 2.5064042806625366,\n",
              " 2.4338716864585876,\n",
              " 2.473858952522278,\n",
              " 2.454137086868286,\n",
              " 2.500549852848053,\n",
              " 2.4815977215766907,\n",
              " 2.476562261581421,\n",
              " 2.444550096988678,\n",
              " 2.5521878004074097,\n",
              " 2.476051092147827,\n",
              " 2.4329848289489746,\n",
              " 2.463919997215271,\n",
              " 2.5223438143730164,\n",
              " 2.522704541683197,\n",
              " 2.454434096813202,\n",
              " 2.5014439821243286,\n",
              " 2.455344796180725,\n",
              " 2.4969674944877625,\n",
              " 2.4822646379470825,\n",
              " 2.505880355834961,\n",
              " 2.4883418679237366,\n",
              " 2.46576064825058,\n",
              " 2.4608429074287415,\n",
              " 2.483643352985382,\n",
              " 2.465174376964569,\n",
              " 2.5030064582824707,\n",
              " 2.4773300886154175,\n",
              " 2.455533504486084,\n",
              " 2.5073710083961487,\n",
              " 2.5071060061454773,\n",
              " 2.5035189986228943,\n",
              " 2.4638918042182922,\n",
              " 2.486216127872467,\n",
              " 2.550220012664795,\n",
              " 2.533084213733673,\n",
              " 2.501745045185089,\n",
              " 2.553088426589966,\n",
              " 2.493733048439026,\n",
              " 2.459625780582428,\n",
              " 2.4904285073280334,\n",
              " 2.453775405883789,\n",
              " 2.4859859943389893,\n",
              " 2.4971688389778137,\n",
              " 2.4676085710525513,\n",
              " 2.519181787967682,\n",
              " 2.4957520961761475,\n",
              " 2.5270662903785706,\n",
              " 2.508932113647461,\n",
              " 2.462709426879883,\n",
              " 2.4600982069969177,\n",
              " 2.445975422859192,\n",
              " 2.470754086971283,\n",
              " 2.467466413974762,\n",
              " 2.5188337564468384,\n",
              " 2.513802170753479,\n",
              " 2.4906861782073975,\n",
              " 2.459295392036438,\n",
              " 2.5454999208450317,\n",
              " 2.480777084827423,\n",
              " 2.4661123752593994,\n",
              " 2.4904171228408813,\n",
              " 2.48945814371109,\n",
              " 2.474949538707733,\n",
              " 2.521586239337921,\n",
              " 2.469554305076599,\n",
              " 2.493976593017578,\n",
              " 2.499532163143158,\n",
              " 2.537824511528015,\n",
              " 2.593529462814331,\n",
              " 2.514756679534912,\n",
              " 2.5027082562446594,\n",
              " 2.495195209980011,\n",
              " 2.506069302558899,\n",
              " 2.5137452483177185,\n",
              " 2.5438151955604553,\n",
              " 2.503102481365204,\n",
              " 2.544149875640869,\n",
              " 2.501973569393158,\n",
              " 2.5360676050186157,\n",
              " 2.5270923376083374,\n",
              " 2.4961217045783997,\n",
              " 2.5257261991500854,\n",
              " 2.5121784806251526,\n",
              " 2.5669723749160767,\n",
              " 2.5237268805503845,\n",
              " 2.5708879828453064,\n",
              " 2.522782862186432,\n",
              " 2.4752175211906433,\n",
              " 2.4881219267845154,\n",
              " 2.5300827622413635,\n",
              " 2.5294047594070435,\n",
              " 2.5352576971054077,\n",
              " 2.505834400653839,\n",
              " 2.5254839062690735,\n",
              " 2.5801771879196167,\n",
              " 2.5310139656066895,\n",
              " 2.5209186673164368,\n",
              " 2.536246180534363,\n",
              " 2.556171417236328,\n",
              " 2.6139174699783325,\n",
              " 2.553598642349243,\n",
              " 2.6171730160713196,\n",
              " 2.5457390546798706,\n",
              " 2.5393869876861572,\n",
              " 2.5150837898254395,\n",
              " 2.5688841342926025,\n",
              " 2.549976408481598]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bZ_CjphBHXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "88c11df5-0c04-4de4-9752-1e567d8688b0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc5X3v8c9vZjTad8uysS3LgG22gAHhQEOCIYGAQ0KbpCR0owmpm+1e8kqbhds2oWl6X+mSpVkulBAKScPSlhDIBhhDMAkQsMGA8b7vlmRZ1mYtM/O7f5wjeSSNZCF7NEb+vl+veemc55w55zmyPN95nucs5u6IiIgMFcl1BURE5MSkgBARkYwUECIikpECQkREMlJAiIhIRgoIERHJKGsBYWazzOwpM1tjZq+b2c1heZWZLTWzjeHPyhHef2O4zkYzuzFb9RQRkcwsW9dBmNl0YLq7v2RmpcBK4PeBPwda3P1rZvZFoNLdvzDkvVXACqAB8PC9F7r7waxUVkREhslaC8Ld97r7S+F0O7AWmAFcB9wTrnYPQWgM9W5gqbu3hKGwFLg6W3UVEZHhYhOxEzOrB84HfgfUuvvecNE+oDbDW2YAO9Pmd4Vlo5oyZYrX19cfS1VFRE4qK1eubHb3mkzLsh4QZlYCPAh8xt3bzGxgmbu7mR1TH5eZLQGWANTV1bFixYpj2ZyIyEnFzLaPtCyrZzGZWR5BOPzY3X8SFu8Pxyf6xykaM7x1NzArbX5mWDaMu9/h7g3u3lBTkzEERURkHLJ5FpMBPwDWuvs30hY9AvSflXQj8HCGtz8GXGVmleFZTleFZSIiMkGy2YJ4G/CnwBVmtip8LQa+BlxpZhuBd4XzmFmDmd0J4O4twD8AL4avr4RlIiIyQbJ2mmsuNDQ0uMYgRETGzsxWuntDpmW6klpERDJSQIiISEYKCBERyUgBAXx72Uae3tCU62qIiJxQFBDAbb/ezG82KiBERNIpIIBYxEimcl0LEZETiwICiEaNZEoJISKSTgFB0IJIpCbP9SAiIseDAgKIRoykAkJEZBAFBBCLRNSCEBEZQgGBWhAiIpkoIAgCQi0IEZHBFBD0tyB0FpOISDoFBP3XQagFISKSTgGBxiBERDJRQKDrIEREMlFAoBaEiEgmCgjC6yCSCggRkXQKCNSCEBHJRAFB/3UQOs1VRCRdLFsbNrO7gGuBRnc/Jyx7AJgfrlIBtLr7ggzv3Qa0A0kgMdIDtY8XtSBERIbLWkAAdwPfBX7YX+DuH+qfNrOvA4dGef/l7t6ctdqliUWMpCsgRETSZS0g3H25mdVnWmZmBlwPXJGt/b8R0YhpkFpEZIhcjUG8Hdjv7htHWO7A42a20syWZLsysai6mEREhspmF9NobgDuG2X5pe6+28ymAkvNbJ27L8+0YhggSwDq6urGVZloJKKAEBEZYsJbEGYWA94PPDDSOu6+O/zZCDwELBxl3TvcvcHdG2pqasZVJ11JLSIyXC66mN4FrHP3XZkWmlmxmZX2TwNXAauzWSGdxSQiMlzWAsLM7gOeA+ab2S4zuylc9GGGdC+Z2Slm9stwthb4jZm9ArwA/MLdH81WPQGipusgRESGyuZZTDeMUP7nGcr2AIvD6S3AedmqVyZRDVKLiAyjK6nR8yBERDJRQKBHjoqIZKKAQC0IEZFMFBAE10GoBSEiMpgCArUgREQyUUBw5DoI1w37REQGKCAIWhCAWhEiImkUEEAkDAiNQ4iIHKGA4EgLIqUuJhGRAQoIgjEIUAtCRCSdAoK0MQg9NEhEZIACAohGg1+DWhAiIkcoINBZTCIimSggSB+D0C2/RUT6KSBQC0JEJBMFBDqLSUQkEwUERwIipYAQERmggCB45CioBSEikk4BwZFbbWgMQkTkCAUEutWGiEgmWQsIM7vLzBrNbHVa2a1mttvMVoWvxSO892ozW29mm8zsi9mqYz/drE9EZLhstiDuBq7OUP5Nd18Qvn45dKGZRYHvAdcAZwE3mNlZWaznkRaEAkJEZEDWAsLdlwMt43jrQmCTu29x917gfuC641q5ITRILSIyXC7GID5tZq+GXVCVGZbPAHamze8Ky7ImohaEiMgwEx0QtwGnAQuAvcDXj3WDZrbEzFaY2YqmpqZxbWPgSmoNUouIDJjQgHD3/e6edPcU8H2C7qShdgOz0uZnhmUjbfMOd29w94aamppx1UuD1CIiw01oQJjZ9LTZPwBWZ1jtRWCumc0xszjwYeCRbNZLg9QiIsPFsrVhM7sPWARMMbNdwJeBRWa2AHBgG/CX4bqnAHe6+2J3T5jZp4HHgChwl7u/nq16AkQ0SC0iMkzWAsLdb8hQ/IMR1t0DLE6b/yUw7BTYbNG9mEREhtOV1GiQWkQkEwUEuheTiEgmCgj0wCARkUwUEGiQWkQkEwUEGqQWEclEAYEGqUVEMlFAoEFqEZFMFBBokFpEJBMFBGpBiIhkMmJAmNl/pU3/05Blj2ezUhOt/3kQCggRkSNGa0HMTZu+csiy8d029QQV1SC1iMgwowXEaJ+Wk+qTdCAgkpPqsEREjsloN+srMrPzCUKkMJy28FU4EZWbKANdTGpBiIgMGC0g9gLfCKf3pU33z08akYhhpgvlRETSjRgQ7n75SMvMLC871cmdqJlutSEikmbMp7la4J1m9gNgVxbrlBPRiKmLSUQkzVEDwswuNrNvA9uBh4HlwBnZrthEi0ZMg9QiImlGuw7i/5rZRuAfgVeB84Emd7/H3Q9OVAUniloQIiKDjTZI/TFgA3Ab8DN37zGzSfsJGo2YBqlFRNKM1sU0Hfgq8F5gs5n9iOB016w9xzqXNEgtIjLYaGcxJYFHgUfNLB+4luD6h91mtszd/2iC6jghohEjpS4mEZEBYzqLyd173P1Bd/8gcDpBcIzKzO4ys0YzW51W9i9mts7MXjWzh8ysYoT3bjOz18xslZmtGOvBHItoxEhokFpEZMCILQgz++wxbvtu4LvAD9PKlgK3uHsivAHgLcAXRnj/5e7efIx1GDMNUouIDDZaC+JfgT8BqoESoDTtVXK0Dbv7cqBlSNnj7p4IZ58HZo6jzlmhQWoRkcFGG3A+H7gBeA+wErgPWOZ+3L5mfxR4YIRlDjwenjX17+5+x3Ha54g0SC0iMtiILQh3f8Xdv+juC4AfANcBa8zsfce6UzP7GyAB/HiEVS519wuAa4BPmdk7RtnWEjNbYWYrmpqaxl0nDVKLiAw2liupawhaE28huMVG47Hs0Mz+nOCMqD8eqTXi7rvDn43AQ8DCkbbn7ne4e4O7N9TUjP8xFRqkFhEZbLRB6o8C1wMFwP8A14cf2ONmZlcDnwcuc/euEdYpBiLu3h5OXwV85Vj2OxZqQYiIDDbaGMSdwGqCezC9G7jKwucmALj7qF1NZnYfsAiYYma7gC8TnLWUDywNt/W8u3/czE4B7nT3xUAt8FC4PAbc6+5HPa32WEUjpkeOioikGS0gRrzd91i4+w0Zin8wwrp7gMXh9BbgvGPZ93hENEgtIjLIaFdSPz2RFcm1mLqYREQGGfPzICa7iAapRUQGUUCE1IIQERlMARHSILWIyGBHvXW3mc0DPgfMTl/f3a/IYr0mnAJCRGSwsTzb4b+B24HvA8nsVid3oqab9YmIpBtLQCTc/bas1yTHIhEjmcp1LUREThxjGYP4mZl90symm1lV/yvrNZtgsYiRTCkhRET6jaUFcWP483NpZQ6cevyrkzsRjUGIiAxy1IBw9zkTUZFciykgREQGGctZTHnAJ4D+W27/muAZDX1ZrNeE0yC1iMhgY+liug3IA/5fOP+nYdnHslWpXIhEDA1BiIgcMZaAuMjd02+e96SZvZKtCuVKLGIklBAiIgPGchZT0sxO658xs1OZhNdD6DRXEZHBxtKC+BzwlJltAYzgiuqPZLVWOaDTXEVEBhvLWUzLzGwuMD8sWu/uPdmt1sSLmM5iEhFJN9ojR69w9yfN7P1DFp1uZrj7T7JctwkVPHI017UQETlxjNaCuAx4EnhvhmUOTKqA0CC1iMhgoz1R7svh5FfcfWv6MjObdBfP6TRXEZHBxnIW04MZyv7neFck19SCEBEZbLQxiDOAs4HyIeMQZUDBWDZuZncB1wKN7n5OWFYFPADUA9uA6939YIb33gj8bTj7VXe/Zyz7HK+IBWMQ7o6ZZXNXIiJvCqO1IOYTfLhXEIxD9L8uAP5ijNu/G7h6SNkXgWXuPhdYFs4PEobIl4G3AguBL5tZ5Rj3OS7RSBAKGqgWEQmMNgbxMPCwmV3i7s+NZ+PuvtzM6ocUXwcsCqfvIbi30xeGrPNuYKm7twCY2VKCoLlvPPUYi/6ASKRSRCPRbO1GRORNYywXyr1sZp8i6G4a6Fpy94+Oc5+17r43nN4H1GZYZwawM21+V1iWNQMtCA1DiIgAYxuk/hEwjeBb/dPATKD9eOzc3Z3glNlxM7MlZrbCzFY0NTWNezuxtBaEiIiMLSBOd/e/AzrDgeL3EIwNjNd+M5sOEP5szLDObmBW2vzMsGwYd7/D3RvcvaGmpmbclYqYWhAiIunGEhD9z31oNbNzgHJg6jHs8xGOPKXuRuDhDOs8BlxlZpXh4PRVYVnW9Hcx6ZkQIiKBsQTEHeGH9N8RfLivAf55LBs3s/uA54D5ZrbLzG4CvgZcaWYbgXeF85hZg5ndCRAOTv8D8GL4+kr/gHW2RNXFJCIyyFhu1ndnOPk0b/A51O5+wwiL3plh3RWkPYTI3e8C7noj+zsWGqQWERlstAvlPjvaG939G8e/OrmjLiYRkcFGa0GUhj/nAxcRdC9BcLHcC9msVC5Ew0HqZFIBISICo18o9/cAZrYcuMDd28P5W4FfTEjtJpBaECIig41lkLoW6E2b7yXzxW1vagMBoUEIERFgbFdS/xB4wcweCud/n+AeS5PKkYDIcUVERE4QYzmL6R/N7FfA28Oij7j7y9mt1sQ7EhDqYhIRgdHPYipz97bwzqrbwlf/sqpsX5cw0QYGqRUQIiLA6C2Iewlu972SwfdLsnD+DV0TcaLTILWIyGCjncV0bfhz0j1eNBMNUouIDDZaF9MFo73R3V86/tXJHQ1Si4gMNloX09dHWebAFce5LjmlQWoRkcFG62K6fCIrkmsKCBGRwcZyHQThbb7PYvAT5X6YrUrlQv/zIDRILSISOGpAmNmXCZ4hfRbwS+Aa4DcEF9BNGjENUouIDDKWW218kOD23Pvc/SPAeQQPDZpUNEgtIjLYWALisLungISZlRE8InTWUd7zpqMxCBGRwcYyBrHCzCqA7xNcNNdB8JS4SUUBISIy2GjXQXwPuNfdPxkW3W5mjwJl7v7qhNRuAmmQWkRksNFaEBuAfzWz6cB/AfdNxpv09dMgtYjIYCOOQbj7v7n7JcBlwAHgLjNbZ2ZfNrN5E1bDCdLfxZTQE+VERIAxDFK7+3Z3/yd3Px+4geB5EGvHu0Mzm29mq9JebWb2mSHrLDKzQ2nrfGm8+xureCz4VfQpIEREgLFdBxEjuPbhwwSnu/4auHW8O3T39cCCcNtRYDfwUIZVn+m/YeBEiEeDgOhNJCdqlyIiJ7TRBqmvJGgxLAZeAO4Hlrh753Hc/zuBze6+/Thuc1z6WxC9uhBCRAQYvYvpFuBZ4Ex3f5+733ucwwGCVsl9Iyy7xMxeMbNfmdnZx3m/wwwEREIBISICo9+sL6t3azWzOPA+giAa6iVgtrt3mNli4KfA3BG2swRYAlBXVzfu+sQihpkCQkSk31iupM6Wa4CX3H3/0AXu3ubuHeH0L4E8M5uSaSPufoe7N7h7Q01NzbgrY2bEoxF61MUkIgLkNiBuYITuJTObZhZcuWZmCwnqeSDbFYpHI2pBiIiExnS77+PNzIqBK4G/TCv7OIC7305wg8BPmFkCOAx82D37lzjHYwoIEZF+OQmIcLC7ekjZ7WnT3wW+O9H1UkCIiByRyy6mE048FtFpriIiIQVEGo1BiIgcoYBIoy4mEZEjFBBp1MUkInKEAiJNPBqhRy0IERFAATGIuphERI5QQKTJV0CIiAxQQKTRGISIyBEKiDR5Os1VRGSAAiJNPBqhTy0IERFAATGIBqlFRI5QQKRRQIiIHKGASBOP6XkQIiL9FBBpCvOi9CZSJFNZv7O4iMgJTwGRpjge3P38cF8yxzUREck9BUSaovwoAF09iRzXREQk9xQQafpbEJ29akGIiCgg0hTFgxZEp1oQIiIKiHTF+WELQgEhIqKASNffguhSF5OISO4Cwsy2mdlrZrbKzFZkWG5m9m0z22Rmr5rZBdmu00ALolctCBGRWI73f7m7N4+w7Bpgbvh6K3Bb+DNrBloQPWpBiIicyF1M1wE/9MDzQIWZTc/mDkvUghARGZDLgHDgcTNbaWZLMiyfAexMm98VlmVNUXiaq8YgRERy28V0qbvvNrOpwFIzW+fuy9/oRsJwWQJQV1d3TBWKxyLkRU1nMYmIkMMWhLvvDn82Ag8BC4esshuYlTY/Mywbup073L3B3RtqamqOuV5F8ZgCQkSEHAWEmRWbWWn/NHAVsHrIao8AfxaezXQxcMjd92a7bmWFMdq6FRAiIrnqYqoFHjKz/jrc6+6PmtnHAdz9duCXwGJgE9AFfGQiKlZZFKels3cidiUickLLSUC4+xbgvAzlt6dNO/CpiawXBAHR2qWAEBE5kU9zzYnKojxaFBAiIgqIoSqL47R29uW6GiIiOaeAGKKyKE57T0LPphaRk54CYojK4jgArYfVzSQiJzcFxBBVRUFA6EwmETnZKSCGqC3LB2Dvoe4c10REJLcUEEPUVRUBsLOlK8c1ERHJLQXEEDWl+eTHIuw4oIAQkZObAmIIM2NWVRE7DyogROTkpoDIoK6qiG3NCggRObkpIDKYV1vKluYOXQshIic1BUQGZ04vpS/pbGrsyHVVRERyRgGRwVnTywBYvftQjmsiIpI7CogMTq0pYVZVIQ+s2Hn0lUVEJikFRAbRiHHT2+awcvtBVm4/mOvqiIjkhAJiBH/YMIvywjy+v3xLrqsiIpITCogRFOfH+JOL63hszT62H+jMdXVERCacAmIUN15ST14kwp3PbM11VUREJpwCYhRTywr4wIUz+fHvtnPXb7bS3NGT6yqJiEwYBcRR/O17zmTBrAq+8vM1/MUPVxA8KltEZPKb8IAws1lm9pSZrTGz183s5gzrLDKzQ2a2Knx9aaLr2a84P8b9Sy7hj95ax8s7WvnYPSvoS+oKaxGZ/GI52GcC+Ct3f8nMSoGVZrbU3dcMWe8Zd782B/UbJh6LcOt7z6YgFuWu327l3d9czscvO43rL5qV66qJyEmmL5kiYkZfMkVBXjSr+5rwgHD3vcDecLrdzNYCM4ChAXFCiccifOm9Z1FWGONbT2zk8w++yt3PbuMd82q45pxpFORFmT+tdNB73B0zy1GNRU5Mx+P/xfp97bR193FRfdWwZX3JFKt2ttIwuxJ3SLqTFx1bZ4m78+zmA8ysLGRrcydvn1tDNDK4rolkiliG7fUmUuxo6eL0qSUD2zIzEskUt/7sdSoK4/z1u+fj7ry+p414LEJpQYxkyjmlvJCXdhzkibWNFMWj/MXbTyWRSrG/rZspJfncsXwL82pLmVVVxM33v8yug4eZUVHI1z7wFlZuP8j5dZVcevqUYXU9VpbLPnUzqweWA+e4e1ta+SLgQWAXsAf4a3d//Wjba2ho8BUrVmSlrunau/v4zpObeG7zAV5Lux3H5fNruGhOFWdNL+P+F3by6Ov7WDinilOnFGNm/MN1Zw/7w3p2UzPF+THOm1VxTHVKppyu3gSlBXnHtJ0T1crtLdz+9Ba+cf15Yz7GxvZuKovibNjfztmnlB91/fbuPl7e0co75tWQSjk7Wrqon1I85jp29CQozIuyevch5k8rZUdLF/NqS4/+xjFwd1q7+qgsjtPdl2Tl9oP83mnVwz5o+5KpgQ/Dw71JPvPAy1w6t4bF50yjuiR/xO23dfdx5/ItLDpjKhfUVZJMOY+/vo/O3iQfvHAmHT0JDvcmKciL8OquQ5xWU8L6/e0srK9id2sXL21vpbwoj7fMKGdqaT53P7uNRfOn0tzRQ9vhPmZVFdHY3sN3lm1kd+thfvyxt/LgS7soiseIRoz3nncKU0riPPDiTmZVFnH3s9uoLolzUX0VVcVxYhFj76Fu9rd1M6+2lM/+1yr6ks71DTPZ1NjBpXNr2NXShZmxbN1+Wrv6+MSi0/jVa3vZdqCLiqI8ZlcXUxZ+IC+cU8XhviSbGzuIxyJsa+4imXJKCmKDLo49v66C+upiUu68tusQu1oP05tIsXBOFR992xyaOnr40XPbONjVR3VxnHX72vlQwyw6ehOs2tFKIpWivDCPDfuD+7qdO7Oc1q4+dhzlgWQzKgo5dLiPjp7EmP4+ppTk8/wtV2QMrqMxs5Xu3pBxWa4CwsxKgKeBf3T3nwxZVgak3L3DzBYD/+buc0fYzhJgCUBdXd2F27dvz3LNj3B31u9v57Zfb+bhVXvIj0XoGeUOsA2zK2nvTtDY3k15YR5N7T109iYBePvcKWw/0MU7z5xKd1+S+upirj3vFJ5e38T8aSU88OJOrjijlmc3N9ObSHHLNWcSjRol+THu+s1WvvLzoAH2N4vP5PqLZtHRk+CU8gLMjNW7D1FWkEc0avzqtb3Mri5mzZ42rltwChEz6qqDp+htamynoihO1IzDfUmK4lG+9cRGbrp0DrPCJ+09s7GJquL4wAfutuZODnT2cuHsSiD4FrV2bxtTy/JZt7edRfNrhn2IPbf5AJXFeZwxrYzuviQFeVFSKWfbgU4OdvXx8o6DvOvM2oEP51d3tfKB256lL+n82SWz+eSi01m2bj8fvqhu4BuTu3PrI6+zoK6CPzh/Jk+ta+Qjd79IQV6E7r4UT/31IqaXF3DfCzsoLcjjqrNrKYnH+M2mZi6cXcmavW384e3PAfDQJ3+PJ9c18p0nN3HNOdP4ynXnsL+tm7bDfSyoqyAvGmFrcyc1Jfms399ONGI8v/kAX1+6gbOml7Fmb/BdJ2Jw90cWct7MCsoKY6za2UrEjHNnlvPclgPsbOki5fCtJzZw2bwabrnmTNbubaOsMI9fr29k7d52LpxdyXmzKvjWExv47aZm/uWD5/HL1/aybF0jAFecMZV4NEIi5Zw5vZS7frOVWxafydTSfP7lsfVsDG84WVOazycuO42V2w9SVRxn3rRSygvz2NrUyau7Wge2B8Fjdxvbe+j/aJhRUcjBrl4O9yWJmJFMjf6ZUVuWz/620c/4ixgM3Ux6WUVRHt19Sbr7Mv9/yosaNSX57DnKo4HzYxFiERv4fzalJE55YR6bmwZf21RTms+sykJe2tHKxadWMb+2lGc2NbMlXC8/FvyOK4viLJxTyVPrmjjcF2yzND/GWaeU8butLRl/B+fNLOeGhXXsaT3Myh0HKc3Pozg/RlNHDyX5UeZMKWZbcxenTS2hpjSfvkSK7z61iXm1Jbz/gpms2dPGuTPLSaScqBnvOrOWgniEAx29LFvXyIyKAk6pKOSMaWWj/i5GcsIFhJnlAT8HHnP3b4xh/W1Ag7s3j7beRLUgMkmE/YKbmzpYvrGZ6xacQmNbDy2dvZQUxHh+ywF+9Nx2uvuS9CZSlBXmsbv1MLOriyjJj/H6noEGFFXFcVo6e4+6TzMY7Z+vOB6lpCA28IdaUZRHa1ffoHWiEePac6fzys5Wto3yFL0/ubiOaWUF/OvjGwA4fWrJsLvdXji7cuDb15SSOM0dvRTmRZldXcTFp1aTSKWory7mq79YC8Clp0/hha0tXDi7kue2HMi433eeMXXQh1e6soIYhfEob59bw3mzKvi7n64G4D1vmc7TG5oGffu6bF4N6/a1DfrgmlKST3NHz0CIjNXRfu/p+j/0akrzaWrvGah3W/fYvhmOVTwaoXfIyRNzphTz7rOn8djr+9janPliTzMoK8hjenkB59dVcqCjh8fX7AfgLTPKeeucKhrbe4hGjKml+Tiwdm8ba/a0sWBWBb3JFOfOLOcdc2tIppwV2w+yfEMTc2tLaOtOMHdqCYvmT2XXwS4OHe4jHo3Q0tnLvrbu8LkrnVx19jRe2NpCY3s3xfEY+9q6+fy7z6CrL8G9v9vBW+dUM628gPxYhPopxbyys5V5taVUF8dp7uihuaOXdfvaOPuUcubVlvD8lhZOrSnm0dX7uHz+VMoKY3T2JkkkU8yuDr50NHf0EIsYRfEYLZ29xGMRKovywi9GR3re94QthrLCPArzohTkRTAzWjqDfRbHY8yfVkpBXpQ9rYeZXl5AW3eC8sKglduTSJIfy+44wbE6oQLCgq+T9wAt7v6ZEdaZBux3dzezhcD/ALP9KJXNZUC8Ef19k5sa25lZWUQsYmxp7mTOlGL6kimK4jE2NXbwyKrdzKkp5om1jexq6aKmtIBb33cWr+w8xH8+v515tSXc+8IOLj19CtctmMG9L+ygvDAPd6ivLqKlq5cdB7rYe6ibU2uKKciLUl9dRF40wuo9bZw5vZSO7gQPvrRr4AOyujhOZ2+CD1wwk1U7W6kqjhONGL9e3wQE35YuP2Mqj7yyBwhC57SakoFvpp09iYFWVHpgpCsvzCOZ8jE3n/vd/M65PLOxidnVxfzitb3DntcRjwZ9ugc6e6kujvOBC2dSXpjH8g1N/G5rC9PKCrhl8Rk8vmY/5YV5NLf3cLgvSUtnEGSfvXIeG/a3c+vP1nBqTTHJlLM9DM33nz+Dc2aUc+hwH00dPfxs1R7y86J8ctFpdPQkWLWzlZvfOZeHXt7NwjlVfO1X6/j05afz4rYWYtEIr+xsZdH8GqaXF7Bi+0EuObWaqWX5/HbTAd4yo5wtzZ0Y0FBfSUd3gpKCGJsbO6gqyeel7QepKMrj2nOns3RNI/XVRVw0p4rdBw+zYX875YV5LJo/lcfX7GNGRSHt3Qk6ehJceVbtQHdTbyLFf/x2Kw31lcyuLmbFtoPUTylidlUxhfHBH2DujjtERujPTiRT9IZ/p/Lmd6IFxKXAM8BrQP//8P8D1AG4++1m9mngEwRnPB0GPuvuzx5t23bBA1MAAAbQSURBVG+WgDiemtp7Bj7Ex8vd6UmkSKSckvxYxkHEw71Jdrd2cUpFIUXxGD2JJPsP9VBemEdpQYyWrl6mlOTj7iRTzhNrG7n8jBryY1F2tnTxyCt7qK8uZnZ1EWdOL2NHSxfr97WxaP5UfrupmYvmVNF2uA8zIxYeS8SMFdtaqKsuYl5t6aCBxkQyhZnh7mxt7mTD/g4Wza8ZOKsj/ffR3+01r7Z02Idhpt/Fhv0dzJ1aQiRitHX3seNAF+fMGD6GoZMQZDI4oQIim07GgBARORajBYSupBYRkYwUECIikpECQkREMlJAiIhIRgoIERHJSAEhIiIZKSBERCQjBYSIiGQ0qS6UM7MmYDx365sCjHqfp0lIx3xy0DGfHI7lmGe7e02mBZMqIMbLzFaMdCXhZKVjPjnomE8O2TpmdTGJiEhGCggREclIARG4I9cVyAEd88lBx3xyyMoxawxCREQyUgtCREQyOukDwsyuNrP1ZrbJzL6Y6/ocL2Z2l5k1mtnqtLIqM1tqZhvDn5VhuZnZt8PfwatmdkHuaj4+ZjbLzJ4yszVm9rqZ3RyWT9pjBjCzAjN7wcxeCY/778PyOWb2u/D4HjCzeFieH85vCpfX57L+42VmUTN72cx+Hs5P6uOF4NHLZvaama0ysxVhWVb/vk/qgDCzKPA94BrgLOAGMzsrt7U6bu4Grh5S9kVgmbvPBZaF8xAc/9zwtQS4bYLqeDwlgL9y97OAi4FPhf+Wk/mYAXqAK9z9PGABcLWZXQz8E/BNdz8dOAjcFK5/E3AwLP9muN6b0c3A2rT5yX68/S539wVpp7Rm9+87eP7syfkCLgEeS5u/Bbgl1/U6jsdXD6xOm18PTA+npwPrw+l/B27ItN6b9QU8DFx5kh1zEfAS8FaCi6ZiYfnA3znwGHBJOB0L17Nc1/0NHufM8MPwCuDngE3m40077m3AlCFlWf37PqlbEMAMYGfa/K6wbLKqdfe94fQ+oDacnlS/h7Ab4Xzgd5wExxx2t6wCGoGlwGag1d0T4SrpxzZw3OHyQ0D1xNb4mH0L+DxHnmlfzeQ+3n4OPG5mK81sSViW1b/v2HhrKm9u7u5mNulOYTOzEuBB4DPu3mZmA8sm6zG7exJYYGYVwEPAGTmuUtaY2bVAo7uvNLNFua7PBLvU3Xeb2VRgqZmtS1+Yjb/vk70FsRuYlTY/MyybrPab2XSA8GdjWD4pfg9mlkcQDj9295+ExZP6mNO5eyvwFEEXS4WZ9X8BTD+2geMOl5cDBya4qsfibcD7zGwbcD9BN9O/MXmPd4C77w5/NhJ8EVhIlv++T/aAeBGYG54BEQc+DDyS4zpl0yPAjeH0jQT99P3lfxae+XAxcCit2fqmYEFT4QfAWnf/RtqiSXvMAGZWE7YcMLNCgnGXtQRB8cFwtaHH3f/7+CDwpIed1G8G7n6Lu89093qC/69PuvsfM0mPt5+ZFZtZaf80cBWwmmz/fed64CXXL2AxsIGg3/Zvcl2f43hc9wF7gT6C/sebCPpelwEbgSeAqnBdIzibazPwGtCQ6/qP43gvJeijfRVYFb4WT+ZjDo/jXODl8LhXA18Ky08FXgA2Af8N5IflBeH8pnD5qbk+hmM49kXAz0+G4w2P75Xw9Xr/Z1W2/751JbWIiGR0sncxiYjICBQQIiKSkQJCREQyUkCIiEhGCggREclIASFyFGaWDO+g2f86bnf9NbN6S7vjrsiJRLfaEDm6w+6+INeVEJloakGIjFN4f/5/Du/R/4KZnR6W15vZk+F9+JeZWV1YXmtmD4XPbnjFzH4v3FTUzL4fPs/h8fCKaMzsf1vwfItXzez+HB2mnMQUECJHVziki+lDacsOuftbgO8S3GUU4DvAPe5+LvBj4Nth+beBpz14dsMFBFfEQnDP/u+5+9lAK/CBsPyLwPnhdj6erYMTGYmupBY5CjPrcPeSDOXbCB7WsyW8UeA+d682s2aCe+/3heV73X2KmTUBM929J20b9cBSDx74gpl9Achz96+a2aNAB/BT4Kfu3pHlQxUZRC0IkWPjI0y/ET1p00mOjA2+h+B+OhcAL6bdrVRkQiggRI7Nh9J+PhdOP0twp1GAPwaeCaeXAZ+AgYf8lI+0UTOLALPc/SngCwS3qR7WihHJJn0jETm6wvCJbf0edff+U10rzexVglbADWHZ/wL+w8w+BzQBHwnLbwbuMLObCFoKnyC4424mUeA/wxAx4NsePO9BZMJoDEJknMIxiAZ3b851XUSyQV1MIiKSkVoQIiKSkVoQIiKSkQJCREQyUkCIiEhGCggREclIASEiIhkpIEREJKP/D7RFx7G1Zeu4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see better the above plot, let's exclude some first points(20)\n",
        "truncated_mae_history = average_mae_history[20:]\n",
        "plt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "En_MfXGHI2Ho",
        "outputId": "e0377c39-9e0d-458d-c67e-0d1191fe9093"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see here, after 200 epochs, the model is getting worse. So, let's build a new one with let's say 130 epochs!"
      ],
      "metadata": {
        "id": "rurQ7ZqsKSuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this model\n",
        "results = model.evaluate(test_data, test_targets)  # returns test_mse_score, test_mae_score\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMYS5Jd-KjNP",
        "outputId": "6bc2d3cd-6ca1-4d6e-c72c-c39645f3c86d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 13.2295 - mae: 2.6657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13.229469299316406, 2.665729284286499]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can also see in evaluation results, mainly in loss(mse), the model is not good, so we need to improve it"
      ],
      "metadata": {
        "id": "dwemZFzPNxNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final model"
      ],
      "metadata": {
        "id": "MwvzSN4WLdT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build and train the final model by limiting the number of epochs to 130\n",
        "model = build_model()\n",
        "\n",
        "history = model.fit(train_data, train_targets,\n",
        "          epochs=130, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2xMaQWOK_RM",
        "outputId": "868f9374-fef9-4ab6-c71d-bd48c5070137"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/130\n",
            "26/26 [==============================] - 1s 15ms/step - loss: 500.4430 - mae: 20.4966\n",
            "Epoch 2/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 331.4435 - mae: 16.1362\n",
            "Epoch 3/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 164.1238 - mae: 10.5392\n",
            "Epoch 4/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 71.9786 - mae: 6.5565\n",
            "Epoch 5/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 42.2718 - mae: 4.8590\n",
            "Epoch 6/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 30.1333 - mae: 3.9416\n",
            "Epoch 7/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 24.7127 - mae: 3.5598\n",
            "Epoch 8/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 22.0184 - mae: 3.2906\n",
            "Epoch 9/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 19.8317 - mae: 3.1255\n",
            "Epoch 10/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 18.3760 - mae: 2.9708\n",
            "Epoch 11/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 17.0055 - mae: 2.8892\n",
            "Epoch 12/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 15.8852 - mae: 2.7870\n",
            "Epoch 13/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 14.7785 - mae: 2.7154\n",
            "Epoch 14/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 14.1970 - mae: 2.6339\n",
            "Epoch 15/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 13.4591 - mae: 2.5805\n",
            "Epoch 16/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 12.9967 - mae: 2.5202\n",
            "Epoch 17/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 12.5559 - mae: 2.5386\n",
            "Epoch 18/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 12.2157 - mae: 2.4897\n",
            "Epoch 19/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 11.8037 - mae: 2.4046\n",
            "Epoch 20/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 11.5056 - mae: 2.4365\n",
            "Epoch 21/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 11.3283 - mae: 2.3945\n",
            "Epoch 22/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 11.0365 - mae: 2.3734\n",
            "Epoch 23/130\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 10.8978 - mae: 2.3810\n",
            "Epoch 24/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.6275 - mae: 2.3363\n",
            "Epoch 25/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.3707 - mae: 2.2987\n",
            "Epoch 26/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.3321 - mae: 2.2970\n",
            "Epoch 27/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.1917 - mae: 2.2769\n",
            "Epoch 28/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 10.1765 - mae: 2.2875\n",
            "Epoch 29/130\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 9.8358 - mae: 2.2562\n",
            "Epoch 30/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.8566 - mae: 2.2505\n",
            "Epoch 31/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.6829 - mae: 2.2151\n",
            "Epoch 32/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.7240 - mae: 2.2307\n",
            "Epoch 33/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.4632 - mae: 2.1741\n",
            "Epoch 34/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.2662 - mae: 2.1556\n",
            "Epoch 35/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.3906 - mae: 2.1783\n",
            "Epoch 36/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.0437 - mae: 2.1635\n",
            "Epoch 37/130\n",
            "26/26 [==============================] - 1s 2ms/step - loss: 8.8997 - mae: 2.1186\n",
            "Epoch 38/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.0795 - mae: 2.1304\n",
            "Epoch 39/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.8937 - mae: 2.1294\n",
            "Epoch 40/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.8932 - mae: 2.1303\n",
            "Epoch 41/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.6719 - mae: 2.1022\n",
            "Epoch 42/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.5843 - mae: 2.0990\n",
            "Epoch 43/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.6562 - mae: 2.0530\n",
            "Epoch 44/130\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 8.5696 - mae: 2.0457\n",
            "Epoch 45/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.4731 - mae: 2.0537\n",
            "Epoch 46/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.2656 - mae: 2.0297\n",
            "Epoch 47/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.2215 - mae: 2.0375\n",
            "Epoch 48/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.1619 - mae: 2.0210\n",
            "Epoch 49/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.0477 - mae: 2.0294\n",
            "Epoch 50/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.0490 - mae: 2.0396\n",
            "Epoch 51/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.0720 - mae: 1.9947\n",
            "Epoch 52/130\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 8.1648 - mae: 2.0258\n",
            "Epoch 53/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.9789 - mae: 1.9717\n",
            "Epoch 54/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.9418 - mae: 1.9963\n",
            "Epoch 55/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.9270 - mae: 2.0047\n",
            "Epoch 56/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.4983 - mae: 1.9368\n",
            "Epoch 57/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.6734 - mae: 1.9861\n",
            "Epoch 58/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.6901 - mae: 1.9437\n",
            "Epoch 59/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.5169 - mae: 1.9393\n",
            "Epoch 60/130\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 7.4570 - mae: 1.9338\n",
            "Epoch 61/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.3999 - mae: 1.9008\n",
            "Epoch 62/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.4108 - mae: 1.8870\n",
            "Epoch 63/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.3650 - mae: 1.8884\n",
            "Epoch 64/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.1835 - mae: 1.8819\n",
            "Epoch 65/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.3725 - mae: 1.8800\n",
            "Epoch 66/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.2462 - mae: 1.8630\n",
            "Epoch 67/130\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 7.2570 - mae: 1.8787\n",
            "Epoch 68/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.9469 - mae: 1.8651\n",
            "Epoch 69/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.0836 - mae: 1.8530\n",
            "Epoch 70/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.9687 - mae: 1.8529\n",
            "Epoch 71/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.0044 - mae: 1.8608\n",
            "Epoch 72/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.7612 - mae: 1.8346\n",
            "Epoch 73/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.8125 - mae: 1.8377\n",
            "Epoch 74/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.7015 - mae: 1.8334\n",
            "Epoch 75/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.5853 - mae: 1.8303\n",
            "Epoch 76/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.7722 - mae: 1.8161\n",
            "Epoch 77/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.6981 - mae: 1.8070\n",
            "Epoch 78/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.5011 - mae: 1.7992\n",
            "Epoch 79/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.4414 - mae: 1.7767\n",
            "Epoch 80/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.4892 - mae: 1.8134\n",
            "Epoch 81/130\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 6.6434 - mae: 1.8189\n",
            "Epoch 82/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.2111 - mae: 1.7614\n",
            "Epoch 83/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.3834 - mae: 1.7895\n",
            "Epoch 84/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.3758 - mae: 1.7999\n",
            "Epoch 85/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.4213 - mae: 1.7508\n",
            "Epoch 86/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.2938 - mae: 1.7738\n",
            "Epoch 87/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.1476 - mae: 1.7099\n",
            "Epoch 88/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0460 - mae: 1.7475\n",
            "Epoch 89/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.1014 - mae: 1.7043\n",
            "Epoch 90/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.2002 - mae: 1.7444\n",
            "Epoch 91/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.9649 - mae: 1.7086\n",
            "Epoch 92/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0186 - mae: 1.7378\n",
            "Epoch 93/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.8689 - mae: 1.6887\n",
            "Epoch 94/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.9881 - mae: 1.7637\n",
            "Epoch 95/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.8767 - mae: 1.6935\n",
            "Epoch 96/130\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 5.7903 - mae: 1.7155\n",
            "Epoch 97/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.7851 - mae: 1.7072\n",
            "Epoch 98/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.6611 - mae: 1.6564\n",
            "Epoch 99/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.8495 - mae: 1.7039\n",
            "Epoch 100/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.5913 - mae: 1.6679\n",
            "Epoch 101/130\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 5.5878 - mae: 1.6611\n",
            "Epoch 102/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.8040 - mae: 1.6825\n",
            "Epoch 103/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4105 - mae: 1.6305\n",
            "Epoch 104/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.6009 - mae: 1.6735\n",
            "Epoch 105/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.5878 - mae: 1.6854\n",
            "Epoch 106/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4860 - mae: 1.6429\n",
            "Epoch 107/130\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 5.4955 - mae: 1.6487\n",
            "Epoch 108/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.5396 - mae: 1.6251\n",
            "Epoch 109/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.3101 - mae: 1.6208\n",
            "Epoch 110/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.2918 - mae: 1.6153\n",
            "Epoch 111/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1019 - mae: 1.5820\n",
            "Epoch 112/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.3769 - mae: 1.6450\n",
            "Epoch 113/130\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 5.1776 - mae: 1.6074\n",
            "Epoch 114/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.2286 - mae: 1.6362\n",
            "Epoch 115/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.1384 - mae: 1.5673\n",
            "Epoch 116/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1123 - mae: 1.5738\n",
            "Epoch 117/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.9933 - mae: 1.5708\n",
            "Epoch 118/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1271 - mae: 1.5934\n",
            "Epoch 119/130\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 4.9040 - mae: 1.5520\n",
            "Epoch 120/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.0916 - mae: 1.5887\n",
            "Epoch 121/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.8356 - mae: 1.5330\n",
            "Epoch 122/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6863 - mae: 1.5149\n",
            "Epoch 123/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.0108 - mae: 1.5736\n",
            "Epoch 124/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7582 - mae: 1.5494\n",
            "Epoch 125/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6271 - mae: 1.5138\n",
            "Epoch 126/130\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 4.8528 - mae: 1.5584\n",
            "Epoch 127/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6494 - mae: 1.5536\n",
            "Epoch 128/130\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.6085 - mae: 1.5268\n",
            "Epoch 129/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.5098 - mae: 1.5190\n",
            "Epoch 130/130\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6443 - mae: 1.5072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check some info of the final model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-OgOExKMA6_",
        "outputId": "41d4b2c2-3d98-40d5-d0ea-cb66697efd70"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 64)                896       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate this final model\n",
        "results = model.evaluate(test_data, test_targets)  # returns test_mse_score, test_mae_score\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNOFEm5Miox",
        "outputId": "117a1fdf-7a53-4f5f-9ab8-3ed1886d93a4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 145ms/step - loss: 15.5291 - mae: 2.6542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15.529105186462402, 2.6541850566864014]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mse and mae here are decreased from the previous ones"
      ],
      "metadata": {
        "id": "ce7ZTUCXP1gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model's predictions. understand the outputs\n",
        "predictions = model.predict(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfmGEsS9M2q7",
        "outputId": "28e3207a-23e9-4a02-a8c5-22cd2a880527"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV2ROPSCQOOX",
        "outputId": "5b298083-e3e0-426e-c53a-1cf59f582bf9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every prediction is a scalar\n",
        "predictions[10].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqZm6sAM2nZ",
        "outputId": "bac1a9d9-aff5-45ef-d142-4fcfaaa74016"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a prediction \n",
        "predictions[10] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMn_Xxq3NQt-",
        "outputId": "46b78537-9cc1-4914-81e0-3952a959624b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21.051819], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and check it manually with its initial test_target \n",
        "test_targets[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdRW6RJYNVc5",
        "outputId": "25399470-185e-4f7b-9a0e-02229d2cb141"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.6"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction[10] and test_target[10] are different, however their distance is small. That's what we are trying to do in all ml and dl problems: to minimize this distance!"
      ],
      "metadata": {
        "id": "KwnSuVa1QdtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, the universal workflow in machine learning(especially when working with NNs):"
      ],
      "metadata": {
        "id": "Chq4Do1_Zyxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the problem and collect the data\n",
        "2. Choose the metrics\n",
        "3. Prepare your data and split to train/val/test sets\n",
        "4. Build, train and evaluate the first model\n",
        "5. Improve the model via addressing overfitting and hyperparameter tuning"
      ],
      "metadata": {
        "id": "cAOOoylVadDf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ff_1urlNNi5u"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}